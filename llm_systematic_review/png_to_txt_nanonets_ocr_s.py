# -*- coding: utf-8 -*-
"""png_to_txt_nanonets-OCR-s.ipynb"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jYhCIpNxt3aL2ImzazUCKnHMMmfZD22p

Code for iteration through folders was generated with the assistance of Claude Sonnet 4

Model page: https://huggingface.co/nanonets/Nanonets-OCR-s
"""


from PIL import Image
from transformers import AutoTokenizer, AutoProcessor, AutoModelForImageTextToText

import os
import re
from pathlib import Path
from collections import defaultdict
import unicodedata


def ocr_page_with_nanonets_s(image_path, model, processor, max_new_tokens=4096):
    prompt = """Extract the text from the above document as if you were reading it naturally. Return the tables in html format. Return the equations in LaTeX representation. If there is an image in the document and image caption is not present, add a small description of the image inside the <img></img> tag; otherwise, add the image caption inside <img></img>. Watermarks should be wrapped in brackets. Ex: <watermark>OFFICIAL COPY</watermark>. Page numbers should be wrapped in brackets. Ex: <page_number>14</page_number> or <page_number>9/22</page_number>. Prefer using ☐ and ☑ for check boxes."""
    image = Image.open(image_path)
    messages = [
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": [
            {"type": "image", "image": f"file://{image_path}"},
            {"type": "text", "text": prompt},
        ]},
    ]
    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    inputs = processor(text=[text], images=[image], padding=True, return_tensors="pt")
    inputs = inputs.to(model.device)

    output_ids = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False)
    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, output_ids)]

    output_text = processor.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)
    return output_text[0]

def extract_page_number(filename):
    """Extract the page number from the filename (last digits after *)."""
    match = re.search(r'\*\d+-(\d+)$', filename.replace('.png', ''))
    return int(match.group(1)) if match else 0

def get_pdf_base_name(png_filename):
    """Extract the base name of the PDF from PNG filename."""
    # Remove the page number part (_0001-XX) and .png extension
    base_name = re.sub(r'_\d+-\d+\.png$', '', png_filename)
    return base_name

def process_folders(root_directory, ocr_function, model, processor, max_new_tokens=4096):
    """
    Process all folders containing PDFs and PNGs, performing OCR on PNG files.
    
    Args:
        root_directory (str): Path to the directory containing numbered folders
        ocr_function: The OCR function (ocr_page_with_nanonets_s)
        model: Model parameter for OCR function
        processor: Processor parameter for OCR function
        max_new_tokens (int): Maximum new tokens for OCR function
    """
    root_path = Path(root_directory)
    
    # Iterate through all subdirectories (numbered folders)
    for folder_path in sorted(root_path.iterdir()):
        if not folder_path.is_dir():
            continue
            
        print(f"Processing folder: {folder_path.name}")
        
        # Group PNG files by their PDF base name
        pdf_groups = defaultdict(list)
        
        # Scan for PNG files in the current folder
        for file_path in folder_path.iterdir():
            if file_path.suffix.lower() == '.png':
                pdf_base = get_pdf_base_name(file_path.name)
                pdf_groups[pdf_base].append(file_path)
        
        # Process each PDF group
        for pdf_base, png_files in pdf_groups.items():
            print(f"  Processing PDF: {pdf_base}")
            
            # Sort PNG files by page number
            png_files.sort(key=lambda x: extract_page_number(x.name))
            
            # Collect OCR results for all pages
            ocr_results = []
            
            for png_file in png_files:
                print(f"    Scanning page: {png_file.name}")
                try:
                    # Perform OCR on the current page
                    result = ocr_function(str(png_file), model, processor, max_new_tokens=max_new_tokens)
                    page_num = extract_page_number(png_file.name)
                    
                    # Add page separator and result
                    ocr_results.append(f"--- Page {page_num:02d} ---")
                    ocr_results.append(str(result))
                    ocr_results.append("")  # Empty line for readability
                    
                except Exception as e:
                    print(f"    Error processing {png_file.name}: {str(e)}")
                    ocr_results.append(f"--- Page {extract_page_number(png_file.name):02d} ---")
                    ocr_results.append(f"ERROR: {str(e)}")
                    ocr_results.append("")
            
            output_filename = f"{pdf_base}_ocr.txt"
            output_path = folder_path / output_filename
            
            # Save OCR results to text file

            with open(output_path, 'w', encoding='utf-8') as f:
                f.write("\n".join(ocr_results))
            
            print(f"  Saved OCR results to: {output_filename}")


def main():
    """
    Main function to run the OCR processing.
    Update the parameters below according to your setup.
    """
    model_path = "nanonets/Nanonets-OCR-s"
    
    root_directory = "data/test_conversion/PDF"
    
    model = AutoModelForImageTextToText.from_pretrained(
    model_path,
    torch_dtype="auto",
    device_map="auto"
    )
    
    processor = AutoProcessor.from_pretrained(model_path)

    process_folders(root_directory, ocr_page_with_nanonets_s, model, processor)
    print("OCR processing completed successfully!")\

if __name__ == "__main__":
    main()
