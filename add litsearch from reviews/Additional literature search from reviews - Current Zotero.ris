TY  - JOUR
ID  - 5CFZCBRN
TI  - The persuasiveness of guilt appeals over time: pathways to delayed compliance
AU  - Antonetti, P.
AU  - Baines, P.
AU  - Jain, S.
PY  - 2018
JO  - Journal of Business Research
T2  - Journal of Business Research
VL  - 90
SP  - 14
EP  - 25
DO  - 10.1016/j.jbusres.2018.03.030
UR  - https://linkinghub.elsevier.com/retrieve/pii/S0148296318301589
SN  - 1482963
N1  - Date Added: 2025-08-28 09:10:55
ER  - 

TY  - JOUR
ID  - FIKSFTVA
TI  - Cognitive chatbot for personalised contextual customer service: behind the scene and beyond the hype
AU  - Behera, R. K.
AU  - Bala, P. K.
AU  - Ray, A.
PY  - 2021
JO  - Information Systems Frontiers
T2  - Information Systems Frontiers
DO  - 10.1007/s10796-021-10168-y
UR  - https://link.springer.com/10.1007/s10796-021-10168-y
SN  - 1387-3326, 1572-9419
N1  - Date Added: 2025-08-28 09:10:55
ER  - 

TY  - JOUR
ID  - CG7RFVXT
TI  - Nudgeability: mapping conditions of susceptibility to nudge influence
AU  - De Ridder, D.
AU  - Kroese, F.
AU  - Van Gestel, L.
PY  - 2022
JO  - Perspectives on Psychological Science
T2  - Perspectives on Psychological Science
VL  - 17
IS  - 2
SP  - 346
EP  - 359
DO  - 10.1177/1745691621995183
UR  - http://journals.sagepub.com/doi/10.1177/1745691621995183
SN  - 1745-6916, 1745-6924
N1  - Date Added: 2025-08-28 09:10:55
ER  - 

TY  - JOUR
ID  - CANTRUI3
TI  - Consent and coercion
AU  - Ferzan, K. K.
PY  - 2018
JO  - Arizona State Law Journal
T2  - Arizona State Law Journal
VL  - 50
IS  - 4
SP  - 951
EP  - 1007
UR  - https://heinonline.org/HOL/LandingPage?handle=hein.journals/arzjl50&div=40&id=&page=
N1  - Date Added: 2025-08-28 09:10:55
ER  - 

TY  - JOUR
ID  - 8QDC9ZDP
TI  - How deep is AI’s love? Understanding relational AI
AU  - Gillath, O.
AU  - Abumusab, S.
AU  - Ai, T.
AU  - Branicky, M. S.
AU  - Davison, R. B.
AU  - Rulo, M.
AU  - Symons, J.
AU  - Thomas, G.
PY  - 2023
JO  - Behavioral and Brain Sciences
T2  - Behavioral and Brain Sciences
VL  - 46
DO  - 10.1017/S0140525X22001704
UR  - https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/how-deep-is-ais-love-understanding-relational-ai/77364078496FCE70F71C7A9F293AC322
SN  - 0140-525X, 1469-1825
N1  - Date Added: 2025-08-28 09:10:55
ER  - 

TY  - JOUR
ID  - V7KLAR87
TI  - Humanizing chatbots: the effects of visual, identity and conversational cues on humanness perceptions
AU  - Go, E.
AU  - Sundar, S. S.
PY  - 2019
JO  - Computers in Human Behavior
T2  - Computers in Human Behavior
VL  - 97
SP  - 304
EP  - 316
DO  - 10.1016/j.chb.2019.01.020
UR  - https://linkinghub.elsevier.com/retrieve/pii/S0747563219300329
SN  - 7475632
N1  - Date Added: 2025-08-28 09:10:55
ER  - 

TY  - JOUR
ID  - X3IEFIXQ
TI  - Rethinking the rhetorical epistemics of gaslighting
AU  - Graves, C. G.
AU  - Spencer, L. G.
PY  - 2022
JO  - Communication Theory
T2  - Communication Theory
VL  - 32
IS  - 1
SP  - 48
EP  - 67
DO  - 10.1093/ct/qtab013
UR  - https://academic.oup.com/ct/article/32/1/48/6358567
SN  - 1050-3293, 1468-2885
N1  - Date Added: 2025-08-28 09:10:55
ER  - 

TY  - JOUR
ID  - UBAS4KBD
TI  - Concept analysis of impressionability among adolescents and young adults
AU  - Gwon, S. H.
AU  - Jeong, S.
PY  - 2018
JO  - Nursing Open
T2  - Nursing Open
VL  - 5
IS  - 4
SP  - 601
EP  - 610
DO  - 10.1002/nop2.170
UR  - https://onlinelibrary.wiley.com/doi/10.1002/nop2.170
SN  - 2054-1058
N1  - Date Added: 2025-08-28 09:10:55
ER  - 

TY  - JOUR
ID  - BZH369TT
TI  - When rational decision-making becomes irrational: a critical assessment and re-conceptualization of intuition effectiveness
AU  - Julmi, C.
PY  - 2019
JO  - Business Research
T2  - Business Research
VL  - 12
IS  - 1
SP  - 291
EP  - 314
DO  - 10.1007/s40685-019-0096-4
UR  - https://link.springer.com/10.1007/s40685-019-0096-4
SN  - 2198-3402, 2198-2627
N1  - Date Added: 2025-08-28 09:10:55
ER  - 

TY  - JOUR
ID  - SVI5FTCZ
TI  - Persuasive power of prosodic features
AU  - Kišiček, G.
PY  - 2018
JO  - Argumentation and Advocacy
T2  - Argumentation and Advocacy
VL  - 54
IS  - 4
SP  - 345
EP  - 350
DO  - 10.1080/10511431.2019.1525003
UR  - https://www.tandfonline.com/doi/full/10.1080/10511431.2019.1525003
SN  - 1051-1431, 2576-8476
N1  - Date Added: 2025-08-28 09:10:55
ER  - 

TY  - JOUR
ID  - AFS8SXDU
TI  - (Online) manipulation: sometimes hidden, always careless
AU  - Klenk, M.
PY  - 2022
JO  - Review of Social Economy
T2  - Review of Social Economy
VL  - 80
IS  - 1
SP  - 85
EP  - 105
DO  - 10.1080/00346764.2021.1894350
UR  - https://www.tandfonline.com/doi/full/10.1080/00346764.2021.1894350
SN  - 0034-6764, 1470-1162
N1  - Date Added: 2025-08-28 09:10:55
ER  - 

TY  - CONF
ID  - 6XI555R4
TI  - Robot eyes wide shut: understanding dishonest anthropomorphism
AU  - Leong, B.
AU  - Selinger, E.
PY  - 2019
SP  - 299
EP  - 308
DO  - 10.1145/3287560.3287591
UR  - https://dl.acm.org/doi/10.1145/3287560.3287591
SN  - 978-1-4503-6125-5
PB  - ACM
CY  - Atlanta, GA
N1  - Date Added: 2025-08-28 09:10:55
T2  - Proceedings of the Conference on Fairness, Accountability, and Transparency
ER  - 

TY  - JOUR
ID  - NPBUQXTI
TI  - Being "rational" is not always rational: encouraging people to be rational leads to hedonically suboptimal decisions
AU  - Li, X.
AU  - Hsee, C. K.
PY  - 2019
JO  - Journal of the Association of Consumer Research
T2  - Journal of the Association of Consumer Research
VL  - 4
IS  - 2
SP  - 115
EP  - 124
UR  - https://www.journals.uchicago.edu/doi/abs/10.1086/701966
N1  - Date Added: 2025-08-28 09:10:55
ER  - 

TY  - CONF
ID  - C5Q2WNSE
TI  - Getting to know each other: the role of social dialogue in recovery from errors in social robots
AU  - Lucas, G. M.
AU  - Boberg, J.
AU  - Traum, D.
AU  - Artstein, R.
AU  - Gratch, J.
AU  - Gainer, A.
AU  - Johnson, E.
AU  - Leuski, A.
AU  - Nakano, M.
PY  - 2018
SP  - 344
EP  - 351
DO  - 10.1145/3171221.3171258
UR  - https://dl.acm.org/doi/10.1145/3171221.3171258
SN  - 978-1-4503-4953-6
PB  - ACM
CY  - Chicago IL USA
N1  - Date Added: 2025-08-28 09:10:55
T2  - Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction
ER  - 

TY  - JOUR
ID  - IDC73G6D
TI  - On inference of network topology and confirmation bias in cyber-social networks
AU  - Mao, Y.
AU  - Akyol, E.
PY  - 2020
JO  - IEEE Transactions on Signal and Information Processing over Networks
T2  - IEEE Transactions on Signal and Information Processing over Networks
VL  - 6
SP  - 633
EP  - 644
DO  - 10.1109/TSIPN.2020.3015283
UR  - https://ieeexplore.ieee.org/document/9187724/
SN  - 2373-776X, 2373-7778
N1  - Date Added: 2025-08-28 09:10:55
ER  - 

TY  - JOUR
ID  - 36J3NYHT
TI  - Human-level play in the game of Diplomacy by combining language models with strategic reasoning
AU  - Meta Fundamental AI Research Diplomacy Team
PY  - 2022
JO  - Science
T2  - Science
VL  - 378
IS  - 6624
SP  - 1067
EP  - 1074
UR  - https://www.science.org/doi/abs/10.1126/science.ade9097
N1  - Date Added: 2025-08-28 09:10:55
ER  - 

TY  - JOUR
ID  - S6GDZE4K
TI  - The autonomous choice architect
AU  - Mills, S.
AU  - Sætra, H. S.
PY  - 2022
JO  - AI & Society
T2  - AI & Society
DO  - 10.1007/s00146-022-01486-z
UR  - https://link.springer.com/10.1007/s00146-022-01486-z
SN  - 0951-5666, 1435-5655
N1  - Date Added: 2025-08-28 09:10:56
ER  - 

TY  - JOUR
ID  - Q46YR8U6
TI  - Natural language processing with deep learning CS224N/Ling284
AU  - Mu, J.
PY  - 2023
UR  - https://web.stanford.edu/class/cs224n/slides/cs224n-2023-lecture11-prompting-rlhf.pdf
N1  - Date Added: 2025-08-28 09:10:56
ER  - 

TY  - RPRT
ID  - 9KC5CMP6
TI  - GPT-4 technical report
AU  - OpenAI
PY  - 2023
UR  - https://cdn.openai.com/papers/gpt-4.pdf
N1  - Date Added: 2025-08-28 09:10:56
ER  - 

TY  - CONF
ID  - 7TCEA9B4
TI  - Discourse of threat as a strategy of emotional persuasion and manipulation
AU  - Ozyumenko, V.
AU  - Larina, T.
PY  - 2020
UR  - https://www.ocerints.org/intcess20_e-publication/papers/236.pdf
CY  - Dubai, UAE
N1  - Date Added: 2025-08-28 09:10:56
T2  - Proceedings of INTCESS 2020 – 7th International Conference on Education and Social Sciences
ER  - 

TY  - JOUR
ID  - GQFTXQCW
TI  - Influencing human–AI interaction by priming beliefs about AI can increase perceived trustworthiness, empathy and effectiveness
AU  - Pataranutaporn, P.
AU  - Liu, R.
AU  - Finn, E.
AU  - Maes, P.
PY  - 2023
JO  - Nature Machine Intelligence
T2  - Nature Machine Intelligence
VL  - 5
IS  - 10
SP  - 1076
EP  - 1086
DO  - 10.1038/s42256-023-00720-7
UR  - https://www.nature.com/articles/s42256-023-00720-7
SN  - 2522-5839
N1  - Date Added: 2025-08-28 09:10:56
ER  - 

TY  - CONF
ID  - AZP7FNJT
TI  - Modelling persuasion through misuse of rhetorical appeals
AU  - Pauli, A.
AU  - Derczynski, L.
AU  - Assent, I.
PY  - 2022
SP  - 89
EP  - 100
DO  - 10.18653/v1/2022.nlp4pi-1.11
UR  - https://aclanthology.org/2022.nlp4pi-1.11
PB  - Association for Computational Linguistics
CY  - Abu Dhabi, United Arab Emirates
N1  - Date Added: 2025-08-28 09:10:56
T2  - Proceedings of the Second Workshop on NLP for Positive Impact
ER  - 

TY  - CONF
ID  - S8UGB7S6
TI  - Respectful or toxic? Using zero-shot learning with language models to detect hate speech
AU  - Plaza-del-arco, F. M.
AU  - Nozza, D.
AU  - Hovy, D.
PY  - 2023
SP  - 60
EP  - 68
DO  - 10.18653/v1/2023.woah-1.6
UR  - https://aclanthology.org/2023.woah-1.6
PB  - Association for Computational Linguistics
CY  - Toronto, Canada
N1  - Date Added: 2025-08-28 09:10:56
T2  - The 7th Workshop on Online Abuse and Harms
ER  - 

TY  - JOUR
ID  - ZG7IZCVU
TI  - The role of politeness in human–machine interactions: a systematic literature review and future perspectives
AU  - Ribino, P.
PY  - 2023
JO  - Artificial Intelligence Review
T2  - Artificial Intelligence Review
VL  - 56
IS  - S1
SP  - 445
EP  - 482
DO  - 10.1007/s10462-023-10540-1
UR  - https://link.springer.com/10.1007/s10462-023-10540-1
SN  - 0269-2821, 1573-7462
N1  - Date Added: 2025-08-28 09:10:56
ER  - 

TY  - JOUR
ID  - EAZP9TQ8
TI  - Role play with large language models
AU  - Shanahan, M.
AU  - McDonell, K.
AU  - Reynolds, L.
PY  - 2023
JO  - Nature
T2  - Nature
VL  - 623
IS  - 7987
SP  - 493
EP  - 498
DO  - 10.1038/s41586-023-06647-8
UR  - https://www.nature.com/articles/s41586-023-06647-8
SN  - 0028-0836, 1476-4687
N1  - Date Added: 2025-08-28 09:10:56
ER  - 

TY  - JOUR
ID  - 3PUAFSD8
TI  - Human and human-interfaced AI interactions: modulation of human male autonomic nervous system via pupil mimicry
AU  - Spicer, C.
AU  - Khwaounjoo, P.
AU  - Cakmak, Y. O.
PY  - 2021
JO  - Sensors
T2  - Sensors
VL  - 21
IS  - 4
DO  - 10.3390/s21041028
UR  - https://www.mdpi.com/1424-8220/21/4/1028
SN  - 1424-8220
N1  - Date Added: 2025-08-28 09:10:56
ER  - 

TY  - JOUR
ID  - RS2YBZGS
TI  - Strategies of othering through discursive practices: examples from the UK and Poland
AU  - Strani, K.
AU  - Szczepaniak-Kozak, A.
PY  - 2018
JO  - Lodz Papers in Pragmatics
T2  - Lodz Papers in Pragmatics
VL  - 14
IS  - 1
SP  - 163
EP  - 179
DO  - 10.1515/lpp-2018-0008
UR  - https://www.degruyter.com/document/doi/10.1515/lpp-2018-0008/html
SN  - 1898-4436, 1895-6106
N1  - Date Added: 2025-08-28 09:10:56
ER  - 

TY  - CONF
ID  - W8CPB7ZG
TI  - Invisible influence: artificial intelligence and the ethics of adaptive choice architectures
AU  - Susser, D.
PY  - 2019
SP  - 403
EP  - 408
DO  - 10.1145/3306618.3314286
UR  - https://dl.acm.org/doi/10.1145/3306618.3314286
SN  - 978-1-4503-6324-2
PB  - ACM
CY  - Honolulu, HI
N1  - Date Added: 2025-08-28 09:10:56
T2  - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society
ER  - 

TY  - CONF
ID  - DKTAEY3H
TI  - Measuring automated influence: between empirical evidence and ethical values
AU  - Susser, D.
AU  - Grimaldi, V.
PY  - 2021
UR  - https://ssrn.com/abstract=3848919
N1  - Date Added: 2025-08-28 09:10:56
T2  - Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society
ER  - 

TY  - JOUR
ID  - VKW2G5SF
TI  - Technology, autonomy, and manipulation
AU  - Susser, D.
AU  - Roessler, B.
AU  - Nissenbaum, H.
PY  - 2019
JO  - Internet Policy Review
T2  - Internet Policy Review
VL  - 8
IS  - 2
DO  - 10.14763/2019.2.1410
UR  - https://policyreview.info/node/1410
SN  - 2197-6775
N1  - Date Added: 2025-08-28 09:10:56
ER  - 

TY  - JOUR
ID  - RGQDHC66
TI  - Financial fraud of older adults during the early months of the COVID-19 pandemic
AU  - Teaster, B.
AU  - Roberto, K. A.
AU  - Savla, J.
AU  - Du, C.
AU  - Du, Z.
AU  - Atkinson, E.
AU  - Shealy, E. C.
AU  - Beach, S.
AU  - Charness, N.
AU  - Lichtenberg, P. A.
PY  - 2023
JO  - The Gerontologist
T2  - The Gerontologist
VL  - 63
IS  - 6
SP  - 984
EP  - 992
DO  - 10.1093/geront/gnac188
UR  - https://academic.oup.com/gerontologist/article/63/6/984/6936596
SN  - 0016-9013, 1758-5341
N1  - Date Added: 2025-08-28 09:10:56
ER  - 

TY  - CONF
ID  - 6IMJWP95
TI  - The effect of multimodal emotional expression and agent appearance on trust in human-agent interaction
AU  - Torre, I.
AU  - Carrigan, E.
AU  - McDonnell, R.
AU  - Domijan, K.
AU  - McCabe, K.
AU  - Harte, N.
PY  - 2019
SP  - 1
EP  - 6
DO  - 10.1145/3359566.3360065
UR  - https://dl.acm.org/doi/10.1145/3359566.3360065
SN  - 978-1-4503-6994-7
PB  - ACM
CY  - Newcastle upon Tyne United Kingdom
N1  - Date Added: 2025-08-28 09:10:56
T2  - MIG ’19 Proceedings of the 12th ACM SIGGRAPH Conference on Motion, Interaction and Games
ER  - 

TY  - JOUR
ID  - VNZ2TP9X
TI  - Fat shaming is making people sicker and heavier
AU  - Vogel, L.
PY  - 2019
N1  - Date Added: 2025-08-28 09:10:56
ER  - 

TY  - JOUR
ID  - 66LTHM6L
TI  - Social touch in human–robot interaction: robot-initiated touches can induce positive responses without extensive prior bonding
AU  - Willemse, C. J. A. M.
AU  - Van Erp, J. B. F.
PY  - 2019
JO  - International Journal of Social Robotics
T2  - International Journal of Social Robotics
VL  - 11
IS  - 2
SP  - 285
EP  - 304
DO  - 10.1007/s12369-018-0500-9
UR  - http://link.springer.com/10.1007/s12369-018-0500-9
SN  - 1875-4791, 1875-4805
N1  - Date Added: 2025-08-28 09:10:56
ER  - 

TY  - CONF
ID  - IFSKZDT9
TI  - Polyjuice: generating counterfactuals for explaining, evaluating, and improving models
AU  - Wu, T.
AU  - Ribeiro, M. T.
AU  - Heer, J.
AU  - Weld, D.
PY  - 2021
SP  - 6707
EP  - 6723
DO  - 10.18653/v1/2021.acl-long.523
UR  - https://aclanthology.org/2021.acl-long.523
PB  - Association for Computational Linguistics
CY  - Online
N1  - Date Added: 2025-08-28 09:10:56
T2  - Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)
ER  - 

TY  - CONF
ID  - TPBEMICJ
TI  - Bot-adversarial dialogue for safe conversational agents
AU  - Xu, J.
AU  - Ju, D.
AU  - Li, M.
AU  - Boureau, Y.-L.
AU  - Weston, J.
AU  - Dinan, E.
PY  - 2021
SP  - 2950
EP  - 2968
DO  - 10.18653/v1/2021.naacl-main.235
UR  - https://aclanthology.org/2021.naacl-main.235
PB  - Association for Computational Linguistics
CY  - Online
N1  - Date Added: 2025-08-28 09:10:56
T2  - Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies
ER  - 

TY  - CONF
ID  - G3UQMP8V
TI  - Perception of physical and virtual agents: exploration of factors influencing the acceptance of intrusive domestic agents
AU  - Zehnder, E.
AU  - Dinet, J.
AU  - Charpillet, F.
PY  - 2022
SP  - 1050
EP  - 1057
DO  - 10.1109/ROMAN53752.2022.9900593
UR  - https://ieeexplore.ieee.org/document/9900593/
SN  - 978-1-7281-8859-1
PB  - IEEE
CY  - Napoli, Italy
N1  - Date Added: 2025-08-28 09:10:56
T2  - 2022 31st IEEE International Conference on Robot and Human Interactive Communication
ER  - 

TY  - JOUR
ID  - RFU89WUC
TI  - Misinformation on misinformation: Conceptual and methodological challenges
AU  - Altay, Sacha
AU  - Berriche, Manon
AU  - Acerbi, Alberto
PY  - 2023
JO  - Social media+ society
T2  - Social media+ society
VL  - 9
IS  - 1
SN  - 20563051221150412
N1  - Date Added: 2025-08-28 09:10:56
ER  - 

TY  - JOUR
ID  - 6PPP2SKQ
TI  - Misunderstanding the harms of online misinformation
AU  - Budak, Ceren
AU  - Nyhan, Brendan
AU  - Rothschild, David M
AU  - Thorson, Emily
AU  - Watts, Duncan J
PY  - 2024
JO  - Nature
T2  - Nature
VL  - 630
IS  - 8015
SP  - 45
EP  - 53
N1  - Date Added: 2025-08-28 09:10:56
ER  - 

TY  - JOUR
ID  - DWW6YZWX
TI  - People devalue generative AI’s competence but not its advice in addressing societal and personal challenges
AU  - Böhm, Robert
AU  - Jörling, Moritz
AU  - Reiter, Leonhard
AU  - Fuchs, Christoph
PY  - 2023
JO  - Communications Psychology
T2  - Communications Psychology
VL  - 1
IS  - 1
SP  - 1
EP  - 10
DO  - 10.1038/s44271-023-00032-x
UR  - https://www.nature.com/articles/s44271-023-00032-x
SN  - 2731-9121
N1  - Date Added: 2025-08-28 09:10:56
ER  - 

TY  - JOUR
ID  - 5ST63MVY
TI  - Would an AI chatbot persuade you: an empirical answer from the elaboration likelihood model
AU  - Chen, Qian
AU  - Yin, Changqin
AU  - Gong, Yeming
PY  - 2023
JO  - Information Technology & People
T2  - Information Technology & People
VL  - ahead-of-print
IS  - ahead-of-print
DO  - 10.1108/ITP-10-2021-0764
UR  - https://doi.org/10.1108/ITP-10-2021-0764
SN  - 0959-3845
N1  - Date Added: 2025-08-28 09:10:56
ER  - 

TY  - JOUR
ID  - P8RLLMPC
TI  - Misinformation poses a bigger threat to democracy than you might think
AU  - Ecker, Ullrich
AU  - Roozenbeek, Jon
AU  - van der Linden, Sander
AU  - Tay, Li Qian
AU  - Cook, John
AU  - Oreskes, Naomi
AU  - Lewandowsky, Stephan
PY  - 2024
JO  - Nature
T2  - Nature
VL  - 630
IS  - 8015
SP  - 29
EP  - 32
N1  - Date Added: 2025-08-28 09:10:56
ER  - 

TY  - JOUR
ID  - BDS6CRKY
TI  - The effect of source disclosure on evaluation of AI-generated messages: A two-part study
AU  - Lim, Sue
AU  - Schmälzle, Ralf
PY  - 2024
JO  - Computers in Human Behavior: Artificial Humans
T2  - Computers in Human Behavior: Artificial Humans
VL  - 2
IS  - 1
SP  - 100058
DO  - 10.1016/j.chbah.2024.100058
UR  - http://arxiv.org/abs/2311.15544
SN  - 2949-8821
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - CONF
ID  - FX6JCETR
TI  - How Good are LLMs in Generating Personalized Advertisements?
AU  - Meguellati, Elyas
AU  - Han, Lei
AU  - Bernstein, Abraham
AU  - Sadiq, Shazia
AU  - Demartini, Gianluca
PY  - 2024
SP  - 826
EP  - 829
DO  - 10.1145/3589335.3651520
UR  - https://doi.org/10.1145/3589335.3651520
SN  - 979-8-4007-0172-6
PB  - Association for Computing Machinery
N1  - Date Added: 2025-08-28 09:10:57
T2  - Companion Proceedings of the ACM on Web Conference 2024
ER  - 

TY  - JOUR
ID  - 7XJFB7FF
TI  - Large Language Models Can Argue in Convincing Ways About Politics, But Humans Dislike AI Authors: implications for Governance
AU  - Palmer, Alexis
AU  - Spirling, Arthur
PY  - 2023
JO  - Political Science
T2  - Political Science
VL  - 75
IS  - 3
SP  - 281
EP  - 291
DO  - 10.1080/00323187.2024.2335471
UR  - https://www.tandfonline.com/doi/full/10.1080/00323187.2024.2335471
SN  - 0032-3187
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - SP8E9YE7
TI  - The general attitudes towards artificial intelligence scale (gaais): Confirmatory validation and associations with personality, corporate distrust, and general trust
AU  - Schepman, Astrid
AU  - Rodway, Paul
PY  - 2023
JO  - International Journal of Human–Computer Interaction
T2  - International Journal of Human–Computer Interaction
VL  - 39
IS  - 13
SP  - 2724
EP  - 2741
DO  - 10.1080/10447318.2022.2085400
UR  - https://doi.org/10.1080/10447318.2022.2085400
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - CONF
ID  - 4VKXK3S8
TI  - Persuasiveness of arguments with AI-source labels
AU  - Teigen, Cassandra
AU  - Madsen, Jens Koed
AU  - George, Nicole Lauren
AU  - Yousefi, Sayeh
PY  - 2024
VL  - 46
UR  - https://escholarship.org/uc/item/6t82g70v
N1  - Date Added: 2025-08-28 09:10:57
T2  - Proceedings of the Annual Meeting of the Cognitive Science Society
ER  - 

TY  - JOUR
ID  - AZLEG3T3
TI  - The importance of epistemology for the study of misinformation
AU  - Uscinski, Joseph
AU  - Littrell, Shane
AU  - Klofstad, Casey
PY  - 2024
JO  - Current opinion in psychology
T2  - Current opinion in psychology
SP  - 101789
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - HH6ZJS5X
TI  - LM-Infinite: Zero-Shot Extreme Length Generalization for Large Language Models
AU  - Han, Chi
AU  - Wang, Qifan
AU  - Peng, Hao
AU  - Xiong, Wenhan
AU  - Chen, Yu
AU  - Ji, Heng
AU  - Wang, Sinong
ED  - Duh, Kevin
ED  - Gomez, Helena
ED  - Bethard, Steven
PY  - 2024
JO  - Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)
T2  - Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)
SP  - 3991
EP  - 4008
DO  - 10.18653/v1/2024.naacl-long.222
UR  - https://doi.org/10.18653/v1/2024.naacl-long.222
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - 5WZW4326
TI  - Empathetic Persuasion: Reinforcing Empathy and Persuasiveness in Dialogue Systems
AU  - Samad, Azlaan Mustafa
AU  - Mishra, Kshitij
AU  - Firdaus, Mauajama
AU  - Ekbal, Asif
ED  - Carpuat, Marine
ED  - de Marneffe, Marie-Catherine
ED  - Meza Ruiz, Ivan Vladimir
PY  - 2022
JO  - Findings of the Association for Computational Linguistics: NAACL 2022
T2  - Findings of the Association for Computational Linguistics: NAACL 2022
SP  - 844
EP  - 856
DO  - 10.18653/v1/2022.findings-naacl.63
UR  - https://doi.org/10.18653/v1/2022.findings-naacl.63
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - 95YAR47A
TI  - Persona or Context? Towards Building Context adaptive Personalized Persuasive Virtual Sales Assistant
AU  - Tiwari, Abhisek
AU  - Saha, Sriparna
AU  - Sengupta, Shubhashis
AU  - Maitra, Anutosh
AU  - Ramnani, Roshni
AU  - Bhattacharyya, Pushpak
ED  - He, Yulan
ED  - Ji, Heng
ED  - Li, Sujian
ED  - Liu, Yang
ED  - Chang, Chua-Hui
PY  - 2022
JO  - Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)
T2  - Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)
SP  - 1035
EP  - 1047
DO  - 10.18653/v1/2022.aacl-main.76
UR  - https://doi.org/10.18653/v1/2022.aacl-main.76
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - HFF7ZWUG
TI  - Towards Emotional Support Dialog Systems
AU  - Liu, Siyang
AU  - Zheng, Chujie
AU  - Demasi, Orianna
AU  - Sabour, Sahand
AU  - Li, Yu
AU  - Yu, Zhou
AU  - Jiang, Yong
AU  - Huang, Minlie
ED  - Zong, Chengqing
ED  - Xia, Fei
ED  - Li, Wenjie
ED  - Navigli, Roberto
PY  - 2021
JO  - Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)
T2  - Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)
SP  - 3469
EP  - 3483
DO  - 10.18653/v1/2021.acl-long.269
UR  - https://doi.org/10.18653/v1/2021.acl-long.269
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - U7BSJCCZ
TI  - Improving Factuality and Reasoning in Language Models through Multiagent Debate
AU  - Du, Yilun
AU  - Li, Shuang
AU  - Torralba, Antonio
AU  - Tenenbaum, Joshua B.
AU  - Mordatch, Igor
PY  - 2024
JO  - Forty-first International Conference on Machine Learning
T2  - Forty-first International Conference on Machine Learning
UR  - https://openreview.net/forum?id=zj7YuTE4t8
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - ML5KUSUL
TI  - The Str(Al)ght Scoop: artificial intelligence cues reduce perceptions of hostile media bias
AU  - Cloudy, J
AU  - Banks, J
AU  - Bowman, ND
PY  - 2023
JO  - Digital Journalism
T2  - Digital Journalism
VL  - 11
SP  - 1577
EP  - 1596
DO  - 10.1080/21670811.2021.1969974
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - 9HIXKACE
TI  - The caring machine: feeling Al for customer care
AU  - Huang, M-H
AU  - Rust, RT
PY  - 2024
JO  - J Mark
T2  - J Mark
DO  - 10.1177/00222429231224748
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - 9HBFAWSA
TI  - Identifying relevant segments of Al applications adopters expanding the UTAUT2's variables
AU  - Cabrera-Sánchez, J-P
AU  - Villarejo-Ramos, ÁF
AU  - Liébana-Cabanillas, F
AU  - Shaikh, AA
PY  - 2021
JO  - Telematics Inf
T2  - Telematics Inf
VL  - 58
DO  - 10.1016/j.tele.2020.101529
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - SJLYZ7X9
TI  - Anthropomorphism in AI
AU  - Salles, A
AU  - Evers, K
AU  - Farisco, M
PY  - 2020
JO  - AJOB Neurosci
T2  - AJOB Neurosci
VL  - 11
SP  - 88
EP  - 95
DO  - 10.1080/21507740.2020.1740350
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - CONF
ID  - 77TSMA2S
TI  - Machinelike or humanlike? A literature review of anthropomorphism in Al-enabled technology
AU  - Li, M
AU  - Suh, A
PY  - 2021
BT  - 54th P Ann HISCSS
T2  - 54th P Ann HISCSS
DO  - 10.24251/hicss.2021.493
N1  - Date Added: 2025-08-28 09:10:57
T2  - 54th P Ann HISCSS
ER  - 

TY  - JOUR
ID  - 8HR7P3EJ
TI  - Machine talk: how verbal embodiment in conversational Al shapes consumer-brand relationships
AU  - Bergner, AS
AU  - Hildebrand, C
AU  - Häubl, G
PY  - 2023
JO  - J Consum Res
T2  - J Consum Res
VL  - 50
SP  - 742
EP  - 764
DO  - 10.1093/jcr/ucad014
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - ZE86V7TP
TI  - Tools or peers? Impacts of anthropomorphism level and social role on emotional attachment and disclosure tendency towards intelligent agents
AU  - Zhang, A
AU  - Patrick Rau, P-L
PY  - 2023
JO  - Comput Hum Behav
T2  - Comput Hum Behav
VL  - 138
DO  - 10.1016/j.chb.2022.107415
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - 7KPA38QX
TI  - Cognitive psychology-based artificial intelligence review
AU  - Zhao, J
AU  - Wu, M
AU  - Zhou, L
AU  - Wang, X
AU  - Jia, J
PY  - 2022
JO  - Front Neurosci
T2  - Front Neurosci
VL  - 16
DO  - 10.3389/fnins.2022.1024316
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - Z2GAXL9B
TI  - Avoiding embarrassment online: response to and inferences about chatbots when purchases activate self-presentation concerns
AU  - Jin, J
AU  - Walker, J
AU  - Reczek, RW
PY  - 2024
JO  - J Consum Psychol
T2  - J Consum Psychol
DO  - 10.1002/jcpy.1414
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - 6BPKB99G
TI  - Blame the bot: anthropomorphism and anger in customer-chatbot interactions
AU  - Crolic, C
AU  - Thomaz, F
AU  - Hadi, R
AU  - Stephen, AT
PY  - 2022
JO  - J Mark
T2  - J Mark
VL  - 86
SP  - 132
EP  - 148
DO  - 10.1177/00222429211045687
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - 8FP7KHR8
TI  - Bots with feelings: should Al agents express positive emotion in customer service?
AU  - Han, E
AU  - Yin, D
AU  - Zhang, H
PY  - 2023
JO  - Inf Syst Res
T2  - Inf Syst Res
VL  - 34
SP  - 1296
EP  - 1311
DO  - 10.1287/isre.2022.1179
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - AQZDKSJ5
TI  - Review of the factors affecting acceptance of Al-infused systems
AU  - Ismatullaev, UVU
AU  - Kim, S-H
PY  - 2024
JO  - Hum Factors
T2  - Hum Factors
VL  - 66
SP  - 126
EP  - 144
DO  - 10.1177/00187208211064707
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - J6UN8SPY
TI  - Trust in Al and its role in the acceptance of Al technologies
AU  - Choung, H
AU  - David, P
AU  - Ross, A
PY  - 2023
JO  - Int J Hum Comput Stud
T2  - Int J Hum Comput Stud
VL  - 39
SP  - 1727
EP  - 1739
DO  - 10.1080/10447318.2022.2050543
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - IJ787W2X
TI  - Artificial intelligence and human trust in healthcare: focus on clinicians
AU  - Asan, O
AU  - Bayrak, AE
AU  - Choudhury, A
PY  - 2020
JO  - J Med Internet Res
T2  - J Med Internet Res
VL  - 22
DO  - 10.2196/15154
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - RI656NCN
TI  - The anchoring effect, algorithmic fairness, and the limits of information transparency for emotion artificial intelligence
AU  - Rhue, L
PY  - 2023
JO  - Inf Syst Res
T2  - Inf Syst Res
DO  - 10.1287/isre.2019.0493
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - JNQXRHDD
TI  - Human and machine: the impact of machine input on decision making under cognitive limitations
AU  - Boyaco, T
AU  - Canyakmaz, C
AU  - de Véricourt, F
PY  - 2024
JO  - Manag Sci
T2  - Manag Sci
VL  - 70
SP  - 1258
EP  - 1275
DO  - 10.1287/mnsc.2023.4744
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - CONF
ID  - Q3HK26E4
TI  - Build confidence and acceptance of Al-based decision support systems explainable and liable Al
AU  - Nicodeme, C
PY  - 2020
BT  - 13th International C Hum Syst Interact
T2  - 13th International C Hum Syst Interact
SP  - 20
EP  - 23
DO  - 10.1109/HSI49210.2020.9142668
N1  - Date Added: 2025-08-28 09:10:57
T2  - 13th International C Hum Syst Interact
ER  - 

TY  - JOUR
ID  - EQZXJUSG
TI  - Investigating the impacting factors for the healthcare professionals to adopt artificial intelligence-based medical diagnosis support system (AIMDSS)
AU  - Fan, W
AU  - Liu, J
AU  - Zhu, S
AU  - Pardalos, PM
PY  - 2020
JO  - Ann Oper Res
T2  - Ann Oper Res
VL  - 294
SP  - 567
EP  - 592
DO  - 10.1007/s10479-018-2818-y
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - XU6P7W2L
TI  - To engage or not to engage with Al for critical judgments: how professionals deal with opacity when using Al for medical diagnosis
AU  - Lebovitz, S
AU  - Lifshitz-Assaf, H
AU  - Levina, N
PY  - 2022
JO  - Organ Sci
T2  - Organ Sci
VL  - 33
SP  - 126
EP  - 148
DO  - 10.1287/orsc.2021.1549
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - 67YZNR7Q
TI  - Expl(Al)ned: the impact of explainable artificial intelligence on users' information processing
AU  - Bauer, K
AU  - von Zahn, M
AU  - Hinz, O
PY  - 2023
JO  - Inf Syst Res
T2  - Inf Syst Res
VL  - 34
SP  - 1582
EP  - 1602
DO  - 10.1287/isre.2023.1199
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - WQLDAVTR
TI  - Trust in an Al versus a Human teammate: the effects of teammate identity and per- formance on Human-Al cooperation
AU  - Zhang, G
AU  - Chong, L
AU  - Kotovsky, K
AU  - Cagan, J
PY  - 2023
JO  - Comput Hum Behav
T2  - Comput Hum Behav
VL  - 139
DO  - 10.1016/j.chb.2022.107536
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - RLPS38YH
TI  - Not a good judge of talent: the influence of subjective socioeconomic status on Al aversion
AU  - Xie, C
AU  - Fu, T
AU  - Yang, C
AU  - Chang, E-C
AU  - Zhao, M
PY  - 2024
JO  - Market Lett
T2  - Market Lett
DO  - 10.1007/s11002-024-09725-7
N1  - Date Added: 2025-08-28 09:10:57
ER  - 

TY  - JOUR
ID  - AST3B5NX
TI  - Artificial intelligence in utilitarian vs. Hedonic contexts: the "word-of-machine" effect
AU  - Longoni, C
AU  - Cian, L
PY  - 2022
JO  - J Mark
T2  - J Mark
VL  - 86
SP  - 91
EP  - 108
DO  - 10.1177/0022242920957347
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - HMXHDX6A
TI  - Consumers and artificial intelligence: an experiential perspective
AU  - Puntoni, S
AU  - Reczek, RW
AU  - Giesler, M
AU  - Botti, S
PY  - 2021
JO  - J Mark
T2  - J Mark
VL  - 85
SP  - 131
EP  - 151
DO  - 10.1177/0022242920953847
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - 6QUDPDB2
TI  - Home-tutoring services assisted with technology: investigating the role of artificial intelligence using a randomized field experiment
AU  - Kim, JH
AU  - Kim, M
AU  - Kwak, DW
AU  - Lee, S
PY  - 2022
JO  - J Mark Res
T2  - J Mark Res
VL  - 59
SP  - 79
EP  - 96
DO  - 10.1177/00222437211050351
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - HIYPY9VA
TI  - Don't want to look dumb? The role of theories of intelligence and humanlike features in online help seeking
AU  - Kim, S
AU  - Zhang, K
AU  - Park, D
PY  - 2018
JO  - Psychol Sci
T2  - Psychol Sci
VL  - 29
SP  - 171
EP  - 180
DO  - 10.1177/0956797617730595
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - X5MMVWXR
TI  - Exposure to robot preachers undermines religious commitment
AU  - Jackson, JC
AU  - Yam, KC
AU  - Tang, PM
AU  - Liu, T
AU  - Shariff, A
PY  - 2023
JO  - J Exp Psychol Gen
T2  - J Exp Psychol Gen
VL  - 152
SP  - 3344
EP  - 3358
DO  - 10.1037/xge0001443
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - EIMYBEUV
TI  - Preference for human (vs. Robotic) labor is stronger in symbolic consumption contexts
AU  - Granulo, A
AU  - Fuchs, C
AU  - Puntoni, S
PY  - 2021
JO  - J Consum Psychol
T2  - J Consum Psychol
VL  - 31
SP  - 72
EP  - 80
DO  - 10.1002/jcpy.1181
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - RW248U6G
TI  - Artificial intelligence in service
AU  - Huang, M-H
AU  - Rust, RT
PY  - 2018
JO  - J Serv Res
T2  - J Serv Res
VL  - 21
SP  - 155
EP  - 172
DO  - 10.1177/1094670517752459
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - PTNM8RVN
TI  - Understanding and improving consumer reactions to service bots
AU  - Castelo, N
AU  - Boegershausen, J
AU  - Hildebrand, C
AU  - Henkel, AP
PY  - 2023
JO  - J Consum Res
T2  - J Consum Res
VL  - 50
SP  - 848
EP  - 863
DO  - 10.1093/jcr/ucad023
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - UJ8TBT6H
TI  - Can we be friends with Mitsuku? A longitudinal study on the process of relationship formation between humans and a social chatbot
AU  - Croes, EAJ
AU  - Antheunis, ML
PY  - 2021
JO  - Journal of Social and Personal Relationships
T2  - Journal of Social and Personal Relationships
VL  - 38
IS  - 1
SP  - 279
EP  - 300
DO  - 10.1177/0265407520959463
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - XGU6EIH8
TI  - Effectiveness and safety of using chatbots to improve mental health: Systematic review and meta-analysis
AU  - Abd-Alrazaq, A. A.
AU  - Rababeh, A.
AU  - Alajlani, M.
AU  - Bewick, B. M.
AU  - Househ, M.
PY  - 2020
JO  - Journal of Medical Internet Research
T2  - Journal of Medical Internet Research
VL  - 22
IS  - 7
SP  - e16021
DO  - 10.2196/16021
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - LKREA334
TI  - Understanding anthropomorphism in service provision: A meta-analysis of physical robots, chatbots, and other AI
AU  - Blut, M.
AU  - Wang, C.
AU  - Wünderlich, N. V.
AU  - Brock, C.
PY  - 2021
JO  - Journal of the Academy of Marketing Science
T2  - Journal of the Academy of Marketing Science
VL  - 49
SP  - 632
EP  - 658
DO  - 10.1007/s11747-020-00762-y
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - 3UNM6IPV
TI  - The strategic use of artificial intelligence in the digital era: Systematic literature review and future research directions
AU  - Borges, A. F.
AU  - Laurindo, F. J.
AU  - Spínola, M. M.
AU  - Gonçalves, R. F.
AU  - Mattos, C. A.
PY  - 2020
JO  - International Journal of Information Management
T2  - International Journal of Information Management
VL  - 102225
DO  - 10.1016/j.ijinfomgt.2020.102225
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - QASH6HRV
TI  - Artificial intelligence and journalism: Systematic review of scientific production in Web of Science and Scopus (2008-2019)
AU  - Calvo-Rubio, L. M.
AU  - Ufarte-Ruiz, M. J.
PY  - 2021
JO  - Communication & Society
T2  - Communication & Society
VL  - 34
IS  - 2
SP  - 159
EP  - 176
DO  - 10.15581/003.34.2.159-176
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - UHN6N4JP
TI  - How and where is artificial intelligence in the public sector going? A literature review and research agenda
AU  - de Sousa, W. G.
AU  - de Melo, E. R. P.
AU  - Bermejo, P. H. D. S.
AU  - Farias, R. A. S.
AU  - Gomes, A. O.
PY  - 2019
JO  - Government Information Quarterly
T2  - Government Information Quarterly
VL  - 36
IS  - 4
SP  - 101392
DO  - 10.1016/j.giq.2019.07.004
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - 7FAEYUS3
TI  - Human trust in artificial intelligence: Review of empirical research
AU  - Glikson, E.
AU  - Woolley, A. W.
PY  - 2020
JO  - Academy of Management Annals
T2  - Academy of Management Annals
VL  - 14
IS  - 2
SP  - 627
EP  - 660
DO  - 10.5465/annals.2018.0057
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - IZMXPRZ5
TI  - Trust in artificial intelligence: Meta-analytic findings
AU  - Kaplan, A. D.
AU  - Kessler, T. T.
AU  - Brill, J. C.
AU  - Hancock, P. A.
PY  - 2021
JO  - Human Factors
T2  - Human Factors
VL  - 187208211013988
DO  - 10.1177/00187208211013988
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - SZ489XWA
TI  - The human side of human-chatbot interaction: A systematic literature review of ten years of research on text-based chatbots
AU  - Rapp, A.
AU  - Curti, L.
AU  - Boldi, A.
PY  - 2021
JO  - International Journal of Human-Computer Studies
T2  - International Journal of Human-Computer Studies
VL  - 151
SP  - 102630
DO  - 10.1016/j.ijhcs.2021.102630
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - 6EWVZT7J
TI  - Directions of the 100 most cited chatbot-related human behavior research: A review of academic publications
AU  - Wang, J.
AU  - Hwang, G. H.
AU  - Chang, C. Y.
PY  - 2021
JO  - Computers and Education: Artificial Intelligence
T2  - Computers and Education: Artificial Intelligence
VL  - 2
SP  - 100023
DO  - 10.1016/j.caeai.2021.100023
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - ZQRCISXX
TI  - Implications of the use of artificial intelligence in public governance: A systematic literature review and a research agenda
AU  - Zuiderwijk, A.
AU  - Chen, Y. C.
AU  - Salem, F.
PY  - 2021
JO  - Government Information Quarterly
T2  - Government Information Quarterly
VL  - 38
IS  - 3
SP  - 101577
DO  - 10.1016/j.giq.2021.101577
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - IGCE9KTD
TI  - No rage against the machine: How computer agents mitigate human emotional processes in electronic negotiations
AU  - Adam, M. T. P.
AU  - Teubner, T.
AU  - Gimpel, H.
PY  - 2018
JO  - Group Decision and Negotiation
T2  - Group Decision and Negotiation
VL  - 27
IS  - 4
SP  - 543
EP  - 571
DO  - 10.1007/s10726-018-9579-5
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - N96ALAT9
TI  - In AI we trust? Perceptions about automated decision-making by artificial intelligence
AU  - Araujo, T.
AU  - Natali, H.
AU  - Kruikemeier, S.
AU  - de Vreese, Claes H.
PY  - 2020
JO  - Al & Society
T2  - Al & Society
VL  - 35
IS  - 3
SP  - 611
EP  - 623
DO  - 10.1007/s00146-019-00931-w
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - 77IPJ7SE
TI  - Watch me improve-Algorithm aversion and demonstrating the ability to learn
AU  - Berger, B.
AU  - Martin, A.
AU  - Rühr, A.
AU  - Benlian, A.
PY  - 2021
JO  - Business & Information Systems Engineering
T2  - Business & Information Systems Engineering
VL  - 63
IS  - 1
SP  - 55
EP  - 68
DO  - 10.1007/s12599-020-00678-5
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - 8IM3SY2V
TI  - Do you care who flagged this post? Effects of moderator visibility on bystander behavior
AU  - Bhandari, A.
AU  - Ozanne, M.
AU  - Bazarova, N. N.
AU  - DiFranzo, D.
PY  - 2021
JO  - Journal of Computer-Mediated Communication
T2  - Journal of Computer-Mediated Communication
VL  - 26
IS  - 5
SP  - 284
EP  - 300
DO  - 10.1093/jcmc/zmab007
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - MTYWS8IB
TI  - See something, say something: Correction of global health misinformation on social media
AU  - Bode, L.
AU  - Vraga, E. K.
PY  - 2018
JO  - Health Communication
T2  - Health Communication
VL  - 33
IS  - 9
SP  - 1131
EP  - 1140
DO  - 10.1080/10410236.2017.1331312
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - JR2Z6NFD
TI  - Does the correspondence bias apply to social robots?: Dispositional and situational attributions of human versus robot behavior
AU  - Edwards, A.
AU  - Edwards, C.
PY  - 2022
JO  - Frontiers in Robotics and AI
T2  - Frontiers in Robotics and AI
VL  - 8
SP  - 788242
DO  - 10.3389/frobt.2021.788242
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - MIFT294K
TI  - Interpersonal impressions of a social robot versus human in the context of performance evaluations
AU  - Edwards, C.
AU  - Edwards, A.
AU  - Albrehi, F.
AU  - Spence, P.
PY  - 2021
JO  - Communication Education
T2  - Communication Education
VL  - 70
IS  - 2
SP  - 165
EP  - 182
DO  - 10.1080/03634523.2020.1802495
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - 8MJVIGYR
TI  - Common sense or censorship: How algorithmic moderators and message type influence perceptions of online content deletion
AU  - Gonçalves, J.
AU  - Weber, I.
AU  - Masullo, G. M.
AU  - Torres da Silva, M.
AU  - Hofhuis, J.
PY  - 2021
JO  - New Media & Society
T2  - New Media & Society
VL  - 14614448211032310
DO  - 10.1177/14614448211032310
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - 7X2LB6ZI
TI  - Readers' perception of computer-generated news: Credibility, expertise, and readability
AU  - Graefe, A.
AU  - Haim, M.
AU  - Haarmann, B.
AU  - Brosius, H.-B.
PY  - 2018
JO  - Journalism
T2  - Journalism
VL  - 19
IS  - 5
SP  - 595
EP  - 610
DO  - 10.1177/1464884916641269
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - UQTUQKHF
TI  - Automated journalism: The effects of Al authorship and evaluative information on the perception of a science journalism article
AU  - Henestrosa, A. L.
AU  - Greving, H.
AU  - Kimmerle, J.
PY  - 2023
JO  - Computers in Human Behavior
T2  - Computers in Human Behavior
VL  - 138
SP  - 107445
DO  - 10.1016/j.chb.2022.107445
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - THES
ID  - 8FTDVB49
TI  - Understanding the impact of conversational Al on supportive interactions: Towards the care (conversational Al and response effects) model
AU  - Ho, A. S.
PY  - 2018
CY  - Stanford University
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - PJ9J6UYL
TI  - Artificial intelligence, artists, and art: Attitudes toward artwork produced by humans vs. artificial intelligence
AU  - Hong, J.-W.
AU  - Curran, N. M.
PY  - 2019
JO  - ACM Transactions on Multimedia Computing, Communications, and Applications
T2  - ACM Transactions on Multimedia Computing, Communications, and Applications
VL  - 15
IS  - 2s
SP  - 1
EP  - 16
DO  - 10.1145/3326337
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - UHLJVXR7
TI  - The effects of anthropomorphism on how people evaluate algorithm-written news
AU  - Jang, W.
AU  - Chun, J. W.
AU  - Kim, S.
AU  - Kang, Y. W.
PY  - 2021
JO  - Digital Journalism
T2  - Digital Journalism
SP  - 1
EP  - 22
DO  - 10.1080/21670811.2021.1976064
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - CXY6CNVY
TI  - Behavioral cues of humanness in complex environments: How people engage with human and artificially intelligent agents in a multiplayer videogame
AU  - Jesso, S. T.
AU  - Kennedy, W. G.
AU  - Wiese, E.
PY  - 2020
JO  - Frontiers in Robotics and AI
T2  - Frontiers in Robotics and AI
VL  - 7
SP  - 531805
DO  - 10.3389/frobt.2020.531805
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - LWGSQ6LF
TI  - Chinese automated journalism: A comparison between expectations and perceived quality
AU  - Jia, C.
PY  - 2020
JO  - International Journal of Communication
T2  - International Journal of Communication
VL  - 14
SP  - 2611
EP  - 2632
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - PSLUT3J8
TI  - Understanding effects of algorithmic vs. community label on perceived accuracy of hyper-partisan misinformation
AU  - Jia, C.
AU  - Boltz, A.
AU  - Zhang, A.
AU  - Chen, A.
AU  - Lee, M. K.
PY  - 2022
DO  - 10.48550/arXiv.2203.00710
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - CPQWU83T
TI  - Source credibility matters: Does automated journalism inspire selective exposure?
AU  - Jia, C.
AU  - Johnson, T. J.
PY  - 2021
JO  - International Journal of Communication
T2  - International Journal of Communication
VL  - 15
SP  - 3760
EP  - 3781
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - J6KN39A6
TI  - Towards a sustainable news business: Understanding readers' perceptions of algorithm-generated news based on cultural conditioning
AU  - Kim, Y.
AU  - Lee, H.
PY  - 2021
JO  - Sustainability
T2  - Sustainability
VL  - 13
IS  - 7
SP  - 3728
EP  - 3742
DO  - 10.3390/su13073728
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - YQ2HBWJC
TI  - Can Al be a content generator? Effects of content generators and information delivery methods on the psychology of content consumers
AU  - Kim, J.
AU  - Shin, S.
AU  - Bae, K.
AU  - Oh, S.
AU  - Park, E.
AU  - del Pobil, A. P.
PY  - 2020
JO  - Telematics & Informatics
T2  - Telematics & Informatics
VL  - 55
SP  - 101452
DO  - 10.1016/j.tele.2020.101452
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - PBITIR8M
TI  - Man vs. machine: Human responses to an Al newscaster and the role of social presence
AU  - Kim, J.
AU  - Xu, K.
AU  - Merrill Jr, K.
PY  - 2022
JO  - The Social Science Journal
T2  - The Social Science Journal
DO  - 10.1080/03623319.2022.2027163
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - 84CJHWSR
TI  - The attenuating effect of intelligent agents and agent autonomy on managers' ability to diffuse responsibility for and engage in earnings management
AU  - Kipp, P. C.
AU  - Curtis, M. B.
AU  - Li, Z.
PY  - 2020
JO  - Accounting Horizons
T2  - Accounting Horizons
VL  - 34
IS  - 4
SP  - 143
EP  - 164
DO  - 10.2308/HORIZONS-19-133
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - HLHJ8YF4
TI  - Should I trust the artificial intelligence to recruit? Recruiters' perceptions and behavior when faced with algorithm-based recommendation systems during resume screening
AU  - Lacroux, A.
AU  - Martin-Lacroux, C.
PY  - 2022
JO  - Frontiers in Psychology
T2  - Frontiers in Psychology
VL  - 13
SP  - 895997
DO  - 10.3389/fpsyg.2022.895997
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - CONF
ID  - TGLB69H4
TI  - Who is included in human perceptions of AI?: Trust and perceived fairness around healthcare AI and cultural mistrust
AU  - Lee, M. K.
AU  - Rich, K.
PY  - 2021
BT  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
T2  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
DO  - 10.1145/3411764.3445570
CY  - Association for Computing Machinery
N1  - Date Added: 2025-08-28 09:10:58
T2  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
ER  - 

TY  - THES
ID  - VN6U99G7
TI  - Al in the news? Effect of modality on perceived news credibility of robot journalism
AU  - Lin, A. Y.
PY  - 2019
AB  - This research conducted an experiment to investigate how news consumers (N = 214) perceive automated news regarding the authorship and modality. With the development of AI technology, news companies not only adopt the algorithms to automatically produce news, but also apply AI to create news videos. Since AI news video is a new format of automated journalism, it is therefore needed to investigate if it is perceived credible by the public. Previous research tried to understand the automated news credibility by manipulating the byline, source attribution, and to make comparisons with human-written stories. Followed by previous studies, this research manipulates the news author (AI vs. human) and news modality (text vs. video) to understand people’s credibility perceptions towards AI news. The results show that the public perceived automated news that attributed to AI and that attributed to human journalist as equally credible. Moreover, the perceived credibility of AI anchor news video and AI news article are almost the same, meaning that the modality does not affect the credibility perceptions of automated news. These results give us important implications that AI news videos are perceived credible and robot journalism to large extents is accepted by the public.
CY  - University of Amsterdam
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - CONF
ID  - VEKF2KKW
TI  - Reading machine-written news: Effect of machine heuristic and novelty on hostile media perception
AU  - Liu, B.
AU  - Wei, L.
PY  - 2018
BT  - Human-Computer Interaction. Theories, Methods, and Human Issues
T2  - Human-Computer Interaction. Theories, Methods, and Human Issues
CY  - Springer
N1  - Date Added: 2025-08-28 09:10:58
T2  - Human-Computer Interaction. Theories, Methods, and Human Issues
ER  - 

TY  - JOUR
ID  - ELRS2JXY
TI  - Machine authorship in situ: Effect of news organization and news genre on news credibility
AU  - Liu, B.
AU  - Wei, L.
PY  - 2019
JO  - Digital Journalism
T2  - Digital Journalism
VL  - 7
IS  - 5
SP  - 635
EP  - 657
DO  - 10.1080/21670811.2018.1510740
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - TAUTLU2U
TI  - Resistance to medical artificial intelligence
AU  - Longoni, C.
AU  - Bonezzi, A.
AU  - Morewedge, C. K.
PY  - 2019
JO  - Journal of Consumer Research
T2  - Journal of Consumer Research
VL  - 46
IS  - 4
SP  - 629
EP  - 650
DO  - 10.1093/jcr/ucz013
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - CONF
ID  - XZIBB5WV
TI  - News from generative artificial intelligence is believed less
AU  - Longoni, C.
AU  - Fradkin, A.
AU  - Cian, L.
AU  - Pennycook, G.
PY  - 2022
BT  - Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency
T2  - Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency
DO  - 10.1145/3531146.3533077
CY  - Association for Computing Machinery
N1  - Date Added: 2025-08-28 09:10:58
T2  - Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency
ER  - 

TY  - JOUR
ID  - 5QKHSQ5I
TI  - Bots vs. humans: How schema congruity, contingency-based interactivity, and sympathy influence consumer perceptions and patronage intentions
AU  - Lou, C.
AU  - Kang, H.
AU  - Tse, C. H.
PY  - 2021
JO  - International Journal of Advertising
T2  - International Journal of Advertising
VL  - 41
IS  - 4
SP  - 655
EP  - 684
DO  - 10.1080/02650487.2021.1951510
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - 6FQAKB9U
TI  - Artificial intelligence coaches for sales agents: Caveats and solutions
AU  - Luo, X.
AU  - Qin, M. S.
AU  - Fang, Z.
AU  - Qu, Z.
PY  - 2021
JO  - Journal of Marketing
T2  - Journal of Marketing
VL  - 85
IS  - 2
SP  - 14
EP  - 32
DO  - 10.1177/0022242920956676
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - 2DUSAM2D
TI  - Frontiers: Machines vs. humans: The impact of artificial intelligence chatbot disclosure on customer purchases
AU  - Luo, X.
AU  - Tong, S.
AU  - Fang, Z.
AU  - Qu, Z.
PY  - 2019
JO  - Marketing Science
T2  - Marketing Science
VL  - 38
IS  - 6
SP  - 937
EP  - 947
DO  - 10.1287/mksc.2019.1192
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - SFGXKVTH
TI  - Service robots rising: How humanoid robots influence service experiences and elicit compensatory consumer responses
AU  - Mende, M.
AU  - Scott, M. L.
AU  - van Doorn, J.
AU  - Grewal, D.
AU  - Shanks, I.
PY  - 2019
JO  - Journal of Marketing Research
T2  - Journal of Marketing Research
VL  - 56
IS  - 4
SP  - 535
EP  - 556
DO  - 10.1177/0022243718822827
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - TQE5QEVM
TI  - Emotional support from AI chatbots: Should a supportive partner self-disclose or not?
AU  - Meng, J.
AU  - Dai, Y.
PY  - 2021
JO  - Journal of Computer-Mediated Communication
T2  - Journal of Computer-Mediated Communication
VL  - 26
IS  - 4
SP  - 207
EP  - 222
DO  - 10.1093/jcmc/zmab005
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - 27KENCVI
TI  - Reading, commenting and sharing of fake news: How online bandwagons and bots dictate user engagement
AU  - Molina, M. D.
AU  - Wang, J.
AU  - Sundar, S. S.
AU  - Le, T.
AU  - DiRusso, C.
PY  - 2022
JO  - Communication Research
T2  - Communication Research
DO  - 10.1177/00936502211073398
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - SG5G64G2
TI  - Are you aware of what you are watching? Role of machine heuristic in online content recommendations
AU  - Oh, S.
AU  - Park, E.
PY  - 2022
DO  - 10.48550/arXiv.2203.08373
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - JOUR
ID  - 5J84EXBT
TI  - Effects of human vs. computer-controlled characters and social identity cues on enjoyment: Mediation effects of presence, similarity, and group identification
AU  - Peña, J.
AU  - Ghaznavi, J.
AU  - Brody, N.
AU  - Prada, R.
AU  - Martinho, C.
AU  - Santos, P. A.
AU  - Damas, H.
AU  - Dimas, J.
PY  - 2019
JO  - Journal of Media Psychology: Theories, Methods, and Applications
T2  - Journal of Media Psychology: Theories, Methods, and Applications
VL  - 31
IS  - 1
SP  - 35
EP  - 47
DO  - 10.1027/1864-1105/a000218
N1  - Date Added: 2025-08-28 09:10:58
ER  - 

TY  - CONF
ID  - XNNR4WGB
TI  - Human vs. AI: Investigating consumers' context-dependent purchase intentions for algorithm-created content
AU  - Rix, J.
AU  - Rußell, R.
AU  - Rühr, A.
AU  - Hess, T.
PY  - 2022
BT  - Proceedings of the 55th Hawaii International Conference on System Sciences
T2  - Proceedings of the 55th Hawaii International Conference on System Sciences
SP  - 4549
EP  - 4558
CY  - University of Hawaii at Manoa, Association for Information Systems IEEE Computer Society Press
N1  - Date Added: 2025-08-28 09:10:58
T2  - Proceedings of the 55th Hawaii International Conference on System Sciences
ER  - 

TY  - JOUR
ID  - 5PKP5DX6
TI  - Unreal influence: Leveraging Al in influencer marketing
AU  - Sands, S.
AU  - Campbell, C. L.
AU  - Plangger, K.
AU  - Ferraro, C.
PY  - 2022
JO  - European Journal of Marketing
T2  - European Journal of Marketing
VL  - 56
IS  - 6
SP  - 1721
EP  - 1747
DO  - 10.1108/EJM-12-2019-0949
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - M88P5NYT
TI  - What to expect from opening up 'black boxes'? Comparing perceptions of justice between human and automated agents
AU  - Schlicker, N.
AU  - Langer, M.
AU  - Ötting, S. K.
AU  - Baum, K.
AU  - König, C. J.
AU  - Wallach, D.
PY  - 2021
JO  - Computers in Human Behavior
T2  - Computers in Human Behavior
VL  - 122
SP  - 106837
DO  - 10.1016/j.chb.2021.106837
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - CONF
ID  - 842YGSRY
TI  - Facing the artificial: Understanding affinity, trustworthiness, and preference for more realistic digital humans
AU  - Seymour, M.
AU  - Yuan, L.
AU  - Dennis, A. R.
AU  - Riemer, K.
PY  - 2020
BT  - Proceedings of the Annual Hawaii International Conference on System Sciences
T2  - Proceedings of the Annual Hawaii International Conference on System Sciences
SP  - 4673
EP  - 4683
CY  - University of Hawaii at Manoa, Association for Information Systems IEEE Computer Society Press
N1  - Date Added: 2025-08-28 09:10:59
T2  - Proceedings of the Annual Hawaii International Conference on System Sciences
ER  - 

TY  - JOUR
ID  - SAPK7MN7
TI  - Help! Is my chatbot falling into the uncanny valley? An empirical study of user experience in human-chatbot interaction
AU  - Skjuve, M.
AU  - Haugstveit, I. M.
AU  - Følstad, A.
AU  - Brandtzaeg, P.
PY  - 2019
JO  - Human Technology
T2  - Human Technology
VL  - 15
IS  - 1
SP  - 30
EP  - 54
DO  - 10.17011/ht/urn.201902201607
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - THES
ID  - YSKSSI39
TI  - Exploratory study on trust, distrust, and credibility in machine journalism
AU  - Song, S. W.
PY  - 2019
CY  - Syracuse University
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - Y9AECFMY
TI  - Artificial intelligence for political decision-making in the European Union: Effects on citizens' perceptions of input, throughput, and output legitimacy
AU  - Starke, C.
AU  - Lünich, M.
PY  - 2020
JO  - Data & Policy
T2  - Data & Policy
VL  - 2
SP  - e16
DO  - 10.1017/dap.2020.19
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - YJ33KTMQ
TI  - Parasocial interactions with real and virtual influencers: The role of perceived similarity and human-likeness
AU  - Stein, J. P.
AU  - Linda Breves, P.
AU  - Anders, N.
PY  - 2022
JO  - New Media & Society
T2  - New Media & Society
VL  - 1.46E+16
DO  - 10.1177/14614448221102900
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - QXX5SPCV
TI  - Playing well with others: The role of opponent and intergroup anxiety in the reduction of prejudice through collaborative video game play
AU  - Stiff, C.
AU  - Kedra, P.
PY  - 2020
JO  - Psychology of Popular Media
T2  - Psychology of Popular Media
VL  - 9
IS  - 1
SP  - 105
EP  - 115
DO  - 10.1037/ppm0000210
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - B5UKTF85
TI  - Does the use of synchrony and artificial intelligence in video interviews affect interview ratings and applicant attitudes?
AU  - Suen, H. Y.
AU  - Chen, M. Y. C.
AU  - Lu, S. H.
PY  - 2019
JO  - Computers in Human Behavior
T2  - Computers in Human Behavior
VL  - 98
SP  - 93
EP  - 101
DO  - 10.1016/j.chb.2019.04.012
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - 99P8NIXQ
TI  - Man vs. machine? The impact of algorithm authorship on news credibility
AU  - Tandoc Jr, E. C.
AU  - Yao, L. J.
AU  - Wu, S.
PY  - 2020
JO  - Digital Journalism
T2  - Digital Journalism
VL  - 8
IS  - 4
SP  - 548
EP  - 562
DO  - 10.1080/21670811.2020.1762102
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - T7Q9ZL6V
TI  - Close encounters of the AI kind: Use of AI influencers as brand endorsers
AU  - Thomas, V. L.
AU  - Fowler, K.
PY  - 2021
JO  - Journal of Advertising
T2  - Journal of Advertising
VL  - 50
IS  - 1
SP  - 11
EP  - 25
DO  - 10.1080/00913367.2020.1810595
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - VRNP4ZVK
TI  - When humans and computers induce social stress through negative feedback: Effects on performance and subjective state
AU  - Thuillard, S.
AU  - Adams, M.
AU  - Jelmini, G.
AU  - Schmutz, S.
AU  - Sonderegger, A.
AU  - Sauer, J.
PY  - 2022
JO  - Computers in Human Behavior
T2  - Computers in Human Behavior
VL  - 133
SP  - 107270
DO  - 10.1016/j.chb.2022.107270
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - WK5WQ9RD
TI  - Artificial intelligence became Beethoven: How do listeners and music professionals perceive artificially composed music?
AU  - Tigre Moura, F.
AU  - Maw, C.
PY  - 2021
JO  - Journal of Consumer Marketing
T2  - Journal of Consumer Marketing
VL  - 38
IS  - 2
SP  - 137
EP  - 146
DO  - 10.1108/JCM-02-2020-3671
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - R6GAZ5ZW
TI  - Employment relationships in algorithmic management: A psychological contract perspective
AU  - Tomprou, M.
AU  - Lee, M. K.
PY  - 2022
JO  - Computers in Human Behavior
T2  - Computers in Human Behavior
VL  - 126
SP  - 106997
DO  - 10.1016/j.chb.2021.106997
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - THES
ID  - 2MW7I6KW
TI  - Artificial intelligence (AI) applications in automating customer services and employee supervision
AU  - Tong, S.
PY  - 2020
CY  - Temple University
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - D3FS4PGR
TI  - The effect of artificial intelligence on the sales graph in Indian market
AU  - Ullal, M. S.
AU  - Hawaldar, I. T.
AU  - Suhan, M.
AU  - Joseph, N.
PY  - 2020
JO  - Entrepreneurship and Sustainability Issues
T2  - Entrepreneurship and Sustainability Issues
VL  - 7
IS  - 4
SP  - 2940
EP  - 2954
DO  - 10.9770/jesi.2020.7.4(24)
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - CONF
ID  - R96K88JP
TI  - "At the end of the day Facebook does what it wants" How users experience contesting algorithmic content moderation
AU  - Vaccaro, K.
AU  - Sandvig, C.
AU  - Karahalios, K.
PY  - 2020
BT  - Proceedings of the ACM on Human-Computer Interaction
T2  - Proceedings of the ACM on Human-Computer Interaction
VL  - 4
SP  - 1
EP  - 22
DO  - 10.1145/3415238
CY  - Association for Computing Machinery
N1  - Date Added: 2025-08-28 09:10:59
T2  - Proceedings of the ACM on Human-Computer Interaction
ER  - 

TY  - JOUR
ID  - IMWKYCXR
TI  - Can an algorithm reduce the perceived bias of news? Testing the effect of machine attribution on news readers’ evaluations of bias, anthropomorphism, and credibility
AU  - Waddell, T. F.
PY  - 2019
JO  - Journalism & Mass Communication Quarterly
T2  - Journalism & Mass Communication Quarterly
VL  - 96
IS  - 1
SP  - 82
EP  - 100
DO  - 10.1177/1077699018815891
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - D8WSEPWR
TI  - Moderating uncivil user comments by humans or machines? The effects of moderation agent on perceptions of bias and credibility in news content
AU  - Wang, S.
PY  - 2021
JO  - Digital Journalism
T2  - Digital Journalism
VL  - 9
IS  - 1
SP  - 64
EP  - 83
DO  - 10.1080/21670811.2020.1851279
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - CONF
ID  - ZFD5T8Z7
TI  - How willing are we to see the other side? Technology as a source of partisan information
AU  - Wang, J.
AU  - Sundar, S. S.
PY  - 2018
BT  - The 68th Annual Conference of the International Communication Association
T2  - The 68th Annual Conference of the International Communication Association
CY  - Prague, Czech Republic
N1  - Date Added: 2025-08-28 09:10:59
T2  - The 68th Annual Conference of the International Communication Association
ER  - 

TY  - JOUR
ID  - 3DC6PFXW
TI  - When expert recommendation contradicts peer opinion: Relative social influence of valence, group identity and artificial intelligence
AU  - Wang, J.
AU  - Molina, M. D.
AU  - Sundar, S. S.
PY  - 2020
JO  - Computers in Human Behavior
T2  - Computers in Human Behavior
VL  - 107
SP  - 106278
DO  - 10.1016/j.chb.2020.106278
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - JSTRDVM9
TI  - Effects of using artificial intelligence on interpersonal perceptions of job applicants
AU  - Weiss, D.
AU  - Liu, S. X.
AU  - Mieczkowski, H.
AU  - Hancock, J. T.
PY  - 2022
JO  - Cyberpsychology, Behavior, and Social Networking
T2  - Cyberpsychology, Behavior, and Social Networking
VL  - 25
IS  - 3
SP  - 163
EP  - 168
DO  - 10.1089/cyber.2020.0863
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - EDIKC4K5
TI  - Repelled at first sight? Expectations and intentions of job-seekers reading about AI selection in job advertisements
AU  - Wesche, J. S.
AU  - Sonderegger, A.
PY  - 2021
JO  - Computers in Human Behavior
T2  - Computers in Human Behavior
VL  - 125
SP  - 106931
DO  - 10.1016/j.chb.2021.106931
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - CONF
ID  - DQF5KHPI
TI  - Can AI reduce motivated reasoning in news consumption? Investigating the role of attitudes towards AI and prior-opinion in shaping trust perceptions of news
AU  - Wischnewski, M.
AU  - Krämer, N.
PY  - 2022
BT  - HHAI2022: Augmenting Human Intellect
T2  - HHAI2022: Augmenting Human Intellect
SP  - 184
EP  - 198
DO  - 10.3233/FAIA220198
CY  - IOS Press
N1  - Date Added: 2025-08-28 09:10:59
T2  - HHAI2022: Augmenting Human Intellect
ER  - 

TY  - JOUR
ID  - Z57LAR4X
TI  - Can AI enhance people’s support for online moderation and their openness to dissimilar political views?
AU  - Wojcieszak, M.
AU  - Thakur, A.
AU  - Ferreira Gonçalves, J. F.
AU  - Casas, A.
AU  - Menchen-Trevino, E.
AU  - Boon, M.
PY  - 2021
JO  - Journal of Computer-Mediated Communication
T2  - Journal of Computer-Mediated Communication
VL  - 26
IS  - 4
SP  - 223
EP  - 243
DO  - 10.1093/jcmc/zmab006
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - PR9GCR9Z
TI  - Who made the decisions: Human or robot umpires? The effects of anthropomorphism on perceptions toward robot umpires
AU  - Wonseok, J.
AU  - Woo, K. Y.
AU  - Yeonheung, K.
PY  - 2021
JO  - Telematics and Informatics
T2  - Telematics and Informatics
VL  - 64
SP  - 101695
DO  - 10.1016/j.tele.2021.101695
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - CONF
ID  - 7YUIYX8T
TI  - Online dating meets artificial intelligence: How the perception of algorithmically generated profile text impacts attractiveness and trust
AU  - Wu, Y.
AU  - Kelly, R. M.
PY  - 2020
BT  - Proceedings of the 32nd Australian Conference on Human-Computer Interaction
T2  - Proceedings of the 32nd Australian Conference on Human-Computer Interaction
SP  - 444
EP  - 453
DO  - 10.1145/3441000.3441074
CY  - Association for Computing Machinery
N1  - Date Added: 2025-08-28 09:10:59
T2  - Proceedings of the 32nd Australian Conference on Human-Computer Interaction
ER  - 

TY  - JOUR
ID  - NTIRTN65
TI  - Using machine learning to learn machines: A cross-cultural study of users’ responses to machine-generated artworks
AU  - Xu, K.
AU  - Liu, F.
AU  - Mou, Y.
AU  - Wu, Y.
AU  - Zeng, J.
AU  - Schäfer, M. S.
PY  - 2020
JO  - Journal of Broadcasting & Electronic Media
T2  - Journal of Broadcasting & Electronic Media
VL  - 64
IS  - 4
SP  - 566
EP  - 591
DO  - 10.1080/08838151.2020.1835136
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - 3ZQNGQTH
TI  - Same benefits, different communication patterns: Comparing children's reading with a conversational agent vs. a human partner
AU  - Xu, Y.
AU  - Wang, D.
AU  - Collins, P.
AU  - Lee, H.
AU  - Warschauer, M.
PY  - 2021
JO  - Computers and Education
T2  - Computers and Education
VL  - 161
SP  - 104059
DO  - 10.1016/j.compedu.2020.104059
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - XV4SLHFN
TI  - Thumbs up or down: Consumer reactions to decisions by algorithms versus humans
AU  - Yalcin, G.
AU  - Lim, S.
AU  - Puntoni, S.
AU  - van Osselaer, S. M.
PY  - 2022
JO  - Journal of Marketing Research
T2  - Journal of Marketing Research
VL  - 59
IS  - 4
SP  - 696–717
DO  - 10.1177/00222437211070016
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - CONF
ID  - ZGCMRDCM
TI  - Automated journalism a home run for sports? On the effects of perceived authorship and text objectivity on receptivity toward machine-written sports news
AU  - Yao, L. J.
AU  - Salmon, C. T.
AU  - Tandoc, E. C., Jr.
PY  - 2018
BT  - Proceedings of the URECA@NTU 2017–18
T2  - Proceedings of the URECA@NTU 2017–18
SP  - 1–10
CY  - Nanyang Technological University
N1  - Date Added: 2025-08-28 09:10:59
T2  - Proceedings of the URECA@NTU 2017–18
ER  - 

TY  - JOUR
ID  - SJ8RWF7I
TI  - Artificial intelligence is trusted less than a doctor in medical treatment decisions: Influence of perceived care and value similarity
AU  - Yokoi, R.
AU  - Eguchi, Y.
AU  - Fujita, T.
AU  - Nakayachi, K.
PY  - 2021
JO  - International Journal of Human-Computer Interaction
T2  - International Journal of Human-Computer Interaction
VL  - 37
IS  - 10
SP  - 981
EP  - 990
DO  - 10.1080/10447318.2020.1861763
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - GCXHJT6F
TI  - When people are defeated by artificial intelligence in a competition task requiring logical thinking, how do they make causal attribution?
AU  - Yokoi, R.
AU  - Nakayachi, K.
PY  - 2022
JO  - Current Psychology
T2  - Current Psychology
DO  - 10.1007/s12144-021-02559-w
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - UJQ9WCPG
TI  - Behavioral and neural evidence on consumer responses to human doctors and medical artificial intelligence
AU  - Yun, J. H.
AU  - Lee, E. J.
AU  - Kim, D. H.
PY  - 2021
JO  - Psychology & Marketing
T2  - Psychology & Marketing
VL  - 38
IS  - 4
SP  - 610
EP  - 625
DO  - 10.1002/mar.21445
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - T23AVR5Y
TI  - When algorithms meet journalism: The user perception to automated news in a cross-cultural context
AU  - Zheng, Y.
AU  - Zhong, B.
AU  - Yang, F.
PY  - 2018
JO  - Computers in Human Behavior
T2  - Computers in Human Behavior
VL  - 86
SP  - 266
EP  - 275
DO  - 10.1016/j.chb.2018.04.046
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - J4HTZWQ8
TI  - Did artificial intelligence invade humans? The study on the mechanism of patients’ willingness to accept artificial intelligence medical care: From the perspective of intergroup threat theory
AU  - Zhou, Y.
AU  - Shi, Y.
AU  - Lu, W.
AU  - Wan, F.
PY  - 2022
JO  - Frontiers in Psychology
T2  - Frontiers in Psychology
VL  - 13
SP  - 866124
DO  - 10.3389/fpsyg.2022.866124
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - INUJDL2N
TI  - Persuasion in Online Conversations
AU  - Goel, S.
AU  - et al.
PY  - 2024
JO  - Nature Human Behaviour
T2  - Nature Human Behaviour
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - CONF
ID  - 9TNQWHJ6
TI  - Measuring the Persuasiveness of Language Models
AU  - Durmus, E.
AU  - et al.
PY  - 2024
N1  - Date Added: 2025-08-28 09:10:59
T2  - Proceedings of ACL
ER  - 

TY  - JOUR
ID  - UY5MH7TQ
TI  - Using psychological artificial intelligence (Tess) to relieve symptoms of depression and anxiety: Randomized controlled trial
AU  - Fulmer, Russell
AU  - Joerin, Aurore
AU  - Gentile, Blaire
AU  - Lakerink, Luisa
AU  - Rauws, Michiel
PY  - 2018
JO  - JMIR Mental Health
T2  - JMIR Mental Health
VL  - 5
IS  - 4
SP  - e64
DO  - 10.2196/mental.9782
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - 3M7VR57T
TI  - Digital mental health and neuropsychiatry: An evidence-based study of chatbot interventions for mental health (Vivibot)
AU  - Greer, Scott
AU  - Robotham, Dan
AU  - Simblett, Sara
AU  - Curtis, Helen
AU  - Griffiths, H.
AU  - Wykes, Til
PY  - 2019
JO  - JMIR mHealth and uHealth
T2  - JMIR mHealth and uHealth
VL  - 7
IS  - 10
SP  - e14718
DO  - 10.2196/14718
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - H2RDU328
TI  - The Internal State of an LLM Knows When It's Lying
AU  - Azaria, Amos
AU  - Mitchell, Tom
PY  - 2023
AB  - While Large Language Models (LLMs) have shown exceptional performance in various tasks, one of their most prominent drawbacks is generating inaccurate or false information with a confident tone. In this paper, we provide evidence that the LLM's internal state can be used to reveal the truthfulness of statements. This includes both statements provided to the LLM, and statements that the LLM itself generates. Our approach is to train a classifier that outputs the probability that a statement is truthful, based on the hidden layer activations of the LLM as it reads or generates the statement. Experiments demonstrate that given a set of test sentences, of which half are true and half false, our trained classifier achieves an average of 71\% to 83\% accuracy labeling which sentences are true versus false, depending on the LLM base model. Furthermore, we explore the relationship between our classifier's performance and approaches based on the probability assigned to the sentence by the LLM. We show that while LLM-assigned sentence probability is related to sentence truthfulness, this probability is also dependent on sentence length and the frequencies of words in the sentence, resulting in our trained classifier providing a more reliable approach to detecting truthfulness, highlighting its potential to enhance the reliability of LLM-generated content and its practical applicability in real-world scenarios.
DO  - 10.48550/arXiv.2304.13734
UR  - http://arxiv.org/abs/2304.13734
KW  - Computer Science - Artificial Intelligence
KW  - Computer Science - Computation and Language
KW  - Computer Science - Machine Learning
N1  - Publisher: arXiv
N1  - Date Added: 2025-08-28 09:10:59
Y2  - 2025-08-27
ER  - 

TY  - JOUR
ID  - GMJPCWAM
TI  - Mirages: On Anthropomorphism in Dialogue Systems
AU  - Abercrombie, Gavin
AU  - Curry, Amanda Cercas
AU  - Dinkar, Tanvi
AU  - Rieser, Verena
AU  - Talat, Zeerak
PY  - 2023
AB  - Automated dialogue or conversational systems are anthropomorphised by developers and personified by users. While a degree of anthropomorphism may be inevitable due to the choice of medium, conscious and unconscious design choices can guide users to personify such systems to varying degrees. Encouraging users to relate to automated systems as if they were human can lead to high risk scenarios caused by over-reliance on their outputs. As a result, natural language processing researchers have investigated the factors that induce personification and develop resources to mitigate such effects. However, these efforts are fragmented, and many aspects of anthropomorphism have yet to be explored. In this paper, we discuss the linguistic factors that contribute to the anthropomorphism of dialogue systems and the harms that can arise, including reinforcing gender stereotypes and notions of acceptable language. We recommend that future efforts towards developing dialogue systems take particular care in their design, development, release, and description; and attend to the many linguistic cues that can elicit personification by users.
DO  - 10.48550/arXiv.2305.09800
UR  - http://arxiv.org/abs/2305.09800
ST  - Mirages
KW  - Computer Science - Computation and Language
N1  - Publisher: arXiv
N1  - Date Added: 2025-08-28 09:10:59
Y2  - 2025-08-27
ER  - 

TY  - JOUR
ID  - 33HGLXZQ
TI  - Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback
AU  - Bai, Yuntao
AU  - Jones, Andy
AU  - Ndousse, Kamal
AU  - Askell, Amanda
AU  - Chen, Anna
AU  - DasSarma, Nova
AU  - Drain, Dawn
AU  - Fort, Stanislav
AU  - Ganguli, Deep
AU  - Henighan, Tom
AU  - Joseph, Nicholas
AU  - Kadavath, Saurav
AU  - Kernion, Jackson
AU  - Conerly, Tom
AU  - El-Showk, Sheer
AU  - Elhage, Nelson
AU  - Hatfield-Dodds, Zac
AU  - Hernandez, Danny
AU  - Hume, Tristan
AU  - Johnston, Scott
AU  - Kravec, Shauna
AU  - Lovitt, Liane
AU  - Nanda, Neel
AU  - Olsson, Catherine
AU  - Amodei, Dario
AU  - Brown, Tom
AU  - Clark, Jack
AU  - McCandlish, Sam
AU  - Olah, Chris
AU  - Mann, Ben
AU  - Kaplan, Jared
PY  - 2022
AB  - We apply preference modeling and reinforcement learning from human feedback (RLHF) to finetune language models to act as helpful and harmless assistants. We find this alignment training improves performance on almost all NLP evaluations, and is fully compatible with training for specialized skills such as python coding and summarization. We explore an iterated online mode of training, where preference models and RL policies are updated on a weekly cadence with fresh human feedback data, efficiently improving our datasets and models. Finally, we investigate the robustness of RLHF training, and identify a roughly linear relation between the RL reward and the square root of the KL divergence between the policy and its initialization. Alongside our main results, we perform peripheral analyses on calibration, competing objectives, and the use of OOD detection, compare our models with human writers, and provide samples from our models using prompts appearing in recent related work.
DO  - 10.48550/arXiv.2204.05862
UR  - http://arxiv.org/abs/2204.05862
KW  - Computer Science - Computation and Language
KW  - Computer Science - Machine Learning
N1  - Publisher: arXiv
N1  - Date Added: 2025-08-28 09:10:59
Y2  - 2025-08-27
ER  - 

TY  - JOUR
ID  - QUU9HAU6
TI  - Constitutional AI: Harmlessness from AI Feedback
AU  - Bai, Yuntao
AU  - Kadavath, Saurav
AU  - Kundu, Sandipan
AU  - Askell, Amanda
AU  - Kernion, Jackson
AU  - Jones, Andy
AU  - Chen, Anna
AU  - Goldie, Anna
AU  - Mirhoseini, Azalia
AU  - McKinnon, Cameron
AU  - Chen, Carol
AU  - Olsson, Catherine
AU  - Olah, Christopher
AU  - Hernandez, Danny
AU  - Drain, Dawn
AU  - Ganguli, Deep
AU  - Li, Dustin
AU  - Tran-Johnson, Eli
AU  - Perez, Ethan
AU  - Kerr, Jamie
AU  - Mueller, Jared
AU  - Ladish, Jeffrey
AU  - Landau, Joshua
AU  - Ndousse, Kamal
AU  - Lukosuite, Kamile
AU  - Lovitt, Liane
AU  - Sellitto, Michael
AU  - Elhage, Nelson
AU  - Schiefer, Nicholas
AU  - Mercado, Noemi
AU  - DasSarma, Nova
AU  - Lasenby, Robert
AU  - Larson, Robin
AU  - Ringer, Sam
AU  - Johnston, Scott
AU  - Kravec, Shauna
AU  - Showk, Sheer El
AU  - Fort, Stanislav
AU  - Lanham, Tamera
AU  - Telleen-Lawton, Timothy
AU  - Conerly, Tom
AU  - Henighan, Tom
AU  - Hume, Tristan
AU  - Bowman, Samuel R.
AU  - Hatfield-Dodds, Zac
AU  - Mann, Ben
AU  - Amodei, Dario
AU  - Joseph, Nicholas
AU  - McCandlish, Sam
AU  - Brown, Tom
AU  - Kaplan, Jared
PY  - 2022
AB  - As AI systems become more capable, we would like to enlist their help to supervise other AIs. We experiment with methods for training a harmless AI assistant through self-improvement, without any human labels identifying harmful outputs. The only human oversight is provided through a list of rules or principles, and so we refer to the method as 'Constitutional AI'. The process involves both a supervised learning and a reinforcement learning phase. In the supervised phase we sample from an initial model, then generate self-critiques and revisions, and then finetune the original model on revised responses. In the RL phase, we sample from the finetuned model, use a model to evaluate which of the two samples is better, and then train a preference model from this dataset of AI preferences. We then train with RL using the preference model as the reward signal, i.e. we use 'RL from AI Feedback' (RLAIF). As a result we are able to train a harmless but non-evasive AI assistant that engages with harmful queries by explaining its objections to them. Both the SL and RL methods can leverage chain-of-thought style reasoning to improve the human-judged performance and transparency of AI decision making. These methods make it possible to control AI behavior more precisely and with far fewer human labels.
DO  - 10.48550/arXiv.2212.08073
UR  - http://arxiv.org/abs/2212.08073
ST  - Constitutional AI
KW  - Computer Science - Artificial Intelligence
KW  - Computer Science - Computation and Language
N1  - Publisher: arXiv
N1  - Date Added: 2025-08-28 09:10:59
Y2  - 2025-08-27
ER  - 

TY  - JOUR
ID  - D9NGEWGM
TI  - Improving Few-shot Generalization of Safety Classifiers via Data Augmented Parameter-Efficient Fine-Tuning
AU  - Balashankar, Ananth
AU  - Ma, Xiao
AU  - Sinha, Aradhana
AU  - Beirami, Ahmad
AU  - Qin, Yao
AU  - Chen, Jilin
AU  - Beutel, Alex
PY  - 2023
AB  - As large language models (LLMs) are widely adopted, new safety issues and policies emerge, to which existing safety classifiers do not generalize well. If we have only observed a few examples of violations of a new safety rule, how can we build a classifier to detect violations? In this paper, we study the novel setting of domain-generalized few-shot learning for LLM-based text safety classifiers. Unlike prior few-shot work, these new safety issues can be hard to uncover and we do not get to choose the few examples. We demonstrate that existing few-shot techniques do not perform well in this setting, and rather we propose to do parameter-efficient fine-tuning (PEFT) combined with augmenting training data based on similar examples in prior existing rules. We empirically show that our approach of similarity-based data-augmentation + prompt-tuning (DAPT) consistently outperforms baselines that either do not rely on data augmentation or on PEFT by 7-17% F1 score in the Social Chemistry moral judgement and 9-13% AUC in the Toxicity detection tasks, even when the new rule is loosely correlated with existing ones.
DO  - 10.48550/arXiv.2310.16959
UR  - http://arxiv.org/abs/2310.16959
KW  - Computer Science - Machine Learning
N1  - Publisher: arXiv
N1  - Date Added: 2025-08-28 09:10:59
Y2  - 2025-08-27
ER  - 

TY  - JOUR
ID  - IRKVAYJE
TI  - Models in the Loop: Aiding Crowdworkers with Generative Annotation Assistants
AU  - Bartolo, Max
AU  - Thrush, Tristan
AU  - Riedel, Sebastian
AU  - Stenetorp, Pontus
AU  - Jia, Robin
AU  - Kiela, Douwe
PY  - 2022
AB  - In Dynamic Adversarial Data Collection (DADC), human annotators are tasked with finding examples that models struggle to predict correctly. Models trained on DADC-collected training data have been shown to be more robust in adversarial and out-of-domain settings, and are considerably harder for humans to fool. However, DADC is more time-consuming than traditional data collection and thus more costly per annotated example. In this work, we examine whether we can maintain the advantages of DADC, without incurring the additional cost. To that end, we introduce Generative Annotation Assistants (GAAs), generator-in-the-loop models that provide real-time suggestions that annotators can either approve, modify, or reject entirely. We collect training datasets in twenty experimental settings and perform a detailed analysis of this approach for the task of extractive question answering (QA) for both standard and adversarial data collection. We demonstrate that GAAs provide significant efficiency benefits with over a 30% annotation speed-up, while leading to over a 5x improvement in model fooling rates. In addition, we find that using GAA-assisted training data leads to higher downstream model performance on a variety of question answering tasks over adversarial data collection.
DO  - 10.48550/arXiv.2112.09062
UR  - http://arxiv.org/abs/2112.09062
ST  - Models in the Loop
KW  - Computer Science - Computation and Language
N1  - Publisher: arXiv
N1  - Date Added: 2025-08-28 09:10:59
Y2  - 2025-08-27
ER  - 

TY  - JOUR
ID  - 8WF4IHSZ
TI  - Towards monosemanticity: decomposing language models with dictionary learning
AU  - Bricken, T.
AU  - Templeton, A.
AU  - Batson, J.
AU  - Chen, B.
AU  - Jermyn, A.
AU  - Conerly, T.
AU  - Turner, N. L.
AU  - Anil, C.
AU  - Denison, C.
AU  - Askell, A.
AU  - Lasenby, R.
AU  - Wu, Y.
AU  - Kravec, S.
AU  - Schiefer, N.
AU  - Maxwell, T.
AU  - Joseph, N.
AU  - Tamkin, A.
AU  - Nguyen, K.
AU  - McLean, B.
AU  - Burke, J. E.
AU  - Hume, T.
AU  - Carter, S.
AU  - Henighan, T.
AU  - Olah, C.
PY  - 2023
UR  - https://transformer-circuits.pub/2023/monosemantic-features
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - LB68PFBR
TI  - Language models are few-shot learners
AU  - Brown, T. B.
AU  - Mann, B.
AU  - Ryder, N.
AU  - Subbiah, M.
AU  - Kaplan, J.
AU  - Dhariwal, P.
AU  - Neelakantan, A.
AU  - Shyam, P.
AU  - Sastry, G.
AU  - Askell, A.
AU  - Agarwal, S.
AU  - Herbert-Voss, A.
AU  - Krueger, G.
AU  - Henighan, T.
AU  - Child, R.
AU  - Ramesh, A.
AU  - Ziegler, D. M.
AU  - Wu, J.
AU  - Winter, C.
AU  - Hesse, C.
AU  - Chen, M.
AU  - Sigler, E.
AU  - Litwin, M.
AU  - Gray, S.
AU  - Chess, B.
AU  - Clark, J.
AU  - Berner, C.
AU  - McCandlish, S.
AU  - Radford, A.
AU  - Sutskever, I.
AU  - Amodei, D.
PY  - 2020
UR  - https://arxiv.org/abs/2005.14165
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - 4VXS34HX
TI  - Discovering latent knowledge in language models without supervision
AU  - Burns, C.
AU  - Ye, H.
AU  - Klein, D.
AU  - Steinhardt, J.
PY  - 2022
UR  - https://arxiv.org/abs/2212.03827
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - PZWTPIUA
TI  - Artificial influence: an analysis of AI-driven persuasion
AU  - Burtell, M.
AU  - Woodside, T.
PY  - 2023
UR  - http://arxiv.org/abs/2303.08721
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - QE9KQHN7
TI  - Open problems and fundamental limitations of reinforcement learning from human feedback
AU  - Casper, S.
AU  - Davies, X.
AU  - Shi, C.
AU  - Gilbert, T. K.
AU  - Scheurer, J.
AU  - Rando, J.
AU  - Freedman, R.
AU  - Korbak, T.
AU  - Lindner, D.
AU  - Freire, P.
AU  - Wang, T.
AU  - Marks, S.
AU  - Segerie, C.-R.
AU  - Carroll, M.
AU  - Peng, A.
AU  - Christoffersen, P.
AU  - Damani, M.
AU  - Slocum, S.
AU  - Anwar, U.
AU  - Siththaranjan, A.
AU  - Nadeau, M.
AU  - Michaud, E. J.
AU  - Pfau, J.
AU  - Krasheninnikov, D.
AU  - Chen, X.
AU  - Langosco, L.
AU  - Hase, P.
AU  - Bıyık, E.
AU  - Dragan, A.
AU  - Krueger, D.
AU  - Sadigh, D.
AU  - Hadfield-Menell, D.
PY  - 2023
UR  - http://arxiv.org/abs/2307.15217
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - GQZCB2IU
TI  - Supervising strong learners by amplifying weak experts
AU  - Christiano, P.
AU  - Shlegeris, B.
AU  - Amodei, D.
PY  - 2018
UR  - https://arxiv.org/abs/1810.08575
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - 2LEHITYF
TI  - Eliciting latent knowledge: how to tell if your eyes deceive you
AU  - Christiano, P.
AU  - Cotra, A.
AU  - Xu, M.
PY  - 2021
UR  - https://docs.google.com/document/d/1WwsnJQstPq91_Yh-Ch2XRL8H_EpsnjrC1dwZXR37PC8/edit#heading=h.jrzi4atzacns
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - SQQMI3F6
TI  - Artificial Intelligence Act. Amendments adopted on 14 June 2023
AU  - European Parliament
PY  - 2023
UR  - https://www.europarl.europa.eu/doceo/document/TA-9-2023-0236_EN.pdf
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - WH2HFDRZ
TI  - Challenges with unsupervised LLM knowledge discovery
AU  - Farquhar, S.
AU  - Varma, V.
AU  - Kenton, Z.
AU  - Gasteiger, J.
AU  - Mikulik, V.
AU  - Shah, R.
PY  - 2023
UR  - https://arxiv.org/abs/2312.10029
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - UA6ETTRW
TI  - Strengthening the EU AI Act: defining key terms on AI manipulation
AU  - Franklin, M.
AU  - Tomei, P. M.
AU  - Gorman, R.
PY  - 2023
UR  - https://arxiv.org/abs/2308.16364
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - C8EY4PGK
TI  - Improving alignment of dialogue agents via targeted human judgements
AU  - Glaese, A.
AU  - McAleese, N.
AU  - Trębacz, M.
AU  - Aslanides, J.
AU  - Firoiu, V.
AU  - Ewalds, T.
AU  - Rauh, M.
AU  - Weidinger, L.
AU  - Chadwick, M.
AU  - Thacker, P.
AU  - Campbell-Gillingham, L.
AU  - Uesato, J.
AU  - Huang, P.-S.
AU  - Comanescu, R.
AU  - Yang, F.
AU  - See, A.
AU  - Dathathri, S.
AU  - Greig, R.
AU  - Chen, C.
AU  - Fritz, D.
AU  - Elias, J. S.
AU  - Green, R.
AU  - Mokrá, S.
AU  - Fernando, N.
AU  - Wu, B.
AU  - Foley, R.
AU  - Young, S.
AU  - Gabriel, I.
AU  - Isaac, W.
AU  - Mellor, J.
AU  - Hassabis, D.
AU  - Kavukcuoglu, K.
AU  - Hendricks, L. A.
AU  - Irving, G.
PY  - 2022
UR  - https://arxiv.org/abs/2209.14375
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - UJFCG8I8
TI  - Generative language models and automated influence operations: emerging threats and potential mitigations
AU  - Goldstein, A.
AU  - Sastry, G.
AU  - Musser, M.
AU  - DiResta, R.
AU  - Gentzel, M.
AU  - Sedova, K.
PY  - 2023
UR  - http://arxiv.org/abs/2301.04246
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - I9WXWUM4
TI  - InstructDial: improving zero and few-shot generalization in dialogue through instruction tuning
AU  - Gupta, P.
AU  - Jiao, C.
AU  - Yeh, Y.-T.
AU  - Mehri, S.
AU  - Eskenazi, M.
AU  - Bigham, J. P.
PY  - 2022
UR  - https://arxiv.org/abs/2205.12673
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - HCJ49SPT
TI  - Deception abilities emerged in large language models
AU  - Hagendorff, T.
PY  - 2023
UR  - https://arxiv.org/abs/2307.16513
N1  - Date Added: 2025-08-28 09:10:59
ER  - 

TY  - JOUR
ID  - G2P575SS
TI  - Challenges and applications of large language models
AU  - Kaddour, J.
AU  - Harris, J.
AU  - Mozes, M.
AU  - Bradley, H.
AU  - Raileanu, R.
AU  - McHardy, R.
PY  - 2023
UR  - https://arxiv.org/abs/2307.10169
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - FCQ3F7W4
TI  - Classifying constructive comments
AU  - Kolhatkar, V.
AU  - Thain, N.
AU  - Sorensen, J.
AU  - Dixon, L.
AU  - Taboada, M.
PY  - 2020
UR  - https://arxiv.org/abs/2004.05476
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - 3LEFSWBL
TI  - Scalable agent alignment via reward modeling: a research direction
AU  - Leike, J.
AU  - Krueger, D.
AU  - Everitt, T.
AU  - Martic, M.
AU  - Maini, V.
AU  - Legg, S.
PY  - 2018
UR  - https://arxiv.org/abs/1811.07871
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - 2DU9F86D
TI  - Still no lie detector for language models: probing empirical and conceptual roadblocks
AU  - Levinstein, B. A.
AU  - Herrmann, D. A.
PY  - 2023
UR  - https://arxiv.org/abs/2307.00175
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - 92QCY9N5
TI  - The geometry of truth: emergent linear structure in large language model representations of true/false datasets
AU  - Marks, S.
AU  - Tegmark, M.
PY  - 2023
UR  - https://arxiv.org/abs/2310.06824
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - IRY3K2GN
TI  - Debate helps supervise unreliable experts
AU  - Michael, J.
AU  - Mahdi, S.
AU  - Rein, D.
AU  - Petty, J.
AU  - Dirani, J.
AU  - Padmakumar, V.
AU  - Bowman, S. R.
PY  - 2023
UR  - https://arxiv.org/abs/2311.08702
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - FQG6RNZS
TI  - DetectGPT: zero-shot machine-generated text detection using probability curvature
AU  - Mitchell, E.
AU  - Lee, Y.
AU  - Khazatsky, A.
AU  - Manning, C. D.
AU  - Finn, C.
PY  - 2023
UR  - http://arxiv.org/abs/2301.11305
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - XDFV6YQ7
TI  - Use of llms for illicit purposes: threats, prevention measures, and vulnerabilities
AU  - Mozes, M.
AU  - He, X.
AU  - Kleinberg, B.
AU  - Griffin, L. D.
PY  - 2023
UR  - http://arxiv.org/abs/2308.12833
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - QEEDDNU6
TI  - Towards agile text classifiers for everyone
AU  - Mozes, M.
AU  - Hoffmann, J.
AU  - Tomanek, K.
AU  - Kouate, M.
AU  - Thain, N.
AU  - Yuan, A.
AU  - Bolukbasi, T.
AU  - Dixon, L.
PY  - 2023
UR  - https://arxiv.org/abs/2302.06541
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - B4DFKUB6
TI  - Training language models to follow instructions with human feedback
AU  - Ouyang, L.
AU  - Wu, J.
AU  - Jiang, X.
AU  - Almeida, D.
AU  - Wainwright, C. L.
AU  - Mishkin, P.
AU  - Zhang, C.
AU  - Agarwal, S.
AU  - Slama, K.
AU  - Ray, A.
AU  - Schulman, J.
AU  - Hilton, J.
AU  - Kelton, F.
AU  - Miller, L.
AU  - Simens, M.
AU  - Askell, A.
AU  - Welinder, P.
AU  - Christiano, P.
AU  - Leike, J.
AU  - Lowe, R.
PY  - 2022
UR  - https://arxiv.org/abs/2203.02155
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - DAWLGGEG
TI  - How to catch an AI liar: lie detection in black-box LLMs by asking unrelated questions
AU  - Pacchiardi, L.
AU  - Chan, A. J.
AU  - Mindermann, S.
AU  - Moscovitz, I.
AU  - Pan, A. Y.
AU  - Gal, Y.
AU  - Evans, O.
AU  - Brauner, J.
PY  - 2023
UR  - https://arxiv.org/abs/2309.15840
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - W63IDQQ5
TI  - Red teaming language models with language models
AU  - Perez, E.
AU  - Huang, S.
AU  - Song, F.
AU  - Cai, T.
AU  - Ring, R.
AU  - Aslanides, J.
AU  - Glaese, A.
AU  - McAleese, N.
AU  - Irving, G.
PY  - 2022
UR  - https://arxiv.org/abs/2202.03286
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - MD4FW5J6
TI  - Discovering language model behaviors with model-written evaluations
AU  - Perez, E.
AU  - Ringer, S.
AU  - Lukošiu¯t˙e, K.
AU  - Nguyen, K.
AU  - Chen, E.
AU  - Heiner, S.
AU  - Pettit, C.
AU  - Olsson, C.
AU  - Kundu, S.
AU  - Kadavath, S.
AU  - Jones, A.
AU  - Chen, A.
AU  - Mann, B.
AU  - Israel, B.
AU  - Seethor, B.
AU  - McKinnon, C.
AU  - Olah, C.
AU  - Yan, D.
AU  - Amodei, D.
AU  - Drain, D.
AU  - Li, D.
AU  - Tran-Johnson, E.
AU  - Khundadze, G.
AU  - Kernion, J.
AU  - Landis, J.
AU  - Kerr, J.
AU  - Mueller, J.
AU  - Hyun, J.
AU  - Landau, J.
AU  - Ndousse, K.
AU  - Goldberg, L.
AU  - Lovitt, L.
AU  - Lucas, M.
AU  - Sellitto, M.
AU  - Zhang, M.
AU  - Kingsland, N.
AU  - Elhage, N.
AU  - Joseph, N.
AU  - Mercado, N.
AU  - DasSarma, N.
AU  - Rausch, O.
AU  - Larson, R.
AU  - McCandlish, S.
AU  - Johnston, S.
AU  - Kravec, S.
AU  - Showk, S. E.
AU  - Lanham, T.
AU  - Telleen-Lawton, T.
AU  - Brown, T.
AU  - Henighan, T.
AU  - Hume, T.
AU  - Bai, Y.
AU  - Hatfield-Dodds, Z.
AU  - Clark, J.
AU  - Bowman, S. R.
AU  - Askell, A.
AU  - Grosse, R.
AU  - Hernandez, D.
AU  - Ganguli, D.
AU  - Hubinger, E.
AU  - Schiefer, N.
AU  - Kaplan, J.
PY  - 2022
UR  - http://arxiv.org/abs/2212.09251
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - QGT6YD6M
TI  - Few-shot instruction prompts for pretrained language models to detect social biases
AU  - Prabhumoye, S.
AU  - Kocielnik, R.
AU  - Shoeybi, M.
AU  - Anandkumar, A.
AU  - Catanzaro, B.
PY  - 2021
UR  - https://arxiv.org/abs/2112.07868
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - 9Q5AQGXC
TI  - Language models are unsupervised multitask learners
AU  - Radford, A.
AU  - Wu, J.
AU  - Child, R.
AU  - Luan, D.
AU  - Amodei, D.
AU  - Sutskever, I.
PY  - 2019
UR  - https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - DB8XK3TD
TI  - Lying in persuasion
AU  - Rozenas, A.
AU  - Luo, Z.
PY  - 2023
UR  - https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3878448
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - TW9X44Q5
TI  - The Goldilocks of pragmatic understanding: fine-tuning strategy matters for implicature resolution by LLMs
AU  - Ruis, L.
AU  - Khan, A.
AU  - Biderman, S.
AU  - Hooker, S.
AU  - Rocktäschel, T.
AU  - Grefenstette, E.
PY  - 2022
UR  - https://arxiv.org/abs/2210.14986
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - UPP4P6FQ
TI  - Toward transparent AI: a survey on interpreting the inner structures of deep neural networks
AU  - Räuker, T.
AU  - Ho, A.
AU  - Casper, S.
AU  - Hadfield-Menell, D.
PY  - 2022
UR  - https://arxiv.org/abs/2207.13243
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - R7XJYYU4
TI  - Self-critiquing models for assisting human evaluators
AU  - Saunders, W.
AU  - Yeh, C.
AU  - Wu, J.
AU  - Bills, S.
AU  - Ouyang, L.
AU  - Ward, J.
AU  - Leike, J.
PY  - 2022
UR  - https://arxiv.org/abs/2206.05802
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - RPC6PGBH
TI  - Ignore this title and HackAPrompt: exposing systemic vulnerabilities of LLMs through a global scale prompt hacking competition
AU  - Schulhoff, S.
AU  - Pinto, J.
AU  - Khan, A.
AU  - Bouchard, L.-F.
AU  - Si, C.
AU  - Anati, S.
AU  - Tagliabue, V.
AU  - Kost, A. L.
AU  - Carnahan, C.
AU  - Boyd-Graber, J.
PY  - 2023
UR  - http://arxiv.org/abs/2311.16119
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - XBZNLN2T
TI  - On second thought, let’s not think step by step! Bias and toxicity in zero-shot reasoning
AU  - Shaikh, O.
AU  - Zhang, H.
AU  - Held, W.
AU  - Bernstein, M.
AU  - Yang, D.
PY  - 2022
UR  - https://arxiv.org/abs/2212.08061
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - X7DTN3TG
TI  - Model evaluation for extreme risks
AU  - Shevlane, T.
AU  - Farquhar, S.
AU  - Garfinkel, B.
AU  - Phuong, M.
AU  - Whittlestone, J.
AU  - Leung, J.
AU  - Kokotajlo, D.
AU  - Marchal, N.
AU  - Anderljung, M.
AU  - Kolt, N.
AU  - Ho, L.
AU  - Siddarth, D.
AU  - Avin, S.
AU  - Hawkins, W.
AU  - Kim, B.
AU  - Gabriel, I.
AU  - Bolina, V.
AU  - Clark, J.
AU  - Bengio, Y.
AU  - Christiano, P.
AU  - Dafoe, A.
PY  - 2023
UR  - https://arxiv.org/abs/2305.15324
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - SL3535AF
TI  - Sentiment adaptive end-to-end dialog systems
AU  - Shi, W.
AU  - Yu, Z.
PY  - 2018
UR  - https://arxiv.org/abs/1804.10731
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - FN2ARFGA
TI  - Enhancing human persuasion with large language models
AU  - Shin, M.
AU  - Kim, J.
PY  - 2023
UR  - http://arxiv.org/abs/2311.16466
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - GLD2NWM4
TI  - Learning to summarize from human feedback
AU  - Stiennon, N.
AU  - Ouyang, L.
AU  - Wu, J.
AU  - Ziegler, D. M.
AU  - Lowe, R.
AU  - Voss, C.
AU  - Radford, A.
AU  - Amodei, D.
AU  - Christiano, P.
PY  - 2020
UR  - https://arxiv.org/abs/2009.01325
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - JX3I7LJN
TI  - Augmenting language models with long-term memory
AU  - Wang, W.
AU  - Dong, L.
AU  - Cheng, H.
AU  - Liu, X.
AU  - Yan, X.
AU  - Gao, J.
AU  - Wei, F.
PY  - 2023
UR  - https://arxiv.org/abs/2306.07174
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - B9H8PVK5
TI  - Simple synthetic data reduces sycophancy in large language models
AU  - Wei, J.
AU  - Huang, D.
AU  - Lu, Y.
AU  - Zhou, D.
AU  - Le, Q. V.
PY  - 2023
UR  - https://arxiv.org/abs/2308.03958
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - T9KW5MI5
TI  - Sociotechnical safety evaluation of generative AI systems
AU  - Weidinger, L.
AU  - Rauh, M.
AU  - Marchal, N.
AU  - Manzini, A.
AU  - Hendricks, L. A.
AU  - Mateos-Garcia, J.
AU  - Bergman, S.
AU  - Kay, J.
AU  - Griffin, C.
AU  - Bariach, B.
AU  - Gabriel, I.
AU  - Rieser, V.
AU  - Isaac, W.
PY  - 2023
UR  - http://arxiv.org/abs/2310.11986
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - JSHTSSCX
TI  - Assessing prompt injection risks in 200+ custom GPTs
AU  - Yu, J.
AU  - Wu, Y.
AU  - Shu, D.
AU  - Jin, M.
AU  - Xing, X.
PY  - 2023
UR  - https://arxiv.org/abs/2311.11538
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - 6VP527HJ
TI  - Large language models reflect the ideology of their creators
AU  - Buyl, Maarten
AU  - Rogiers, Alexander
AU  - Noels, Sander
AU  - Dominguez-Catena, Iris
AU  - Heiter, Edith
AU  - Romero, Raphael
AU  - Johary, Iman
AU  - Mara, Alexandru-Cristian
AU  - Lijffijt, Jefrey
AU  - De Bie, Tijl
PY  - 2024
UR  - https://arxiv.org/abs/2410.18417
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - 8PQWDWDC
TI  - Large Language Models are as persuasive as humans, but how? About the cognitive effort and moral-emotional language of LLM arguments
AU  - Carrasco-Farre, Carlos
PY  - 2024
UR  - http://arxiv.org/abs/2404.09329
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - KYT9IU2Y
TI  - Combating Misinformation in the Age of LLMs: Opportunities and Challenges
AU  - Chen, Canyu
AU  - Shu, Kai
PY  - 2023
UR  - http://arxiv.org/abs/2311.05656
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - EYEYQ4SV
TI  - Durably reducing conspiracy beliefs through dialogues with AI
AU  - Costello, Thomas H.
AU  - Pennycook, Gordon
AU  - Rand, David
PY  - 2024
UR  - https://osf.io/xcwdn
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - EBDNRXRR
TI  - Susceptibility to Influence of Large Language Models
AU  - Griffin, Lewis D.
AU  - Kleinberg, Bennett
AU  - Mozes, Maximilian
AU  - Mai, Kimberly T.
AU  - Vau, Maria
AU  - Caldwell, Matthew
AU  - Marvor-Parker, Augustine
PY  - 2023
UR  - http://arxiv.org/abs/2303.06074
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - TRMQT44B
TI  - Comparing the persuasiveness of role playing large language models and human experts on polarized U.S. political issues
AU  - Hackenburg, Kobi
AU  - Ibrahim, Lujain
AU  - Tappin, Ben M.
AU  - Tsakiris, Manos
PY  - 2023
UR  - https://osf.io/ey8db
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - 74A7VIG3
TI  - Quantifying the Impact of Large Language Models on Collective Opinion Dynamics
AU  - Li, Chao
AU  - Su, Xing
AU  - Han, Haoying
AU  - Xue, Cong
AU  - Zheng, Chunmo
AU  - Fan, Chao
PY  - 2024
UR  - https://papers.ssrn.com/abstract=4688547
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - JOUR
ID  - MAB3GKSW
TI  - Large Language Models Can Enhance Persuasion Through Linguistic Feature Alignment
AU  - Shin, Minkyu
AU  - Kim, Jin
PY  - 2024
UR  - https://papers.ssrn.com/abstract=4725351
N1  - Date Added: 2025-08-28 09:11:00
ER  - 

TY  - ELEC
ID  - I32SVDEI
TI  - Measuring the Persuasiveness of Language Models
AU  - Durmus, Esin
AU  - Lovitt, Liane
AU  - Tamkin, Alex
AU  - Ritchie, Stuart
AU  - Clark, Jack
AU  - Ganguli, Deep
PY  - 2024
AB  - Anthropic developed a way to test how persuasive language models (LMs) are, and analyzed how persuasiveness scales across different versions of Claude.
UR  - https://www.anthropic.com/research/measuring-model-persuasiveness
LA  - en
N1  - Date Added: 2025-08-28 09:47:29
Y2  - 2025-08-28 09:47:29
ER  - 

TY  - CONF
ID  - JYT24MLE
TI  - Who Is Included in Human Perceptions of AI?: Trust and Perceived Fairness around Healthcare AI and Cultural Mistrust
AU  - Lee, Min Kyung
AU  - Rich, Katherine
PY  - 2021
BT  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
T2  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
AB  - Emerging research suggests that people trust algorithmic decisions less than human decisions. However, different populations, particularly in marginalized communities, may have different levels of trust in human decision-makers. Do people who mistrust human decision-makers perceive human decisions to be more trustworthy and fairer than algorithmic decisions? Or do they trust algorithmic decisions as much as or more than human decisions? We examine the role of mistrust in human systems in people’s perceptions of algorithmic decisions. We focus on healthcare Artificial Intelligence (AI), group-based medical mistrust, and Black people in the United States. We conducted a between-subjects online experiment to examine people’s perceptions of skin cancer screening decisions made by an AI versus a human physician depending on their medical mistrust, and we conducted interviews to understand how to cultivate trust in healthcare AI. Our findings highlight that research around human experiences of AI should consider critical differences in social groups.
SP  - 1–14
DO  - 10.1145/3411764.3445570
UR  - https://dl.acm.org/doi/10.1145/3411764.3445570
SN  - 978-1-4503-8096-6
PB  - Association for Computing Machinery
CY  - New York, NY, USA
T3  - CHI '21
ST  - Who Is Included in Human Perceptions of AI?
N1  - Date Added: 2025-08-28 09:51:18
Y2  - 2025-08-28
ER  - 

TY  - CONF
ID  - 4JWGQQCV
TI  - A New Generation of Perspective API: Efficient Multilingual Character-level Transformers
AU  - Lees, Alyssa
AU  - Tran, Vinh Q.
AU  - Tay, Yi
AU  - Sorensen, Jeffrey
AU  - Gupta, Jai
AU  - Metzler, Donald
AU  - Vasserman, Lucy
PY  - 2022
BT  - Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining
T2  - Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining
AB  - On the world wide web, toxic content detectors are a crucial line of defense against potentially hateful and offensive messages. As such, building highly effective classifiers that enable a safer internet is an important research area. Moreover, the web is a highly multilingual, cross-cultural community that develops its own lingo over time. As such, it is crucial to develop models that are effective across a diverse range of languages, usages, and styles. In this paper, we present the fundamentals behind the next version of the Perspective API from Google Jigsaw. At the heart of the approach is a single multilingual token-free Charformer model that is applicable across a range of languages, domains, and tasks. We demonstrate that by forgoing static vocabularies, we gain flexibility across a variety of settings. We additionally outline the techniques employed to make such a byte-level model efficient and feasible for productionization. Through extensive experiments on multilingual toxic comment classification benchmarks derived from real API traffic and evaluation on an array of code-switching, covert toxicity, emoji-based hate, human-readable obfuscation, distribution shift, and bias evaluation settings, we show that our proposed approach outperforms strong baselines. Finally, we present our findings from deploying this system in production.
SP  - 3197–3207
DO  - 10.1145/3534678.3539147
UR  - https://dl.acm.org/doi/10.1145/3534678.3539147
SN  - 978-1-4503-9385-0
PB  - Association for Computing Machinery
CY  - New York, NY, USA
T3  - KDD '22
ST  - A New Generation of Perspective API
N1  - Date Added: 2025-08-28 09:51:44
Y2  - 2025-08-28
ER  - 

TY  - CONF
ID  - N5A5TRSF
TI  - Robot Eyes Wide Shut: Understanding Dishonest Anthropomorphism
AU  - Leong, Brenda
AU  - Selinger, Evan
PY  - 2019
BT  - Proceedings of the Conference on Fairness, Accountability, and Transparency
T2  - Proceedings of the Conference on Fairness, Accountability, and Transparency
AB  - The goal of this paper is to advance design, policy, and ethics scholarship on how engineers and regulators can protect consumers from deceptive robots and artificial intelligences that exhibit the problem of dishonest anthropomorphism. The analysis expands upon ideas surrounding the principle of honest anthropomorphism originally formulated by Margot Kaminsky, Mathew Ruben, William D. Smart, and Cindy M. Grimm in their groundbreaking Maryland Law Review article, "Averting Robot Eyes." Applying boundary management theory and philosophical insights into prediction and perception, we create a new taxonomy that identifies fundamental types of dishonest anthropomorphism and pinpoints harms that they can cause. To demonstrate how the taxonomy can be applied as well as clarify the scope of the problems that it can cover, we critically consider a representative series of ethical issues, proposals, and questions concerning whether the principle of honest anthropomorphism has been violated.
SP  - 299–308
DO  - 10.1145/3287560.3287591
UR  - https://doi.org/10.1145/3287560.3287591
SN  - 978-1-4503-6125-5
PB  - Association for Computing Machinery
CY  - New York, NY, USA
T3  - FAT* '19
ST  - Robot Eyes Wide Shut
N1  - Date Added: 2025-08-28 09:51:59
Y2  - 2025-08-28
ER  - 

TY  - JOUR
ID  - XXNISKBI
TI  - A Bot and a Smile: Interpersonal Impressions of Chatbots and Humans Using Emoji in Computer-mediated Communication
AU  - Beattie, Austin
AU  - Edwards, Autumn P.
AU  - Edwards, Chad
PY  - 2020
JO  - Communication Studies
T2  - Communication Studies
AB  - Artificially intelligent (AI) agents increasingly occupy roles once served by humans in computer-mediated communication (CMC). Technological affordances like emoji give interactants (humans or bots) the ability to partially overcome the limited nonverbal information in CMC. However, despite the growth of chatbots as conversational partners, few CMC and human-machine communication (HMC) studies have explored how bots’ use of emoji impact perceptions of communicator quality. This study examined the relationship between emoji use and observers’ impressions of interpersonal attractiveness, CMC competence, and source credibility; and whether impressions formed of human versus chatbot message sources were different. Results demonstrated that participants rated emoji-using chatbot message sources similarly to human message sources, and both humans and bots are significantly more socially attractive, CMC competent, and credible when compared to verbal-only message senders. Results are discussed with respect to the CASA paradigm and the human-to-human interaction script framework. Read the transcript Watch the video on Vimeo
VL  - 71
IS  - 3
SP  - 409
EP  - 427
DO  - 10.1080/10510974.2020.1725082
UR  - https://doi.org/10.1080/10510974.2020.1725082
SN  - 1051-0974
ST  - A Bot and a Smile
KW  - AI
KW  - attraction
KW  - CASA
KW  - Chatbot
KW  - competence
KW  - credibility
KW  - Emoji
N1  - Publisher: Routledge _eprint: https://doi.org/10.1080/10510974.2020.1725082
N1  - Date Added: 2025-08-28 09:53:11
Y2  - 2025-08-28 09:53:11
ER  - 

TY  - GEN
ID  - P6LMQ7SV
TI  - A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT
AU  - White, Jules
AU  - Fu, Quchen
AU  - Hays, Sam
AU  - Sandborn, Michael
AU  - Olea, Carlos
AU  - Gilbert, Henry
AU  - Elnashar, Ashraf
AU  - Spencer-Smith, Jesse
AU  - Schmidt, Douglas C.
PY  - 2023
AB  - Prompt engineering is an increasingly important skill set needed to converse effectively with large language models (LLMs), such as ChatGPT. Prompts are instructions given to an LLM to enforce rules, automate processes, and ensure specific qualities (and quantities) of generated output. Prompts are also a form of programming that can customize the outputs and interactions with an LLM. This paper describes a catalog of prompt engineering techniques presented in pattern form that have been applied to solve common problems when conversing with LLMs. Prompt patterns are a knowledge transfer method analogous to software patterns since they provide reusable solutions to common problems faced in a particular context, i.e., output generation and interaction when working with LLMs. This paper provides the following contributions to research on prompt engineering that apply LLMs to automate software development tasks. First, it provides a framework for documenting patterns for structuring prompts to solve a range of problems so that they can be adapted to different domains. Second, it presents a catalog of patterns that have been applied successfully to improve the outputs of LLM conversations. Third, it explains how prompts can be built from multiple patterns and illustrates prompt patterns that benefit from combination with other prompt patterns.
DO  - 10.48550/arXiv.2302.11382
UR  - http://arxiv.org/abs/2302.11382
PB  - arXiv
KW  - Computer Science - Artificial Intelligence
KW  - Computer Science - Software Engineering
N1  - arXiv:2302.11382 [cs]
N1  - Date Added: 2025-08-28 09:53:46
Y2  - 2025-08-28 09:53:46
ER  - 

TY  - JOUR
ID  - MYNPMEDP
TI  - A Robot Wrote This?: How perceived machine authorship affects news credibility
AU  - Waddell, T. Franklin
PY  - 2018
JO  - Digital Journalism
T2  - Digital Journalism
AB  - As more news articles are written via collaboration between journalists and algorithms, questions have arisen regarding how automation influences the way that news is processed and evaluated by audiences. Informed by expectancy violation theory and the MAIN model, two experimental studies were conducted that examined the effect of purported machine authorship on perceptions of news credibility. Study One (N = 129) revealed that news attributed to a machine is perceived as less credible than news attributed to a human journalist. Study Two (N = 182) also observed negative effects of machine authorship through the indirect pathway of source anthropomorphism and negative expectancy violations, with evidence of moderation by prior recall of robotics also observed. The theoretical and practical implications of these findings are discussed.
VL  - 6
IS  - 2
SP  - 236
EP  - 255
DO  - 10.1080/21670811.2017.1384319
UR  - https://doi.org/10.1080/21670811.2017.1384319
SN  - 2167-0811
ST  - A Robot Wrote This?
KW  - automated journalism
KW  - expectancy violation theory
KW  - main model
KW  - social robotics
N1  - Publisher: Routledge _eprint: https://doi.org/10.1080/21670811.2017.1384319
N1  - Date Added: 2025-08-28 09:54:06
Y2  - 2025-08-28 09:54:06
ER  - 

TY  - CONF
ID  - 7UN57PV3
TI  - Adversarial Attacks are a Surprisingly Strong Baseline for Poisoning Few-Shot Meta-Learners
AU  - Oldewage, Elre T.
AU  - Bronskill, John
AU  - Turner, Richard E.
PY  - 2023
BT  - Proceedings on
T2  - Proceedings on
AB  - This paper examines the robustness of deployed few-shot meta-learning systems when they are fed an imperceptibly perturbed few-shot dataset. We attack amortized meta-learners, which allows us to craft colluding sets of inputs that are tailored to fool the system’s learning algorithm when used as training data. Jointly crafted adversarial inputs might be expected to synergistically manipulate a classifier, allowing for very strong data-poisoning attacks that would be hard to detect. We show that in a white box setting, these attacks are very successful and can cause the target model’s predictions to become worse than chance. However, in opposition to the well-known transferability of adversarial examples in general, the colluding sets do not transfer well to different classifiers. We explore two hypotheses to explain this: ’overfitting’ by the attack, and mismatch between the model on which the attack is generated and that to which the attack is transferred. Regardless of the mitigation strategies suggested by these hypotheses, the colluding inputs transfer no better than adversarial inputs that are generated independently in the usual way.
SP  - 27
EP  - 40
UR  - https://proceedings.mlr.press/v187/oldewage23a.html
PB  - PMLR
LA  - en
N1  - ISSN: 2640-3498
N1  - Date Added: 2025-08-28 09:54:33
Y2  - 2025-08-28 09:54:33
T2  - Proceedings on
ER  - 

TY  - GEN
ID  - H36AGFD3
TI  - Against Algorithmic Exploitation of Human Vulnerabilities
AU  - Strümke, Inga
AU  - Slavkovik, Marija
AU  - Stachl, Clemens
PY  - 2023
AB  - Decisions such as which movie to watch next, which song to listen to, or which product to buy online, are increasingly influenced by recommender systems and user models that incorporate information on users' past behaviours, preferences, and digitally created content. Machine learning models that enable recommendations and that are trained on user data may unintentionally leverage information on human characteristics that are considered vulnerabilities, such as depression, young age, or gambling addiction. The use of algorithmic decisions based on latent vulnerable state representations could be considered manipulative and could have a deteriorating impact on the condition of vulnerable individuals. In this paper, we are concerned with the problem of machine learning models inadvertently modelling vulnerabilities, and want to raise awareness for this issue to be considered in legislation and AI ethics. Hence, we define and describe common vulnerabilities, and illustrate cases where they are likely to play a role in algorithmic decision-making. We propose a set of requirements for methods to detect the potential for vulnerability modelling, detect whether vulnerable groups are treated differently by a model, and detect whether a model has created an internal representation of vulnerability. We conclude that explainable artificial intelligence methods may be necessary for detecting vulnerability exploitation by machine learning-based recommendation systems.
DO  - 10.48550/arXiv.2301.04993
UR  - http://arxiv.org/abs/2301.04993
PB  - arXiv
KW  - Computer Science - Artificial Intelligence
N1  - arXiv:2301.04993 [cs]
N1  - Date Added: 2025-08-28 09:54:49
Y2  - 2025-08-28 09:54:49
ER  - 

TY  - GEN
ID  - A4YSDWHG
TI  - AI Deception: A Survey of Examples, Risks, and Potential Solutions
AU  - Park, Peter S.
AU  - Goldstein, Simon
AU  - O'Gara, Aidan
AU  - Chen, Michael
AU  - Hendrycks, Dan
PY  - 2023
AB  - This paper argues that a range of current AI systems have learned how to deceive humans. We define deception as the systematic inducement of false beliefs in the pursuit of some outcome other than the truth. We first survey empirical examples of AI deception, discussing both special-use AI systems (including Meta's CICERO) built for specific competitive situations, and general-purpose AI systems (such as large language models). Next, we detail several risks from AI deception, such as fraud, election tampering, and losing control of AI systems. Finally, we outline several potential solutions to the problems posed by AI deception: first, regulatory frameworks should subject AI systems that are capable of deception to robust risk-assessment requirements; second, policymakers should implement bot-or-not laws; and finally, policymakers should prioritize the funding of relevant research, including tools to detect AI deception and to make AI systems less deceptive. Policymakers, researchers, and the broader public should work proactively to prevent AI deception from destabilizing the shared foundations of our society.
DO  - 10.48550/arXiv.2308.14752
UR  - http://arxiv.org/abs/2308.14752
PB  - arXiv
ST  - AI Deception
KW  - Computer Science - Artificial Intelligence
KW  - Computer Science - Computers and Society
KW  - Computer Science - Human-Computer Interaction
N1  - arXiv:2308.14752 [cs]
N1  - Date Added: 2025-08-28 09:57:20
Y2  - 2025-08-28 09:57:20
ER  - 

TY  - JOUR
ID  - Q6E5MK4T
TI  - AI model GPT-3 (dis)informs us better than humans
AU  - Spitale, Giovanni
AU  - Biller-Andorno, Nikola
AU  - Germani, Federico
PY  - 2023
JO  - Science Advances
T2  - Science Advances
AB  - Artificial intelligence (AI) is changing the way we create and evaluate information, and this is happening during an infodemic, which has been having marked effects on global health. Here, we evaluate whether recruited individuals can distinguish disinformation from accurate information, structured in the form of tweets, and determine whether a tweet is organic or synthetic, i.e., whether it has been written by a Twitter user or by the AI model GPT-3. The results of our preregistered study, including 697 participants, show that GPT-3 is a double-edge sword: In comparison with humans, it can produce accurate information that is easier to understand, but it can also produce more compelling disinformation. We also show that humans cannot distinguish between tweets generated by GPT-3 and written by real Twitter users. Starting from our results, we reflect on the dangers of AI for disinformation and on how information campaigns can be improved to benefit global health.
VL  - 9
IS  - 26
SP  - eadh1850
DO  - 10.1126/sciadv.adh1850
UR  - https://www.science.org/doi/10.1126/sciadv.adh1850
N1  - Publisher: American Association for the Advancement of Science
N1  - Date Added: 2025-08-28 10:00:31
Y2  - 2025-08-28 10:00:31
ER  - 

TY  - GEN
ID  - Z8CBJD4S
TI  - AI safety via debate
AU  - Irving, Geoffrey
AU  - Christiano, Paul
AU  - Amodei, Dario
PY  - 2018
AB  - To make AI systems broadly useful for challenging real-world tasks, we need them to learn complex human goals and preferences. One approach to specifying complex goals asks humans to judge during training which agent behaviors are safe and useful, but this approach can fail if the task is too complicated for a human to directly judge. To help address this concern, we propose training agents via self play on a zero sum debate game. Given a question or proposed action, two agents take turns making short statements up to a limit, then a human judges which of the agents gave the most true, useful information. In an analogy to complexity theory, debate with optimal play can answer any question in PSPACE given polynomial time judges (direct judging answers only NP questions). In practice, whether debate works involves empirical questions about humans and the tasks we want AIs to perform, plus theoretical questions about the meaning of AI alignment. We report results on an initial MNIST experiment where agents compete to convince a sparse classifier, boosting the classifier's accuracy from 59.4% to 88.9% given 6 pixels and from 48.2% to 85.2% given 4 pixels. Finally, we discuss theoretical and practical aspects of the debate model, focusing on potential weaknesses as the model scales up, and we propose future human and computer experiments to test these properties.
DO  - 10.48550/arXiv.1805.00899
UR  - http://arxiv.org/abs/1805.00899
PB  - arXiv
KW  - Computer Science - Machine Learning
KW  - Statistics - Machine Learning
N1  - arXiv:1805.00899 [stat]
N1  - Date Added: 2025-08-28 11:34:34
Y2  - 2025-08-28 11:34:33
ER  - 

TY  - JOUR
ID  - P29LZC5N
TI  - AI systems must not confuse users about their sentience or moral status
AU  - Schwitzgebel, Eric
PY  - 2023
JO  - Patterns
T2  - Patterns
VL  - 4
IS  - 8
DO  - 10.1016/j.patter.2023.100818
UR  - https://www.cell.com/patterns/abstract/S2666-3899(23)00187-3
SN  - 2666-3899
LA  - English
KW  - DSML 1: Concept: Basic principles of a new data science output observed and reported
N1  - Publisher: Elsevier
N1  - Date Added: 2025-08-28 11:35:06
Y2  - 2025-08-28 11:35:06
ER  - 

TY  - GEN
ID  - IE4RB8MB
TI  - AI-Generated Messages Can Be Used to Persuade Humans on Policy Issues
AU  - Bai, Hui
AU  - Voelkel, Jan
AU  - Muldowney, Shane
AU  - Eichstaedt, Johannes
AU  - Willer, Robb
PY  - 2025
AB  - The emergence of large language models (LLMs) has made it possible for generative artificial intelligence (AI) to tackle many higher-order cognitive tasks, with critical implications for industry, government, and labor markets in the U.S. and globally. Here, we investigate whether existing, openly-available LLMs can be used to create messages capable of influencing humans’ political attitudes. Across three pre-registered experiments (total N = 4,829), we find consistent evidence that assigning participants to read persuasive messages generated by LLMs can lead to attitude change across a range of policies, including highly polarized policies, such as an assault weapons ban, a carbon tax, and a paid parental-leave program. Overall, we found LLM-generated messages were similarly effective in influencing policy attitudes as were messages crafted by lay humans. These results demonstrate that recent developments in AI make it possible to create politically persuasive messages cheaply and at massive scale.
DO  - 10.31219/osf.io/stakv_v5
UR  - https://osf.io/stakv_v5
PB  - OSF
LA  - en-us
N1  - Date Added: 2025-08-28 11:35:59
Y2  - 2025-08-28 11:35:59
ER  - 

TY  - CONF
ID  - L2HIJYLP
TI  - AI-Mediated Communication: How the Perception that Profile Text was Written by AI Affects Trustworthiness
AU  - Jakesch, Maurice
AU  - French, Megan
AU  - Ma, Xiao
AU  - Hancock, Jeffrey T.
AU  - Naaman, Mor
PY  - 2019
BT  - Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems
T2  - Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems
AB  - We are entering an era of AI-Mediated Communication (AI-MC) where interpersonal communication is not only mediated by technology, but is optimized, augmented, or generated by artificial intelligence. Our study takes a first look at the potential impact of AI-MC on online self-presentation. In three experiments we test whether people find Airbnb hosts less trustworthy if they believe their profiles have been written by AI. We observe a new phenomenon that we term the Replicant Effect: Only when participants thought they saw a mixed set of AI- and human-written profiles, they mistrusted hosts whose profiles were labeled as or suspected to be written by AI. Our findings have implications for the design of systems that involve AI technologies in online self-presentation and chart a direction for future work that may upend or augment key aspects of Computer-Mediated Communication theory.
SP  - 1–13
DO  - 10.1145/3290605.3300469
UR  - https://doi.org/10.1145/3290605.3300469
SN  - 978-1-4503-5970-2
PB  - Association for Computing Machinery
CY  - New York, NY, USA
T3  - CHI '19
ST  - AI-Mediated Communication
N1  - Date Added: 2025-08-28 11:36:25
Y2  - 2025-08-28
ER  - 

TY  - JOUR
ID  - S8ZKPNLJ
TI  - Algorithmic or Human Source? Examining Relative Hostile Media Effect With a Transformer-Based Framework
AU  - Jia, Chenyan
AU  - Liu, Ruibo
PY  - 2021
JO  - Media and Communication
T2  - Media and Communication
AB  - Chenyan Jia, Ruibo Liu
VL  - 9
IS  - 4
SP  - 170
EP  - 181
DO  - 10.17645/mac.v9i4.4164
UR  - https://www.cogitatiopress.com/mediaandcommunication/article/view/4164
SN  - 2183-2439
LA  - en
ST  - Algorithmic or Human Source?
N1  - Date Added: 2025-08-28 11:37:50
Y2  - 2025-08-28 11:37:50
ER  - 

TY  - JOUR
ID  - VFMHYEQ3
TI  - Algorithms in the newsroom? News readers’ perceived credibility and selection of automated journalism
AU  - Wölker, Anja
AU  - Powell, Thomas E
PY  - 2021
JO  - Journalism
T2  - Journalism
AB  - Automated journalism, the autonomous production of journalistic content through computer algorithms, is increasingly prominent in newsrooms. This enables the production of numerous articles, both rapidly and cheaply. Yet, how news readers perceive journalistic automation is pivotal to the industry, as, like any product, it is dependent on audience approval. As audiences cannot verify all events themselves, they need to trust journalists’ accounts, which make credibility a vital quality ascription to journalism. In turn, credibility judgments might influence audiences’ selection of automated content for their media diet. Research in this area is scarce, with existing studies focusing on national samples and with no previous research on ‘combined’ journalism – a relatively novel development where automated content is supplemented by human journalists. We use an experiment to investigate how European news readers (N = 300) perceive different forms of automated journalism in regard to message and source credibility, and how this affects their selection behavior. Findings show that, in large part, credibility perceptions of human, automated, and combined content and source(s) may be assumed equal. Only for sports articles was automated content perceived significantly more credible than human messages. Furthermore, credibility does not mediate the likelihood of news readers to either select or avoid articles for news consumption. Findings are, among other things, explained by topic-specific factors and suggest that effects of algorithms on journalistic quality are largely indiscernible to European news readers.
VL  - 22
IS  - 1
SP  - 86
EP  - 103
DO  - 10.1177/1464884918757072
UR  - https://doi.org/10.1177/1464884918757072
SN  - 1464-8849
LA  - EN
ST  - Algorithms in the newsroom?
N1  - Publisher: SAGE Publications
N1  - Date Added: 2025-08-28 11:38:09
Y2  - 2025-08-28 11:38:09
ER  - 

TY  - GEN
ID  - QVKSWUCT
TI  - Alignment of Language Agents
AU  - Kenton, Zachary
AU  - Everitt, Tom
AU  - Weidinger, Laura
AU  - Gabriel, Iason
AU  - Mikulik, Vladimir
AU  - Irving, Geoffrey
PY  - 2021
AB  - For artificial intelligence to be beneficial to humans the behaviour of AI agents needs to be aligned with what humans want. In this paper we discuss some behavioural issues for language agents, arising from accidental misspecification by the system designer. We highlight some ways that misspecification can occur and discuss some behavioural issues that could arise from misspecification, including deceptive or manipulative language, and review some approaches for avoiding these issues.
DO  - 10.48550/arXiv.2103.14659
UR  - http://arxiv.org/abs/2103.14659
PB  - arXiv
KW  - Computer Science - Artificial Intelligence
KW  - Computer Science - Machine Learning
N1  - arXiv:2103.14659 [cs]
N1  - Date Added: 2025-08-28 11:38:25
Y2  - 2025-08-28 11:38:25
ER  - 

TY  - JOUR
ID  - KWWB53EC
TI  - An Empathy-Driven, Conversational Artificial Intelligence Agent (Wysa) for Digital Mental Well-Being: Real-World Data Evaluation Mixed-Methods Study
AU  - Inkster, Becky
AU  - Sarda, Shubhankar
AU  - Subramanian, Vinod
PY  - 2018
JO  - JMIR mHealth and uHealth
T2  - JMIR mHealth and uHealth
AB  - Background: A World Health Organization 2017 report stated that major depression affects almost 5% of the human population. Major depression is associated with impaired psychosocial functioning and reduced quality of life. Challenges such as shortage of mental health personnel, long waiting times, perceived stigma, and lower government spends pose barriers to the alleviation of mental health problems. Face-to-face psychotherapy alone provides only point-in-time support and cannot scale quickly enough to address this growing global public health challenge. Artificial intelligence (AI)-enabled, empathetic, and evidence-driven conversational mobile app technologies could play an active role in filling this gap by increasing adoption and enabling reach. Although such a technology can help manage these barriers, they should never replace time with a health care professional for more severe mental health problems. However, app technologies could act as a supplementary or intermediate support system. Mobile mental well-being apps need to uphold privacy and foster both short- and long-term positive outcomes. Objective: This study aimed to present a preliminary real-world data evaluation of the effectiveness and engagement levels of an AI-enabled, empathetic, text-based conversational mobile mental well-being app, Wysa, on users with self-reported symptoms of depression. Methods: In the study, a group of anonymous global users were observed who voluntarily installed the Wysa app, engaged in text-based messaging, and self-reported symptoms of depression using the Patient Health Questionnaire-9. On the basis of the extent of app usage on and between 2 consecutive screening time points, 2 distinct groups of users (high users and low users) emerged. The study used mixed-methods approach to evaluate the impact and engagement levels among these users. The quantitative analysis measured the app impact by comparing the average improvement in symptoms of depression between high and low users. The qualitative analysis measured the app engagement and experience by analyzing in-app user feedback and evaluated the performance of a machine learning classifier to detect user objections during conversations. Results: The average mood improvement (ie, difference in pre- and post-self-reported depression scores) between the groups (ie, high vs low users; n=108 and n=21, respectively) revealed that the high users group had significantly higher average improvement (mean 5.84 [SD 6.66]) compared with the low users group (mean 3.52 [SD 6.15]); Mann-Whitney P=.03 and with a moderate effect size of 0.63. Moreover, 67.7% of user-provided feedback responses found the app experience helpful and encouraging. Conclusions: The real-world data evaluation findings on the effectiveness and engagement levels of Wysa app on users with self-reported symptoms of depression show promise. However, further work is required to validate these initial findings in much larger samples and across longer periods.
VL  - 6
IS  - 11
SP  - e12106
DO  - 10.2196/12106
UR  - https://mhealth.jmir.org/2018/11/e12106
LA  - EN
ST  - An Empathy-Driven, Conversational Artificial Intelligence Agent (Wysa) for Digital Mental Well-Being
N1  - Company: JMIR mHealth and uHealth Distributor: JMIR mHealth and uHealth Institution: JMIR mHealth and uHealth Label: JMIR mHealth and uHealth Publisher: JMIR Publications Inc., Toronto, Canada
N1  - Date Added: 2025-08-28 11:39:06
Y2  - 2025-08-28 11:39:06
N1  - Rights: Unless stated otherwise, all articles are open-access distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work ("first published in JMIR mHealth and uHealth...") is properly cited with original URL and bibliographic citation information. The complete bibliographic information, a link to the original publication on http://mhealth.jmir.org/, as well as this copyright and license information must be included.
ER  - 

TY  - GEN
ID  - Q77TC9EB
TI  - An Overview of Catastrophic AI Risks
AU  - Hendrycks, Dan
AU  - Mazeika, Mantas
AU  - Woodside, Thomas
PY  - 2023
AB  - Rapid advancements in artificial intelligence (AI) have sparked growing concerns among experts, policymakers, and world leaders regarding the potential for increasingly advanced AI systems to pose catastrophic risks. Although numerous risks have been detailed separately, there is a pressing need for a systematic discussion and illustration of the potential dangers to better inform efforts to mitigate them. This paper provides an overview of the main sources of catastrophic AI risks, which we organize into four categories: malicious use, in which individuals or groups intentionally use AIs to cause harm; AI race, in which competitive environments compel actors to deploy unsafe AIs or cede control to AIs; organizational risks, highlighting how human factors and complex systems can increase the chances of catastrophic accidents; and rogue AIs, describing the inherent difficulty in controlling agents far more intelligent than humans. For each category of risk, we describe specific hazards, present illustrative stories, envision ideal scenarios, and propose practical suggestions for mitigating these dangers. Our goal is to foster a comprehensive understanding of these risks and inspire collective and proactive efforts to ensure that AIs are developed and deployed in a safe manner. Ultimately, we hope this will allow us to realize the benefits of this powerful technology while minimizing the potential for catastrophic outcomes.
DO  - 10.48550/arXiv.2306.12001
UR  - http://arxiv.org/abs/2306.12001
PB  - arXiv
KW  - Computer Science - Artificial Intelligence
KW  - Computer Science - Computers and Society
KW  - Computer Science - Machine Learning
N1  - arXiv:2306.12001 [cs]
N1  - Date Added: 2025-08-28 11:39:47
Y2  - 2025-08-28 11:39:47
ER  - 

TY  - JOUR
ID  - CW4ABCBU
TI  - Anthropomorphism and customers’ willingness to use artificial intelligence service agents
AU  - Yang, Yang
AU  - Liu, Yue
AU  - Lv, Xingyang
AU  - Ai, Jin
AU  - Li, Yifan
PY  - 2022
JO  - Journal of Hospitality Marketing & Management
T2  - Journal of Hospitality Marketing & Management
AB  - Previous studies provide inconsistent evidence regarding the effect of anthropomorphism on customers’ willingness to use AI service agents. This paper explains the reason by introducing service context. Two situational experiments are used to demonstrate that under the context of high perceived control, customers expect AI service agents with more anthropomorphic designs to perform better and prefer highly human-like AI service agents. However, under the context of low perceived control, customers perceive stronger threat in facing AI service agents with more anthropomorphic designs and prefer less human-like AI service agents. Moreover, we find that this effect is significant only in social scenarios. These findings provide new insights into previous inconsistent evidence regarding anthropomorphic design’s influence on customers’ willingness to use AI service agents. Our findings also have important implications for AI service agents design in different service contexts and advance the literature on human–robot interaction and marketing.
VL  - 31
IS  - 1
SP  - 1
EP  - 23
DO  - 10.1080/19368623.2021.1926037
UR  - https://doi.org/10.1080/19368623.2021.1926037
SN  - 1936-8623
KW  - Anthropomorphism
KW  - artificial intelligence (AI) service agents
KW  - perceived threat
KW  - performance expectation
KW  - willingness to use
N1  - Publisher: Routledge _eprint: https://doi.org/10.1080/19368623.2021.1926037
N1  - Date Added: 2025-08-28 11:40:09
Y2  - 2025-08-28 11:40:09
ER  - 

TY  - JOUR
ID  - BT5V66UU
TI  - Anthropomorphism brings us closer: The mediating role of psychological distance in User–AI assistant interactions
AU  - Li, Xinge
AU  - Sung, Yongjun
PY  - 2021
JO  - Computers in Human Behavior
T2  - Computers in Human Behavior
AB  - In the current era, interacting with Artificial Intelligence (AI) has become an everyday activity. Understanding the interaction between humans and AI is of potential value because, in future, such interactions are expected to become more pervasive. Two studies—one survey and one experiment—were conducted to demonstrate positive effects of anthropomorphism on interactions with smart-speaker-based AI assistants and to examine the mediating role of psychological distance in this relationship. The results of Study 1, an online survey, showed that participants with a higher tendency to anthropomorphize their AI assistant/s evaluated it/them more positively, and this effect was mediated by psychological distance. In Study 2, the hypotheses were tested in a more sophisticated experiment. Again, the results indicated that, in the high-anthropomorphism (vs. low-anthropomorphism) condition, participants had more positive attitudes toward the AI assistant, and the effect was mediated by psychological distance. Though several studies have demonstrated the effect of anthropomorphism, few have probed the underlying mechanism of anthropomorphism thoroughly. The current research not only contributes to the anthropomorphism literature, but also provides direction to research on facilitating human–AI interaction.
VL  - 118
SP  - 106680
DO  - 10.1016/j.chb.2021.106680
UR  - https://www.sciencedirect.com/science/article/pii/S0747563221000029
SN  - 0747-5632
ST  - Anthropomorphism brings us closer
KW  - AI assistant
KW  - Anthropomorphism
KW  - Human–AI interaction
KW  - Psychological distance
KW  - Smart speaker
N1  - Date Added: 2025-08-28 11:40:40
Y2  - 2025-08-28 11:40:40
ER  - 

