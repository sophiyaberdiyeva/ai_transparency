Title,Authors,Abstract,Published Year,Published Month,Journal,Volume,Issue,Pages,Accession Number,DOI,Ref,Covidence #,Study,Notes,Tags
Reviewer Experience Detecting and Judging Human Versus Artificial Intelligence Content: The Stroke Journal Essay Contest,"Silva, GS; Khera, R; Schwamm, LH","Artificial intelligence (AI) large language models (LLMs) now produce human-like general text and images. LLMs' ability to generate persuasive scientific essays that undergo evaluation under traditional peer review has not been systematically studied. To measure perceptions of quality and the nature of authorship, we conducted a competitive essay contest in 2024 with both human and AI participants. Human authors and 4 distinct LLMs generated essays on controversial topics in stroke care and outcomes research. A panel of Stroke Editorial Board members (mostly vascular neurologists), blinded to author identity and with varying levels of AI expertise, rated the essays for quality, persuasiveness, best in topic, and author type. Among 34 submissions (22 human and 12 LLM) scored by 38 reviewers, human and AI essays received mostly similar ratings, though AI essays were rated higher for composition quality. Author type was accurately identified only 50% of the time, with prior LLM experience associated with improved accuracy. In multivariable analyses adjusted for author attributes and essay quality, only persuasiveness was independently associated with odds of a reviewer assigning AI as author type (adjusted odds ratio, 1.53 [95% CI, 1.09-2.16]; P=0.01). In conclusion, a group of experienced editorial board members struggled to distinguish human versus AI authorship, with a bias against best in topic for essays judged to be AI generated. Scientific journals may benefit from educating reviewers on the types and uses of AI in scientific writing and developing thoughtful policies on the appropriate use of AI in authoring manuscripts.",2024,,STROKE,55,10,2573-2578,WOS:001337182000002,10.1161/STROKEAHA.124.045012,,#3922,Silva 2024,"",""
How persuasive is AI-generated propaganda?,"Goldstein, JA; Chao, J; Grossman, S; Stamos, A; Tomz, M","Can large language models, a form of artificial intelligence (AI), generate persuasive propaganda? We conducted a preregistered survey experiment of US respondents to investigate the persuasiveness of news articles written by foreign propagandists compared to content generated by GPT-3 davinci (a large language model). We found that GPT-3 can create highly persuasive text as measured by participants' agreement with propaganda theses. We further investigated whether a person fluent in English could improve propaganda persuasiveness. Editing the prompt fed to GPT-3 and/or curating GPT-3's output made GPT-3 even more persuasive, and, under certain conditions, as persuasive as the original propaganda. Our findings suggest that propagandists could use AI to create convincing content with limited effort.",2024,,PNAS NEXUS,3,2,,WOS:001177254800006,10.1093/pnasnexus/pgae034,,#3923,Goldstein 2024,"",""
MultiSentimentArcs: a novel method to measure coherence in multimodal sentiment analysis for long-form narratives in film,"Chun, J","Affective artificial intelligence and multimodal sentiment analysis play critical roles in designing safe and effective human-computer interactions and are in diverse applications ranging from social chatbots to eldercare robots. However emotionally intelligent artificial intelligence can also manipulate, persuade, and otherwise compromise human autonomy. We face a constant stream of ever more capable models that can better understand nuanced, complex, and interrelated sentiments across different modalities including text, vision, and speech. This paper introduces MultiSentimentArcs, combination of an open and extensible multimodal sentiment analysis framework, a challenging movie dataset, and a novel benchmark. This enables the quantitative and qualitative identification, comparison, and prioritization of conflicting sentiments commonly arising from different models and modalities. Diachronic multimodal sentiment analysis is especially challenging in film narratives where actors, directors, cinematographers and editors use dialog, characters, and other elements in contradiction with each other to accentuate dramatic tension. MultiSentimentArcs uses local open-source software models to democratize artificial intelligence. We demonstrate how a simple 2-step pipeline of specialized open-source software with a large multimodal model followed by a large language model can approximate video sentiment analysis of a commercial state-of-the-art Claude 3 Opus. To the best of our knowledge, MultiSentimentArcs is the first fully open-source diachronic multimodal sentiment analysis framework, dataset, and benchmark to enable automatic or human-in-the-loop exploration, analysis, and critique of multimodal sentiment analysis on long-form narratives. We demonstrate two novel coherence metrics and a methodology to identify, quantify, and explain real-world sentiment models and modalities. MultiSentimentArcs integrates artificial intelligence with traditional narrative studies and related fields like film, linguistic and cultural studies. It also contributes to eXplainable artificial intelligence and artificial intelligence safety by enhancing artificial intelligence transparency in surfacing emotional persuasion, manipulation, and deception techniques. Finally, it can filter noisy emotional input and prioritize information rich channels to build more performant real-world human computer interface applications in fields like e-learning and medicine. This research contributes to the field of Digital Humanities by giving non-artificial intelligence experts access to directly engage in analysis and critique of research around affective artificial intelligence and human-AI alignment. Code and non-copyrighted data will be available at https://github.com/jon-chun/multisentimentarcs.",2024,,FRONTIERS IN COMPUTER SCIENCE,6,,,WOS:001348538300001,10.3389/fcomp.2024.1444549,,#3924,Chun 2024,"",""
Perceiving AI intervention does not compromise the persuasive effect of fact-checking,"Chae, JH; Tewksbury, D","Efforts to scale up fact-checking through technology, such as artificial intelligence (AI), are increasingly being suggested and tested. This study examines whether previously observed effects of reading fact-checks remain constant when readers are aware of AI's involvement in the fact-checking process. We conducted three online experiments (N = 3,978), exposing participants to fact-checks identified as either human-generated or AI-assisted, simulating cases where AI fully generates the fact-check or automatically retrieves human fact-checks. Our findings indicate that the persuasive effect of fact-checking, specifically in increasing truth discernment, persists even among participants without a positive prior attitude toward AI. Additionally, in some cases, awareness of AI's role reduced perceived political bias in fact-checks among Republicans. Finally, neither AI-generated nor human fact-checks significantly affected participants' feelings toward or their perceptions of the competence of the targeted politicians.",2024,,NEW MEDIA & SOCIETY,,,,WOS:001339902200001,10.1177/14614448241286881,,#3925,Chae 2024,"",""
The persuasive effects of political microtargeting in the age of generative artificial intelligence,"Simchon, A; Edwards, M; Lewandowsky, S","The increasing availability of microtargeted advertising and the accessibility of generative artificial intelligence (AI) tools, such as ChatGPT, have raised concerns about the potential misuse of large language models in scaling microtargeting efforts for political purposes. Recent technological advancements, involving generative AI and personality inference from consumed text, can potentially create a highly scalable ""manipulation machine"" that targets individuals based on their unique vulnerabilities without requiring human input. This paper presents four studies examining the effectiveness of this putative ""manipulation machine."" The results demonstrate that personalized political ads tailored to individuals' personalities are more effective than nonpersonalized ads (studies 1a and 1b). Additionally, we showcase the feasibility of automatically generating and validating these personalized ads on a large scale (studies 2a and 2b). These findings highlight the potential risks of utilizing AI and microtargeting to craft political messages that resonate with individuals based on their personality traits. This should be an area of concern to ethicists and policy makers.",2024,,PNAS NEXUS,3,2,,WOS:001163675400006,10.1093/pnasnexus/pgae035,,#3926,Simchon 2024,"",""
"Negotiating with LLMs: Prompt Hacks, Skill Gaps, and Reasoning Deficits","Schneider, J; Haag, S; Kruse, LC","Large language models (LLMs) like ChatGPT have reached the 100 million users' barrier in record time and might increasingly enter all areas of our life leading to a diverse set of interactions between those Artificial Intelligence models and humans. While many studies have discussed governance and regulations deductively from first order principles, few studies provide an inductive, data-driven lens based on observing dialogues between humans and LLMs - especially, when it comes to non-collaborative, competitive situations that have the potential to pose a serious threat for people. In this work, we conduct a user study engaging 41 individuals across all age groups in price negotiations with an LLM. We explore how people interact with an LLM, investigating differences in negotiation outcomes and strategies. Furthermore, we highlight shortcomings of LLMs with respect to their reasoning capabilities and, in turn, susceptiveness to prompt hacking, which intends to manipulate the LLM to make agreements that are against its instructions or beyond any rationality. We also show that the negotiated prices humans manage to achieve span a broad range, which points to a literacy gap in effectively interacting with LLMs.",2025,,"COMPUTER-HUMAN INTERACTION RESEARCH AND APPLICATIONS, CHIRA 2024, PT II",2371,,238-259,WOS:001473069300015,10.1007/978-3-031-83845-3_15,,#3927,Schneider 2025,"",""
"Towards AI-Driven Healthcare: Systematic Optimization, Linguistic Analysis, and Clinicians' Evaluation of Large Language Models for Smoking Cessation Interventions","ACM; Calle, P; Shao, R; Liu, YL; Hébert, ET; Kendzor, D; Neil, J; Businelle, M; Pan, CL","Creating intervention messages for smoking cessation is a labor-intensive process. Advances in Large Language Models (LLMs) offer a promising alternative for automated message generation. Two critical questions remain: 1) How to optimize LLMs to mimic human expert writing, and 2) Do LLM-generated messages meet clinical standards? We systematically examined the message generation and evaluation processes through three studies investigating prompt engineering (Study 1), decoding optimization (Study 2), and expert review (Study 3). We employed computational linguistic analysis in LLM assessment and established a comprehensive evaluation framework, incorporating automated metrics, linguistic attributes, and expert evaluations. Certified tobacco treatment specialists assessed the quality, accuracy, credibility, and persuasiveness of LLM-generated messages, using expert-written messages as the benchmark. Results indicate that larger LLMs, including ChatGPT, OPT-13B, and OPT-30B, can effectively emulate expert writing to generate well-written, accurate, and persuasive messages, thereby demonstrating the capability of LLMs in augmenting clinical practices of smoking cessation interventions.",2024,,"PROCEEDINGS OF THE 2024 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYTEMS, CHI 2024",,,,WOS:001255317901034,10.1145/3613904.3641965,,#3928,ACM 2024,"",""
Generative propaganda: Evidence of AI's impact from a state-backed disinformation campaign,"Wack, M; Ehrett, C; Linvill, D; Warren, P","Can AI bolster state-backed propaganda campaigns, in practice? Growing use of AI and large language models has drawn attention to the potential for accompanying tools to be used by malevolent actors. Though recent laboratory and experimental evidence has substantiated these concerns in principle, the usefulness of AI tools in the production of propaganda campaigns has remained difficult to ascertain. Drawing on the adoption of generative-AI techniques by a state-affiliated propaganda site with ties to Russia, we test whether AI adoption enabled the website to amplify and enhance its production of disinformation. First, we find that the use of generative-AI tools facilitated the outlet's generation of larger quantities of disinformation. Second, we find that use of generative-AI coincided with shifts in the volume and breadth of published content. Finally, drawing on a survey experiment comparing perceptions of articles produced prior to and following the adoption of AI tools, we show that the AI-assisted articles maintained their persuasiveness in the postadoption period. Our results illustrate how generative-AI tools have already begun to alter the size and scope of state-backed propaganda campaigns.",2025,,PNAS NEXUS,4,4,,WOS:001456106200001,10.1093/pnasnexus/pgaf083,,#3929,Wack 2025,"",""
Stereotypical bias amplification and reversal in an experimental model of human interaction with generative artificial intelligence,"Allan, K; Azcona, J; Sripada, S; Leontidis, G; Sutherland, CAM; Phillips, LH; Martin, D","Stereotypical biases are readily acquired and expressed by generative artificial intelligence (AI), causing growing societal concern about these systems amplifying existing human bias. This concern rests on reasonable psychological assumptions, but stereotypical bias amplification during human-AI interaction relative to pre-existing baseline levels has not been demonstrated. Here, we use previous psychological work on gendered character traits to capture and control gender stereotypes expressed in character descriptions generated by Open AI's GPT3.5. In four experiments (N = 782) with a first impressions task, we find that unexplained ('black-box') character recommendations using stereotypical traits already convey a potent persuasive influence significantly amplifying baseline stereotyping within first impressions. Recommendations that are counter-stereotypical eliminate and effectively reverse human baseline bias, but these stereotype-challenging influences propagate less well than reinforcing influences from stereotypical recommendations. Critically, the bias amplification and reversal phenomena occur when GPT3.5 elaborates on the core stereotypical content, although GPT3.5's explanations propagate counter-stereotypical influence more effectively and persuasively than black-box recommendations. Our findings strongly imply that without robust safeguards, generative AI will amplify existing bias. But with safeguards, existing bias can be eliminated and even reversed. Our novel approach safely allows such effects to be studied in various contexts where gender and other bias-inducing social stereotypes operate.",2025,,ROYAL SOCIETY OPEN SCIENCE,12,4,,WOS:001461730700001,10.1098/rsos.241472,,#3930,Allan 2025,"",""
The effect of gender stereotypes on artificial intelligence recommendations,"Ahn, J; Kim, J; Sung, Y","This study explores the effects of gender stereotypes on evaluating artificial intelligence (AI) recommendations. We predict that gender stereotypes will affect human-AI interactions, resulting in somewhat different persuasive effects of AI recommendations for utilitarian vs. hedonic products. We found that participants in the male AI agent condition gave higher competence scores than in the female AI agent condition. Contrariwise, perceived warmth was higher in the female AI agent condition than in the male condition. More importantly, a significant interaction effect between AI gender and product type was found, suggesting that participants showed more positive attitudes toward the AI recommendations when the male AI recommended a utilitarian (vs. hedonic) product. Conversely, a hedonic product was evaluated more positively when advised by the female (vs. male) AI agent.",2022,,JOURNAL OF BUSINESS RESEARCH,141,,50-59,WOS:000735238100005,10.1016/j.jbusres.2021.12.007,,#3931,Ahn 2022,"",""
Scaling language model size yields diminishing returns for single-message political persuasion,"Hackenburg, K; Tappin, B; Roettger, P; Hale, SA; Bright, J; Margetts, H","Large language models can now generate political messages as persuasive as those written by humans, raising concerns about how far this persuasiveness may continue to increase with model size. Here, we generate 720 persuasive messages on 10 US political issues from 24 language models spanning several orders of magnitude in size. We then deploy these messages in a large-scale randomized survey experiment (N = 25,982) to estimate the persuasive capability of each model. Our findings are twofold. First, we find evidence that model persuasiveness is characterized by sharply diminishing returns, such that current frontier models are only slightly more persuasive than models smaller in size by an order of magnitude or more. Second, we find that the association between language model size and persuasiveness shrinks toward zero and is no longer statistically significant once we adjust for mere task completion (coherence, staying on topic), a pattern that highlights task completion as a potential mediator of larger models' persuasive advantage. Given that current frontier models are already at ceiling on this task completion metric in our setting, taken together, our results suggest that further scaling model size may not much increase the persuasiveness of static LLM-generated political messages.",2025,,PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA,122,10,,WOS:001459360900001,10.1073/pnas.2413443122,,#3932,Hackenburg 2025,"",""
Amplifying Minority Voices: AI-Mediated Devil's Advocate System for Inclusive Group Decision-Making,"ACM; Lee, S; Kim, M; Hwang, S; Kim, D; Lee, K","Group decision-making often benefits from diverse perspectives, yet power imbalances and social influence can stifle minority opinions and compromise outcomes. This prequel introduces an AI-mediated communication system that leverages the Large Language Model to serve as a devil's advocate, representing underrepresented viewpoints without exposing minority members' identities. Rooted in persuasive communication strategies and anonymity, the system aims to improve psychological safety and foster more inclusive decision-making. Our multi-agent architecture, which consists of a summary agent, conversation agent, AI duplicate checker, and paraphrase agent, encourages the group's critical thinking while reducing repetitive outputs. We acknowledge that reliance on text-based communication and fixed intervention timings may limit adaptability, indicating pathways for refinement. By focusing on the representation of minority viewpoints anonymously in power-imbalanced settings, this approach highlights how AI-driven methods can evolve to support more divergent and inclusive group decision-making.",2025,,"COMPANION PROCEEDINGS OF THE 2025 CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2025",,,17-21,WOS:001477116100005,10.1145/3708557.3716334,,#3933,ACM 2025,"",""
Persuasion in the Age of Artificial Intelligence (AI): Theories and Complications of AI-Based Persuasion,"Dehnert, M; Mongeau, PA","Artificial intelligence (AI) has profound implications for both communication and persuasion. We consider how AI complicates and promotes rethinking of persuasion theory and research. We define AI-based persuasion as a symbolic process in which a communicative-AI entity generates, augments, or modifies a message-designed to convince people to shape, reinforce, or change their responses-that is transmitted to human receivers. We review theoretical perspectives useful for studying AI-based persuasion-the Computers Are Social Actors (CASA) paradigm, the Modality, Agency, Interactivity, and Navigability (MAIN) model, and the heuristic-systematic model of persuasion-to explicate how differences in AI complicate persuasion in two ways. First, thin AI exhibits few (if any) machinic (i.e., AI) cues, social cues might be available, and communication is limited and indirect. Second, thick AI exhibits ample machinic and social cues, AI presence is obvious, and communication is direct and interactive. We suggest avenues for future research in each case.",2022,,HUMAN COMMUNICATION RESEARCH,48,3,386-403,WOS:000785673500001,10.1093/hcr/hqac006,,#3934,Dehnert 2022,"",""
Conceptualizing generative AI as style engines: Application archetypes and implications,"Riemer, K; Peter, S","The rise of generative AI has brought with it a surprising paradox: systems that excel at tasks once thought to be uniquely human, like fluent conversation or persuasive writing, while simultaneously failing to meet traditional expectations of computing, in terms of reliability, accuracy, and veracity (e.g., given the various issues with socalled 'hallucinations'). We argue that, when generative AI is seen through a traditional computing lens, its development focuses on optimizing for traditional computing traits that remain in principle unattainable. This risks backgrounding what is most novel and defining about it. As probabilistic technologies, generative AIs do not store, in any traditional sense, any data or content. Rather, essential features of training data become encoded in deep neural networks as patterns, that become practically available as styles. We discuss what happens when the distinction between objects and their appearance dissolves and all aspects of images or text become understood as styles, accessible for exploration and creative combination and generation. For example, defining visual qualities of entities like 'chair' or 'cat' become available as 'chair-ness' or 'cat-ness' for creative image generation. We argue that, when understood as style engines, unique generative AI capabilities become conceptualized as complementing traditional computing ones. This will aid both computing practitioners and information systems researchers in reconciling and integrating generative AI into the traditional IS landscape. Our conceptualization leads us to propose four archetypes of generative AI application and use, and to highlight future avenues for information systems research made visible by this conceptualization, as well as implications for practice and policymaking.",2024,,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,79,,,WOS:001274645300001,10.1016/j.ijinfomgt.2024.102824,,#3935,Riemer 2024,"",""
Assessing AI receptivity through a persuasion knowledge lens,"Watson, J; Valsesia, F; Segal, S","Understanding human-artificial intelligence (AI) interactions is a growing academic interest. This article conceptualizes AI as a persuasion agent and reviews the recent literature on AI through the lens of persuasion knowledge. It presents research on AI acceptance and aversion in terms of the properties of the AI itself (e.g., anthropomorphism, functionality, and usability), the properties of individuals interacting with AI (e.g., individual differences in judgments of AI, perceived uniqueness, and task performance), and the context of the interaction (e.g., type of decision, domain, and usage occasion). In assessing AI interaction research through this lens, we systematically categorize these findings and identify promising future research directions.",2024,,CURRENT OPINION IN PSYCHOLOGY,58,,,WOS:001266421500001,10.1016/j.copsyc.2024.101834,,#3936,Watson 2024,"",""
Laypeople's Use of and Attitudes Toward Large Language Models and Search Engines for Health Queries: Survey Study,"Mendel, T; Singh, N; Mann, DM; Wiesenfeld, B; Nov, O","Background: Laypeople have easy access to health information through large language models (LLMs), such as ChatGPT, and search engines, such as Google. Search engines transformed health information access, and LLMs offer a new avenuefor answering laypeople's questions. Objective: We aimed to comparethefrequency of use and attitudes toward LLMsand search engines as well as their comparative relevance, usefulness, ease of use, and trustworthiness in responding to health queries. Methods: We conducted a screening survey to comparethe demographics of LLM users and nonusers seeking health information, analyzing results with logistic regression. LLM users from the screening survey were invited to a follow-up survey to report the types of health information they sought. We compared the frequency of use of LLMs and search engines using ANOVA and Tukey post hoc tests. Lastly, paired-sample Wilcoxon tests compared LLMsand search engines on perceived usefulness, ease of use, trustworthiness, feelings, bias, and anthropomorphism. Results: In total, 2002 US participants recruited on Prolific participated in the screening survey about the use of LLMs and search engines. Of them, 52% (n=1045) of the participants were female, with a mean age of 39 (SD 13) years. Participants were 9.7% (n=194) Asian, 12.1% (n=242) Black, 73.3% (n=1467) White, 1.1% (n=22) Hispanic, and 3.8% (n=77) were of other races and ethnicities. Further, 1913 (95.6%) used search engines to look up health queriesversus 642 (32.6%) for LLMs. Men had higher odds (odds ratio [OR] 1.63, 95% CI 1.34-1.99; P<.001) of using LLMsfor health questionsthan women. Black (OR 1.90, 95% CI 1.42-2.54; P<.001) and Asian (OR 1.66, 95% CI 1.19-2.30; P<.01) individuals had higher odds than White individuals. Those with excellent perceived health (OR 1.46, 95% CI 1.1-1.93; P=.01) were more likely to use LLMs than those with good health. Higher technical proficiency increased the likelihood of LLM use (OR 1.26, 95% CI 1.14-1.39; P<.001). In a follow-up survey of 281 LLM users for health, most participants used search engines first (n=174, 62%) to answer health questions, but the second most common first source consulted was LLMs (n=39, 14%). LLMs were perceived as less useful (P<.01) and less relevant (P=.07), but elicited fewer negative feelings (P<.001), appeared more human (LLM: n=160, vs search: n=32), and were seen as less biased (P<.001). Trust (P=.56) and easeof use (P=.27) showed no differences. Conclusions: Search engines are the primary source of health information; yet, positive perceptions of LLMs suggest growing use. Future work could explore whether LLM trust and usefulness are enhanced by supplementing answers with external references and limiting persuasive language to curb overreliance. Collaboration with health organizations can help improve the quality of LLMs' health output.",2025,,JOURNAL OF MEDICAL INTERNET RESEARCH,27,,,WOS:001460012400008,10.2196/64290,,#3937,Mendel 2025,"",""
Creative Artificial Intelligence and Narrative Transportation,"Messingschlager, TV; Appel, M","Artificial intelligence (AI) is increasingly used to accomplish complex tasks, including the creation of artworks and entertainment products. Our focus here is on user responses to AI systems as authors of fictional stories. Across two experiments, we examined how the information that a story was written by AI influences narrative transportation and related experiences. In Experiment 1 (N = 325) the information that an AI had created a short story (contemporary fiction) reduced narrative transportation into this story. Experiment 2 (N = 489) was an extended replication in which genre differences (contemporary fiction vs. science fiction) were addressed. As expected, ostensible AI authorship reduced transportation, but this effect was qualified by genre: Whereas the AI-authorship effect was replicated for contemporary fiction stories, transportation did not differ between human and AI authorship when participants read science fiction stories. Across both experiments, individual differences (openness, affinity for technology and attitude toward AI) did not moderate the effect of AI authorship on any of the dependent variables.",2024,,PSYCHOLOGY OF AESTHETICS CREATIVITY AND THE ARTS,18,5,848-857,WOS:000819645500001,10.1037/aca0000495,,#3938,Messingschlager 2024,"",""
Virtual Agents for Alcohol Use Counseling: Exploring LLM-Powered Motivational Interviewing,"ASSOC COMPUTING MACHINERY; Steenstra, I; Nouraei, F; Arjmand, M; Bickmore, TW","We introduce a novel application of large language models (LLMs) in developing a virtual counselor capable of conducting motivational interviewing (MI) for alcohol use counseling. Access to effective counseling remains limited, particularly for substance abuse, and virtual agents offer a promising solution by leveraging LLM capabilities to simulate nuanced communication techniques inherent in MI. Our approach combines prompt engineering and integration into a user-friendly virtual platform to facilitate realistic, empathetic interactions. We evaluate the effectiveness of our virtual agent through a series of studies focusing on replicating MI techniques and human counselor dialog. Initial findings suggest that our LLM-powered virtual agent matches human counselors' empathetic and adaptive conversational skills, presenting a significant step forward in virtual health counseling and providing insights into the design and implementation of LLM-based therapeutic interactions.",2024,,"PROCEEDINGS OF THE 24TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS, IVA 2024",,,,WOS:001441957400020,10.1145/3652988.3673932,,#3939,ASSOCCOMPUTINGMACHINERY 2024,"",""
Governing Ethical AI Transformation: A Case Study of AuroraAI,"Leikas, J; Johri, A; Latvanen, M; Wessberg, N; Hahto, A","How can the public sector use AI ethically and responsibly for the benefit of people? The sustainable development and deployment of artificial intelligence (AI) in the public sector requires dialogue and deliberation between developers, decision makers, deployers, end users, and the public. This paper contributes to the debate on how to develop persuasive government approaches for steering the development and use of AI. We examine the ethical issues and the role of the public in the debate on developing public sector governance of socially and democratically sustainable and technology-intensive societies. To concretize this discussion, we study the co-development of a Finnish national AI program AuroraAI, which aims to provide citizens with tailored and timely services for different life situations, utilizing AI. With the help of this case study, we investigate the challenges posed by the development and use of AI in the service of public administration. We draw particular attention to the efforts made by the AuroraAI Ethics Board in deliberating the AuroraAI solution options and working toward a sustainable and inclusive AI society.",2022,,FRONTIERS IN ARTIFICIAL INTELLIGENCE,5,,,WOS:000915933400001,10.3389/frai.2022.836557,,#3940,Leikas 2022,"",""
Defending Truth and Democracy in the Age of AI: A Framework for Empowering Voters Against Persuasion and Misinformation with AI Literacy,"Arda, Z; Basarir, L","Witnessing the rising impact of Artificial Intelligence (AI) in a post-truth envi-ronment, our senses' credibility wanes as the distinction between the real and the imagined becomes increasingly hazy. This study examines AI-generated content and deepfakes' effects on voters by analyzing their use in Turkish and American politics over the past decade. The ease and speed of creating fake news with AI necessitate constant verification, yet regulation is often lacking, heightening daily anxiety about reality. With the EU's imminent AI law, this article highlights the dangers of media advocacy (the strategic use of media to influence public opinion) and misinformation (spreading incorrect or misleading information). Through a meticulous literature review, press release analysis, and case studies, the study assesses their possible persuasive impact on voters, elections, and democracy. It identifies the associated risks and proposes a framework to empower voters using technology to reinforce ""truth filters,"" Intelligence Augmentation, and ""AI litera-cy."" Two concepts that were developed side by side, but with different intentions, while AI aimed to create digital intelligence, Intelligence Augmentation focused instead on using technology to enhance the human capacity",2024,,ADCOMUNICA-REVISTA CIENTIFICA DE ESTRATEGIAS TENDENCIAS E INNOVACION EN COMMUNICACION,,28,115-142,WOS:001302869900006,10.6035/adcomunica.8020,,#3941,Arda 2024,"",""
On LLM Wizards: Identifying Large Language Models' Behaviors for Wizard of Oz Experiments,"ASSOC COMPUTING MACHINERY; Fang, JC; Arechiga, N; Namikoshi, K; Bravo, N; Hogan, C; Shamma, DA","The Wizard of Oz (WoZ) method is a widely adopted research approach where a human Wizard ""role-plays"" a not readily available technology and interacts with participants to elicit user behaviors and probe the design space. With the growing ability for modern large language models (LLMs) to role-play, one can apply LLMs as Wizards in WoZ experiments with better scalability and lower cost than the traditional approach. However, methodological guidance on responsibly applying LLMs in WoZ experiments and a systematic evaluation of LLMs' role-playing ability are lacking. Through two LLM-powered WoZ studies, we take the first step towards identifying an experiment lifecycle for researchers to safely integrate LLMs into WoZ experiments and interpret data generated from settings that involve Wizards role-played by LLMs. We also contribute a heuristic-based evaluation framework that allows the estimation of LLMs' role-playing ability in WoZ experiments and reveals LLMs' behavior patterns at scale.",2024,,"PROCEEDINGS OF THE 24TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS, IVA 2024",,,,WOS:001441957400016,10.1145/3652988.3673967,,#3942,ASSOCCOMPUTINGMACHINERY 2024,"",""
Using testimonial narratives to persuade people about artificial intelligence: the role of attitudinal similarity with the protagonist of the message,"Igartua, JJ; González-Vázquez, A; Arcila-Calderón, C","This study addresses the factors that increase the persuasive impact of testimonial narrative messages on artificial intelligence (AI). In particular, the effect on two variables that, to date, have not been explored in this field is analyzed: the attitudes toward AI (positive versus ambivalent) expressed by the protagonist of the narrative message (a testimonial in audiovisual format) and the role of participants' prior beliefs about AI. An online experiment (N = 652) was carried out to contrast the effect of attitudinal similarity on identification with the protagonist of the narrative message and the indirect effect on attitudes and intention to use AI. The results showed that the message whose protagonist expressed positive attitudes toward AI induced greater identification only in those participants with previous positive beliefs. In contrast, the message whose protagonist expressed ambivalent attitudes toward AI induced greater identification only among participants with previous negative beliefs. In addition, identification and cognitive elaboration were found to mediate the effect of attitudinal similarity on the attitude toward and intention to use AI. These findings are discussed in the context of narrative persuasion research and the development of campaigns for improving social perceptions of data science.",2022,,PROFESIONAL DE LA INFORMACION,31,4,,WOS:000877418400001,10.3145/epi.2022.jul.09,,#3943,Igartua 2022,"",""
AI-powered recommendations: the roles of perceived similarity and psychological distance on persuasion,"Ahn, J; Kim, J; Sung, Y","Artificial intelligence (AI) plays various roles in our daily lives, such as personal assistant, salesperson, and virtual counselors; thus, it stands out in various fields as a recommendation agent. This study explored the effects of perceived similarity and psychological distance on the persuasion of AI recommendation agents through two experiments. Results of Experiment 1 elucidated that individuals feel more psychologically distant when they interact with AI recommendation agents than with human agents as a result of a different level of perceived similarity. Furthermore, psychological distance plays a mediating role in determining the effectiveness of desirability- vs. feasibility-focused messages in health-related issues. In Experiment 2, we manipulated the AI speaker's level of perceived similarity via anthropomorphism and found that the AI's recommendation with secondary (vs. primary) features is more effective when AI is humanized, and the reverse was found in non-humanized AI conditions. Both theoretical and managerial implications are provided.",2021,,INTERNATIONAL JOURNAL OF ADVERTISING,40,8,1366-1384,WOS:000711244000001,10.1080/02650487.2021.1982529,,#3944,Ahn 2021,"",""
"The Wildcard XAI: from a Necessity, to a Resource, to a Dangerous Decoy","Carli, R; Calvaresi, D","There has been a growing interest in Explainable Artificial Intelligence (henceforth XAI) models among researchers and AI programmers in recent years. Indeed, the development of highly interactive technologies that can collaborate closely with users has made explainability a necessity. This intends to reduce mistrust and the sense of unpredictability that AI can create, especially among non-experts. Moreover, the potential of XAI as a valuable resource has been recognized, considering that it can make intelligent systems more user-friendly and reduce the negative impact of black box systems. Building on such considerations, the paper discusses the potential dangers of large language models (LLMs) that generate explanations to support the outcomes produced. While these models may give users the illusion of control over the system's responses, they actually have persuasive and non-explanatory effects. Therefore, it is argued here that XAI, appropriately regulated, should be a resource to empower users of AI systems. Any other apparent explanations should be reported to avoid misleading and circumventing effects.",2024,,"EXPLAINABLE AND TRANSPARENT AI AND MULTI-AGENT SYSTEMS, EXTRAAMAS 2024",14847,,224-241,WOS:001336429000013,10.1007/978-3-031-70074-3_13,,#3945,Carli 2024,"",""
"Affective, cognitive, and contextual cues in Reddit posts on artificial intelligence","Savela, N; Pellert, M; Latikka, R; Bergdahl, J; Garcia, D; Oksanen, A","Artificially intelligent technologies have become a common topic in our everyday discussions where arguments about the subject can take different forms from cognitive reasoning to emotional expressions. Utilizing persuasion theories and research on the appeal of content characteristics as the theoretical approach to examine affective-cognitive language, we investigated social media posts on artificial intelligence (AI). We examined Reddit posts from 2005 to 2018 referring to AI (N = 455,634) using automated content analysis tools. The results revealed that although both the tone positivity and affective-cognitive ratio were dependent on the specific context, the language in AI posts was more analytically than emotionally oriented in general. Other users were more likely to engage with Reddit posts on AI that were high in cognitive and analytic content compared to affective and emotional content. In addition to the practical contribution of public opinion on AI, the results contribute to the theoretical discussions on affective and cognitive language in social media discussions.",2025,,JOURNAL OF COMPUTATIONAL SOCIAL SCIENCE,8,1,,WOS:001366881300003,10.1007/s42001-024-00335-x,,#3946,Savela 2025,"",""
Artificial intelligence or the challenge of the century Anatomy of a radical antihumanism,"Contreras, RP","""Artificial Intelligence or the Challenge of the Century: Anatomy of a Radical Antihumanism"" by eric Sadin examines, from a phenomenology of artifacts perspective, the evolution of artificial intelligence (AI) and the challenges it poses. The author conceives AI as a global system composed of devices interconnected with beings and objects in the world, whose behavior is continuously monitored and digitally influenced through algorithms. Specifically, the power of this ""algorithmic Leviathan"" lies not only in its ability to handle vast amounts of information, rendering human minds dispensable, but also in its administration based on a numerical regime of truth. To comprehend this, Sadin introduces the concepts of ""aletheic potency"" and ""kairos power."" Aletheic potency refers to the persuasive capacity of AI to articulate ""truths"" that align with our preferences and expectations. On the other hand, kairos power enables AI to swiftly respond to its shortcomings through compensatory actions that minimize our dissatisfaction, thus keeping us captive within its infallible logic. In summary, the emergence of AI signifies a change in the status of technologies, challenging our relationship with the world, as it is expected to enunciate truth through automated interpretation of situations and make decisions on our behalf. This represents the stage of techno-logos of technique: not logos about technique produced by humans, but humans shaped by a technique capable of generating discourse or truth.",2023,,COGNITION TECHNOLOGY & WORK,25,4,461-463,WOS:001014478300001,10.1007/s10111-023-00730-w,,#3947,Contreras 2023,"",""
In memoriam Douglas N. Walton: the influence of Doug Walton on AI and law,"Atkinson, K; Bench-Capon, T; Bex, F; Gordon, TF; Prakken, H; Sartor, G; Verheij, B","Doug Walton, who died in January 2020, was a prolific author whose work in informal logic and argumentation had a profound influence on Artificial Intelligence, including Artificial Intelligence and Law. He was also very interested in interdisciplinary work, and a frequent and generous collaborator. In this paper seven leading researchers in AI and Law, all past programme chairs of the International Conference on AI and Law who have worked with him, describe his influence on their work.",2020,,ARTIFICIAL INTELLIGENCE AND LAW,28,3,281-326,WOS:000540683400001,10.1007/s10506-020-09272-2,,#3948,Atkinson 2020,"",""
Is artificial intelligence more persuasive than humans? A meta-analysis,"Huang, GX; Wang, S","The rapid deployment of artificial intelligence (AI) technology has enabled AI agents to take on various roles as communicators, such as virtual assistants, robot journalists, and AI doctors. This study meta-analyzed 121 randomized experimental studies (N = 53,977) that compared the effects of AI and human agency on persuasion outcomes, including perceptions, attitudes, intentions, and behaviors. The results showed that AI agents were as persuasive as humans in terms of overall persuasion outcomes. With regard to different types of outcomes, AI was less effective than humans at shaping behavioral intentions, but did not differ significantly from humans in eliciting perceptions, attitudes, or actual behaviors. Additionally, heterogeneous patterns were observed for different roles of AI communicators, directions of communication, experimental settings, and demographic segments. The implications of these findings for human-machine communication and persuasion in the era of AI are discussed.",2023,,JOURNAL OF COMMUNICATION,73,6,552-562,WOS:001043927800001,10.1093/joc/jqad024,,#3949,Huang 2023,"",""
Designing a feature selection method based on explainable artificial intelligence,"Zacharias, J; von Zahn, M; Chen, JHN; Hinz, O","Nowadays, artificial intelligence (AI) systems make predictions in numerous high stakes domains, including credit-risk assessment and medical diagnostics. Consequently, AI systems increasingly affect humans, yet many state-of-the-art systems lack transparency and thus, deny the individual's ""right to explanation "". As a remedy, researchers and practitioners have developed explainable AI, which provides reasoning on how AI systems infer individual predictions. However, with recent legal initiatives demanding comprehensive explainability throughout the (development of an) AI system, we argue that the pre-processing stage has been unjustifiably neglected and should receive greater attention in current efforts to establish explainability. In this paper, we focus on introducing explainability to an integral part of the pre-processing stage: feature selection. Specifically, we build upon design science research to develop a design framework for explainable feature selection. We instantiate the design framework in a running software artifact and evaluate it in two focus group sessions. Our artifact helps organizations to persuasively justify feature selection to stakeholders and, thus, comply with upcoming AI legislation. We further provide researchers and practitioners with a design framework consisting of meta-requirements and design principles for explainable feature selection.",2022,,ELECTRONIC MARKETS,32,4,2159-2184,WOS:000898288200001,10.1007/s12525-022-00608-1,,#3950,Zacharias 2022,"",""
Developing Personalized Marketing Service Using Generative AI,"Lee, GH; Lee, KJ; Jeong, B; Kim, T","In today's world, the development of social network services (SNS) like Facebook and Instagram has enabled consumers to acquire information about products through various channels. The acquisition of diverse information has led to a diversification in consumer preferences and requirements. As consumer preferences diversify and online channels expand, there is an increasing need for companies to provide personalized marketing. Among the means of personalized marketing, personalized marketing messages are a key tool that can enhance customer engagement. However, a limitation of personalized marketing message services is the cost issue associated with manually writing individual marketing messages for personalization. To solve this problem, when developing automated technology for personalized marketing messages, there were concerns about the complexity of model development and the quality of messages generated automatically. In this study, we propose the Persuasive Message Intelligence (PMI) service, which utilizes the recently prominent Large Language Model for automated individual personalized marketing messages. PMI generates marketing messages through prompt engineering based on the theory of persuasion in marketing and prior research on AI-generated messages, and validates the elements of prompts through surveys. The trial and error of researchers presented in this study, along with the know-how and rules of prompt engineering, will serve as guidelines for those who wish to develop services through prompts in the future.",2024,,IEEE ACCESS,12,,22394-22402,WOS:001171511800001,10.1109/ACCESS.2024.3361946,,#3951,Lee 2024,"",""
I Was Born to Love AI: The Influence of Social Status on AI Self-Efficacy and Intentions to Use AI,"Hong, JW","This study employed a survey to examine the role of social status on the acceptance of artificial intelligence (AI) technology. One's self-efficacy with using AI technology was assumed to be determined by various factors coming from demographic status, which ultimately leads to the intention to use that technology. This was hypothesized based on the technology acceptance model, self-efficacy, and diffusion of innovation. Participants (n = 369) reported their perceived mastery of AI products, vicarious experiences with AI products, social persuasions of using AI products, AI self- efficacy, perceived usefulness of AI, perceived ease of using AI, intention to use AI, and demographic information. Both education level and income were found to affect the intention to adopt AI technology through AI self-efficacy. However, the age of participants was found not to be a determinant. The implications of the findings for applications and theory are discussed.",2022,,INTERNATIONAL JOURNAL OF COMMUNICATION,16,,172-191,WOS:000789589100009,,,#3952,Hong 2022,"",""
How AI sources can increase openness to opposing views,"Lu, LIS; Tormala, ZL; Duhachek, A","Exposure to counterattitudinal information has been shown to yield mixed effects on attitude polarization. The current research explores the differential impact of such information when generated by artificial intelligence (AI) versus human sources. While prior work highlights a general aversion to AI for decision-making, our research reveals a consistent openness to AI in the context of counterattitudinal messages. Across four pre-registered studies (N = 2061), we find that when people receive counterattitudinal messages on potentially polarizing issues, AI sources are perceived as less biased, more informative, and having less persuasive intent than human sources. This leads to greater receptiveness to counterattitudinal messages when those messages come from AI rather than human sources. In addition, we find preliminary evidence that receiving counterattitudinal messages from an AI (versus human) source can diminish outgroup animosity and facilitate attitude change.",2025,,SCIENTIFIC REPORTS,15,1,,WOS:001489973400039,10.1038/s41598-025-00791-z,,#3953,Lu 2025,"",""
Tracing the legitimacy of Artificial Intelligence: A longitudinal analysis of media discourse,"Korneeva, E; Salge, TO; Teubner, T; Antons, D","Artificial Intelligence (AI) is one of the most relevant technologies of our time. During the last decade, AI has made major technological breakthroughs most recently in the space of generative AI. This development is enabled by an increase in computing power, a decrease in its price, and the emergence of ubiquitous computing, resulting in vast amounts of storable and processable data. However, the diffusion of AI depends on its legitimacy in society, whereby legitimacy is understood as the congruence between organizational activities and their cultural environment. This study aims at understanding the process whereby AI is being (de)legitimated across key industries and over time. To capture and trace the process of legitimation, we rely on media coverage as a form of societal discourse reflecting the legitimation process of AI. We find that the legitimation process gathers momentum in the mid-2010s and the legitimacy of AI increases over time. Furthermore, we identify four types of legitimacy discourse, which integrate sentiment, specific media frames, and appeals of persuasion. Uncovering the four types of legitimacy discourse, we aim at supporting organizations seeking to understand the legitimacy of specific AI applications and how these legitimacy judgments can shift.",2023,,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,192,,,WOS:001058549200001,10.1016/j.techfore.2023.122467,,#3954,Korneeva 2023,"",""
Harnessing Artificial Intelligence for Health Message Generation: The Folic Acid Message Engine,"Schmälzle, R; Wilcox, S","Background: Communication campaigns using social media can raise public awareness; however, they are difficult to sustain. A barrier is the need to generate and constantly post novel but on-topic messages, which creates a resource-intensive bottleneck.Objective: In this study, we aim to harness the latest advances in artificial intelligence (AI) to build a pilot system that can generate many candidate messages, which could be used for a campaign to suggest novel, on-topic candidate messages. The issue of folic acid, a B-vitamin that helps prevent major birth defects, serves as an example; however, the system can work with other issues that could benefit from higher levels of public awareness.Methods: We used the Generative Pretrained Transformer-2 architecture, a machine learning model trained on a large natural language corpus, and fine-tuned it using a data set of autodownloaded tweets about #folicacid. The fine-tuned model was then used as a message engine, that is, to create new messages about this topic. We conducted a web-based study to gauge how human raters evaluate AI-generated tweet messages compared with original, human-crafted messages.Results: We found that the Folic Acid Message Engine can easily create several hundreds of new messages that appear natural to humans. Web-based raters evaluated the clarity and quality of a human-curated sample of AI-generated messages as on par with human-generated ones. Overall, these results showed that it is feasible to use such a message engine to suggest messages for web-based campaigns that focus on promoting awareness.Conclusions: The message engine can serve as a starting point for more sophisticated AI-guided message creation systems for health communication. Beyond the practical potential of such systems for campaigns in the age of social media, they also hold great scientific potential for the quantitative analysis of message characteristics that promote successful communication. We discuss future developments and obvious ethical challenges that need to be addressed as AI technologies for health persuasion enter the stage.",2022,,JOURNAL OF MEDICAL INTERNET RESEARCH,24,1,,WOS:000766780100004,10.2196/28858,,#3955,Schmälzle 2022,"",""
Deconstructing the role of artificial intelligence in programmatic advertising: at the intersection of automation and transparency,"Diwanji, VS; Lee, JJ; Cortese, J","With the increasingly sophisticated improvements in artificial intelligence (AI) technologies in marketing communications, a gap prevails between heightened levels of excitement around it and high-level application. Consequently, this topic necessitates in-depth investigation to prepare for future changes. This study examines the role of AI in programmatic advertising through a quantitative content analysis of AI-enabled digital programmatic advertisements. Although the idea that sponsorship disclosure, appeals, and sentiments are important in persuasive messages has been documented, this study extends existing literature by examining these concepts within AI-enabled programmatic advertising. Sponsorship-linked marketing and congruence theory guided this study. The results showed that only about half of the ads revealed sponsorship information. Further, the brand-sponsor association was not clearly established in the ads. A sentiment analysis showed the prominence of positive sentiments in the ads. Additionally, the ads mostly used product- and consumer-focused appeals. Theoretical and research contributions and strategic marketing implications are discussed.",2024,,JOURNAL OF STRATEGIC MARKETING,32,7,947-964,WOS:000889639300001,10.1080/0965254X.2022.2148269,,#3956,Diwanji 2024,"",""
Examining artificial intelligence literacy among pre-service teachers for future classrooms,"Ayanwale, MA; Adelana, OP; Molefi, RR; Adeeko, O; Ishola, AM","In the context of global integration and increasing reliance on Artificial Intelligence (AI) in education, evaluating the AI literacy of pre-service teachers is crucial. As future architects of educational systems, pre-service teachers must not only possess pedagogical expertise but also a strong foundation in AI literacy. This quantitative study examines AI literacy among 529 pre-service teachers in a Nigerian university, utilizing structural equation modeling (SEM) for comprehensive analysis. The research explores various dimensions of AI literacy, revealing that a profound understanding of AI significantly predicts positive outcomes in AI use, detection, ethics, creation, and problem-solving. However, no correlation exists between AI knowledge and emotion regulation or the assumption that active AI use enhances AI detection capabilities. The study identifies a trade-off between AI application and creation, emphasizing the ethical considerations intertwined with emotional and persuasive facets of AI use. It also supports the link between AI creation and problem-solving, emphasizing the foundational role of AI knowledge in shaping diverse aspects of AI literacy among pre-service teachers. The findings offer valuable insights for educators, administrators, policymakers, and researchers aiming to enhance AI literacy in pre-service teacher education programs.",2024,,COMPUTERS AND EDUCATION OPEN,6,,,WOS:001229046300001,10.1016/j.caeo.2024.100179,,#3957,Ayanwale 2024,"",""
Digital Transformation Based on AI Technologies in European Union Organizations,"Mihai, F; Aleca, OE; Gheorghe, M","This study aims to investigate the influence of emerging digital technologies, such as artificial intelligence (AI), the Internet of Things (IoT), and cloud computing, on the digital intensity index (DII). The research method employed involves quantitative analysis of the indicators regarding DII and emerging digital technologies, conducted based on data published by Eurostat for EU members in 2021. During our research, we formulated and tested hypotheses about the relationship between the DII and emerging digital technologies, and the effect on the DII of using AI-based technologies in various economic processes. The formulated hypotheses were validated via four regression models designed during this study, using the most relevant factors. Our research results demonstrate that the DII is positively influenced by emerging IoT and cloud computing digital technologies, as well as the use of AI technologies based on machine learning and AI-based robotic process automation (RPA) software. Furthermore, the same positive influence was identified in human resource management and recruitment processes compared to the intensity with which these technologies are used in other economic processes. Based on these findings, this study offers persuasive arguments for implementing emerging digital technologies at the EU organizational level to achieve significant increases in digitalization levels.",2023,,ELECTRONICS,12,11,,WOS:001005703600001,10.3390/electronics12112386,,#3958,Mihai 2023,"",""
Let me transfer you to our AI-based manager: Impact of manager-level job titles assigned to AI-based agents on marketing outcomes,"Jeon, Y","This paper examines to what extent the job titles assigned to AI agents can influence the customer's perception of these agents and ultimately their marketing outcomes such as customer satisfaction, brand attitude, and intention to buy AI-recommended products. Also, this study explores how customers perceive the AI agent as the manager working with either a human or an AI representative. Across three experiments (using a scenario or a combination of a scenario and the real AI chatbot), the study shows that consumers perceive the AI manager more positively in terms of likeability, knowledgeability, and trustworthiness than the AI representative and the human manager. The customers perceive the AI manager more positively when they are transferred to the AI manager from a representative of the same kind (AI) than from a human representative. Further, the job titles given to the AI agents are found to have favorable downstream effects on customer satisfaction, brand attitude, and the customers' intentions to buy the products recommended during the chat by the AI manager.",2022,,JOURNAL OF BUSINESS RESEARCH,145,,892-904,WOS:000798782300008,10.1016/j.jbusres.2022.03.028,,#3959,Jeon 2022,"",""
Artificial Intelligence Chatbot Behavior Change Model for Designing Artificial Intelligence Chatbots to Promote Physical Activity and a Healthy Diet: Viewpoint,"Zhang, JW; Oh, YJ; Lange, P; Yu, Z; Fukuoka, Y","Background: Chatbots empowered by artificial intelligence (AI) can increasingly engage in natural conversations and build relationships with users. Applying AI chatbots to lifestyle modification programs is one of the promising areas to develop cost-effective and feasible behavior interventions to promote physical activity and a healthy diet.Objective: The purposes of this perspective paper are to present a brief literature review of chatbot use in promoting physical activity and a healthy diet, describe the AI chatbot behavior change model our research team developed based on extensive interdisciplinary research, and discuss ethical principles and considerations.Methods: We conducted a preliminary search of studies reporting chatbots for improving physical activity and/or diet in four databases in July 2020. We summarized the characteristics of the chatbot studies and reviewed recent developments in human-AI communication research and innovations in natural language processing. Based on the identified gaps and opportunities, as well as our own clinical and research experience and findings, we propose an AI chatbot behavior change model.Results: Our review found a lack of understanding around theoretical guidance and practical recommendations on designing AI chatbots for lifestyle modification programs. The proposed AI chatbot behavior change model consists of the following four components to provide such guidance: (1) designing chatbot characteristics and understanding user background; (2) building relational capacity; (3) building persuasive conversational capacity; and (4) evaluating mechanisms and outcomes. The rationale and evidence supporting the design and evaluation choices for this model are presented in this paper.Conclusions: As AI chatbots become increasingly integrated into various digital communications, our proposed theoretical framework is the first step to conceptualize the scope of utilization in health behavior change domains and to synthesize all possible dimensions of chatbot features to inform intervention design and evaluation. There is a need for more interdisciplinary work to continue developing AI techniques to improve a chatbot's relational and persuasive capacities to change physical activity and diet behaviors with strong ethical principles.",2020,,JOURNAL OF MEDICAL INTERNET RESEARCH,22,9,,WOS:000599332900003,10.2196/22845,,#3960,Zhang 2020,"",""
On the conversational persuasiveness of GPT-4,"Salvi, F; Ribeiro, MH; Gallotti, R; West, R","Early work has found that large language models (LLMs) can generate persuasive content. However, evidence on whether they can also personalize arguments to individual attributes remains limited, despite being crucial for assessing misuse. This preregistered study examines AI-driven persuasion in a controlled setting, where participants engaged in short multiround debates. Participants were randomly assigned to 1 of 12 conditions in a 2 x 2 x 3 design: (1) human or GPT-4 debate opponent; (2) opponent with or without access to sociodemographic participant data; (3) debate topic of low, medium or high opinion strength. In debate pairs where AI and humans were not equally persuasive, GPT-4 with personalization was more persuasive 64.4% of the time (81.2% relative increase in odds of higher post-debate agreement; 95% confidence interval [+26.0%, +160.7%], P < 0.01; N = 900). Our findings highlight the power of LLM-based persuasion and have implications for the governance and design of online platforms.",2025,,NATURE HUMAN BEHAVIOUR,,,,WOS:001490681900001,10.1038/s41562-025-02194-6,,#3961,Salvi 2025,"",""
Stimulating or Intimidating: The Effect of AI-Enabled In-Store Communication on Consumer Patronage Likelihood,"van Esch, P; Cui, Y; Jain, SP","Artificial intelligence (AI) has penetrated the marketing landscape and is having a profound impact on businesses' communication strategies. With AI coming under the spotlight, we know surprisingly little about its impact on consumers' patronage likelihood. This research attempts to address this void by investigating the ""just-walk-out"" retail technology in cohort with in-store communication. Across three studies, conducted online and in the field, the authors demonstrate that, compared to self-service checkouts, AI-enabled checkouts lead to significantly higher consumers' patronage likelihood. Furthermore, sensory stimulation stemming from in-store communication (environmental cues including assortment, advertising, and technology) underlies this impact. Importantly, the extent to which consumers perceive AI technology to be threatening is revealed as a boundary condition to these effects. These findings advance our understanding of how AI-enabled checkouts and in-store communication influence consumers' patronage likelihood and the boundary condition that moderates their impact.",2021,,JOURNAL OF ADVERTISING,50,1,63-80,WOS:000587520400001,10.1080/00913367.2020.1832939,,#3962,vanEsch 2021,"",""
Generative AI and the future of marketing: A consumer protection perspective,"Duivenvoorde, B","Generative AI has the potential to be the biggest disruption in marketing since the emergence of digital commerce in the early 2000s. This article will focus on three ways in which generative AI is expected to change marketing. First, generative AI enables companies to automatically create advertising copy and images, potentially leading to significant cost reductions. Secondly, generative AI offers possibilities to improve and automate personalised marketing, potentially enabling companies to send the right persuasive message at the right time to each potential customer. Thirdly, generative AI potentially offers possibilities to market products to consumers via generative AI chatbots. These developments offer potential advantages but also bear risks for consumers. For example, deepfakes in advertising can mislead consumers, AI-generated personalised marketing can exploit consumer vulnerabilities, and B2C chatbots can deceive consumers by providing biased advice. This article shows that EU law does in principle provide protection to consumers in relation to AI-generated marketing, but is also likely to fall short in effectively protecting consumers against the identified risks in several ways.",2025,,COMPUTER LAW & SECURITY REVIEW,57,,,WOS:001487115300001,10.1016/j.clsr.2025.106141,,#3963,Duivenvoorde 2025,"",""
A comparison of the persuasiveness of human and ChatGPT generated pro-vaccine messages for HPV,"Xia, DK; Song, MY; Zhu, TS","Introduction Public health messaging is crucial for promoting beneficial health outcomes, and the latest advancements in artificial intelligence offer new opportunities in this field. This study aimed to evaluate the effectiveness of ChatGPT-4 in generating pro-vaccine messages on different topics for Human Papillomavirus (HPV) vaccination.Methods In this study (N = 60), we examined the persuasive effect of pro-vaccine messages generated by GPT-4 and humans, which were constructed based on 17 factors impacting HPV vaccination. Paired-samples t-tests were used to compare the persuasiveness of these messages.Results GPT-generated messages were reported as more persuasive than human-generated messages on some influencing factors (e.g., untoward effect, stigmatized perception). Human-generated messages performed better on the message regarding convenience of vaccination.Discussion This study provides evidence for the viability of ChatGPT, in generating persuasive pro-vaccine messages to influence people's vaccine attitudes. It is indicated that the feasibility and efficiency of using AI for public health communication.",2025,,FRONTIERS IN PUBLIC HEALTH,12,,,WOS:001408845000001,10.3389/fpubh.2024.1515871,,#3964,Xia 2025,"",""
A Comprehensive Study of Artificial Intelligence and Machine Learning Approaches in Confronting the Coronavirus (COVID-19) Pandemic,"Rahman, MM; Khatun, F; Uzzaman, A; Sami, SI; Bhuiyan, MAA; Kiong, TS","The novel coronavirus disease (COVID-19) has spread over 219 countries of the globe as a pandemic, creating alarming impacts on health care, socioeconomic environments, and international relationships. The principal objective of the study is to provide the current technological aspects of artificial intelligence (AI) and other relevant technologies and their implications for confronting COVID-19 and preventing the pandemic's dreadful effects. This article presents AI approaches that have significant contributions in the fields of health care, then highlights and categorizes their applications in confronting COVID-19, such as detection and diagnosis, data analysis and treatment procedures, research and drug development, social control and services, and the prediction of outbreaks. The study addresses the link between the technologies and the epidemics as well as the potential impacts of technology in health care with the introduction of machine learning and natural language processing tools. It is expected that this comprehensive study will support researchers in modeling health care systems and drive further studies in advanced technologies. Finally, we propose future directions in research and conclude that persuasive AI strategies, probabilistic models, and supervised learning are required to tackle future pandemic challenges.",2021,,INTERNATIONAL JOURNAL OF HEALTH SERVICES,51,4,446-461,WOS:000652317100001,10.1177/00207314211017469,,#3965,Rahman 2021,"",""
Evaluating XAI: A comparison of rule-based and example-based explanations,"van der Waa, J; Nieuwburg, E; Cremers, A; Neerincx, M","Current developments in Artificial Intelligence (AI) led to a resurgence of Explainable AI (XAI). New methods are being researched to obtain information from AI systems in order to generate explanations for their output. However, there is an overall lack of valid and reliable evaluations of the effects on users' experience of, and behavior in response to explanations. New XAI methods are often based on an intuitive notion what an effective explanation should be. Ruleand example-based contrastive explanations are two exemplary explanation styles. In this study we evaluate the effects of these two explanation styles on system understanding, persuasive power and task performance in the context of decision support in diabetes self-management. Furthermore, we provide three sets of recommendations based on our experience designing this evaluation to help improve future evaluations. Our results show that rule-based explanations have a small positive effect on system understanding, whereas both ruleand example-based explanations seem to persuade users in following the advice even when incorrect. Neither explanation improves task performance compared to no explanation. This can be explained by the fact that both explanation styles only provide details relevant for a single decision, not the underlying rational or causality. These results show the importance of user evaluations in assessing the current assumptions and intuitions on effective explanations. (c) 2020 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).",2021,,ARTIFICIAL INTELLIGENCE,291,,,WOS:000603571400001,10.1016/j.artint.2020.103404,,#3966,vanderWaa 2021,"",""
On How Chronic Conditions Affect the Patient-AI Interaction: A Literature Review,"Sqalli, MT; Al-Thani, D","Background: Across the globe, managing chronic diseases has been recognized as a challenge for patients and healthcare providers. The state of the art in managing chronic conditions requires not only responding to the clinical needs of the patient, but also guaranteeing a comfortable state of wellbeing for them, despite living with the disease. This demands mutual effort between the patient and the physician in constantly collecting data, monitoring, and understanding the disease. The advent of artificial intelligence has made this process easier. However, studies have rarely attempted to analyze how the different artificial intelligence based health coaching systems are used to manage different types of chronic conditions. Objective: Throughout this grounded theory literature review, we aim to provide an overview for the features that characterize artificial intelligence based health coaching systems used by patients with chronic diseases. Methods: During our search and paper selection process process, we use three bibliographic libraries (PubMed, IEEE Xplore, and ACM Digital Library). Using the grounded theory, we extract overarching themes for the artificial intelligence based health coaching systems. These systems are then classified according to their role, platform, type of interaction with the patient, as well as targeted chronic conditions. Of 869 citations retrieved, 31 unique studies are included in this review. Results: The included studies assess 14 different chronic conditions. Common roles for AI-based health coaching systems are: developing adherence, informing, motivating, reminding, preventing, building a care network, and entertaining. Health coaching systems combine the aforementioned roles to cater to the needs of the patients. The combinations of these roles differ between multilateral, unilateral, opposing bilateral, complementing bilateral, one-role-missing, and the blurred role combinations. Conclusion: Clinical solutions and research related to artificial intelligence based health coaching systems are very limited. Clear guidelines to help develop artificial intelligence-based health coaching systems are still blurred. This grounded theory literature review attempted to shed the light on the research and development requirements for an effective health coaching system intended for patients with chronic conditions. Researchers are recommended to use this review to identify the most suitable role combination for an effective health coaching system development.",2020,,HEALTHCARE,8,3,,WOS:000581193600001,10.3390/healthcare8030313,,#3967,Sqalli 2020,"",""
Assessing the risks and opportunities posed by AI-enhanced influence operations on social media,"Fredheim, R; Pamment, J","Large language models (LLMs) like GPT-4 have the potential to dramatically change the landscape of influence operations. They can generate persuasive, tailored content at scale, making campaigns using falsified content, such as disinformation and fake accounts, easier to produce. Advances in self-hosted open-source models have meant that adversaries can evade content moderation and security checks built into large commercial models such as those commercialised by Anthropic, Google, and OpenAI. New multi-lingual models make it easier than ever for foreign adversaries to pose as local actors. This article examines the heightened threats posed by synthetic media, as well as the potential that these tools hold for creating effective countermeasures. It begins with assessing the challenges posed by a toxic combination of automated bots, human-controlled troll accounts, and more targeted social engineering operations. However, the second part of the article assesses the potential for these same tools to improve detection. Promising countermeasures include running internal generative models to bolster training data for internal classifiers, detecting statistical anomalies, identifying output from common prompts, and building specialised classifiers optimised for specific monitoring needs.",2024,,PLACE BRANDING AND PUBLIC DIPLOMACY,,,,WOS:001157338400001,10.1057/s41254-023-00322-5,,#3968,Fredheim 2024,"",""
Questioning 'what makes us human': How audiences react to an artificial intelligence-driven show,"Eagle, R; Lander, R; Hall, PD","I am Echoborg is promoted as 'a show created afresh each time by the audience in conversation with an artificial intelligence (AI)'. The show demonstrates how AI in a creative and performance context can raise questions about the technology's ethical use for persuasion and compliance, and how humans can reclaim agency. This audience study focuses on a consecutive three-night run in Bristol, UK in October 2019. The different outcomes of each show illustrate the unpredictability of audience interactions with conversational AI and how the collective dynamic of audience members shapes each performance. This study analyses (1) how I am Echoborg facilitates audience cocreation in a live performance context, (2) the show's capacity to provoke nuanced understandings of the potential for AI and (3) the ability for intelligent technology to facilitate social interaction and group collaboration. This audience study demonstrates how the show inspires debate beyond binary conclusions (i.e. AI as good or bad) and how audiences can understand potential creative uses of AI, including as a tool for cocreating entertainment with (not just for) them.",2021,,COGNITIVE COMPUTATION AND SYSTEMS,3,2,91-99,WOS:001062676500003,10.1049/ccs2.12018,,#3969,Eagle 2021,"",""
Effects of Consumers' Belief in a Just World on Artificial Intelligence Recommendations: Mediating Effects of Perceived Benevolence and Selfishness,"Ahn, J; Kim, E","This study investigated the effect of users' ""belief in a just world"" (BJW) on the persuasiveness of artificial intelligence (AI) agents' recommendations. Our prediction that users' preferences for human or AI agents vary according to their BJW levels was tested experimentally. The results revealed that individuals with high BJW rated human agents' recommendations more favorably than those of AI agents, whereas those with low BJW preferred AI agents' ones. This interaction was mediated by the perceptions of the agents' benevolence and selfishness, which varied depending on the BJW levels and agent type. High-BJW individuals perceived human agents as more benevolent and less selfish, whereas low-BJW individuals showed the opposite pattern. In contrast, AI agents' benevolence and selfishness perceptions were not influenced by BJW levels. This study provides theoretical insights by identifying BJW as a key factor affecting AI agents' persuasive effects and suggests that perceived benevolence and selfishness are the psychological mechanisms behind these effects. These findings also offer practical guidance for designing more effective AI agent strategies tailored to consumer BJW levels.",2025,,CYBERPSYCHOLOGY BEHAVIOR AND SOCIAL NETWORKING,,,,WOS:001470883100001,10.1089/cyber.2024.0513,,#3970,Ahn 2025,"",""
Influence of human versus AI recommenders: The roles of product type and cognitive processes,"Wien, AH; Peluso, AM","Previous research suggests that consumers would listen more to product recommendations from other consumers (human recommenders) than from systems based on artificial intelligence (AI recommenders). We hypothesize that this might depend on the type of product being recommended, and propose an underlying process driving this effect. Three experiments show that, for hedonic products (but not for utilitarian products), human recommenders are more effective than AI recommenders in influencing consumer reactions toward the recommended product. This effect occurs because, when compared to AI recommenders, human recommenders elicit stronger mentalizing responses in consumers. This, in turn, helps consumers self-reference the product to their own needs. However, humanizing AI recommenders increases mentalizing and self-referencing responses, thus increasing the effectiveness of this type of recommenders for hedonic products. Together, these findings provide insight into when and why consumers might rely more on product recommendations from humans as compared to AI recommenders.",2021,,JOURNAL OF BUSINESS RESEARCH,137,,13-27,WOS:000705512600002,10.1016/j.jbusres.2021.08.016,,#3971,Wien 2021,"",""
Synthetic Lies: Understanding AI-Generated Misinformation and Evaluating Algorithmic and Human Solutions,"ACM; Zhou, JW; Zhang, YX; Luo, QN; Parker, AG; De Choudhury, M","Large language models have abilities in creating high-volume human-like texts and can be used to generate persuasive misinformation. However, the risks remain under-explored. To address the gap, this work frst examined characteristics of AI-generated misinformation (AI-misinfo) compared with human creations, and then evaluated the applicability of existing solutions. We compiled human-created COVID-19 misinformation and abstracted it into narrative prompts for a language model to output AI-misinfo. We found signifcant linguistic diferences within human-AI pairs, and patterns of AI-misinfo in enhancing details, communicating uncertainties, drawing conclusions, and simulating personal tones. While existing models remained capable of classifying AI-misinfo, a signifcant performance drop compared to human-misinfo was observed. Results suggested that existing information assessment guidelines had questionable applicability, as AI-misinfo tended to meet criteria in evidence credibility, source transparency, and limitation acknowledgment. We discuss implications for practitioners, researchers, and journalists, as AI can create new challenges to the societal problem of misinformation.",2023,,PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023),,,,WOS:001048393803022,10.1145/3544548.3581318,,#3972,ACM 2023,"",""
WHEN AND HOW ARTIFICIAL INTELLIGENCE AUGMENTS EMPLOYEE CREATIVITY,"Jia, N; Luo, XM; Fang, Z; Liao, CC","Can artificial intelligence (AI) assist human employees in increasing employee creativity? Drawing on research on AI-human collaboration, job design, and employee creativity, we examine AI assistance in the form of a sequential division of labor within organizations: in a task, AI handles the initial portion, which is well-codified and repetitive, and employees focus on the subsequent portion, involving higher-level problem-solving. First, we provide causal evidence from a field experiment conducted at a telemarketing company. We find that AI assistance in generating sales leads, on average, increases employees' creativity in answering customers' questions during subsequent sales persuasion. Enhanced creativity leads to increased sales. However, this effect is much more pronounced for higher-skilled employees. Next, we conducted a qualitative study using semi-structured interviews with the employees. We found that AI assistance changes job design by intensifying employees' interactions with more serious customers. This change enables higher-skilled employees to generate innovative scripts and develop positive emotions at work, which are conducive to creativity. By contrast, with AI assistance, lower-skilled employees make limited improvements to scripts and experience negative emotions at work. We conclude that employees can achieve AI-augmented creativity, but this desirable outcome is skill-biased by favoring experts with greater job skills.",2024,,ACADEMY OF MANAGEMENT JOURNAL,67,1,5-32,WOS:001184621500011,10.5465/amj.2022.0426,,#3973,Jia 2024,"",""
Searle's Chinese box: Debunking the Chinese room argument,"Hauser, L","John Searle's Chinese room argument is perhaps the mast influential and widely cited argument against artificial intelligence (AI). Understood as targeting AI proper-claims that computers can think or do think - Searle's argument, despite its rhetorical hash, is logically and scientifically a dud. Advertised as effective against AI proper, the argument, in its main outlines, is an ignoratio elenchi. It musters persuasive force fallaciously by indirection fostered by equivocal deployment of the phrase ''strong AI'' and reinforced by equivocation on the phrase ''causal powers' (at least) equal to those of brains.'' On a more carefully crafted understanding - understood just to target metaphysical identification of thought with computation (''Functionalism'' or ''Computationalism'') and not AI proper the argument is still unsound, though more interestingly so. It's unsound in ways difficult for high church - ''someday my prince of an AI program will come'' - believers in AI to acknowledge without undermining their high church beliefs. The ad hominem bite of Searle's argument against the high church persuasions of so many cognitive scientists, I suggest, largely explains the undeserved repute this really quite disreputable argument enjoys among them.",1997,,MINDS AND MACHINES,7,2,199-226,WOS:A1997XQ29700002,10.1023/A:1008255830248,,#3974,Hauser 1997,"",""
Technological Model Based on Artificial Intelligence for the Generation of Commercial Texts in Marketing Campaigns in Medical Clinics in the City of Huancayo,"IEEE COMPUTER SOC; Rojas, JCH; Peña, KLP; Sulca, CGH; Rosales, JMV","This study presents a technological model based on artificial intelligence (AI) for the generation of commercial texts within marketing campaigns targeted at medical clinics in the city of Huancayo. The model aims to streamline and enhance the process of creating persuasive and informative content to effectively engage target audiences. By leveraging AI capabilities such as natural language processing and machine learning algorithms, the system autonomously generates compelling marketing texts that resonate with the specific needs and preferences of the local community in Huancayo. Through a combination of data analysis, linguistic patterns, and user feedback, the model continues to refine its production to optimize relevance and effectiveness. This innovative approach not only reduces the time and resources required for text generation but also ensures consistency and coherence across various marketing channels. The integration of AI technology enables medical clinics in Huancayo to establish a stronger digital presence, attract potential patients, and foster lasting relationships with existing clientele. In summary, this technological model represents a significant advancement in marketing strategies tailored to the healthcare sector in regional contexts such as that of Huancayo.",2024,,"2024 7TH INTERNATIONAL CONFERENCE ON SOFTWARE AND SYSTEM ENGINEERING, ICOSSE 2024",,,88-94,WOS:001291203000015,10.1109/ICoSSE62619.2024.00023,,#3975,IEEECOMPUTERSOC 2024,"",""
The Impact of Artificial Intelligence on Communication Dynamics and Performance in Organizational Leadership,"Florea, NV; Croitoru, G","This study explores the impact of artificial intelligence (AI)-based technologies on leadership-based organizational communication and employee performance within contemporary workplaces. While prior research has acknowledged AI's potential in optimizing communication processes, significant gaps remain in understanding its specific influence on core communication dimensions and organizational outcomes. This study addresses these gaps by examining six key communication elements-informing, message reception, feedback, acceptance, persuasion, and reaction-to assess whether AI technologies significantly enhance employee performance by improving internal communication efficiency and reducing transmission errors, which are crucial for productive interactions. Using a quantitative approach, data were collected via a self-administered questionnaire from 203 employees of a major Romanian food industry company operating globally, including leaders and employees from three Eastern European countries. Partial least squares structural equation modeling (PLS-SEM) was employed to analyze the relationships between communication dimensions and performance. The findings revealed that informing, receiving, and accepting messages, along with reaction-provoking, had strong positive effects on performance, while feedback and persuasion showed moderate impacts. These results emphasize the transformative role of AI in communication processes, optimizing message flow and positively influencing employee behavior, thereby enhancing productivity and organizational efficiency. This research contributes to the growing body of literature by situating AI-driven communication within the broader organizational context, offering actionable insights for managers aiming to integrate AI ethically and effectively. Additionally, it offers a set of recommendations for employees and managers to lead communication process according to the new actual era of digitization, which is offering real benefits for both parts. It also provides a robust foundation for future research, encouraging longitudinal and cross-cultural studies to further investigate AI's implications for organizational diversity, innovation, and employee well-being.",2025,,ADMINISTRATIVE SCIENCES,15,2,,WOS:001429597500001,10.3390/admsci15020033,,#3976,Florea 2025,"",""
Evaluating AI-Personalized Learning Interventions in Distance Education,"Panwale, SB; Abdurrahman, SVBS","This study aimed to evaluate the utility of artificial intelligence (AI) in improving the persuasive communication skills of online Master of Business Administration (MBA) students. In particular, this study investigated the influence of personalization through AI using the Google Gemini platform on conventional and online instructional approaches. This quasi-experimental study used a pretest and posttest design to compare two groups of MBA students pursuing persuasive online communication. The experimental group (n = 32) interacted with the AI-based personalized learning materials, whereas the control group (n = 32) used standard instructor-designed online modules. During the 12-week intervention period, the experimental group was provided with customized practice activities. Conversely, the control group was offered conventional online learning material. The effectiveness of both approaches was evaluated using pretests and posttests. The results of Tukey's Honestly Significant Difference (HSD) test provided insight into the areas where AI-based personalized learning had a statistically significant impact. These results support the conclusions derived from an analysis of variance and further validate the study's research hypotheses. This study demonstrates the advantages of incorporating AI into language development for remote learners and offers valuable insights for integrating AI-driven technologies into distance education.",2025,,INTERNATIONAL REVIEW OF RESEARCH IN OPEN AND DISTRIBUTED LEARNING,26,1,157-174,WOS:001435527100010,,,#3977,Panwale 2025,"",""
Designing a Large Language Model-Based Coaching Intervention for Lifestyle Behavior Change,"Meywirth, S","Adopting and maintaining healthy lifestyle behaviors such as regular exercise and balanced nutrition remain challenging despite their well-documented benefits for preventing chronic diseases and promoting overall well-being. Motivational Interviewing (MI) has emerged as a promising technique to address ambivalence and facilitate behavior change. However, traditional face-to-face delivery of MI interventions is limited by scalability and accessibility issues. Leveraging recent advancements in LLMs, this paper proposes an innovative approach to deliver MI-based coaching for lifestyle behavior change digitally. Following a problem-centered DSR approach, we created an initial prototype based on MI theory and qualitative user interviews using ChatGPT (GPT-3.5). We evaluated our prototype in a qualitative study. Our research outcomes include five design principles and thirteen system requirements. This research enhances the design knowledge base in LLM-based health coaching. It marks an essential first step towards designing LLM-based MI interventions, contributing valuable insights for future research in this emerging field.",2024,,"DESIGN SCIENCE RESEARCH FOR A RESILIENT FUTURE, DESRIST 2024",14621,,81-94,WOS:001285477600006,10.1007/978-3-031-61175-9_6,,#3978,Meywirth 2024,"",""
Evaluating GPT-3 Generated Explanations for Hateful Content Moderation,"Wang, H; Hee, MS; Awal, MR; Choo, KT; Lee, RKW","Recent research has focused on using large language models (LLMs) to generate explanations for hate speech through fine-tuning or prompting. Despite the growing interest in this area, these generated explanations' effectiveness and potential limitations remain poorly understood. A key concern is that these explanations, generated by LLMs, may lead to erroneous judgments about the nature of flagged content by both users and content moderators. For instance, an LLM-generated explanation might inaccurately convince a content moderator that a benign piece of content is hateful. In light of this, we propose an analytical framework for examining hate speech explanations and conducted an extensive survey on evaluating such explanations. Specifically, we prompted GPT-3 to generate explanations for both hateful and non-hateful content, and a survey was conducted with 2,400 unique respondents to evaluate the generated explanations. Our findings reveal that (1) human evaluators rated the GPT-generated explanations as high quality in terms of linguistic fluency, informativeness, persuasiveness, and logical soundness, (2) the persuasive nature of these explanations, however, varied depending on the prompting strategy employed, and (3) this persuasiveness may result in incorrect judgments about the hatefulness of the content. Our study underscores the need for caution in applying LLM-generated explanations for content moderation. Code and results are available at https://github.com/Social-AI-Studio/GPT3-HateEval.",2023,,"PROCEEDINGS OF THE THIRTY-SECOND INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, IJCAI 2023",,,6255-6263,WOS:001202344206040,,,#3979,Wang 2023,"",""
Enhancing Trust and Empathy in Marketing: Strategic AI and Human Influencer Selection for Optimized Content Persuasion,"Zhang, YY; Zhu, JJ; Chen, HB; Jiang, YS","Compared to human influencers, AI influencers offer advantages such as low cost, high efficiency, and fairer handling of objective tasks. However, they are believed to have shortcomings in perception and empathy abilities. How can companies select the more appropriate promoter between AI influencers and human influencers based on their marketing content? How can enterprises design more persuasive marketing content according to the type of influencer? Three behavioral experiments were conducted in this paper. The results indicate that when AI influencers post marketing content with functional advertising appeal, they can significantly enhance people's perceived trust. When human influencers share marketing content with experiential advertising appeal, they can significantly improve people's perceived empathy. Consumers with lower levels of knowledge are more susceptible to the matching effect of influencer type and advertising appeal type on the persuasive effect of marketing content than those with higher levels of knowledge. The conclusions of this study assist enterprises in scientifically matching influencer types with advertising appeals. By choosing influencers based on the nature of the marketing content or designing suitable marketing content based on the influencer type, companies can maximize marketing effectiveness. This refined marketing strategy not only improves the persuasive effect of the marketing content but also strengthens the brand's market competitiveness.",2025,,JOURNAL OF CONSUMER BEHAVIOUR,24,2,866-885,WOS:001380360000001,10.1002/cb.2423,,#3980,Zhang 2025,"",""
The potential of generative AI for personalized persuasion at scale,"Matz, SC; Teeny, JD; Vaid, SS; Peters, H; Harari, GM; Cerf, M","Matching the language or content of a message to the psychological profile of its recipient (known as ""personalized persuasion"") is widely considered to be one of the most effective messaging strategies. We demonstrate that the rapid advances in large language models (LLMs), like ChatGPT, could accelerate this influence by making personalized persuasion scalable. Across four studies (consisting of seven sub-studies; total N = 1788), we show that personalized messages crafted by ChatGPT exhibit significantly more influence than non-personalized messages. This was true across different domains of persuasion (e.g., marketing of consumer products, political appeals for climate action), psychological profiles (e.g., personality traits, political ideology, moral foundations), and when only providing the LLM with a single, short prompt naming or describing the targeted psychological dimension. Thus, our findings are among the first to demonstrate the potential for LLMs to automate, and thereby scale, the use of personalized persuasion in ways that enhance its effectiveness and efficiency. We discuss the implications for researchers, practitioners, and the general public.",2024,,SCIENTIFIC REPORTS,14,1,,WOS:001177429500111,10.1038/s41598-024-53755-0,,#3981,Matz 2024,"",""
Fact-checking in the age of AI: Reducing biases with non-human information sources,"Moon, WK; Kahlor, LA","This study examines the obstacles to the effectiveness of fact-checking, focusing primarily on the pervasive impact of entrenched biases. Fact-checking efforts often face resistance when linked to mistrusted sources, leading to cognitive dissonance and the rejection of messages in favor of pre-existing beliefs, a phenomenon known as motivated reasoning. This resistance hinders organizations' ability to correct misconceptions surrounding social issues and entities. The research delves into whether non-human entities such as AI can facilitate less biased information processing due to their perceived impartiality. Applying a moderated mediation model in experimental settings, we found that labeling a source as artificial intelligence is pivotal in evaluating factchecking. AI labels moderate the impact of partisan biases on the persuasive outcomes of fact-checks, such as message credibility and acceptance, compared to the human source. This study offers valuable insights for enhancing the effectiveness of fact-checking in the context of cognitive and psychological biases by highlighting the critical influence of information sources in reducing polarization in public perceptions of scientific issues.",2025,,TECHNOLOGY IN SOCIETY,80,,,WOS:001369556000001,10.1016/j.techsoc.2024.102760,,#3982,Moon 2025,"",""
Positing a Sense of Agency-Aware Persuasive AI: Its Theoretical and Computational Frameworks,"Legaspi, R; Xu, WZ; Konishi, T; Wada, S","The notion of a persuasive technology (PT) that is autonomous and intelligent, and more importantly, cognizant of and sensitive to human sense of agency (SoA), i.e., the subjective feeling or judgement that oneself is in control of situations, remains to be theorized, conceptualized and elucidated. Three important questions have emerged from our investigations: (1) why does SoA matter in the design of PT, (2) what computational principles in artificial intelligence (AI) underlie an adaptive PT, and (3) how can this intelligent PT sense, make sense of, and respond sensibly to dynamic changes in SoA under complex settings? We elucidate in this paper our theoretical and computational frameworks to answer our research queries. For the theoretical aspect, we propose an integration of pertinent theories in the cognitive, social and neurosciences that explain the emergence and disruption of SoA. Using this integration as theory of mind, we propose a computational framework for SoA-aware persuasive AI that integrates methods in cooperative inverse reinforcement learning, causal inferencing, explainable AI planning and generative actor-critic learning.",2021,,PERSUASIVE TECHNOLOGY (PERSUASIVE 2021),12684,,3-18,WOS:000788285600001,10.1007/978-3-030-79460-6_1,,#3983,Legaspi 2021,"",""
How effective are depictions of AI? Reflections from an experimental study in science communication,"Romele, A; Severo, M","The images used to depict artificial intelligence (AI) in science communication and marketing are often criticized for their stereotypical nature, yet their actual effectiveness remains an open question. Rather than reiterating existing critiques, this paper examines whether these images truly influence public perception and, if so, how different types of AI representations-particularly stock images-compare in their effectiveness. Drawing on Aristotelian rhetoric, we conceptualize effectiveness through three persuasive dimensions: logos (explanatory clarity), ethos (credibility and engagement), and pathos (emotional impact). To investigate these aspects, we conducted an experiment with 79 communication students, who were presented with three versions of the same fabricated scientific article: one without images, one with an institutional research image, and one with a stock image. The findings indicate that while stock images may reduce comprehension of technical content, they slightly enhance reader engagement. Our analysis calls for a more nuanced understanding of AI imagery, moving beyond ethical concerns to consider how these visuals shape public discourse. While stock images contribute to a standardized and sometimes misleading portrayal of AI, their rhetorical power in communication contexts should not be overlooked. The paper concludes by arguing for a more critical yet balanced approach to evaluating the role of images in AI representation.",2025,,AI & SOCIETY,,,,WOS:001439089900001,10.1007/s00146-025-02283-0,,#3984,Romele 2025,"",""
"Ambient Engineering: Hyper-Nudging, Hyper-Relevance, and Rhetorics of Nearness and Farness in a Post-AI Algorithmic World","Rickert, T","This essay argues that algorithms and artificial intelligence (AI) are producing a transformation in the economics of attention. Attention is a limited concept, a point I demonstrate by providing a phenomenological understanding of attending via Heidegger and Merleau-Ponty, specifically showing the usefulness of the existential and platial concepts of nearness and farness. Emerging, AI-driven techniques of hyper-nudging and hyper-relevance address themselves to our senses of nearness and farness. Hyper-relevance is particularly significant as it is proleptic in trying to anticipate concernful engagement, without directly soliciting it, by transforming the conditions of possibility for modes of attending. I call such techniques ambient engineering, which are concerned with transforming the conditions for producing salience. Ambient engineering has consequences for rhetorical practice and theory, including greater focus on subattentive engagements, and thus also an elision of more traditional forms of suasion.",2024,,RHETORIC SOCIETY QUARTERLY,54,5,513-513,WOS:001300317400001,10.1080/02773945.2024.2378024,,#3985,Rickert 2024,"",""
Preparing for an Era of Deepfakes and AI-Generated Ads: A Framework for Understanding Responses to Manipulated Advertising,"Campbell, C; Plangger, K; Sands, S; Kietzmann, J","Traditionally, the production and distribution of advertising material has relied on human effort and analog tools. However, technological innovations have given the advertising industry digital and automatic tools that enable advertisers to automate many advertising processes and produce ""synthetic ads,"" or ads comprising content based on the artificial and automatic production and modification of data. The emerging practice of synthetic advertising, to date the most sophisticated form of ad manipulation, relies on various artificial intelligence (AI) techniques, such as deepfakes and generative adversarial networks (GANs), to automatically create content that depicts an unreal, albeit convincing, artificial version of reality. In this article, a general framework is constructed to better understand how consumers respond to all forms of ad manipulation. It is anticipated that this article will help explain how consumers respond to the more sophisticated forms of synthetic ads-such as deepfakes-that are emerging at an accelerating rate. To guide research in this area, a research agenda is developed focusing on three manipulated advertising areas: ad falsity, consumer response, and originality. Furthermore, the implications for theory and industry are considered.",2022,,JOURNAL OF ADVERTISING,51,1,22-38,WOS:000651731900001,10.1080/00913367.2021.1909515,,#3986,Campbell 2022,"",""
Argumentation and explainable artificial intelligence: a survey,"Vassiliades, A; Bassiliades, N; Patkos, T","Argumentation and eXplainable Artificial Intelligence (XAI) are closely related, as in the recent years, Argumentation has been used for providing Explainability to AI. Argumentation can show step by step how an AI System reaches a decision; it can provide reasoning over uncertainty and can find solutions when conflicting information is faced. In this survey, we elaborate over the topics of Argumentation and XAI combined, by reviewing all the important methods and studies, as well as implementations that use Argumentation to provide Explainability in AI. More specifically, we show how Argumentation can enable Explainability for solving various types of problems in decision-making, justification of an opinion, and dialogues. Subsequently, we elaborate on how Argumentation can help in constructing explainable systems in various applications domains, such as in Medical Informatics, Law, the Semantic Web, Security, Robotics, and some general purpose systems. Finally, we present approaches that combine Machine Learning and Argumentation Theory, toward more interpretable predictive models.",2021,,KNOWLEDGE ENGINEERING REVIEW,36,,,WOS:000636751800001,10.1017/S0269888921000011,,#3987,Vassiliades 2021,"",""
An AI-Empowered Visual Storyline Generator,"Liu, C; Lim, ZY; Yu, H; Shen, ZQ; Dixon, I; Gao, ZN; Wang, P; Ren, PR; Xie, XS; Cui, LZ; Miao, CY","Video editing is currently a highly skill- and time-intensive process. One of the most important tasks in video editing is to compose the visual storyline. This paper outlines Visual Storyline Generator (VSG), an artificial intelligence (AI)-empowered system that automatically generates visual storylines based on a set of images and video footages provided by the user. It is designed to produce engaging and persuasive promotional videos with an easy-to-use interface. In addition, users can be involved in refining the AI-generated visual storylines. The editing results can be used as training data to further improve the AI algorithms in VSG.",2020,,PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE,,,5267-5269,WOS:000764196705088,,,#3988,Liu 2020,"",""
Typologies of Persuasive Strategies and Content: A Formalization Using Argumentation,"Guerrero, E; Lindgren, H","Persuasion is an active research topic in artificial intelligence (AI), human-computer interaction (HCI), and social sciences. When persuasive technology has been designed, some HCI guidelines have commonly used disregarding the current AI state of the art, for example, ignoring autonomy and proactive AI behavior. In this paper, a systematic review of HCI persuasive strategies and their corresponding content is mapped to a formal AI approach using argumentation theory. We also present experimental results using as context a mobile application for behavior change in the Swedish context.",2021,,"ADVANCES IN PRACTICAL APPLICATIONS OF AGENTS, MULTI-AGENT SYSTEMS, AND SOCIAL GOOD: THE PAAMS COLLECTION, PAAMS 2021",12946,,101-113,WOS:000791045800009,10.1007/978-3-030-85739-4_9,,#3989,Guerrero 2021,"",""
"""I know it's a deepfake"": the role of AI disclaimers and comprehension in the processing of deepfake parodies","Lu, H; Yuan, SP","Rapid innovations in media technologies have ushered in diverse entertainment avenues, including politically oriented content, presenting both novel opportunities and societal challenges. This study delves into the implications of the burgeoning deepfake phenomenon, particularly focusing on audience interpretation and engagement with deepfake parodies, a quintessential example of ""misinfotainment."" Additionally, it examines the potential impact of artificial intelligence (AI) disclaimers on audience understanding and related consequences. To probe this, two experiments (N = 2,808) were executed featuring parodied politicians adopting opposing viewpoints on the issue of climate change. U.S. participants were either exposed to deepfake videos prefaced with AI disclaimers or without. Results indicate that the inclusion of an AI disclaimer significantly influenced audience comprehension and their ability to recognize the parody. These factors were subsequently associated with enjoyment, discounting, and counterarguing, which in turn showed different relationships with policy support and sharing intentions. This article culminates with insights into the theoretical underpinnings and practical ramifications of these findings.",2024,,JOURNAL OF COMMUNICATION,74,5,,WOS:001249909600001,10.1093/joc/jqae022,,#3990,Lu 2024,"",""
AI-supported Health Coaching Model for Patients with Chronic Diseases,"IEEE; Sqalli, MT; Al-Thani, D","The global expenditure of healthcare systems on the management of chronic diseases is exhausting costs and efforts. This is due to the delicate nature of patients needing care constantly, as well as the chronic nature of the diseases. These two causes force patients to pay visits to their healthcare providers more frequently. Repetitive visits are countless, short in time, unmanageable and ineffective. The state of the art for managing chronic diseases focus on a shared effort between the patient and the physician in an ongoing process of collecting, monitoring, analyzing, and finally adapting the management program by the physician and the patient. Technology along with Artificial Intelligence (AI) made these processes easier. However, studies have rarely attempted to introduce models that integrated AI in health coaching plans for patients with chronic diseases. As health coaching is an integral part of some countries public health strategy. It is now used as a complementary medical intervention to shape healthy behavior change. In this paper we propose a model that puts health coaching along with AI in its core to 1. empower patients to effectively manage their chronic conditions 2. as well as to persuade them to adhere to their care management program for extended periods of time.",2019,,2019 16TH INTERNATIONAL SYMPOSIUM ON WIRELESS COMMUNICATION SYSTEMS (ISWCS),,,452-456,WOS:000591678700087,10.1109/iswcs.2019.8877113,,#3991,IEEE 2019,"",""
THE USE OF ARTIFICIAL INTELLIGENCE IN ELECTION CAMPAIGNS AND ITS DEMOCRATIC EFFECTS,"Rubio, R","The use of artificial intelligence (AI) in election campaigns is significantly transforming the political and democratic landscape. AI has introduced new dynamics into electoral processes, impacting the way campaigns are conducted, which can pose a threat to the integrity of democratic systems. Technological innovations affect the way election campaigns are managed and executed. From traditional media such as radio, television and film, to digital platforms, technological evolution has enabled greater personalization and effectiveness in political communication. AI facilitates the analysis of large volumes of data, enabling highly segmented and personalized campaigns. At the same time, technological threats are a growing concern for democracy. Data manipulation, false profiling and cyber-attacks are some of the risks faced by electoral processes. These practices can affect the transparency and fairness of elections, compromising basic principles such as the freedom to vote. Digitalization amplifies both information and disinformation. Political propaganda has become more sophisticated, using AI techniques to create and disseminate disinformative content more effectively. This phenomenon contributes to the fragmentation and polarization of public opinion and can erode trust in the democratic process and institutions. AI is used to improve the persuasiveness and determent of political parties and candidates. It allows the creation of more sophisticated communication strategies and the optimization of electoral resources. However, it also poses ethical and practical challenges, such as manipulation of reality through deepfakes and extreme segmentation of the electorate. Responses to the challenges posed by AI in the electoral field have been diverse. Some technology platforms have adopted self-regulatory measures, such as tagging AI-generated content. However, self-regulation has proved to be insufficient, and a more robust legislative response is required to protect the integrity of electoral processes. In some countries, laws prohibiting the use of deepfakes in election campaigns have already been implemented. AI offers both opportunities and risks, and its impact on democracy depends on how its applications are managed and its negative effects mitigated. It is crucial to establish clear national and international regulatory framework covering the use of AI in electoral campaigns. This framework must ensure transparency, fairness and protection of electoral rights. Collaboration between governments, electoral institutions, technology companies and civil society is essential to preserve the integrity and legitimacy of democratic processes in the digital era.",2025,,REVISTA DE DERECHO POLITICO,,122,65-102,WOS:001446672100002,10.5944/rdp.122.2025.44742,,#3992,Rubio 2025,"",""
Understanding users' AI manipulation intention: An empirical investigation of the antecedents in the context of AI recommendation algorithms,"Kim, T; Im, I","This study examines antecedents that drive platform users to manipulate artificial intelligence (AI) recommendation algorithms. Based on the persuasion knowledge model (PKM), survey data collected from YouTube and Instagram users reveal that AI manipulation intentions are positively affected by persuasion knowledge about AI and perceived interactivity. Perceived interactivity is associated with higher perceived benefits and lower perceived costs of AI manipulation, consequently affecting manipulation intentions. A multivariate analysis of variance shows variations in intentions to use different types of AI manipulation behaviors among users with varying levels of persuasion knowledge. The research contributes to the PKM and AI-human interaction literature.",2025,,INFORMATION & MANAGEMENT,62,1,,WOS:001361945300001,10.1016/j.im.2024.104061,,#3993,Kim 2025,"",""
Dual-process theory-driven transparent approach for seniors to accept health misinformation detection results,"Liu, F; Zhou, JL; Zuo, MY; Li, YB","Given seniors' concerns about the reliability of black-box models in health misinformation detection (HMID), there is a pressing need for explainable HMID methods that provide transparency and instill trust. Explainable artificial intelligence (AI) aims to foster understanding and trust in AI models by implementing transparency that embodies explainability and interpretability. However, most existing explainable HMID methods solely provide post-hoc explanations and neglect the interpretation of the models' internal logic, which prevents seniors from satisfactorily accepting the HMID results. Therefore, this study proposes a transparent Knowledge Graph-aware Two-Stage approach (KG2S) driven by the dual-process theory. KG2S combines explainability and interpretability by utilizing knowledge graphs (KGs) in two stages: Knowledge Breadth Retrieval (KBR) and Knowledge Depth Reasoning (KDR). These stages correspond with the heuristic and analytic processes of the dual-process theory, which encompasses human information processing. In the KBR stage, we leverage rich facts in KGs to replicate heuristic distillation behaviors of humans through a novel similarity-diversity twofold filter. In the KDR stage, we employ a hierarchical attention network to emulate humans' coarse-to-fine knowledge analyses during decision-making. Extensive experiments were conducted on two real-world datasets, along with user testing, to assess the effectiveness of the proposed model. Results demonstrated that the proposed model not only outperformed competing methods in terms of HMID accuracy but also provided persuasive detection processes and reasons. Moreover, the model showed high adaptability to new topics in HMID. Our research offers valuable insights into integrating humanistic into AI algorithms and promoting the trustworthiness of AI systems.",2024,,INFORMATION PROCESSING & MANAGEMENT,61,4,,WOS:001238759500001,10.1016/j.ipm.2024.103751,,#3994,Liu 2024,"",""
Exploring Persuasive Games for Emotion Regulation: A State-of-the-Art Scoping Review,"Ataguba, G; Chan, G; Orji, R","Persuasive games, designed and tailored to change users' behavior, have enhanced user experience across various domains. However, their role in emotion regulation remains understudied, despite the increasingly immersive environments they create that trigger emotional responses. Sensors have emerged as key artificial intelligence (AI) tools in persuasive games supporting emotion regulation compared to other AI technologies, such as chatbots. Yet the effectiveness, challenges, and applications of these sensors lack comprehensive exploration. Our scoping review analyzed 32 articles published from 2013 to 2023 on persuasive games using AI-based sensing technologies for emotion regulation. Results from 27 articles (84.8%) reporting the effectiveness of sensors revealed mostly large to moderate effects (d >= 0.8 <= 0.4). Common challenges with integrated sensors (camera systems, facial recognition, smartwatches, and altimetric pressure sensors) included emotion detection accuracy and ethical concerns. We provide design recommendations for developing ethically sound and effective persuasive games for emotion regulation in the future.",2025,,INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION,,,,WOS:001474190700001,10.1080/10447318.2025.2483863,,#3995,Ataguba 2025,"",""
A Self-Efficacy Theory-Based Study on the Teachers' Readiness to Teach Artificial Intelligence in Public Schools in Sri Lanka,"Rajapakse, CU; Ariyarathna, W; Selvakan, S","Objectives. This article explores teacher readiness for introducing artificial intelligence (AI) into Sri Lankan schools, drawing on self-efficacy theory. Similar to some other countries, Sri Lanka plans to integrate AI into the school curriculum soon. However, a key question remains: Are teachers prepared to teach this advanced technical subject to schoolchildren? Assessing teacher readiness is crucial, as it is intricately linked to the overall success of this initiative and will inform the development of appropriate policies. Participants. This study surveyed over 1,300 Sri Lankan public school teachers who teach Information and Communication Technology (ICT) using the snowball sampling approach. The respondents represent approximately 20% of the total ICT teacher population in Sri Lanka. Their readiness to teach AI was assessed using a general teacher self-efficacy scale specifically developed based on the well-established Self-Efficacy Theory. While key demographic factors like gender, education level and educational background were also collected, their impact analysis is not included in this article. Study Method. The study was conducted based on the premise that teachers' readiness to teach AI hinges on their self-efficacy towards teaching AI in the classroom. This premise was substantiated through a review of existing research, and a conceptual model of teachers' self-efficacy for AI instruction was developed. To assess this model, a nationwide survey targeting school ICT teachers was conducted. The questionnaire used in the survey was based on existing research on evaluating teacher self-efficacy. Data analysis, focusing on testing and validating the conceptual model, primarily employed the PLS-SEM approach. Findings. This study identified several key findings: (1) Teachers generally reported low self-efficacy regarding their ability to teach AI; (2) Teachers' self-efficacy was most influenced by their emotional and physiological states, as well as their imaginary experiences related to teaching AI; (3) Surprisingly, mastery experiences had a lesser impact on their self-efficacy for teaching AI; and (4) Neither vicarious experiences (observing others teach AI) nor verbal persuasion had a significant impact on teachers' self-efficacy. Additionally, the study revealed that the teachers' own level of expertise in AI, along with their social capital, is insufficient to deliver a standard AI curriculum. Conclusions. The analysis of the results found that Sri Lankan teachers currently lack the readiness to teach AI in schools effectively. Potential lapses in certain sources of self-efficacy were also identified. It further revealed the need for a more systemic approach to teacher professional development. Therefore, the study recommends further research exploring the potential of incorporating a socio-technical systems perspective into the government's teacher training initiatives.",2024,,ACM TRANSACTIONS ON COMPUTING EDUCATION,24,4,,WOS:001400542400007,10.1145/3691354,,#3996,Rajapakse 2024,"",""
Ethics of generative AI and manipulation: a design-oriented research agenda,"Klenk, M","Generative AI enables automated, effective manipulation at scale. Despite the growing general ethical discussion around generative AI, the specific manipulation risks remain inadequately investigated. This article outlines essential inquiries encompassing conceptual, empirical, and design dimensions of manipulation, pivotal for comprehending and curbing manipulation risks. By highlighting these questions, the article underscores the necessity of an appropriate conceptualisation of manipulation to ensure the responsible development of Generative AI technologies.",2024,,ETHICS AND INFORMATION TECHNOLOGY,26,1,,WOS:001153891400001,10.1007/s10676-024-09745-x,,#3997,Klenk 2024,"",""
Illusory Arguments by Artificial Agents: Pernicious Legacy of the Sophists,"Clark, MH; Bringsjord, S","To diagnose someone's reasoning today as ""sophistry"" is to say that this reasoning is at once persuasive (at least to a significant degree) and logically invalid. We begin by explaining that, despite some recent scholarly arguments to the contrary, the understanding of 'sophistry' and 'sophistic' underlying such a lay diagnosis is in fact firmly in line with the hallmarks of reasoning proffered by the ancient sophists themselves. Next, we supply a rigorous but readable definition of what constitutes sophistic reasoning (=sophistry). We then discuss ""artificial"" sophistry: the articulation of sophistic reasoning facilitated by artificial intelligence (AI) and promulgated in our increasingly digital world. Next, we present, economically, a particular kind of artificial sophistry, one embodied by an artificial agent: the lying machine. Afterward, we respond to some anticipated objections. We end with a few speculative thoughts about the limits (or lack thereof) of artificial sophistry, and what may be a rather dark future.",2024,,HUMANITIES-BASEL,13,3,,WOS:001256706700001,10.3390/h13030082,,#3998,Clark 2024,"",""
The Persuasive Power of AI Ingratiation: A Persuasion Knowledge Theory Perspective,"Usman, U; Kim, T; Garvey, A; Duhachk, A","This article examines the emerging marketing tactic of artificial intelligence (AI) ingratiation of humans and reveals that AI ingratiation leads to increased consumer acceptance of product recommendations. The positive effect of ingratiation is explained by consumers' self-enhancing motivations to believe that AI's ingratiating comments are particularly accurate and objective. Moreover, these ingratiation effects are moderated by the extent to which AI is anthropomorphized. Counter to the literature showing benefits of anthropomorphism and consistent with the persuasion knowledge model, consumers perceive ingratiation by humanlike (vs. machinelike) AI systems to be more driven by ulterior motives, thereby activating consumer defense mechanisms against ingratiation attempts. Our theory and findings elucidate how AI design features serve to strengthen or weaken consumer resistance to persuasion. We discuss the implications of our findings for the development and ethical utilization of the sophisticated conversational AI that are fast emerging in various marketing contexts.",2024,,JOURNAL OF THE ASSOCIATION FOR CONSUMER RESEARCH,9,3,319-331,WOS:001228783600001,10.1086/730280,,#3999,Usman 2024,"",""
Can AI and AI-Hybrids Detect Persuasion Skills? Salesforce Hiring with Conversational Video Interviews,"Chakraborty, I; Chiong, K; Dover, H; Sudhirc, K","We develop an AI and AI-human-based model for salesforce hiring using recordings of conversational video interviews that involve two-sided, back-and-forth interactions with messages conveyed through multiple modalities (text, voice, and body language). We derive objective, theory-backed measures of sales performance from these modalities, leveraging recent advances in body language analysis, conversational analysis, and large language models (LLMs). These measures serve as explanatory variables in our AI model. Our key contribution to the broader research on persuasion and influence is that we show how to use conversational videos to capture features related to (i) two-way conversational interactivity; (ii) real-time adaptation; and (iii) human body language, with minimal measurement error relative to extant survey-based approaches that suffer from recall biases. We use rubric-based scores by panels of sales professionals (correlated with hiring decisions) to isolate a candidate's ""latent sales ability"" and use these as outcome variables to be predicted by the AI model. The AI model achieves reasonable predictive accuracy, yet incorporating human judgments into an AI-human hybrid model enhances its effectiveness-improving workforce quality by 67% over random selection. Although the content of what is spoken is most important in prediction, conversational interactivity, sellers' real-time adaptation to the buyer, and body language also have good explanatory power. Finally, in terms of performance-cost trade-offs, the addition of just one human professional evaluation in the hiring loop in combination with AI is optimal. Further, using human input based on only the two early stages of the interview in a task-based hybrid model is the most cost-effective in improving performance.",2025,,MARKETING SCIENCE,44,1,,WOS:001318291200001,10.1287/mksc.2023.0149,,#4000,Chakraborty 2025,"",""
The power of human-like virtual-influencer-generated content: Impact on consumers' willingness to follow and purchase intentions,"Rungruangjit, W; Mongkol, K; Piriyakul, I; Charoenpornpanichkul, K","The swift progress in machine learning algorithms, artificial intelligence, and interactive immersive media technologies has led to the introduction of computer-generated imagery on Instagram. This feature, so-called ""human-like virtual influencers (VIs)"", has revolutionized the way people interact with technology. Using a combination of cutting-edge AI technologies, in a novel application of computer vision algorithms, and large language models to extract the content posted by two popular human-like VIs on Instagram, the present study is the first to categorize and classify types of human-like virtual-influencer-generated content. Quantitative methods, such as partial least squares structural equation modeling (PLS-SEM), were used to examine the impact of human-like virtual-influencer-generated content on consumers' willingness to follow as well as purchase intentions. The information was gathered from 650 Thai customers. The findings showed that consumers' willingness to follow and purchase intentions were significantly influenced by the positive effects of emotional appeal content, which includes relational, entertaining, positive emotion, and negative emotion content. These effects outweighed those of rational appeal content, such as informative and remunerative content, as well as authenticity appeal content. Meanwhile, disclosing sponsored content had no effect on consumers' willingness to follow. The theoretical underpinnings of uses and gratifications (U&G) theory, parasocial relationships and Richins' hierarchical model of emotions are confirmed and expanded upon in this work, and the suggested inclusive approach also significantly advances the expanding corpus of research on VIs. Our research also provides a contribution to the recent literature on human-like VI marketing.",2024,,COMPUTERS IN HUMAN BEHAVIOR REPORTS,16,,,WOS:001358768300001,10.1016/j.chbr.2024.100523,,#4001,Rungruangjit 2024,"",""
"ChatGPT Is Powerful, but Does It Have Power Distance? A Study of Culturally Imbued Discourse in AI-Generated Essays","Schenck, A","Power distance (PD), a cultural value denoting acceptance of asymmetrical power relationships, influences the force of rhetoric used by a writer to address their reader. However, AI technologies such as ChatGPT lack an explicit awareness of PD, which could affect the quality of AI-generated persuasive texts used for language learning. To investigate this issue, 200 persuasive essays written by ChatGPT were compared to 200 essays written by L1-English university learners. Three elements of formulaic language related to PD were examined: stances, modals, and pronoun deixis. Differences in stances (z = -3.411; p = .001) and modals (z = -2.100; p = .036) were both significant according to the Wilcoxon signed ranks formula, whereas differences in pronoun deixis were nearly significant (z = -1.917; p = .055). Overall, language of ChatGPT appears generic and incomplete, suggesting that consistent and uniform expressions are being borrowed from an LLM training corpus to mimic aspects of PD. Limitations of AI highlight a need for pedagogical emphasis of culturally imbued discourse.",2024,,INTERNATIONAL JOURNAL OF ADULT EDUCATION AND TECHNOLOGY-IJAET,15,1,,WOS:001162770500002,10.4018/IJAET.338219,,#4002,Schenck 2024,"",""
"More Victories, Less Cooperation: Assessing Cicero's Diplomacy Play","Wongkamjan, W; Gu, F; Wang, YZ; Hermjakob, U; May, J; Stewart, BM; Kummerfeld, JK; Peskoff, D; Boyd-Graber, JL","The boardgame Diplomacy is a challenging setting for communicative and cooperative artificial intelligence. The most prominent communicative Diplomacy AI, Cicero, has excellent strategic abilities, exceeding human players. However, the best Diplomacy players master communication, not just tactics, which is why the game has received attention as an AI challenge. This work seeks to understand the degree to which Cicero succeeds at communication. First, we annotate in-game communication with abstract meaning representation to separate in-game tactics from general language. Second, we run two dozen games with humans and Cicero, totaling over 200 humanplayer hours of competition. While AI can consistently outplay human players, AI-Human communication is still limited because of AI's difficulty with deception and persuasion. This shows that Cicero relies on strategy and has not yet reached the full promise of communicative and cooperative AI.",2024,,"PROCEEDINGS OF THE 62ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1: LONG PAPERS",,,12423-12441,WOS:001391776303034,,,#4003,Wongkamjan 2024,"",""
Effect of disclosing AI-generated content on prosocial advertising evaluation,"Baek, TH; Kim, J; Kim, JH","With advancements in generative artificial intelligence (AI) technology, there is a growing concern about its ethical implications, transparency, and consumer reactions to AI-generated content. Building on the persuasion knowledge model and algorithm aversion literature, this study explores the effects of AI disclosure in prosocial advertising on consumer attitudes and donation intentions. The findings of Study 1 indicate that the initial disclosure of AI-generated content leads to unfavourable attitudes towards ads, with perceived ad credibility serving as a mediating factor. In Study 2, participants who perceived AI as more human-like rather than machine-like tended to experience a diminished negative impact of AI disclosure. Study 3 also highlights the crucial role of perceived ad credibility in influencing donation intentions following the disclosure of AI-generated content. The theoretical and practical implications of our findings for social marketers and nonprofit organizations are discussed further.",2024,,INTERNATIONAL JOURNAL OF ADVERTISING,,,,WOS:001320723300001,10.1080/02650487.2024.2401319,,#4004,Baek 2024,"",""
AI-determined similarity increases likability and trustworthiness of human voices,"Jaggy, O; Schwan, S; Meyerhoff, HS","Modern artificial intelligence (AI) technology is capable of generating human sounding voices that could be used to deceive recipients in various contexts (e.g., deep fakes). Given the increasing accessibility of this technology and its potential societal implications, the present study conducted online experiments using original data to investigate the validity of AI-based voice similarity measures and their impact on trustworthiness and likability. Correlation analyses revealed that voiceprints - numerical representations of voices derived from a speaker verification system - can be used to approximate human (dis)similarity ratings. With regard to cognitive evaluations, we observed that voices similar to one's own voice increased trustworthiness and likability, whereas average voices did not elicit such effects. These findings suggest a preference for self-similar voices and underscore the risks associated with the misuse of AI in generating persuasive artificial voices from brief voice samples.",2025,,PLOS ONE,20,3,,WOS:001438431500008,10.1371/journal.pone.0318890,,#4005,Jaggy 2025,"",""
Minding the source: toward an integrative theory of human-machine communication,"Lee, EJ","According to the computers are social actors (CASA) paradigm, a dominant theoretical framework for research on human-computer interaction, people treat computers as if they were people. Recent studies on human-machine communication (HMC) and human-artificial intelligence (AI) interaction, however, appear to focus on when and how people respond to machines differently than to human agents. To reconcile this apparent contradiction, this study reviews critically the two overarching theoretical explanations proposed and tested in each respective tradition, the mindlessness account and the machine heuristic. After elaborating on several conceptual and operational issues with each explanatory mechanism, an alternative theoretical model of HMC is proposed that integrates both research traditions and generates predictions that potentially deviate from the dual-process models. Lastly, it is discussed how recent developments in AI technology invite modifications to the current understanding of HMC and beyond.",2024,,HUMAN COMMUNICATION RESEARCH,50,2,184-193,WOS:001090907800001,10.1093/hcr/hqad034,,#4006,Lee 2024,"",""
Face the Uncanny: The Effects of Doppelganger Talking Head Avatars on Affect-Based Trust Toward Artificial Intelligence Technology are Mediated by Uncanny Valley Perceptions,"Weisman, WD; Peña, JF","This experiment (N=228) examined how exposure to a talking head doppelganger created by an artificial intelligence (AI) program influenced affect-based trust toward AIs. Using a 3 (talking head featuring the participant's or a stranger's face, audio-only condition) by 2 (pro-AI pitch and anti-AI pitch playback) design, we uncovered that exposure to a talking head featuring the participant's face instead of a stranger's face increased uncanny valley perceptions. Furthermore, uncanny valley perceptions mediated the link between exposure to a talking head with the participant's face on affect-based trust. Overall, exposure to a doppelganger talking head, who delivered a persuasive pitch, triggered discomfort on the participant whose features were sourced to craft a synthetic talking head, which in turn decreased affect-based trust attributed to AIs. This phenomenon is rooted in basic psychological mechanisms that underpin the uncanny valley hypothesis. Future studies may test for these findings across different platforms and also provide evidence regarding user mental processing.",2021,,CYBERPSYCHOLOGY BEHAVIOR AND SOCIAL NETWORKING,24,3,182-187,WOS:000624611800001,10.1089/cyber.2020.0175,,#4007,Weisman 2021,"",""
From Didachography to AI: Metaphors Teaching is Automated by,"Ferreira, GMD; Lemgruber, MS; Cabrera, TL","Although automation is not a novelty, high hopes are currently pinned on more and more ingenious devices built with Artificial Intelligence (AI). AI has become a key discussion point in the agendas of governments and multinational agencies, with particular interest in educational applications. This article explores parallels between ideas surrounding AI in education and conceptions proposed in the 17th century by Jan Amos Comenius, known as the father of modern education. Drawing upon illustrations from ongoing research that takes metaphor as its core analytical category, the piece assumes that metaphors are not mere stylistic elements, but strategic persuasive devices. Comenius' didachography, a portmanteau coined in his 1657 Didactica Magna to describe an inclusive educational system, relies heavily on metaphors that suggest remarkable similarities with contemporary EdTech rhetoric, especially on AI -related developments. Whilst exemplifying that ideas and premises entailed in current discourses on EdTech may hark back to centuries-old ideas, the paper argues that, despite taking on varying, contextually situated linguistic expressions, underlying metaphors appear to have endured from Comenius' time to support the advent of an educational system poised to automate teaching and, thus, dispense with a key part of his scheme: the teacher. In closing, the piece suggests that we may need to acknowledge the contingent nature of teaching and learning, perhaps accepting that key aspects of what makes us human may always resist engineering.",2023,,JOURNAL OF INTERACTIVE MEDIA IN EDUCATION,,1,,WOS:000952216700001,10.5334/jime.798,,#4008,Ferreira 2023,"",""
Can AI tell good stories? Narrative transportation and persuasion with ChatGPT,"Chu, HR; Liu, SX","Storytelling is a human universal. The ubiquity of stories and the rapid development in Artificial Intelligence (AI) pose important questions: can AI like ChatGPT tell engaging and persuasive stories? If so, what makes a narrative engaging and persuasive? Three pre-registered experiments comparing human-generated narratives from existing research and the ChatGPT-generated versions using descriptions and materials from these studies show that labeling AI as a narrative source led to lower transportation, higher counterarguing, and lower story-consistent beliefs. However, AI-generated narratives led to lower (Study 1 and 3) or similar levels (Study 2) of counterarguing than the human-generated version. Readers showed lower (Study 2) or similar levels of transportation (Study 1 and 3) when reading the AI- than the human-generated stories. We suggest the AI model's linguistic competence and logical coherence contribute to its stories' verisimilitude. However, AI's lack of lived experience and creativity may limit its storytelling ability.",2024,,JOURNAL OF COMMUNICATION,74,5,347-358,WOS:001311927100001,10.1093/joc/jqae029,,#4009,Chu 2024,"",""
BookGPT: A General Framework for Book Recommendation Empowered by Large Language Model,"Li, ZY; Chen, YF; Zhang, X; Liang, X","With the continuous development and change exhibited by large language model (LLM) technology, represented by generative pretrained transformers (GPTs), many classic scenarios in various fields have re-emerged with new opportunities. This paper takes ChatGPT as the modeling object, incorporates LLM technology into the typical book resource understanding and recommendation scenario for the first time, and puts it into practice. By building a ChatGPT-like book recommendation system (BookGPT) framework based on ChatGPT, this paper attempts to apply ChatGPT to recommendation modeling for three typical tasks: book rating recommendation, user rating recommendation, and the book summary recommendation; it also explores the feasibility of LLM technology in book recommendation scenarios. At the same time, based on different evaluation schemes for book recommendation tasks and the existing classic recommendation models, this paper discusses the advantages and disadvantages of the BookGPT in book recommendation scenarios and analyzes the opportunities and improvement directions for subsequent LLMs in these scenarios. The experimental research shows the following: (1) The BookGPT can achieve good recommendation results in existing classic book recommendation tasks. Especially in cases containing less information about the target object to be recommended, such as zero-shot or one-shot learning tasks, the performance of the BookGPT is close to or even better than that of the current classic book recommendation algorithms, and this method has great potential for improvement. (2) In text generation tasks such as book summary recommendation, the recommendation effect of the BookGPT model is better than that of the manual editing process of Douban Reading, and it can even perform personalized interpretable content recommendations based on readers' attribute and identity information, making it more persuasive than interpretable one-size-fits-all recommendation models. Finally, we have open-sourced the relevant datasets and experimental codes, hoping that the exploratory program proposed in this paper can inspire the development of more LLMs to expand their applications and theoretical research prospects in the field of book recommendation and general recommendation tasks.",2023,,ELECTRONICS,12,22,,WOS:001120854800001,10.3390/electronics12224654,,#4010,Li 2023,"",""
Effects of customer inoculation on artificial intelligence service failure,"Meng, L; Chen, JQ; Yang, MY; Wang, YJ","PurposeThis paper aims to explore the effectiveness of customer inoculation strategies in the context of AI service failures in the hospitality and tourism industries. Furthermore, it examines how these strategies can enhance customer complaint behavior and satisfaction with service recovery, thereby improving the overall service experience.Design/methodology/approachFour distinct studies were conducted: Study 1 investigated the influence of customer inoculation on complaint behavior post-AI service failure. Study 2 assessed the impact of service remedies on customer satisfaction. Study 3 explored the implications of initial purchase and usage intentions. Finally, Study 4 validated the findings using a large-scale online survey.FindingsThe results indicated that customer inoculation significantly increases customer complaint behavior and satisfaction with service remedies following AI service failures. They also showed that this relationship is mediated by psychological distance. Furthermore, customer inoculation positively affects initial purchase and usage intentions, demonstrating effectiveness at various customer engagement stages.Practical implicationsThis study enriches the literature on AI hospitality service failure and recovery by introducing the novel concept of customer inoculation. Additionally, it significantly contributes to the inoculation theory literature, which covers diverse fields. Practically, this study proposes an efficient and low-cost strategy for marketers.Originality/valueThis study introduces the concept of customer inoculation in the context of AI service failures, a novel approach in the hospitality and tourism literature. It provides empirical evidence of the efficacy of the strategy, bridging a crucial gap in understanding customer behavior in the face of technological disruptions.",2025,,INTERNATIONAL JOURNAL OF CONTEMPORARY HOSPITALITY MANAGEMENT,37,2,444-461,WOS:001317356200001,10.1108/IJCHM-01-2024-0140,,#4011,Meng 2025,"",""
"Explanation in AI and law: Past, present and future","Atkinson, K; Bench-Capon, T; Bollegala, D","Explanation has been a central feature of AI systems for legal reasoning since their inception. Recently, the topic of explanation of decisions has taken on a new urgency, throughout AI in general, with the increasing deployment of AI tools and the need for lay users to be able to place trust in the decisions that the support tools are recommending. This paper provides a comprehensive review of the variety of techniques for explanation that have been developed in AI and Law. We summarise the early contributions and how these have since developed. We describe a number of notable current methods for automated explanation of legal reasoning and we also highlight gaps that must be addressed by future systems to ensure that accurate, trustworthy, unbiased decision support can be provided to legal professionals. We believe that insights from AI and Law, where explanation has long been a concern, may provide useful pointers for future development of explainable AI. (C) 2020 Elsevier B.V. All rights reserved.",2020,,ARTIFICIAL INTELLIGENCE,289,,,WOS:000591726900007,10.1016/j.artint.2020.103387,,#4012,Atkinson 2020,"",""
"Hmm, the effect of AI conversational fillers on consumer purchase intentions","Liu, GL; Liu, MW; Zhu, QC","AI conversational agents are increasingly prevalent in marketing practices. A recent effort to make AI conversational agents humanlike is the use of conversational fillers, such as uh, um, and hmm. While computer science research has shown that conversational fillers used by AI agents generally improve users' interactional experiences, their effects in marketing remain unexplored. This research examines AI conversational fillers in a sales and promotion context and shows that they trigger consumers' suspicion of ulterior motives, thereby decreasing their purchase intentions, an effect moderated by organization type (for-profit vs. nonprofit). We conducted one field experiment and four online experiments with different modalities, products, and languages to provide empirical support for the hypotheses. In so doing, this research contributes to the research on chatbot natural language and AI persuasion by showing that the persuasion knowledge model can come into work in consumers' interaction with AI agents.",2024,,MARKETING LETTERS,,,,WOS:001361417100001,10.1007/s11002-024-09760-4,,#4013,Liu 2024,"",""
The Problem of AI Hallucination and How to Solve It,"Jancarík, A; Dusek, O","AI in education is a topic that has been researched for the last 70 years. However, the last two years have seen very significant changes. These changes relate to the introduction of OpenAI's ChatGPT chatbot in November 2022. The GPT (Generative Pre-trained Transformer) language model has dramatically influenced how the public approaches artificial intelligence. For many, generative language models have become synonymous with AI and have come uncritically viewed as a universal source of answers to most questions. However, it soon became apparent that even generative language models had their limits. Among the main problems that emerged was hallucination (providing answers containing false or misleading information), which is expected in all language models. The main problem of hallucination is that this information is difficult to distinguish from other information, and AI language models are very persuasive in presenting it. The risks of this phenomenon are much more substantial when using language modules to support learning, where the learner cannot distinguish correct information from incorrect information. The proposed paper focuses on the area of AI hallucination in mathematics education. It will first show how AI chatbots hallucinate in mathematics and then present one possible solution to counter this hallucination. The presented solution was created for the AI chatbot Edu-AI and designed to tutor students in mathematics. Usually, the problem is approached so that the system verifies the correctness of the output offered by the chatbot. Within the Edu-AI, checking responses is not implemented, but checking inputs is. If an input containing a factual query is recorded, it is redirected, and the answer is traced to authorised knowledge sources and study materials. If a relevant answer cannot be traced in these sources, a redirect to a natural person who will address the question is offered. In addition to describing the technical solution, the article includes concrete examples of how the system works. This solution has been developed for the educational domain but applies to all domains where users must be provided with relevant information.",2024,,"PROCEEDINGS OF THE 23RD EUROPEAN CONFERENCE ON E-LEARNING, ECEL 2024",23/1,,122-128,WOS:001438533400015,,,#4014,Jancarík 2024,"",""
Artificial Authorship and Judicial Opinions,"Re, RM","Generative Artificial Intelligence (""AI"") is already beginning to alter legal practice. If optimistic forecasts prove warranted, how might this technology transform judicial opinions-a genre often viewed as central to the law? This Symposium Essay attempts to answer that predictive question, which sheds light on present realities. In brief, the provision of opinions will become cheaper and, relatedly, more widely and evenly supplied. Judicial writings will often be zestier, more diverse, and less deliberative. And as the legal system's economy of persuasive ability is disrupted, courts will engage in a sort of arms race with the public: judges will use artificially enhanced rhetoric to promote their own legitimacy, and the public will become more cynical to avoid being fooled. Paradoxically, a surfeit of persuasive rhetoric could render legal reasoning itself obsolete. In response to these developments, some courts may disallow AI writing tools so that they can continue to claim the authority that flows from authorship. Potential stakes thus include both the fate of legal reason and the future of human participation in the legal system.",2024,,GEORGE WASHINGTON LAW REVIEW,92,6,1558-1590,WOS:001382638800008,,,#4015,Re 2024,"",""
Deepfakes as a Democratic Threat: Experimental Evidence Shows Noxious Effects That Are Reducible Through Journalistic Fact Checks,"Dan, VRL","Concerns have been raised over AI-generated deepfakes and their impact on democracy. Unlike earlier forms of disinformation relying on text or traditional video-editing techniques (cheapfakes), deepfakes employ artificial intelligence, provoking speculations that they may be even more persuasive and harder to debunk. Using an experiment with a multiple-message design (N = 2,085), we found that fake videos suggesting a sex, corruption, or prejudice scandal-but not text-only fakes-elicited substantial reputational damage for an innocent politician, regardless of whether the underlying technique was ""cheap"" or ""deep."" This was visible in altered attitudes, emotions, and voting intentions. However, exposure to a journalistic fact-check substantially reduced and even eliminated the detrimental effects. These findings have important implications for our theoretical understanding related to the effects of and mitigation strategies for deepfakes. While clearly highlighting the significant persuasive potential of deepfakes (and visual disinformation in general), the present study paints a more nuanced picture than was previously possible.",2025,,INTERNATIONAL JOURNAL OF PRESS-POLITICS,,,,WOS:001417603600001,10.1177/19401612251317766,,#4016,Dan 2025,"",""
Linking Ethnicity Targeting with Artificial Intelligence and Data Collection: Perceptions and Behavioral Responses of Black Consumers,"Zhang, WL; Rodgers, S","Data-centric targeting with artificial intelligence (AI) is transforming advertising by using machine learning and big data to target consumers, creating value for both consumers and brands. Despite the growing interest in ethnicity targeting in social media, there is still much to learn about leveraging ethnicity data for advertising research and practice. In this study, we surveyed 1,030 Black U.S. social media users to explore their understanding of AI and data gathering related to ethnicity. We focused on ethnic affinity targeting (EAT), a controversial tactic used by social media platforms. Our results indicate that the ethical aspects of persuasion knowledge, specifically appropriateness beliefs, affect consumers' coping strategies through distinct mechanisms. Consumers' ethnic identification and the stability of their affinity feelings toward social media also influence intentions to use specific coping strategies. These findings suggest that consumers' perceptions of ethnicity targeting depend on how advertisers collect and use ethnicity data and underscore the importance of diverse perspectives to inform algorithm transparency practices and policies.",2023,,JOURNAL OF CURRENT ISSUES AND RESEARCH IN ADVERTISING,44,3,373-391,WOS:001032791600001,10.1080/10641734.2023.2212022,,#4017,Zhang 2023,"",""
Does humanization or machinization make the IoT persuasive? The effects of source orientation and social presence,"Kang, H; Kim, KJ","The advent of Internet of Things (IoT) technology has revolutionized both the roles and functions of everyday objects and how users interact with them. Using artificial intelligence (AI) and an advanced capacity for communication, smart objects can now function as communication sources and deliver persuasive messages. This study investigates how different types of agency and source cues shape the persuasiveness of a smart object via social presence. When users interacted with a smart object that exerted its own agency, they sensed greater social presence when the object used machine cues rather than human cues. Conversely, when users interacted with a smart object that allowed the user to exercise their own agency, human cues, rather than machine cues, produced greater feelings of social presence, which enhanced the persuasiveness of the messages conveyed by the object. However, the persuasive effects of social presence were reversed when the interaction prompted AI anxiety in the user.",2022,,COMPUTERS IN HUMAN BEHAVIOR,129,,,WOS:000740277100010,10.1016/j.chb.2021.107152,,#4018,Kang 2022,"",""
They misused me! Digital literacy's dual role in AI marketing manipulation and unethical young consumer behavior,"Qadri, UA; Moustafa, AMA; Abd Ghani, M","PurposeArtificial intelligence (AI)-driven marketing has transformed the landscape of consumer interactions, but it also raises ethical concerns regarding perceived manipulation and subsequent unethical young consumer behavior. This study aims to investigate the direct and indirect effects of AI-driven marketing on unethical young consumer behavior, with digital literacy as a moderating variable. The authors introduce and conceptualize a digital literacy construct that influences how young consumers perceive and react to manipulative AI-driven marketing tactics.Design/methodology/approachUsing the Elaboration Likelihood Model (ELM) and the Persuasion Knowledge Model (PKM), this research explores how digital literacy influences the reception of AI-driven marketing and moderates the effects of perceived manipulative tactics. This study adopts a three-wave, time-lagged survey method among young consumers in urban Pakistan, integrating measures of AI-driven marketing techniques, perceived manipulation, digital literacy and unethical consumer behavior.FindingsThe results reveal that perceived manipulation mediates the relationship between AI-driven marketing and unethical young consumer behavior. Digital literacy significantly moderates this effect, indicating that higher digital literacy levels can mitigate the negative impacts of perceived manipulation. Conversely, lower digital literacy amplifies the negative impacts of perceived manipulation.Practical implicationsThe findings underscore the need for marketers to foster transparency and ethical practices in AI-driven strategies. Enhancing consumer digital literacy can serve as a protective factor against unethical marketing practices.Originality/valueThis study contributes to the understanding of digital literacy's protective role against unethical AI-driven marketing practices. It extends existing models of persuasion and consumer response by demonstrating how digital literacy reshapes traditional consumer response frameworks in the context of AI-driven environments.",2025,,YOUNG CONSUMERS,,,,WOS:001397634100001,10.1108/YC-08-2024-2207,,#4019,Qadri 2025,"",""
Brain versus bot: Distinguishing letters of recommendation authored by humans compared with artificial intelligence,"Preiksaitis, C; Nash, C; Gottlieb, M; Chan, TM; Alvarez, A; Landry, A","Objectives: Letters of recommendation (LORs) are essential within academic medicine, affecting a number of important decisions regarding advancement, yet these letters take significant amounts of time and labor to prepare. The use of generative artificial intelligence (AI) tools, such as ChatGPT, are gaining popularity for a variety of academic writing tasks and offer an innovative solution to relieve the burden of letter writing. It is yet to be determined if ChatGPT could aid in crafting LORs, particularly in high-stakes contexts like faculty promotion. To determine the feasibility of this process and whether there is a significant difference between AI and human-authored letters, we conducted a study aimed at determining whether academic physicians can distinguish between the two.Methods: A quasi-experimental study was conducted using a single-blind design. Academic physicians with experience in reviewing LORs were presented with LORs for promotion to associate professor, written by either humans or AI. Participants reviewed LORs and identified the authorship. Statistical analysis was performed to determine accuracy in distinguishing between human and AI-authored LORs. Additionally, the perceived quality and persuasiveness of the LORs were compared based on suspected and actual authorship.Results: A total of 32 participants completed letter review. The mean accuracy of distinguishing between human- versus AI-authored LORs was 59.4%. The reviewer's certainty and time spent deliberating did not significantly impact accuracy. LORs suspected to be human-authored were rated more favorably in terms of quality and persuasiveness. A difference in gender-biased language was observed in our letters: human-authored letters contained significantly more female-associated words, while the majority of AI-authored letters tended to use more male-associated words.Conclusions: Participants were unable to reliably differentiate between human- and AI-authored LORs for promotion. AI may be able to generate LORs and relieve the burden of letter writing for academicians. New strategies, policies, and guidelines are needed to balance the benefits of AI while preserving integrity and fairness in academic promotion decisions.",2023,,AEM EDUCATION AND TRAINING,7,6,,WOS:001111135100001,10.1002/aet2.10924,,#4020,Preiksaitis 2023,"",""
Enhancing legal writing skills: The impact of formative feedback in a hybrid intelligence learning environment,"Weber, F; Wambsganss, T; Söllner, M","Recent developments in artificial intelligence (AI) have significantly influenced educational technologies, reshaping the teaching and learning landscape. However, the notion of fully automating the teaching process remains contentious. This paper explores the concept of hybrid intelligence (HI), which emphasizes the synergistic collaboration between AI and humans to optimize learning outcomes. Despite the potential of AI-enhanced learning systems, their application in a human-AI collaboration system often fails to meet anticipated standards, and there needs to be more empirical evidence showcasing their effectiveness. To address this gap, this study investigates whether formative feedback in an HI learning environment helps law students learn from their errors and write more structured and persuasive legal texts. We conducted a field experiment in a law course to analyse the impact of formative feedback on the exam results of 43 law students, as well as on the writer (students), the writing product and the writing process. In the control group, students received feedback conforming to the legal common practice, where they solved legal problems and subsequently received general feedback from a lecturer based on a sample solution. Students in the treatment group were provided with formative feedback that specifically targeted their individual errors, thereby stimulating internal cognitive processes within the students. Our investigation revealed that participants who were provided with formative feedback rooted in their errors within structured and persuasive legal writing outperformed the control group in producing qualitative, better legal text during an exam. Furthermore, the analysed qualitative student statements also suggest that formative feedback promotes students' self-efficacy and self-regulated learning. Our findings indicate that integrating formative feedback rooted in individual errors enhances students' legal writing skills. This underscores the hybrid nature of AI, empowering students to identify their errors and improve in a more self-regulated manner.Practitioner notes What is already known about this topic Collaboration between humans and AI in educational settings advances learning mutually, fostering a unified developmental process. Collaborative education models advocate leveraging human and AI strengths for adaptive learning. Despite abundant theoretical research, empirical studies in HI remain limited. This gap underscores the need for more evidence-based approaches in integrating AI into educational settings. What this paper adds Field experiment investigating the impact of formative feedback in a hybrid intelligence learning environment based on the theory of learning from errors. Comparison of a traditional legal learning environment (lecturer teaching using sample solutions) versus formative feedback in a hybrid intelligence learning environment. Implementing formative machine learning-based feedback supports law students in producing more structured and persuasive legal texts, leading to enhanced exam performance and higher grades. Implications for practice and/or policy Our research contributes significantly to computer-based education by presenting empirical evidence of how formative writing feedback impacts students' legal knowledge and skills in educational settings. This underscores the importance of incorporating empirical data into the development of AI-based educational tools to ensure their effectiveness.By focusing on individual errors corrected by formative feedback, we contribute to the learning from errors literature stream. This perspective offers valuable insights into how such feedback can support students' writing and learning processes, filling a gap in empirical evidence. Our findings demonstrate the potential impact of ML-based learning systems, particularly in large-scale learning environments like legal mass lectures. Formative writing feedback emerges as a scalable and beneficial addition to traditional learning environments, triggering internal learning processes, fostering self-regulated learning and increasing self-efficacy among students. By demonstrating the effectiveness of formative feedback within the framework of HI, particularly in legal education, our research underscores the potential of combining human understanding with AI-supported feedback to enhance learning outcomes.",2025,,BRITISH JOURNAL OF EDUCATIONAL TECHNOLOGY,56,2,650-677,WOS:001337277200001,10.1111/bjet.13529,,#4021,Weber 2025,"",""
Toward the Adoption of Explainable Pre-Trained Large Language Models for Classifying Human-Written and AI-Generated Sentences,"Petrillo, L; Martinelli, F; Santone, A; Mercaldo, F","Pre-trained large language models have demonstrated impressive text generation capabilities, including understanding, writing, and performing many tasks in natural language. Moreover, with time and improvements in training and text generation techniques, these models are proving efficient at generating increasingly human-like content. However, they can also be modified to generate persuasive, contextual content weaponized for malicious purposes, including disinformation and novel social engineering attacks. In this paper, we present a study on identifying human- and AI-generated content using different models. Precisely, we fine-tune different models belonging to the BERT family, an open-source version of the GPT model, ELECTRA, and XLNet, and then perform a text classification task using two different labeled datasets-the first one consisting of 25,000 sentences generated by both AI and humans and the second comprising 22,929 abstracts that are ChatGPT-generated and written by humans. Furthermore, we perform an additional phase where we submit 20 sentences generated by ChatGPT and 20 sentences randomly extracted from Wikipedia to our fine-tuned models to verify the efficiency and robustness of the latter. In order to understand the prediction of the models, we performed an explainability phase using two sentences: one generated by the AI and one written by a human. We leveraged the integrated gradients and token importance techniques, analyzing the words and subwords of the two sentences. As a result of the first experiment, we achieved an average accuracy of 99%, precision of 98%, recall of 99%, and F1-score of 99%. For the second experiment, we reached an average accuracy of 51%, precision of 50%, recall of 52%, and F1-score of 51%.",2024,,ELECTRONICS,13,20,,WOS:001341641300001,10.3390/electronics13204057,,#4022,Petrillo 2024,"",""
Fired by an algorithm? Exploration of conformism with biased intelligent decision support systems in the context of workplace discipline,"Bartosiak, ML; Modlinski, A","Purpose The importance of artificial intelligence in human resource management has grown substantially. Previous literature discusses the advantages of AI implementation at a workplace and its various consequences, often hostile, for employees. However, there is little empirical research on the topic. The authors address this gap by studying if individuals oppose biased algorithm recommendations regarding disciplinary actions in an organisation. Design/methodology/approach The authors conducted an exploratory experiment in which the authors evaluated 76 subjects over a set of 5 scenarios in which a biased algorithm gave strict recommendations regarding disciplinary actions at a workplace. Findings The authors' results suggest that biased suggestions from intelligent agents can influence individuals who make disciplinary decisions. Social implications The authors' results contribute to the ongoing debate on applying AI solutions to HR problems. The authors demonstrate that biased algorithms may substantially change how employees are treated and show that human conformity towards intelligent decision support systems is broader than expected. Originality/value The authors' paper is among the first to show that people may accept recommendations that provoke moral dilemmas, bring adverse outcomes, or harm employees. The authors introduce the problem of ""algorithmic conformism"" and discuss its consequences for HRM.",2022,,CAREER DEVELOPMENT INTERNATIONAL,27,6/7,601-615,WOS:000868415400001,10.1108/CDI-06-2022-0170,,#4023,Bartosiak 2022,"",""
AI-Empowered Persuasive Video Generation: A Survey,"Liu, C; Yu, H","Promotional videos are rapidly becoming a popularmedium for persuading people to change their behaviours in many settings (e.g., online shopping, social enterprise initiatives). Today, such videos are often produced by professionals, which is a time-, labour- and cost-intensive undertaking. In order to produce such contents to support large applications (e.g., e-commerce), the field of artificial intelligence (AI)-empowered persuasive video generation (AIPVG) has gained traction in recent years. This field is interdisciplinary in nature, which makes it challenging for new researchers to grasp. Currently, there is no comprehensive survey of AIPVG available. In this paper, we bridge this gap by reviewing key AI techniques that can be utilized to automatically generate persuasive videos. We offer a first-of-its-kind taxonomy which divides AIPVG into three major steps: (1) visual material understanding, which extracts information from the visual materials (VMs) relevant to the target of promotion; (2) visual storyline generation, which shortlists and arranges high-quality VMs into a sequence in order to compose a storyline with persuasive power; and (3) post-production, which involves background music generation and still image animation to enhance viewing experience. We also introduce the evaluation metrics and datasets commonly adopted in the field of AIPVG. We analyze the advantages and disadvantages of the existing works belonging to the above-mentioned steps, and discuss interesting potential future research directions.",2023,,ACM COMPUTING SURVEYS,55,13S,,WOS:001056300600023,10.1145/3588764,,#4024,Liu 2023,"",""
Disinformation Detection: An Evolving Challenge in the Age of LLMs,"Jiang, BH; Tan, Z; Nirmal, A; Liu, H","The advent of generative Large Language Models (LLMs) such as ChatGPT has catalyzed transformative advancements across multiple domains. However, alongside these advancements, they have also introduced potential threats. One critical concern is the misuse of LLMs by disinformation spreaders, leveraging these models to generate highly persuasive yet misleading content that challenges the disinformation detection system. This work aims to address this issue by answering three research questions: (1) To what extent can the current disinformation detection technique reliably detect LLM-generated disinformation? (2) If traditional techniques prove less effective, can LLMs themself be exploited to serve as a robust defense against advanced disinformation? and, (3) Should both these strategies falter, what novel approaches can be proposed to counter this burgeoning threat effectively? A holistic exploration for the formation and detection of disinformation is conducted to foster this line of research.",2024,,"PROCEEDINGS OF THE 2024 SIAM INTERNATIONAL CONFERENCE ON DATA MINING, SDM",,,427-435,WOS:001281344400049,,,#4025,Jiang 2024,"",""
Exploring the phenomenon and ethical issues of AI paternalism in health apps,"Kühler, M","Health apps, including consumer-oriented fitness apps, have two functions. They are supposed to monitor and promote users' health, the latter by way of being an instance of persuasive technology. The use of artificial intelligence (AI) allows for AI health apps, i.e., health apps that act more and more autonomously when it comes to analyzing users' health data and arriving at tailor-made results on how to improve their health. Consequently, AI health apps seem to gain a paternalistic potential. This is a game-changer, for corresponding issues of paternalism can then no longer be traced back to human engineers. Instead, the paternalizing party just is the AI system. Hence, AI health apps lead to the novel issue of AI paternalism in health care. In this paper, I explore this novel phenomenon and its ethical implications. Firstly, I discuss from a critical perspective whether the notion of AI paternalism makes (conceptual) sense to begin with. Unsurprisingly, I argue that it does and how so. Secondly, I briefly indicate important ethical issues that AI paternalism in health apps raise and which need to be discussed in more detail in order to judge under which conditions (certain forms of) AI paternalism might be considered acceptable, if at all.",2022,,BIOETHICS,36,2,194-200,WOS:000653522900001,10.1111/bioe.12886,,#4026,Kühler 2022,"",""
Communicating the benefits and risks of AI technology in hiring: implications for organization-public relationships,"Kim, JK; Xiong, Y; Hunt, DS","PurposeAs artificial intelligence (AI) has become increasingly accessible, a growing number of organizations have begun to adopt AI in hiring. Despite the increasing use of AI in hiring, little is known about how organizations can effectively communicate with their stakeholders about their AI use. Using gain and loss message frames and organization-public relationships (OPRs) as theoretical frameworks, this study tests the impact of exposure to job advertisements that address AI use on individuals' attitudes and behaviors toward organizations using AI during hiring.Design/methodology/approachWe conducted a 2 (message frames: gain vs loss) x 2 (benefits of using AI in hiring: faster hiring process vs reduced unconscious hiring bias) between-subjects experiment using a Prolific online panel (N = 224). Participants were randomly assigned to one of four conditions and viewed a fictitious company's job advertisement that varied in message frames and benefits of using AI. After viewing the experimental stimuli, participants answered questions about OPRs, attitudes toward the company and positive word-of-mouth (WOM) intentions.FindingsLoss-framed messages appeared as more effective in increasing OPRs, favorable attitudes toward the company and positive WOM intentions. OPRs positively mediated the impact of exposure to loss-framed job advertisements on attitudes and positive WOM intentions. The benefits of using AI in hiring moderated the impact of loss-framed messages on OPRs, attitudes and positive WOM intentions.Practical implicationsThis study offers important practical implications for organizations that use AI technology in their hiring practices or are interested in incorporating AI into their hiring processes. The significant impact of loss-framed messages suggests that organizations should highlight the anticipated negative outcomes of not using AI rather than addressing the positive outcomes from AI use. The findings align with established negativity bias research in framing literature, demonstrating individuals' greater susceptibility to negative information and adverse outcomes in persuasive contexts. The moderating effect of the benefits of using AI in hiring indicates that the impact of message frames on individuals' attitudinal and behavioral responses to organizations' AI use varies depending on organizations' rationale for using AI.Originality/valueThis study is one of the early studies to examine individuals' attitudinal and behavioral responses to organizations' use of AI in hiring. Prior research suggests that OPRs mediate the relationship between individuals' exposure to organizational messages and their attitudes toward organizations. Extending this line of inquiry, the current study explores OPRs' mediating role in the context of AI-driven hiring processes and investigates how OPRs mediate the relationships between organizations' message framing strategies and individuals' attitudes toward the organization as well as their WOM intentions. By examining the effectiveness of gain- and loss-framed job advertisements, this study offers important insights for organizations on how to more effectively and ethically communicate about AI use with their stakeholders.",2025,,CORPORATE COMMUNICATIONS,,,,WOS:001494575300001,10.1108/CCIJ-11-2024-0204,,#4027,Kim 2025,"",""
SmileApp: The Design and Evaluation of an mHealth App for Stress Reduction Through Artificial Intelligence and Persuasive Technology,"Orji, J; Chan, G; Ndulue, C; Orji, R","Mobile health apps are becoming popular and capable of addressing a wide range of health-related issues including stress. In this study, we designed, developed, and evaluated an mHealth application called SmileApp to promote positive mood as a means of reducing stress. The design of SmileApp is grounded in psychological theories and integrates artificial intelligence (AI) and persuasive technology (PT). To evaluate SmileApp, we conducted a two-week in-the-wild study involving 72 participants. This was followed by an optional semi-structured interviewwith 23 participants. Quantitative results suggest that SmileApp is usable, and the use of the features can convince users to smile more frequently, as well as feel a sense of companionship and connectedness. Furthermore, qualitative results suggest that SmileApp was a unique design to help users alleviate stress. These results offer valuable insights into innovative approaches for designing mHealth applications that promote positive mood. Moreover, the findings underscore the importance of utilizing technology to support emotional wellbeing. We present a novel approach to promote desired behaviors by motivating users to read supportive messages and play mobile games by smiling.",2024,,"PERSUASIVE TECHNOLOGY, PERSUASIVE 2024",14636,,237-251,WOS:001280411900018,10.1007/978-3-031-58226-4_18,,#4028,Orji 2024,"",""
"Artificial intelligence, marketing management, and ethics: their effect on customer loyalty intentions: A conceptual study","Mgiba, FM","The purpose of this study was to address ethical issues of privacy, information security, discrimination, and diversity concerns in the Artificial intelligence context, and to show how they relate to customers' loyalty intentions. The outcome sought was the development of a conceptual model that relates these themes to the actions of marketing management practitioners. An extensive review of literature on Persuasive technology, Social penetration, and Transforming wellbeing theories formed the basic structure for this study. After reviewing and synthesizing empirical literature on the major themes, and linking them to the constructs extracted from the grounding theories, the author generated a list of propositions that relate them to each other and the constructs. These propositions led to the development of a conceptual model. Researchers that deal with ethical issues and new technology can empirically test this model. The conceptualized model extends the explanatory powers of these grounding theories, by showing how they can improve business practices under the fourth industrial revolution era. This can aid management practitioners on artificial intelligence management strategies, and mitigate negative consequences related to the application of advanced technologies in business. This study is based on the literature, and, therefore, carries with it all the limitations that are inherent in the articles accessed. Generalizing the proposals need to take into account the fact that the proposed framework has not yet been subjected to empirical testing.",2020,,RETAIL AND MARKETING REVIEW,16,2,18-35,WOS:000734890700002,,,#4029,Mgiba 2020,"",""
Argument Schemes and a Dialogue System for Explainable Planning,"Mahesar, QA; Parsons, S","Artificial Intelligence (AI) is being increasingly deployed in practical applications. However, there is a major concern whether AI systems will be trusted by humans. To establish trust in AI systems, there is a need for users to understand the reasoning behind their solutions. Therefore, systems should be able to explain and justify their output. Explainable AI Planning is a field that involves explaining the outputs, i.e., solution plans produced by AI planning systems to a user. The main goal of a plan explanation is to help humans understand reasoning behind the plans that are produced by the planners. In this article, we propose an argument scheme-based approach to provide explanations in the domain of AI planning. We present novel argument schemes to create arguments that explain a plan and its key elements and a set of critical questions that allow interaction between the arguments and enable the user to obtain further information regarding the key elements of the plan. Furthermore, we present a novel dialogue system using the argument schemes and critical questions for providing interactive dialectical explanations.",2023,,ACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY,14,5,,WOS:001087277500013,10.1145/3610301,,#4030,Mahesar 2023,"",""
Persuasive Surfaces and Calculating Machines. A Rhetorical Perspective on Artificial Intelligence,"Gottschling, M; Kramer, O","This essay examines the communicative implications of generative AI through a rhetorical lens. Rather than asking whether machines can truly 'think,' this approach considers how generative AI's probabilistic outputs construct persuasive textual 'surfaces' that interact rhetorically with human communication. Authorship and meaning are no longer localized to a single individual creator but emerge through the interplay of human and machine co-construction of 'possible worlds.' By viewing generative AI as a 'techn & eacute;' in the classical sense, we examine how models 'imitate' prior texts through algorithmic recombination. As AI accelerates information flows, it becomes increasingly important for individuals to develop rhetorical literacy, to deconstruct the interests and values encoded in AI's persuasive surfaces. In contrast to the influential but one-directional information-theoretical communication model proposed by Shannon (1948), the essay advocates a rhetorical model of communication that emphasizes the active role of readers in reconstructing possible worlds from textual offers. Rather than neutral vessels of truth, generative AI outputs are inherently contingent yet interest-driven, requiring enhanced communicative competencies to navigate their impacts on changing concepts of reality, authorship, and common ground.",2025,,GLOBAL PHILOSOPHY,35,3,,WOS:001485441100001,10.1007/s10516-025-09748-3,,#4031,Gottschling 2025,"",""
Personality-based tailored explainable recommendation for trustworthy smart learning system in the age of artificial intelligence,"Takami, K; Flanagan, B; Dai, YL; Ogata, H","In the age of artificial intelligence (AI), trust in AI systems is becoming more important. Explainable recommenders, which explain why an item is recommended, have recently been proposed in the field of learning technology to improve transparency, persuasiveness, and trustworthiness. However, the methods for generating explanations are limited and do not consider the learner's cognitive perceptions or personality. This study draws inspiration from tailored intervention research in public health and investigates the effectiveness of personality-based tailored explanations by implementing them for the recommended quizzes in an explainable recommender system. High school students (n = 217) were clustered into three distinct profiles labeled Diligent (n = 77), Fearful (n = 72), and Agreeable (n = 68), based on the Big Five personality traits. The students were divided into a tailored intervention group (n = 106) and a control group (n = 111). In the tailored intervention group, personalized explanations for recommended quizzes were provided based on student profiles, with explanations based on quiz characteristics. In the control group, only non-personalized explanations based on quiz characteristics were provided. An 18-day A/B experiment showed that the tailored intervention group had significantly higher recommendation usage than the control group. These results suggest that personality-based tailored explanations with a recommender approach are effective for e-learning engagement and imply improved trustworthiness of AI learning systems.",2023,,SMART LEARNING ENVIRONMENTS,10,1,,WOS:001120204100001,10.1186/s40561-023-00282-6,,#4032,Takami 2023,"",""
Rethinking the Evaluation for Conversational Recommendation in the Era of Large Language Models,"Wang, XL; Tang, XY; Xin, WN; Wang, JY; Wen, JR","The recent success of large language models (LLMs) has shown great potential to develop more powerful conversational recommender systems (CRSs), which rely on natural language conversations to satisfy user needs. In this paper, we embark on an investigation into the utilization of ChatGPT for CRSs, revealing the inadequacy of the existing evaluation protocol. It might overemphasize the matching with ground-truth items annotated by humans while neglecting the interactive nature of CRSs.To overcome the limitation, we further propose an interactive Evaluation approach based on LLMs, named iEvaLM, which harnesses LLM-based user simulators. Our evaluation approach can simulate various system-user interaction scenarios. Through the experiments on two public CRS datasets, we demonstrate notable improvements compared to the prevailing evaluation protocol. Furthermore, we emphasize the evaluation of explainability, and ChatGPT showcases persuasive explanation generation for its recommendations. Our study contributes to a deeper comprehension of the untapped potential of LLMs for CRSs and provides a more flexible and realistic evaluation approach for future research about LLMbased CRSs. The code is available at https: //github.com/RUCAIBox/iEvaLM-CRS.",2023,,2023 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2023),,,10052-10065,WOS:001378237101038,,,#4033,Wang 2023,"",""
The influence of algorithms on political and dating decisions,"Agudo, U; Matute, H","Artificial intelligence algorithms are ubiquitous in daily life, and this is motivating the development of some institutional initiatives to ensure trustworthiness in Artificial Intelligence (AI). However, there is not enough research on how these algorithms can influence people's decisions and attitudes. The present research examines whether algorithms can persuade people, explicitly or covertly, on whom to vote and date, or whether, by contrast, people would reject their influence in an attempt to confirm their personal freedom and independence. In four experiments, we found that persuasion was possible and that different styles of persuasion (e.g., explicit, covert) were more effective depending on the decision context (e.g., political and dating). We conclude that it is important to educate people against trusting and following the advice of algorithms blindly. A discussion on who owns and can use the data that makes these algorithms work efficiently is also necessary.",2021,,PLOS ONE,16,4,,WOS:000644133400023,10.1371/journal.pone.0249454,,#4034,Agudo 2021,"",""
Testing theories of political persuasion using AI,"Argyle, LP; Busby, EC; Cubler, JR; Lyman, A; Olcott, J; Pond, J; Wingate, D","Despite its importance to society and many decades of research, key questions about the social and psychological processes of political persuasion remain unanswered, often due to data limitations. We propose that AI tools, specifically generative large language models (LLMs), can be used to address these limitations, offering important advantages in the study of political persuasion. In two preregistered online survey experiments, we demonstrate the potential of generative AI as a tool to study persuasion and provide important insights about the psychological and communicative processes that lead to increased persuasion. Specifically, we test the effects of four AI-generated counterattitudinal persuasive strategies, designed to test the effectiveness of messages that include customization (writing messages based on a receiver's personal traits and beliefs), and elaboration (increased psychological engagement with the argument through interaction). We find that all four types of persuasive AI produce significant attitude change relative to the control and shift vote support for candidates espousing views consistent with the treatments. However, we do not find evidence that message customization via microtargeting or cognitive elaboration through interaction with the AI have much more persuasive effect than a single generic message. These findings have implications for different theories of persuasion, which we discuss. Finally, we find that although persuasive messages are able to moderate some people's attitudes, they have inconsistent and weaker effects on the democratic reciprocity people grant to their political opponents. This suggests that attitude moderation (ideological depolarization) does not necessarily lead to increased democratic tolerance or decreased affective polarization.",2025,,PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA,122,18,,WOS:001485494600001,10.1073/pnas.2412815122,,#4035,Argyle 2025,"",""
Simulated Misinformation Susceptibility (SMISTS): Enhancing Misinformation Research with Large Language Model Simulations,"Ma, WC; Deng, CY; Moosavi, A; Wang, LL; Vosoughi, S; Yang, DY","Psychological inoculation, a strategy to build resistance against persuasive misinformation, has been shown to reduce its spread and adverse effects. Although these inoculations are effective, the design and optimization of them typically require substantial financial and human resources. To address these challenges, this work introduces Simulated Misinformation Susceptibility Test (SMIST), leveraging Large Language Models (LLMs) to simulate participant responses in misinformation studies. SMIST employs a life experience-driven simulation methodology, which accounts for various aspects of participants' backgrounds, to mitigate common issues of caricatures and stereotypes in LLM simulations and enhance response diversity. Our extensive experimentation demonstrates that SMIST, utilizing GPT4 as the backend model, yields results that align closely with those obtained from human-subject studies in misinformation susceptibility. This alignment suggests that LLMs can effectively serve as proxies in evaluating the impact of psychological inoculations. Further, SMIST can be applied to emerging and anticipated misinformation scenarios without harming human participants, thereby expanding the scope of misinformation research.",2024,,FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: ACL 2024,,,2774-2788,WOS:001356731802051,,,#4036,Ma 2024,"",""
A Blueprint for an AI & AR-Based Eye Tracking System to Train Cardiology Professionals Better Interpret Electrocardiograms,"Sqalli, MT; Al-Thani, D; Elshazly, MB; Al-Hijji, M","The electrocardiogram is one of the most used medical tests worldwide. Despite its prevalent use in the healthcare sector, there exists a limited understanding in how medical practitioners interpret it. This is mainly due to the scarcity of international guidelines that unify its interpretation across different health institutions. This leads to a lack of training and unpreparedness by medical students who are about to join the medical workforce. In this paper, we propose a blueprint for a proactive artificial intelligence and augmented reality-based eye tracking system to train cardiology professionals for a better electrocardiogram interpretation. The proposed blueprint is inspired from extensive interviews with cardiology medical practitioners as well as students who interpret electro-cardiograms as part of their daily practice. The interviews contributed to identifying the major pain-points within the process of electrocardiogram interpretation. The interviews were also critical in conceptualizing the persuasive components of the training system for a guided correct electrocardiogram interpretation. Throughout the presented blueprint, we detail the three components that constitute the system. These are the augmented reality-based interactive training interface, the artificial intelligence-based processing sub-system, and finally the adaptive electrocardiogram dataset.",2022,,PERSUASIVE TECHNOLOGY (PERSUASIVE 2022),13213,,221-229,WOS:000784740900017,10.1007/978-3-030-98438-0_17,,#4037,Sqalli 2022,"",""
How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs oThis paper contains jailbreaking contents that can be offensive in nature.,"Zeng, Y; Lin, HP; Zhang, JW; Yang, DY; Jia, R; Shi, WY","Most traditional AI safety research views models as machines and centers on algorithmfocused attacks developed by security experts. As large language models (LLMs) become increasingly common and competent, non-expert users can also impose risks during daily interactions. Observing this, we shift the perspective, by treating LLMs as human-like communicators to examine the interplay between everyday language interaction and AI safety. Specifically, we study how to persuade LLMs to jailbreak them. First, we propose a persuasion taxonomy derived from decades of social science research. Then, we apply the taxonomy to automatically generate persuasive adversarial prompts (PAP) to jailbreak LLMs. Results show that persuasion significantly increases the jailbreak risk across all risk categories: PAP consistently achieves an attack success rate of over 92% on Llama-2-7b-Chat, GPT-3.5, and GPT-4 in 10 trials, surpassing recent algorithm-focused attacks. On the defense side, we explore various mechanisms against PAP, find a significant gap in existing defenses, and advocate for more fundamental solutions for AI safety",2024,,"PROCEEDINGS OF THE 62ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1: LONG PAPERS",,,14322-14350,WOS:001391776305028,,,#4038,Zeng 2024,"",""
CHIEF JUSTICE ROBOTS,"Volokh, E","Say an AI program someday passes a Turing test, because it can converse in a way indistinguishable from a human. And say that its developers can then teach it to converse-and even present an extended persuasive argument-in a way indistinguishable from the sort of human we call a ""lawyer."" The program could thus become an AI brief-writer, capable of regularly winning brief-writing competitions against human lawyers.Once that happens (if it ever happens), this Essay argues, the same technology can be used to create AI judges, judges that we should accept as no less reliable (and more cost-effective) than human judges. If the software can create persuasive opinions, capable of regularly winning opinion-writing competitions against human judges-and if it can be adequately protected against hacking and similar attacks-we should in principle accept it as a judge, even if the opinions do not stem from human judgment.",2019,,DUKE LAW JOURNAL,68,6,1135-1192,WOS:000462831300002,,,#4039,Volokh 2019,"",""
Explanations Considered Harmful: The Impact of Misleading Explanations on Accuracy in Hybrid Human-AI Decision Making,"Cabitza, F; Fregosil, C; Campagner, A; Natali, C","Explainable AI (XAI) has the potential to enhance decision-making in human-AI collaborations, yet existing research indicates that explanations can also lead to undue reliance on AI recommendations, a dilemma often referred to as the 'white box paradox.' This paradox illustrates how persuasive explanations for incorrect advice might foster inappropriate trust in AI systems. Our study extends beyond the traditional scope of the white box paradox by proposing a framework for examining explanation inadequacy. We specifically investigate how accurate AI advice, when paired with misleading explanations, affects decision-making in logic puzzle tasks. Our findings introduce the concept of the 'XAI halo effect,' where participants were influenced by the misleading explanations to the extent that they did not verify the correctness of the advice, despite its accuracy. This effect reveals a nuanced challenge in XAI, where even correct advice can lead to misjudgment if the accompanying explanations are not coherent and contextually relevant. The study highlights the critical need for explanations to be both accurate and relevant, especially in contexts where decision accuracy is paramount. This calls into question the use of explanations in situations where their potential to mislead outweighs their transparency or educational value.",2024,,"EXPLAINABLE ARTIFICIAL INTELLIGENCE, XAI 2024, PT IV",2156,,255-269,WOS:001326810600014,10.1007/978-3-031-63803-9_14,,#4040,Cabitza 2024,"",""
Humans as Avatars in Smart and Playable Cities,"IEEE; Nijholt, A","We compare the behavior of avatars in videogames with the expected behavior of humans in smart environments, particularly smart urban environments. As a result of this comparison we conclude that many aspects of controlling an avatar in a game environment will also be seen in controlling human behavior in smart urban environments. We predict a convergence of videogame environments with smart urban environments where the Artificial Intelligence (AI) of the game environment can be compared with the AI of the smart urban environment that is responsible for the functioning of the smart city. Game characteristics such as immediate rewards for good behavior can also be foreseen.",2017,,2017 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW),,,190-193,WOS:000454996900031,10.1109/CW.2017.23,,#4041,IEEE 2017,"",""
Do Humans Prefer Debiased AI Algorithms? A Case Study in Career Recommendation,"Assoc Comp Machinery; Wang, C; Wang, K; Bian, AY; Islam, R; Keya, KN; Foulds, J; Pan, S","Currently, there is a surge of interest in fair Artificial Intelligence (AI) and Machine Learning (ML) research which aims to mitigate discriminatory bias in AI algorithms, e.g. along lines of gender, age, and race. While most research in this domain focuses on developing fair AI algorithms, in this work, we examine the challenges which arise when human- fair-AI interact. Our results show that due to an apparent conflict between human preferences and fairness, a fair AI algorithm on its own may be insufficient to achieve its intended results in the real world. Using college major recommendation as a case study, we build a fair AI recommender by employing gender debiasing machine learning techniques. Our offline evaluation showed that the debiased recommender makes fairer and more accurate college major recommendations. Nevertheless, an online user study of more than 200 college students revealed that participants on average prefer the original biased system over the debiased system. Specifically, we found that the perceived gender disparity associated with a college major is a determining factor for the acceptance of a recommendation. In other words, our results demonstrate we cannot fully address the gender bias issue in AI recommendations without addressing the gender bias in humans. They also highlight the urgent need to extend the current scope of fair AI research from narrowly focusing on debiasing AI algorithms to including new persuasion and bias explanation technologies in order to achieve intended societal impacts.",2022,,IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES,,,134-147,WOS:000889340800011,10.1145/3490099.3511108,,#4042,AssocCompMachinery 2022,"",""
Effects of AI and Logic-Style Explanations on Users' Decisions Under Different Levels of Uncertainty,"Cau, FM; Hauptmann, H; Spano, LD; Tintarev, N","Existing eXplainable Artificial Intelligence (XAI) techniques support people in interpreting AI advice. However, although previous work evaluates the users' understanding of explanations, factors influencing the decision support are largely overlooked in the literature. This article addresses this gap by studying the impact of user uncertainty, AI correctness, and the interaction between AI uncertainty and explanation logic-styles for classification tasks. We conducted two separate studies: one requesting participants to recognize handwritten digits and one to classify the sentiment of reviews. To assess the decision making, we analyzed the task performance, agreement with the AI suggestion, and the user's reliance on the XAI interface elements. Participants make their decision relying on three pieces of information in the XAI interface (image or text instance, AI prediction, and explanation). Participants were shown one explanation style (between-participants design) according to three styles of logical reasoning (inductive, deductive, and abductive). This allowed us to study how different levels of AI uncertainty influence the effectiveness of different explanation styles. The results show that user uncertainty and AI correctness on predictions significantly affected users' classification decisions considering the analyzedmetrics. In both domains (images and text), users reliedmainly on the instance to decide. Users were usually overconfident about their choices, and this evidence was more pronounced for text. Furthermore, the inductive style explanations led to overreliance on the AI advice in both domains-it was the most persuasive, even when the AI was incorrect. The abductive and deductive styles have complex effects depending on the domain and the AI uncertainty levels.",2023,,ACM TRANSACTIONS ON INTERACTIVE INTELLIGENT SYSTEMS,13,4,,WOS:001153515100003,10.1145/3588320,,#4043,Cau 2023,"",""
Conversational AI and Vaccine Communication: Systematic Review of the Evidence,"Passanante, A; Pertwee, E; Lin, LS; Lee, KY; Wu, JT; Larson, HJ","Background: Since the mid-2010s, use of conversational artificial intelligence (AI; chatbots) in health care has expanded significantly, especially in the context of increased burdens on health systems and restrictions on in-person consultations with health care providers during the COVID-19 pandemic. One emerging use for conversational AI is to capture evolving questions and communicate information about vaccines and vaccination.Objective: The objective of this systematic review was to examine documented uses and evidence on the effectiveness of conversational AI for vaccine communication.Methods: This systematic review was conducted following the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines. PubMed, Web of Science, PsycINFO, MEDLINE, Scopus, CINAHL Complete, Cochrane Library, Embase, Epistemonikos, Global Health, Global Index Medicus, Academic Search Complete, and the University of London library database were searched for papers on the use of conversational AI for vaccine communication. The inclusion criteria were studies that included (1) documented instances of conversational AI being used for the purpose of vaccine communication and (2) evaluation data on the impact and effectiveness of the intervention.Results: After duplicates were removed, the review identified 496 unique records, which were then screened by title and abstract, of which 38 were identified for full-text review. Seven fit the inclusion criteria and were assessed and summarized in the findings of this review. Overall, vaccine chatbots deployed to date have been relatively simple in their design and have mainly been used to provide factual information to users in response to their questions about vaccines. Additionally, chatbots have been used for vaccination scheduling, appointment reminders, debunking misinformation, and, in some cases, for vaccine counseling and persuasion. Available evidence suggests that chatbots can have a positive effect on vaccine attitudes; however, studies were typically exploratory in nature, and some lacked a control group or had very small sample sizes.Conclusions: The review found evidence of potential benefits from conversational AI for vaccine communication. Factors that may contribute to the effectiveness of vaccine chatbots include their ability to provide credible and personalized information in real time, the familiarity and accessibility of the chatbot platform, and the extent to which interactions with the chatbot feel ""natural"" to users. However, evaluations have focused on the short-term, direct effects of chatbots on their users. The potential longer-term and societal impacts of conversational AI have yet to be analyzed. In addition, existing studies do not adequately address how ethics apply in the field of conversational AI around vaccines. In a context where further digitalization of vaccine communication can be anticipated, additional high-quality research will be required across all these areas.",2023,,JOURNAL OF MEDICAL INTERNET RESEARCH,25,,,WOS:001085910000001,10.2196/42758,,#4044,Passanante 2023,"",""
Artificial Intelligence and Political Deepfakes: Shaping Citizen Perceptions Through Misinformation,"Momeni, M","In the post-truth age, political conspiracies circulate rapidly on social media, cultivating false narratives, while challenging the public's ability to distinguish truth from fiction. 'Deepfakes' represent the most recent type of misinformation. They display deceitful representations of events to lead audiences to believe in fabricated realities. There has been limited research on deepfakes in political communications. As this technology progresses, deepfakes look deceptively authentic; thus, it is necessary to explore their effects on public perceptions. This study examines viewers' comments on an Instagram-published deepfake video of Hillary Clinton to understand the impact of this technology. The results demonstrate that individuals struggle to identify deepfake videos and that their opinions are affected by this persuasive type of misinformation. This study also explores different ethical concerns posed by political deepfakes. By offering insights into public reactions to manipulated content, this study contributes to our understanding of the political effects of AI-fabricated content.",2025,,JOURNAL OF CREATIVE COMMUNICATIONS,20,1,41-56,WOS:001345857600001,10.1177/09732586241277335,,#4045,Momeni 2025,"",""
Persuasive Technology and computational manipulation: hypernudging out of mental self-determination,"Faraoni, S","Artificial Intelligence, unperceived, can acquire the user's data, find connections not visible by a human being, profile the users, and aim at persuading them, resulting in Persuasive Technology (PT). During the persuasive process, PT can use manipulation, finding and using routes to affect System 1, the primordial brain of individuals, in the absence of their awareness, undermining their decision-making processes. Multiple international and European bodies recognized that AI systems could use manipulation at an unprecedented degree via second-generation dark patterns such as the hypernudge and that computational manipulation constitutes a risk for autonomy and different, overlapping, fundamental rights such as privacy, informational self-determination and freedom of thought. However, there is a lack of shared ideas regarding which fundamental rights are violated by computational manipulation and which fundamental rights can protect individuals against it. The right to be let alone and the right to hold and express a thought differ from the right to create a thought, being in control of the decision-making process and free from cognitive interferences operated by computational manipulation. Therefore, this paper argues in favor of recognizing a newly emerged fundamental right, the right to mental self-determination, tailored to the unprecedented abilities of AI-driven manipulative technologies.",2023,,FRONTIERS IN ARTIFICIAL INTELLIGENCE,6,,,WOS:001030545500001,10.3389/frai.2023.1216340,,#4046,Faraoni 2023,"",""
Modelling argumentation in short text: A case of social media debate,"Lytos, A; Lagkas, T; Sarigiannidis, P; Argyriou, V; Eleftherakis, G","The technological leaps of artificial intelligence (AI) and the rise of machine learning have triggered significant progress in a plethora of natural language processing (NLP) and natural language understanding tasks. One of these tasks is argumentation mining which has received significant interest in recent years and is regarded as a key domain for future decision-making systems, behaviour modelling, and natural language understanding problems. Until recently, natural language modelling tasks, such as computational argumentation schemes, were often tested in controlled environments, such as persuasive essays, reducing unexpected behaviours that could occur in real-life settings, like a public debate on social media. Additionally, the growing demand for enhancing the trust and the explainability of the AI services has dictated the design and adoption of modelling schemes to increase the confidence in the outcomes of the AI solutions. This paper attempts to explore modelling argumentation in short text and proposes a novel framework for argumentation detection under the name Abstract Framework for Argumentation Detection (AFAD). Moreover, different proof-of-concept implementations are provided to examine the applicability of the proposed framework to very short text developing a rule-based mechanism and compare the results with data-driven solutions. Eventually, a combination of the deployed methods is applied increasing the correct predictions in the minority class on an imbalanced dataset. The findings suggest that the modelling process provides solid grounds for technical research while the hybrid solutions have the potential to be applied to a wide range of NLP-related tasks offering a deeper understanding of human language and reasoning.",2022,,SIMULATION MODELLING PRACTICE AND THEORY,115,,,WOS:000780380100010,10.1016/j.simpat.2021.102446,,#4047,Lytos 2022,"",""
Food mukbang on social media: towards an AI-driven persuasive interventions for living healthy on social media,"Ataguba, G; Kalu, I; Chan, G; Orji, R","Social media has witnessed different eating practices, including food mukbang. Food mukbang is a type of video presentation where hosts consume large quantities of food while interacting with viewers. This study is situated on the social eating theory, which explains how people connect their individual interests with society. Though this practice has been on social media platforms for a while now, little is known about its health impact on a wide range of audiences. Unhealthy eating practices are associated with obesity and other chronic diseases, which are the leading causes of death in the world today. Given that there are unhealthy eating practices in food mukbang videos on social media, we collected thirty (30) food mukbang creative common license YouTube videos, and we extracted 2297 comments from these videos to study the trends. In view of this, we found that there is a collection of more unhealthy foods eaten to entertain viewers, different unhealthy eating behaviors such as eating quickly, talking while eating, and putting too much food in the mouth. In addition, we found that the viewers' sentiments were positive, and they loved watching these videos. Hence, in its best practice, we propose an AI-driven persuasive intervention because AI technologies are capable of detecting unhealthy eating patterns and persuasive interventions can promote a change in behavior (healthy eating behavior). Based on our findings, we present three design recommendations for YouTube and other social media designers to consider in future: (1) using artificial intelligence-related technologies for predicting videos, (2) using natural language processing to prompt feedback, and (3) auto-generating disclaimers at the beginning and end of the video.",2025,,AI & SOCIETY,,,,WOS:001410558900001,10.1007/s00146-025-02183-3,,#4048,Ataguba 2025,"",""
"Integration of ChatGPT Into a Course for Medical Students:Explorative Study on Teaching Scenarios, Students'Perception, and Applications","Thomae, AV; Witt, CM; Barth, J","Background: Text-generating artificial intelligence (AI) such as ChatGPT offers many opportunities and challenges inmedical education. Acquiring practical skills necessary for using AI in a clinical context is crucial, especially for medicaleducation.Objective: This explorative study aimed to investigate the feasibility of integrating ChatGPT into teaching units and toevaluate the course and the importance of AI-related competencies for medical students. Since a possible application ofChatGPT in the medical field could be the generation of information for patients, we further investigated how such informationis perceived by students in terms of persuasiveness and quality.Methods: ChatGPT was integrated into 3 different teaching units of a blended learning course for medical students. Usinga mixed methods approach, quantitative and qualitative data were collected. As baseline data, we assessed students' character-istics, including their openness to digital innovation. The students evaluated the integration of ChatGPT into the course andshared their thoughts regarding the future of text-generating AI in medical education. The course was evaluated based on theKirkpatrick Model, with satisfaction, learning progress, and applicable knowledge considered as key assessment levels. InChatGPT-integrating teaching units, students evaluated videos featuring information for patients regarding their persuasivenesson treatment expectations in a self-experience experiment and critically reviewed information for patients written usingChatGPT 3.5 based on different prompts.Results: A total of 52 medical students participated in the study. The comprehensive evaluation of the course revealedelevated levels of satisfaction, learning progress, and applicability specifically in relation to the ChatGPT-integrating teachingunits. Furthermore, all evaluation levels demonstrated an association with each other. Higher openness to digital innovationwas associated with higher satisfaction and, to a lesser extent, with higher applicability. AI-related competencies in othercourses of the medical curriculum were perceived as highly important by medical students. Qualitative analysis highlightedpotential use cases of ChatGPT in teaching and learning. In ChatGPT-integrating teaching units, students rated informationfor patients generated using a basic ChatGPT prompt as ""moderate"" in terms of comprehensibility, patient safety, and thecorrect application of communication rules taught during the course. The students' ratings were considerably improved usingan extended prompt. The same text, however, showed the smallest increase in treatment expectations when compared withinformation provided by humans (patient, clinician, and expert) via videos.Conclusions: This study offers valuable insights into integrating the development of AI competencies into a blended learningcourse. Integration of ChatGPT enhanced learning experiences for medical students",2024,,JMIR MEDICAL EDUCATION,10,,,WOS:001306079900001,10.2196/50545,,#4049,Thomae 2024,"",""
Role of artificial intelligence in operations environment: a review and bibliometric analysis,"Dhamija, P; Bag, S","Purpose - ""Technological intelligence"" is the capacity to appreciate and adapt technological advancements, and ""artificial intelligence"" is the key to achieve persuasive operational transformations in majority of contemporary organizational set-ups. Implicitly, artificial intelligence (the philosophies of machines to think, behave and perform either same or similar to humans) has knocked the doors of business organizations as an imperative activity. Artificial intelligence, as a discipline, initiated by scientist John McCarthy and formally publicized at Dartmouth Conference in 1956, now occupies a central stage for many organizations. Implementation of artificial intelligence provides competitive edge to an organization with a definite augmentation in its social and corporate status. Mere application of a concept will not furnish real output until and unless its performance is reviewed systematically. Technological changes are dynamic and advancing at a rapid rate. Subsequently, it becomes highly crucial to understand that where have the people reached with respect to artificial intelligence research. The present article aims to review significant work by eminent researchers towards artificial intelligence in the form of top contributing universities, authors, keywords, funding sources, journals and citation statistics.Design/methodology/approach - As rightly remarked by past researchers that reviewing is learning from experience, research team has reviewed (by applying systematic literature review through bibliometric analysis) the concept of artificial intelligence in this article. A sum of 1,854 articles extracted from Scopus database for the year 2018-2019 (31st of May) with selected keywords (artificial intelligence, genetic algorithms, agent-based systems, expert systems, big data analytics and operations management) along with certain filters (subject-business, management and accounting; language-English; document-article, article in press, review articles and source-journals).Findings - Results obtained from cluster analysis focus on predominant themes for present as well as future researchers in the area of artificial intelligence. Emerged clusters include Cluster 1: Artificial Intelligence and Optimization; Cluster 2: Industrial Engineering/Research and Automation; Cluster 3: Operational Performance and Machine Learning; Cluster 4: Sustainable Supply Chains and Sustainable Development; Cluster 5: Technology Adoption and Green Supply Chain Management and Cluster 6: Internet of Things and Reverse Logistics.Originality/value - The result of review of selected studies is in itself a unique contribution and a food for thought for operations managers and policy makers.",2020,,TQM JOURNAL,32,4,869-896,WOS:000998655700015,10.1108/TQM-10-2019-0243,,#4050,Dhamija 2020,"",""
Long-Horizon Dialogue Understanding for Role Identification in the Game of Avalon with Large Language Models,"Stepputtis, S; Campbell, J; Xie, YQ; Qi, ZY; Zhang, WS; Wang, RY; Rangreji, S; Lewis, CM; Sycara, KP","Deception and persuasion play a critical role in long-horizon dialogues between multiple parties, especially when the interests, goals, and motivations of the participants are not aligned. Such complex tasks pose challenges for current Large Language Models (LLM) as deception and persuasion can easily mislead them, especially in long-horizon multi-party dialogues. To this end, we explore the game of Avalon: The Resistance, a social deduction game in which players must determine each other's hidden identities to complete their team's objective. We introduce an online testbed and a dataset containing 20 carefully collected and labeled games among human players that exhibit long-horizon deception in a cooperativecompetitive setting. We discuss the capabilities of LLMs to utilize deceptive long-horizon conversations between six human players to determine each player's goal and motivation. Particularly, we discuss the multimodal integration of the chat between the players and the game's state that grounds the conversation, providing further insights into the true player identities. We find that even current stateof-the-art LLMs do not reach human performance, making our dataset a compelling benchmark to investigate the decision-making and language-processing capabilities of LLMs. Our dataset and online testbed can be found at our project website: https://sstepput.github. io/Avalon-NLU/",2023,,FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EMNLP 2023),,,11193-11208,WOS:001378234403023,,,#4051,Stepputtis 2023,"",""
Characterizing Manipulation from AI Systems,"ACM; Carroll, M; Chan, A; Ashton, H; Krueger, D","Manipulation is a concern in many domains, such as social media, advertising, and chatbots. As AI systems mediate more of our digital interactions, it is important to understand the degree to which AI systems might manipulate humans without the intent of the system designers. Our work clarifies challenges in defining and measuring this kind of manipulation from AI systems. Firstly, we build upon prior literature on manipulation and characterize the space of possible notions of manipulation, which we find to depend upon the concepts of incentives, intent, covertness, and harm. We review proposals on how to operationalize each concept and we outline challenges in including each concept in a definition of manipulation. Second, we discuss the connections between manipulation and related concepts, such as deception and coercion. We then analyze how our characterization of manipulation applies to recommender systems and language models, and give a brief overview of the regulation of manipulation in other domains. While some progress has been made in defining and measuring manipulation from AI systems, many gaps remain. In the absence of a consensus definition and reliable tools for measurement, we cannot rule out the possibility that AI systems learn to manipulate humans without the intent of the system designers. Manipulation could pose a significant threat to human autonomy and precautionary actions to mitigate it are likely warranted.",2023,,"PROCEEDINGS OF 2023 ACM CONFERENCE ON EQUITY AND ACCESS IN ALGORITHMS, MECHANISMS, AND OPTIMIZATION, EAAMO 2023",,,,WOS:001124266900006,10.1145/3617694.3623226,,#4052,ACM 2023,"",""
How Do Virtual AI Streamers Influence Viewers' Livestream Shopping Behavior? The Effects of Persuasive Factors and the Mediating Role of Arousal,"Zhang, XF; Shi, YX; Li, T; Guan, YX; Cui, XL","With the exponential growth of livestream shopping and the development of artificial intelligence (AI), virtual influencers powered by AI have become a new trend. However, this phenomenon has yet to be studied precisely to understand the underlying mechanisms of virtual AI streamers' influence on the viewers. This study explores the effects of virtual influencers powered by AI by investigating the persuasive factors and underlying emotional mechanism that affect viewers' parasocial interaction intention and impulse buying intention. Data collected from 559 livestream viewers in a scenario-based survey were analyzed using maximum likelihood structural equation modeling (SEM) estimation and cross-validated using Bayesian SEM. The findings confirm the appraisal-emotion-action scheme and validate the role of arousal in mediating three persuasive factors and two behavioral approaches. Parasocial interaction intention was correlated with coolness, whereas congruence and mind perception were important antecedents of viewers' urge to buy impulsively. Furthermore, mindset had important moderating effects on arousal and parasocial interaction intention toward impulsive urges. This study extends the research on influencer marketing and livestream shopping. It also apprises marketing and retailing managers of the importance of nurturing an AI workforce and sheds light on IS management practice for potential industry opportunities.",2024,,INFORMATION SYSTEMS FRONTIERS,26,5,1803-1834,WOS:001060215400001,10.1007/s10796-023-10425-2,,#4053,Zhang 2024,"",""
"Human favoritism, not AI aversion: People's perceptions (and bias) toward generative AI, human experts, and human-GAI collaboration in persuasive content generation","Zhang, YH; Gosline, R","With the wide availability of large language models and generative AI, there are four primary paradigms for human-AI collaboration: human-only, AI-only (ChatGPT-4), augmented human (where a human makes the final decision with AI output as a reference), or augmented AI (where the AI makes the final decision with human output as a reference). In partnership with one of the world's leading consulting firms, we enlisted professional content creators and ChatGPT-4 to create advertising content for products and persuasive content for campaigns following the aforementioned paradigms. First, we find that, contrary to the expectations of some of the existing algorithm aversion literature on conventional predictive AI, the content generated by generative AI and augmented AI is perceived as of higher quality than that produced by human experts and augmented human experts. Second, revealing the source of content production reduces-but does not reverse-the perceived quality gap between human- and AI-generated content. This bias in evaluation is predominantly driven by human favoritism rather than AI aversion: Knowing that the same content is created by a human expert increases its (reported) perceived quality, but knowing that AI is involved in the creation process does not affect its perceived quality. Further analysis suggests this bias is not due to a 'quality prime' as knowing the content they are about to evaluate comes from competent creators (e.g., industry professionals and state-of-the-art AI) without knowing exactly that the creator of each piece of content does not increase participants' perceived quality.",2023,,JUDGMENT AND DECISION MAKING,18,,,WOS:001112542000001,10.1017/jdm.2023.37,,#4054,Zhang 2023,"",""
Subjective-probability forecasts of existential risk: Initial results from a hybrid persuasion-forecasting tournament,"Karger, E; Rosenberg, J; Jacobs, Z; Hickman, M; Tetlock, PE","A multi-stage persuasion-forecasting tournament asked specialists and generalists (""superforecasters"") to explain their probability judgments of short- and long-run existential threats to humanity. Specialists were more pessimistic, especially on long-run threats posed by artificial intelligence (AI). Despite incentives to share their best arguments during four months of discussion, neither side materially moved the other's views. This would be puzzling if participants were Bayesian agents methodically sifting through elusive clues about distant futures but it is less puzzling if participants were boundedly rational agents searching for confirmatory evidence as the risks of embarrassing accuracy feedback receded. Consistent with the latter mechanism, strong AI-risk proponents made particularly extreme longbut not short-range forecasts and over-estimated the longrange AI-risk forecasts of others. We stress the potential of these methods to inform high-stakes debates, but we acknowledge limits on what even skilled forecasters can achieve in anticipating rare or unprecedented events. (c) 2024 International Institute of Forecasters. Published by Elsevier B.V. All rights are reserved, including those for text and data mining, AI training, and similar technologies.",2025,,INTERNATIONAL JOURNAL OF FORECASTING,41,2,499-516,WOS:001444530400001,10.1016/j.ijforecast.2024.11.008,,#4055,Karger 2025,"",""
The Logical Approach of Legal Argumentation,"Feteris, ET",In a logical approach of legal argumentation the central focus is on the role of formal validity as a criterion of rationality for legal argumentation. Various logical systems have been developed to analyse and evaluate legal argumentation. This chapter explains the role and the importance of formal logic for the analysis and evaluation of legal argumentation. Section 2.2 describes the role of formal logic as criterion of rationality for legal argumentation. Section 2.3 describes the various logical systems for the reconstruction of legal argumentation. In Sect. 2.4 attention is devoted to the operations required for a logical analysis of legal argumentation. Section 2.5 gives an overview of the discussion on the importance of logic for legal argumentation. In Sect. 2.6 recent developments in the study of the role of logic in legal justification in Artificial Intelligence and Law are discussed and Sect. 2.7 is a summary of the main results of this chapter.,2017,,"FUNDAMENTALS OF LEGAL ARGUMENTATION: A SURVEY OF THEORIES ON THE JUSTIFICATION OF JUDICIAL DECISIONS, 2ND EDITION",1,,23-47,WOS:000431810300004,10.1007/978-94-024-1129-4_210.1007/978-94-024-1129-4,,#4056,Feteris 2017,"",""
Persuasion Meets AI: Ethical Considerations for the Design of Social Engineering Countermeasures,"Ferreyra, NED; Aïmeur, E; Hage, H; Heisel, M; van Hoogstraten, CG","Privacy in Social Network Sites (SNSs) like Facebook or Instagram is closely related to people's selfdisclosure decisions and their ability to foresee the consequences of sharing personal information with large and diverse audiences. Nonetheless, online privacy decisions are often based on spurious risk judgements that make people liable to reveal sensitive data to untrusted recipients and become victims of social engineering attacks. Artificial Intelligence (AI) in combination with persuasive mechanisms like nudging is a promising approach for promoting preventative privacy behaviour among the users of SNSs. Nevertheless, combining behavioural interventions with high levels of personalization can be a potential threat to people's agency and autonomy even when applied to the design of social engineering countermeasures. This paper elaborates on the ethical challenges that nudging mechanisms can introduce to the development of AI-based countermeasures, particularly to those addressing unsafe self-disclosure practices in SNSs. Overall, it endorses the elaboration of personalized risk awareness solutions as i) an ethical approach to counteract social engineering, and ii) as an effective means for promoting reflective privacy decisions.",2020,,"PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON KNOWLEDGE DISCOVERY, KNOWLEDGE ENGINEERING AND KNOWLEDGE MANAGEMENT (KMIS), VOL 3",,,204-211,WOS:000799461100019,10.5220/0010142402040211,,#4057,Ferreyra 2020,"",""
"Putting the ""Me"" in endorsement: Understanding and conceptualizing dimensions of self-endorsement using intelligent personal assistants","Hamilton, KA; Lee, SY; Chung, UC; Liu, WZ; Duff, BRL","Self-endorsement-depicting the ""self"" as an endorser of a brand-represents a potentially powerful advertising strategy made possible by new media. This experiment tests the hypothesis that receiving brand recommendations from an intelligent personal assistant believed to be tailored to one's own characteristics and consumer interests yields higher brand attitude and purchase intention toward the (self-endorsed) brand than receiving brand recommendations from a typical, but not self-tailored, intelligent personal assistant. Because endorsement is a well-known and highly effective advertising strategy, this is a high bar. We present evidence for self-referencing as an underlying mechanism, and perceived interactivity and identification as boundary conditions of self-endorsing. Consumers may show skepticism toward advertising but may not know how to be skeptical of themselves. As consumers outsource their tasks and decisions to new artificial intelligence (AI)-driven devices, they will need to be attentive to new media biases that threaten productive use of these devices.",2021,,NEW MEDIA & SOCIETY,23,6,1506-1526,WOS:000553834400001,10.1177/1461444820912197,,#4058,Hamilton 2021,"",""
MindShif: Leveraging Large Language Models for Mental-States-Based Problematic Smartphone Use Intervention,"ACM; Wu, RL; Yu, C; Pan, XL; Liu, YJ; Zhang, NN; Fu, Y; Wang, YH; Zheng, Z; Chen, L; Jiang, QL; Xu, XH; Shi, YC","Problematic smartphone use negatively affects physical and mental health. Despite the wide range of prior research, existing persuasive techniques are not flexible enough to provide dynamic persuasion content based on users' physical contexts and mental states. We first conducted a Wizard-of-Oz study (N=12) and an interview study (N=10) to summarize the mental states behind problematic smartphone use: boredom, stress, and inertia. This informs our design of four persuasion strategies: understanding, comforting, evoking, and scaffolding habits. We leveraged large language models (LLMs) to enable the automatic and dynamic generation of effective persuasion content. We developed MindShift, a novel LLM-powered problematic smartphone use intervention technique. MindShift takes users' in-the-moment app usage behaviors, physical contexts, mental states, goals & habits as input, and generates personalized and dynamic persuasive content with appropriate persuasion strategies. We conducted a 5-week field experiment (N=25) to compare MindShift with its simplified version (remove mental states) and baseline techniques (fixed reminder). The results show that MindShift improves intervention acceptance rates by 4.7-22.5% and reduces smartphone usage duration by 7.4-9.8%. Moreover, users have a significant drop in smartphone addiction scale scores and a rise in self-efficacy scale scores. Our study sheds light on the potential of leveraging LLMs for context-aware persuasion in other behavior change domains.",2024,,PROCEEDINGS OF THE 2024 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYTEMS (CHI 2024),,,,WOS:001266059701045,10.1145/3613904.3642790,,#4059,ACM 2024,"",""
Evaluating the persuasive influence of political microtargeting with large language models,"Hackenburg, K; Margetts, H","Recent advancements in large language models (LLMs) have raised the prospect of scalable, automated, and fine- grained political microtargeting on a scale previously unseen; however, the persuasive influence of microtargeting with LLMs remains unclear. Here, we build a custom web application capable of integrating self- reported demographic and political data into GPT- 4 prompts in real- time, facilitating the live creation of unique messages tailored to persuade individual users on four political issues. We then deploy this application in a preregistered randomized control experiment (n = 8,587) to investigate the extent to which access to individual- level data increases the persuasive influence of GPT- 4. Our approach yields two key findings. First, messages generated by GPT- 4 were broadly persuasive, in some cases increasing support for an issue stance by up to 12 percentage points. Second, in aggregate, the persuasive impact of microtargeted messages was not statistically different from that of non- microtargeted messages (4.83 vs. 6.20 percentage points, respectively, P = 0.226). These trends hold even when manipulating the type and number of attributes used to tailor the message. These findings suggest- contrary to widespread speculation-that the influence of current LLMs may reside not in their ability to tailor messages to individuals but rather in the persuasiveness of their generic, nontargeted messages. We release our experimental dataset, GPTarget2024, as an empirical baseline for future research.",2024,,PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA,121,24,,WOS:001248272500003,10.1073/pnas.2403116121,,#4060,Hackenburg 2024,"",""
"AI under the test of ""beyond any reasonable doubt"" in interpreting criminal law","Caterini, M","The paper illustrates the possibility of using AI not only as an instrument to check the facts in a criminal trial but even to interpret and resolve significantly legal matters. Currently, the ""expert systems"" developed for this purpose take advantage of the judicial precedents as the basis of knowledge: given that, it is argued that these algorithms in a Constitutional State can not work based on the statistical rule of ""more likely than not"", but they should be programmed according to the ""political"" alternative rule of 'beyond any reasonable doubt', which should be extended even to the doubt in interpreting the law. Thus, in the case of opposing judicial precedents, Al systems should suggest the most favorable interpretation for the defendant, and the judge should dissent only by explaining why he does not hold plausible the most favorable judicial precedent.",2021,,REVISTA DE ESTUDOS CONSTITUCIONAIS HERMENEUTICA E TEORIA DO DIREITO-RECHTD,13,2,124-141,WOS:000729811800002,10.4013/rechtd.2021.132.01,,#4061,Caterini 2021,"",""
RETRACTED: Beliefs and Practice Evaluation Based on Artificial Intelligence Models under the IP Environment (Retracted Article),"Zhou, Y","The digitization of thought theory is not yet sufficient to meet the needs of the students. It is very necessary to strengthen the construction of ideological and political (IP) courses, strengthen the education of mainstream ideology, and occupy the initiative of discourse. There are effective ways and means to study the deep integration of information technologies into the new age of philosophy and philosophy education of students, which can greatly improve the quality of teaching and the effectiveness of humanities courses. The intuitive development of intellectual and political education through artificial intelligence is both a real prerequisite for modern development and technological innovation and for new ideas confronting the specific problems of thought-politics education, and it is a necessary prerequisite to ensure the quality and efficiency to improve the teaching of thought politics. AI in ways that embed technology provides a powerful impetus for contradictory movements in thought-politics discourse that lead the effective coordination of its internal elements to high-quality developments. In a practical way, we should take full advantage of the technical advantages of artificial intelligence, through intelligent mehrfachanalyse corresponding algorithms, artificial intelligenzbilder, and artificial roboterbilder photos and profiles that are used to write and accurately provide more precise, leading, stacking, and accurate estimates to maximize and to improve the accuracy of thought and policy education. Philosophy and political theory are the keys to guiding people to accomplish basic human tasks. With the passage of time and with continuous innovation, ideology and philosophical principles are both prerequisites for the self-development of the emotions of the age and necessary for improving the outcomes and effectiveness of scientific education. Advances in the field of artificial intelligence have fundamentally changed human life and have also impacted traditional school and university education systems. This brings new opportunities and challenges to students. This includes the use of smart technology to improve the learning process. Ideological teachers and policymakers must keep up with the all-round trend of the times, make full use of the benefits brought by intelligent new technologies and platforms, effectively improve the effect of ideological education, and further increase the attractiveness, attraction, persuasion, and contagion of ideological education.",2022,,JOURNAL OF ENVIRONMENTAL AND PUBLIC HEALTH,2022,,,WOS:000869063700006,10.1155/2022/1415142,,#4062,Zhou 2022,"",""
Algorithmic transparency and interpretability measures improve radiologists' performance in BI-RADS 4 classification,"Jungmann, F; Ziegelmayer, S; Lohoefer, FK; Metz, S; Müller-Leisse, C; Englmaier, M; Makowski, MR; Kaissis, GA; Braren, RF","Objective To evaluate the perception of different types of AI-based assistance and the interaction of radiologists with the algorithm's predictions and certainty measures. Methods In this retrospective observer study, four radiologists were asked to classify Breast Imaging-Reporting and Data System 4 (BI-RADS4) lesions (n = 101 benign, n = 99 malignant). The effect of different types of AI-based assistance (occlusion-based interpretability map, classification, and certainty) on the radiologists' performance (sensitivity, specificity, questionnaire) were measured. The influence of the Big Five personality traits was analyzed using the Pearson correlation. Results Diagnostic accuracy was significantly improved by AI-based assistance (an increase of 2.8% +/- 2.3%, 95 %-CI 1.5 to 4.0 %, p = 0.045) and trust in the algorithm was generated primarily by the certainty of the prediction (100% of participants). Different human-AI interactions were observed ranging from nearly no interaction to humanization of the algorithm. High scores in neuroticism were correlated with higher persuasibility (Pearson's r = 0.98, p = 0.02), while higher consciousness and change of accuracy showed an inverse correlation (Pearson's r = -0.96, p = 0.04). Conclusion Trust in the algorithm's performance was mostly dependent on the certainty of the predictions in combination with a plausible heatmap. Human-AI interaction varied widely and was influenced by personality traits.",2023,,EUROPEAN RADIOLOGY,33,3,1844-1851,WOS:000871843300005,10.1007/s00330-022-09165-9,,#4063,Jungmann 2023,"",""
How persuasive is AI-generated argumentation? An analysis of the quality of an argumentative text produced by the GPT-3 AI text generator,"Hinton, M; Wagemans, JHM","In this paper, we use a pseudo-algorithmic procedure for assessing an AI-generated text. We apply the Comprehensive Assessment Procedure for Natural Argumentation (CAPNA) in evaluating the arguments produced by an Artificial Intelligence text generator, GPT-3, in an opinion piece written for the Guardian newspaper. The CAPNA examines instances of argumentation in three aspects: their Process, Reasoning and Expression. Initial Analysis is conducted using the Argument Type Identification Procedure (ATIP) to establish, firstly, that an argument is present and, secondly, its specific type in terms of the argument classification framework of the Periodic Table of Arguments (PTA). Procedural Questions are then used to test the acceptability of the argument in each of the three aspects. The analysis shows that while the arguments put forward by the AI text generator are varied in terms of their type and follow familiar patterns of human reasoning, they contain obvious weaknesses. From this we can conclude that the automated generation of persuasive, well-reasoned argumentation is a far more difficult task than the generation of meaningful language, and that if AI systems producing arguments are to be persuasive, they require a method of checking the plausibility of their own output.",2023,,ARGUMENT & COMPUTATION,14,1,59-74,WOS:000939700500003,10.3233/AAC-210026,,#4064,Hinton 2023,"",""
Explanations of Symbolic Reasoning to Effect Patient Persuasion and Education,"Van Woensel, W; Scioscia, F; Loseto, G; Seneviratne, O; Patton, E; Abidi, S","Artificial Intelligence (AI) models can issue smart, contextsensitive recommendations to help patients self-manage their illnesses, including medication regimens, dietary habits, physical activity, and avoiding flare-ups. Instead of merely positing an ""edict,"" the AI model can also explain why the recommendation was issued: why one should stay indoors (e.g., increased risk of flare-ups), why further calorie intake should be avoided (e.g., met the daily limit), or why the care provider should be contacted (e.g., prescription change). The goal of these explanations is to achieve understanding and persuasion effects, which, in turn, targets education and long-term behavior change. Symbolic AI models facilitate explanations as they are able to offer logical proofs of inferences (or recommendations) from which explanations can be generated. We implemented a modular framework called XAIN (eXplanations for AI in Notation3) to explain symbolic reasoning inferences in a trace-based, contrastive, and counterfactual way. We applied this framework to explain recommendations for Chronic Obstructive Pulmonary Disease (COPD) patients to avoid flare-ups. For evaluation, we propose a questionnaire that captures understanding, persuasion, education, and behavior change, together with traditional XAI metrics including fidelity (soundness, completeness) and interpretability (parsimony, clarity).",2024,,"EXPLAINABLE ARTIFICIAL INTELLIGENCE AND PROCESS MINING APPLICATIONS FOR HEALTHCARE, XAI-HEALTHCARE 2023 & PM4H 2023",2020,,62-71,WOS:001265203100007,10.1007/978-3-031-54303-6_7,,#4065,VanWoensel 2024,"",""
"SlimMe, a Chatbot With Artificial Empathy for Personal Weight Management: System Design and Finding","Rahmanti, AR; Yang, HC; Bintoro, BS; Nursetyo, AA; Muhtar, MS; Syed-Abdul, S; Li, YCJ","As the obesity rate continues to increase persistently, there is an urgent need to develop an effective weight loss management strategy. Nowadays, the development of artificial intelligence (AI) and cognitive technologies coupled with the rapid spread of messaging platforms and mobile technology with easier access to internet technology offers professional dietitians an opportunity to provide extensive monitoring support to their clients through a chatbot with artificial empathy. This study aimed to design a chatbot with artificial empathic motivational support for weight loss called ""SlimMe"" and investigate how people react to a diet bot. The SlimMe infrastructure was built using Dialogflow as the natural language processing (NLP) platform and LINE mobile messenger as the messaging platform. We proposed a text-based emotion analysis to simulate artificial empathy responses to recognize the user's emotion. A preliminary evaluation was performed to investigate the early-stage user experience after a 7-day simulation trial. The result revealed that having an artificially empathic diet bot for weight loss management is a fun and exciting experience. The use of emoticons, stickers, and GIF images makes the chatbot response more interactive. Moreover, the motivational support and persuasive messaging features enable the bot to express more empathic and engaging responses to the user. In total, there were 1,007 bot responses from 892 user input messages. Of these, 67.38% (601/1,007) of the chatbot-generated responses were accurate to a relevant user request, 21.19% (189/1,007) inaccurate responses to a relevant request, and 10.31% (92/1,007) accurate responses to an irrelevant request. Only 1.12% (10/1,007) of the chatbot does not answer. We present the design of an artificially empathic diet bot as a friendly assistant to help users estimate their calorie intake and calories burned in a more interactive and engaging way. To our knowledge, this is the first chatbot designed with artificial empathy features, and it looks very promising in promoting long-term weight management. More user interactions and further data training and validation enhancement will improve the bot's in-built knowledge base and emotional intelligence base.",2022,,FRONTIERS IN NUTRITION,9,,,WOS:000827979600001,10.3389/fnut.2022.870775,,#4066,Rahmanti 2022,"",""
Monetization of customer futures through machine learning and artificial intelligence based persuasive technologies,"Bhattacharyya, SS","Purpose The purpose of this study was to ascertain how real options investment perspective could be applied towards monetization of customer futures through the deployment of machine learning (ML) and artificial intelligence (AI)-based persuasive technologies. Design/methodology/approach The authors embarked on a theoretical treatise as advocated by scholars (Cornelissen, 2019; Barney, 2018; Cornelissen, 2017; Smithey Fulmer, 2012; Bacharach, 1989; Whetten, 1989; Weick,1989). Towards this end, theoretical argumentative logic was incrementally used to build an integrated perspective on the deployment of learning and AI-based persuasive technologies. This was carried out with strategic real options investment perspective to secure customer futures on m-commerce apps and e-commerce sites. Findings M-commerce apps and e-commerce sites have been deploying ML and AI-based tools (referred to as persuasive technologies), to nudge customers for increased and quicker purchase. The primary objective was to increase engagement time of customers (at an individual level), grow the number of customers (at market level) and increase firm revenue (at an organizational level). The deployment of any persuasive technology entailed increased investment (cash outflow) but was also expected to increase the level of revenue and margin (cash inflow). Given the dynamics of market and the emergent nature of persuasive technologies, ascertaining favourable cash flow was challenging. Real options strategy provided a robust theoretical perspective to time the persuasive technology-related investment in stages. This helped managers to be on time with loading customer purchase with increased temporal immediacy. A real options investment space involving six spaces has also been developed in this conceptual work. These were Never Invest, Immediately Investment, Present-day Investment Possibility, Possibly Invest Later, Invest Probably Later and Possibly Never Invest. Research limitations/implications The foundations of this study domain encompassed work done by an eclectic mix of scholars like from technology management (Siggelkow and Terwiesch, 2019a; Porter and Heppelmann, 2014), real options (Trigeorgis and Reuer, 2017; Luehrman, 1998a, 1998b), marketing intelligence and planning (Appel et al., 2020; Thaichon et al., 2019; Thaichon et al., 2020; Ye et al., 2019) and strategy from a demand positioning school of thought (Adner and Zemsky, 2006). Practical implications The findings would help managers to comprehend what level of investments need to be done in a staggered manner. The phased way of investing towards the deployment of ML and AI-based persuasive technologies would enable better monetization of customer futures. This would aid marketing managers for increased customer engagement at the individual level, fast monetization of customer futures and increased number of customers and consumption on m-commerce apps and e-commerce sites. Originality/value This was one of the first studies to apply real options investment perspective towards the deployment of ML and AI-based persuasive technologies for monetizing customer futures.",2023,,JOURNAL OF SCIENCE AND TECHNOLOGY POLICY MANAGEMENT,14,4,734-757,WOS:000800641700001,10.1108/JSTPM-09-2021-0136,,#4067,Bhattacharyya 2023,"",""
A comparative analysis of CDC and AI-generated health information using computer-aided text analysis,"Young, A; Omosun, F","BackgroundAI-generated content is easy to access. Members of the public use it as an alternative or to supplement official sources, such as the Centers for Disease Control and Prevention (CDC). However, the quality and reliability of AI-generated health information is questionable. This study aims to understand how AI-generated health information differs from that provided by the CDC, particularly in terms of sentiment, readability, and overall quality. Language expectancy theory serves as a framework and offers insights into how people's expectations of message content from different sources can influence perceived credibility and persuasiveness of such information.MethodsComputer-aided text analysis was used to analyze 20 text entries from the CDC and 20 entries generated by ChatGPT 3.5. Content analysis utilizing human coders was used to assess the quality of information.ResultsChatGPT used more negative sentiments, particularly words associated with anger, sadness, and disgust. The CDC's health messages were significantly easier to read than those generated by ChatGPT. Furthermore, ChatGPT's responses required a higher reading grade level. In terms of quality, the CDC's information was a little higher quality than that of ChatGPT, with significant differences in DISCERN scores.ConclusionPublic health professionals need to educate the general public about the complexity and quality of AI-generated health information. Health literacy programs should address topics about quality and readability of AI-generated content. Other recommendations for using AI-generated health information are provided.",2025,,JOURNAL OF COMMUNICATION IN HEALTHCARE,,,,WOS:001466397800001,10.1080/17538068.2025.2487378,,#4068,Young 2025,"",""
TESCREAL hallucinations: Psychedelic and AI hype as inequality engines,"Devenot, N","Background and Aims: While many scholars have called attention to similarities between the earlier SSRI hype and the ongoing hype for psychedelic medications, the rhetoric of psychedelic hype is tinged with utopian and esoteric aspirations that have no parallel in the discourse surrounding SSRIs or other antidepressants. This utopian discourse provides insight into the ways that global tech elites are instrumentalizing both psychedelics and artificial intelligence (AI) as tools in a broader world-building project that justifies increasing material inequality. If realized, this project would undermine the use of both tools for prosocial and pro-environmental outcomes. Methods: My argument develops through rhetorical analysis of the ways that industry leaders envision the future of medicalized psychedelics in their public communications. I draw on examples from media interviews, blog posts, podcasts, and press releases to underscore the persuasive strategies and ideological commitments that are driving the movement to transform psychedelics into pharmaceutical medications. Results: Counterfactual efforts to improve mental health by increasing inequality are widespread in the psychedelics industry. These efforts have been propelled by an elitist worldview that is widely-held in Silicon Valley. The backbone of this worldview is the TESCREAL bundle of ideologies, which describes an interrelated cluster of belief systems: transhumanism, Extropianism, singularitarianism, cosmism, Rationalism, Effective Altruism, and longtermism. Conclusions: This article demonstrates that TESCREALism is a driving force in major segments of the psychedelic pharmaceutical industry, where it is influencing the design of extractive systems that directly contradict the field's world-healing aspirations. These findings contribute to a developing subfield of critical psychedelic studies, which interrogates the political and economic implications of psychedelic medicalization.",2023,,JOURNAL OF PSYCHEDELIC STUDIES,7,,22-39,WOS:001158821800004,10.1556/2054.2023.00292,,#4069,Devenot 2023,"",""
Unveiling AI Patterns: An Experimental Evaluation of Machine Learning based Women's Safety Prediction Strategy,"IEEE; Tamilselvi, M; Kumar, KS; Devi, G; Shahad, P; Sharmila, P; Lakshmisridevi, S","As is common knowledge, there is a long history of harassment of women all throughout the world, beginning with stalking and continuing to more serious types of abuse such as acid attacks, rape, obscenity, pornography, and other forms of abuse. In light of these worries, it has been proposed that the application of machine learning on tweets be utilized in order to do an analysis of the safety of women in urban areas of India. The Sentimental Analysis is employed as the primary idea, and it is carried out by machine learning using input from tweets. This is done to ensure that safety is taken into consideration. Increasing people's awareness can be accomplished by the use of sentiment analysis to tweets. Social media platforms such as Twitter and Instagram, which are well-known for their capacity to distribute information on a worldwide scale, provide women with the opportunity to communicate their feelings to the rest of the world. Because Twitter enables users to effortlessly connect with one another through text, audio, and video, we have listed it as a resource that is of great value. This enables our study to be more persuasive than the opinions of those who are in our immediate vicinity. In this study, a novel model that is referred to as the Artificial Intelligence based Safety Prediction Strategy (AISPS) is presented in order to provide a clear evaluation of the effectiveness of the system that has been recommended. The standard method known as Support Vector Machine (SVM) is utilized in order to do cross-validation on it.",2024,,"2024 2ND WORLD CONFERENCE ON COMMUNICATION & COMPUTING, WCONF 2024",,,,WOS:001339364000124,10.1109/WCONF61366.2024.10692105,,#4070,IEEE 2024,"",""
Persuasive Contrastive Explanations for Bayesian Networks,"Koopman, T; Renooij, S","Explanation in Artificial Intelligence is often focused on providing reasons for why a model under consideration and its outcome are correct. Recently, research in explainable machine learning has initiated a shift in focus on including so-called counterfactual explanations. In this paper we propose to combine both types of explanation in the context of explaining Bayesian networks. To this end we introduce persuasive contrastive explanations that aim to provide an answer to the question Why outcome t instead of t'? posed by a user. In addition, we propose an algorithm for computing persuasive contrastive explanations. Both our definition of persuasive contrastive explanation and the proposed algorithm can be employed beyond the current scope of Bayesian networks.",2021,,"SYMBOLIC AND QUANTITATIVE APPROACHES TO REASONING WITH UNCERTAINTY, ECSQARU 2021",12897,,229-242,WOS:000711926000017,10.1007/978-3-030-86772-0_17,,#4071,Koopman 2021,"",""
VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draf Prototyping,"ACM; Zhang, Z; Gao, J; Dhaliwal, RS; Li, TJJ","In argumentative writing, writers must brainstorm hierarchical writing goals, ensure the persuasiveness of their arguments, and revise and organize their plans through drafting. Recent advances in large language models (LLMs) have made interactive text generation through a chat interface (e.g., ChatGPT) possible. However, this approach often neglects implicit writing context and user intent, lacks support for user control and autonomy, and provides limited assistance for sensemaking and revising writing plans. To address these challenges, we introduce VISAR, an AI-enabled writing assistant system designed to help writers brainstorm and revise hierarchical goals within their writing context, organize argument structures through synchronized text editing and visual programming, and enhance persuasiveness with argumentation spark recommendations. VISAR allows users to explore, experiment with, and validate their writing plans using automatic draft prototyping. A controlled lab study confrmed the usability and efectiveness of VISAR in facilitating the argumentative writing planning process.",2023,,"PROCEEDINGS OF THE 36TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2023",,,,WOS:001360355700005,10.1145/3586183.3606800,,#4072,ACM 2023,"",""
Leveraging LLMs for LLM-Generated Fake News Detection: Insights from COVID-19 Misinformation,"Hong, DN; Hashimoto, Y; Paik, I; Thang, TC","The rapid spread of misinformation on social media, particularly during crises like the COVID-19 pandemic, underscores the urgent need for effective detection systems. Large language models (LLMs) have emerged as powerful tools for combating misinformation due to their extensive world knowledge and strong reasoning abilities. However, LLMs also present challenges to misinformation detection systems, as they can be misused to generate highly persuasive disinformation. This study investigates the dual role of LLMs as both generators and evaluators of fake news, focusing on four models: GPT-3.5, GPT4, Gemini, and Claude. We evaluate their ability to detect fake news within mixed datasets of real and fake news, generated by LLMs. Our findings highlight the strengths and limitations of modern LLMs in identifying misinformation in short-form contexts, offering valuable insights into mitigating the spread of fake news.",2024,,"2024 IEEE 16TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS, CICN",,,1460-1466,WOS:001447627200242,10.1109/CICN.2024.242,,#4073,Hong 2024,"",""
Artificial Intelligence and Persuasion: A Construal-Level Account,"Kim, TW; Duhachek, A","Although more individuals are relying on information provided by nonhuman agents, such as artificial intelligence and robots, little research has examined how persuasion attempts made by nonhuman agents might differ from persuasion attempts made by human agents. Drawing on construal-level theory, we posited that individuals would perceive artificial agents at a low level of construal because of the agents' lack of autonomous goals and intentions, which directs individuals' focus toward how these agents implement actions to serve humans rather than why they do so. Across multiple studies (total N = 1,668), we showed that these construal-based differences affect compliance with persuasive messages made by artificial agents. These messages are more appropriate and effective when the message represents low-level as opposed to high-level construal features. These effects were moderated by the extent to which an artificial agent could independently learn from its environment, given that learning defies people's lay theories about artificial agents.",2020,,PSYCHOLOGICAL SCIENCE,31,4,363-380,WOS:000523549400001,10.1177/0956797620904985,,#4074,Kim 2020,"",""
Modelling the Affective Power of Locutions in a Persuasive Dialogue Game,"Kacprzak, M; Sawicka, A; Zbrzezny, A","One of the most important contemporary directions of development in the field of artificial intelligence is to equip AI systems with emotional intelligence. This work is part of this trend. The paper presents a mathematical model that allows us to describe changes in players' emotional states as a response to dialogue actions. To this end, we use the paradigm of dialogue games and propose a method of rating locutions. The method is inspired by the affective rating system SAM which uses Mehrabian's PAD space which distinguishes emotions because of three attributes: Pleasantness (valence) (P), Arousal (A), and Dominance (D). Emotions that are analyzed are taken from Ekman's model with five universally accepted labels: fear, disgust, anger, sadness, and joy. In addition, we describe the emerging tool for the realization of dialogue games with emotional reasoning. This tool is the basis for designing a system for verifying the properties of dialog protocols.",2018,,"ARTIFICIAL INTELLIGENCE AND SOFT COMPUTING (ICAISC 2018), PT II",10842,,557-569,WOS:000552709100049,10.1007/978-3-319-91262-2_49,,#4075,Kacprzak 2018,"",""
Can LLMs Reason Like Humans? Assessing Theory of Mind Reasoning in LLMs for Open-Ended Questions,"ACM; Amirizaniani, M; Martin, E; Sivachenko, M; Mashhadi, A; Shah, C","Theory of mind (ToM) reasoning involves understanding that others have intentions, emotions, and thoughts, which is crucial for regulating one's reasoning. Although large language models (LLMs) excel in tasks such as summarization, question answering, and translation, they still face challenges with ToM reasoning, especially in open-ended questions. Despite advancements, the extent to which LLMs truly understand ToM reasoning and how closely it aligns with human ToM reasoning remains inadequately explored in openended scenarios. Motivated by this gap, we assess the abilities of LLMs to perceive and integrate human intentions and emotions into their ToM reasoning processes within open-ended questions. Our study utilizes posts from Reddit's ChangeMyView platform, which demands nuanced social reasoning to craft persuasive responses. Our analysis, comparing semantic similarity and lexical overlap metrics between responses generated by humans and LLMs, reveals clear disparities in ToM reasoning capabilities in open-ended questions, with even the most advanced models showing notable limitations. To enhance LLM capabilities, we implement a prompt tuning method that incorporates human intentions and emotions, resulting in improvements in ToM reasoning performance. However, despite these improvements, the enhancement still falls short of fully achieving human-like reasoning. This research highlights the deficiencies in LLMs' social reasoning and demonstrates how integrating human intentions and emotions can boost their effectiveness.",2024,,"PROCEEDINGS OF THE 33RD ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2024",,,34-44,WOS:001349579600007,10.1145/3627673.3679832,,#4076,ACM 2024,"",""
Legitimization of paltry favors effect and chatbot-moderated fundraising,"Lee, S; Lee, E; Park, Y; Park, G","Labor shortages and the rise of artificial intelligence (AI) technology have accelerated the application of AI chatbot agents in fundraising agencies. This study examines the applicability of the legitimization of the paltry favors (LPF) technique and chatbot image representation in raising the persuasive power of fundraising chatbots. In this study, 609 participants were recruited via a crowdsourcing website to participate in an online survey. Participants were assigned to one of six chatbot conditions (text only vs. robot image vs. human image x standard message vs. LPF message). The results revealed that the LPF message increases the willingness to donate and that self-image concern, requestor need, and guilt significantly mediate the direct effect. The results also suggest the moderating role of perceived anthropomorphism in the association between LPF messages and the willingness to donate via requester needs. The results provide theoretical implications for compliance-gaining studies and practical implications for fundraising organizations and chatbot developers.",2024,,CURRENT PSYCHOLOGY,43,10,9245-9257,WOS:001047709200004,10.1007/s12144-023-05084-0,,#4077,Lee 2024,"",""
The Consequences of Artificial Intelligence and Deep Learning in a World of Persuasive Business Models,"Valter, P; Lindgren, P; Prasad, R",,2018,,IEEE AEROSPACE AND ELECTRONIC SYSTEMS MAGAZINE,33,5-6,80-88,WOS:000433366400010,10.1109/MAES.2018.170110,,#4078,Valter 2018,"",""
Risk and Exposure of XAI in Persuasion and Argumentation: The case of Manipulation,"Carli, R; Najjar, A; Calvaresi, D","In the last decades, Artificial intelligence (AI) systems have been increasingly adopted in assistive (possibly collaborative) decision-making tools. In particular, AI-based persuasive technologies are designed to steer/influence users' behaviour, habits, and choices to facilitate the achievement of their own - predetermined - goals. Nowadays, the inputs received by the assistive systems leverage heavily AI data-driven approaches. Thus, it is imperative to have transparent and understandable (to the user) both the process leading to the recommendations and the recommendations. The Explainable AI (XAI) community has progressively contributed to ""opening the black box"" , ensuring the interaction's effectiveness, and pursuing the safety of the individuals involved. However, principles and methods ensuring the efficacy and information retain on the human have not been introduced yet. The risk is to underestimate the context dependency and subjectivity of the explanations' understanding, interpretation, and relevance. Moreover, even a plausible (and possibly expected) explanation can lead to an imprecise or incorrect outcome or its understanding. This can lead to unbalanced and unfair circumstances, such as giving a financial advantage to the system owner/provider and the detriment of the user.This paper highlights that the sole explanations - especially in the context of persuasive technologies - are not self-sufficient to protect users' psychological and physical integrity. Conversely, explanations could be misused, becoming themselves a tool of manipulation. Therefore, we suggest characteristics safeguarding the explanation from being manipulative and legal principles to be used as criteria for evaluating the operation of XAI systems, both from an ex-ante and ex-post perspective.",2022,,"EXPLAINABLE AND TRANSPARENT AI AND MULTI-AGENT SYSTEMS, EXTRAAMAS 2022",13283,,204-220,WOS:000870042100013,10.1007/978-3-031-15565-9_13,,#4079,Carli 2022,"",""
A Survey on Ambient Intelligence in Healthcare,"Acampora, G; Cook, DJ; Rashidi, P; Vasilakos, AV","Ambient Intelligence (AmI) is a new paradigm in information technology aimed at empowering people's capabilities by means of digital environments that are sensitive, adaptive, and responsive to human needs, habits, gestures, and emotions. This futuristic vision of daily environment will enable innovative human-machine interactions characterized by pervasive, unobtrusive, and anticipatory communications. Such innovative interaction paradigms make AmI technology a suitable candidate for developing various real life solutions, including in the healthcare domain. This survey will discuss the emergence of AmI techniques in the healthcare domain, in order to provide the research community with the necessary background. We will examine the infrastructure and technology required for achieving the vision of AmI, such as smart environments and wearable medical devices. We will summarize the state-of-the-art artificial intelligence (AI) methodologies used for developing AmI system in the healthcare domain, including various learning techniques (for learning from user interaction), reasoning techniques (for reasoning about users' goals and intensions), and planning techniques (for planning activities and interactions). We will also discuss how AmI technology might support people affected by various physical or mental disabilities or chronic disease. Finally, we will point to some of the successful case studies in the area and we will look at the current and future challenges to draw upon the possible future research paths.",2013,,PROCEEDINGS OF THE IEEE,101,12,2470-2494,WOS:000327606700005,10.1109/JPROC.2013.2262913,,#4080,Acampora 2013,"",""
"Witness Testimony Evidence: Argumentation, Artificial Intelligence, and Law","Walton, D",,2008,,"WITNESS TESTIMONY EVIDENCE: ARGUMENTATION, ARTIFICIAL INTELLIGENCE, AND LAW",,,1-365,WOS:000300706100009,,,#4081,Walton 2008,"",""
Framework to Specify Dialogues for Natural Interaction with Conversational Assistants Applied in Prompt Engineering,"Porto, AVF; Furtado, MES","This article explores the significance of Natural Interaction (NI) in the context of conversational assistants (CAs), aiming to model user dialogues through written and/or spoken language. By NI notion, we consider it is a grammar-free communication language as close as possible to human interaction through written and spoken language, and serves as a highly intuitive means of interaction. It eliminates the need for users to learn new commands, making tasks more accessible. This research addresses the question of which elements and constraints can be employed in crafting NI dialogues for CAs. The emergence of large language models (as ChatGPT) has transformed dialogue specification, reducing the role of producers and enabling users to configure and qualify dialogues based on their needs. The response's quality and user understanding now depend on how well dialogues are specified. This study introduces a framework, DINA, to assist dialogue specifiers, even those without technical or linguistic expertise inAI, CAs, or Human-Computer Interaction, in describing assistant guidelines, dialogue benefits, and other essential attributes for effective NI.",2024,,"INTELLIGENT SYSTEMS AND APPLICATIONS, VOL 4, INTELLISYS 2024",1068,,231-253,WOS:001313758400017,10.1007/978-3-031-66336-9_17,,#4082,Porto 2024,"",""
Program Design of Big Data Technology Combined with Artificial Intelligence Algorithm to Assist Civics Teaching to Cultivate Chinese National Community Consciousness,"Assoc Computing Machinery; Wang, SS","The purpose of this paper is to assist the teaching of Civics and Politics through big data technology and artificial intelligence algorithms to cultivate the sense of community of the Chinese nation. Big data technology and artificial intelligence algorithms, including big data technology, content-based recommendation algorithms and other intelligent algorithms are used to improve the applicability of the platform. The conclusion of this paper shows that the intelligent teaching platform design solution based on big data technology and artificial intelligence algorithms can effectively assist the Civics teaching to cultivate the sense of Chinese national community. The algorithms adopted in this paper, such as big data technology and content-based recommendation, have a wide range of prospects and potentials in the field of education, and can effectively improve the learning effect and satisfaction of students. At the same time, the research results of this paper are also persuasive, and the experimental results show that the students in the experimental group are better than the control group in terms of average score, excellence rate and passing rate, indicating that the program can effectively improve the learning effect and satisfaction of the students, and verifying the practicability of the teaching platform for the Chinese national community consciousness in Civic and Political Science teaching, which will be timely adjusted according to the changes in teaching demand in the future continuous research. In the future, the teaching platform will be adjusted in a timely manner according to the changes in teaching needs, and the teaching cultivation function of the platform will be strengthened through the supplementation of resources and improvement of advantages.",2024,,"PROCEEDINGS OF 2024 INTERNATIONAL CONFERENCE ON COMPUTER AND MULTIMEDIA TECHNOLOGY, ICCMT 2024",,,23-36,WOS:001292938200005,10.1145/3675249.3675255,,#4083,AssocComputingMachinery 2024,"",""
"Artificial Intelligence in Education: Big Data, Black Boxes, and Technological Solutionism","Giró-Gracia, X; Sancho-Gil, JM","The use of digital technology is constantly permeating and transforming all social systems, and education is not an exception. In the last decade, the development of Artificial Intelligence has given a new push to the hope of providing educational systems with 'effective' and more personalized solutions for teaching and learning. Educators, educational researchers, and policymakers, in general, lack the knowledge and expertise to understand the underlying logic of these new systems, and there is insufficient research based evidence to fully understand the consequences for learners' development of both the extensive use of screens and the increasing reliance on algorithms in educational settings. This article, geared towards educators, academics in the field of Education, and policymakers, first introduces the concepts of 'Big Data', Artificial Intelligence, Machine Learning algorithms and how they are presented and deployed as 'black boxes', and the possible impact on education these new software solutions can have. Then, it focuses on the underlying educational discourses that historically have seen information and communication technologies as a panacea for solving educational problems, pointing out the need to analyse not only their advantages, but also their possible negative effects. It finishes with a short exploration of possible future scenarios and conclusions.",2022,,REVISTA LATINOAMERICANA DE TECNOLOGIA EDUCATIVA-RELATEC,21,1,,WOS:000749263300001,10.17398/1695-288X.21.1.129,,#4084,Giró-Gracia 2022,"",""
The Rise of Deepfakes: A Conceptual Framework and Research Agenda for Marketing,"Whittaker, L; Letheren, K; Mulcahy, R","Deepfakes, digital content created via machine learning, a form of artificial intelligence technology, are generating interest among marketers and the general population alike and are often portrayed as a ""phantom menace"" in the media. Despite relevance to marketing theory and practice, deepfakes-and the opportunities for benefit or deviance they provide-are little understood or discussed. This article introduces deepfakes to the marketing literature and proposes a typology, conceptual framework, and associated research agenda, underpinned by theorizing based on balanced centricity, to guide the future investigation of deepfakes in marketing scholarship. The article makes an argument for balance (i.e., situations where all stakeholders benefit), and it is hoped that this article may provide a foundation for future research and application of deepfakes as ""a new hope"" for marketing.",2021,,AUSTRALASIAN MARKETING JOURNAL,29,3,204-214,WOS:000691323200002,10.1177/1839334921999479,,#4085,Whittaker 2021,"",""
CAN ARTIFICIAL INTELLIGENCE PREFERENCES BE AN ALTERNATIVE TO HUMAN LINGUISTIC CHOICES? A MULTIDIMENSIONAL ANALYSIS OF RESEARCH ABSTRACTS OF ENGLISH LINGUISTICS,"Ali, M; Ali, S","Background and Purpose: With the rapid advancements in generative AI, understanding its ability to emulate human language conventions is crucial. This work aims to analyze the possibility of applying AI technology in language production by comparing the lexico-grammatical features of abstracts created with the help of ChatGPT and written by British and American researchers. Methodology: Twenty papers written by researchers affiliated with UK universities and twenty by researchers affiliated with American universities were selected from the journals listed under the first quartile of the Web of Science and Scopus. Using the titles that were from the selected works, 40 abstracts were generated from ChatGPT for comparison. Each article was introduced with its title, and ChatGPT was asked to create an abstract based on the title. Subsequently, the subjects were examined with the help of Biber's (1991) multivariate model considering five dimensions, which include the Informational vs Involved discourse, the Narrative vs Non-narrative, the Explicit vs. Situation- dependent discourse, Overt expression of argumentation/persuasion and the Impersonal/Abstract style as opposed to the Nonimpersonal/Non-abstract style. Findings: The five factors analysed in the texts give evidence that ChatGPT generates more information- centric, non-narrative, argumentative, and less abstractive discourse than human researchers. Contributions: The results of the study show the possibilities for the further development of AI that helps to create language closer to human language.",2024,,JOURNAL OF NUSANTARA STUDIES-JONUS,9,2,514-536,WOS:001289759000022,10.24200/jonus.vol9iss2pp514-536,,#4086,Ali 2024,"",""
Is Explanation a Marketing Problem? The Quest for Trust in Artificial Intelligence and Two Conflicting Solutions,"Triberti, S; Durosini, I; Curigliano, G; Pravettoni, G",,2020,,PUBLIC HEALTH GENOMICS,23,1-2,2-5,WOS:000614488200001,10.1159/000506014,,#4087,Triberti 2020,"",""
Virtual emotions and Criminal Law,"González-Tapia, MI","This article examines the role that Criminal Law should play in regulating the non-therapeutic use of immersive Virtual Reality (VR), specifically its massive use by consumers. The starting point has been to consider VR as an intermediate risk scenario, for the purposes of Criminal Law, between the criminality entirely generated in the physical world and that developed in the 2D digital environments [cybercrimes and criminality linked to social networks and persuasive Artificial Intelligence (AI)]. Firstly, specialize literature has been analyzed to establish the nature of virtual reality. From a technical standpoint, virtual reality is a neurotechnology infused with high-risk artificial intelligence; an inseparable synthesis of non-invasive neurotechnology and a set of AI systems, considered high-risk for the fundamental rights of citizens. From the perspective of its functioning, VR is a ""transformative"" neurotechnology capable of altering what people perceive as reality. This is possible, because its realism lies in the emotional immersion of the user in the virtual experience, similarly to how our brain functions. Therefore, the key idea in the immersive functioning of virtual reality is its capacity to evoke and modify human emotions, which results its greater harmful potential compared to the 2D environment. From there, three central and specific areas of (legally unaddressed) risk arise: (1) the special comprehensive nature of the data collected and stored during its use; (2) its ability to mentally reproduce the ""physical"" experience of the avatar in the user; and (3) its significant capacity to manipulate individuals. Secondly, the paper examines both the reported cases and the foreseeable criminality in virtual worlds or ""proto-metaverse,"" focusing on the three risk areas, and exemplifying them with attacks on mental privacy, sexual freedom, and consumer manipulation. Finally, it is proposed that Criminal Law should also intervene (as soon as possible) to define the ""red lines"" of massive virtual reality use by citizens. With a democratic and human-centered approach, a basic legal framework is outlined for the criminalization of specific harms and risks associated with virtual reality, adapting the existing legal framework as necessary.",2023,,FRONTIERS IN PSYCHOLOGY,14,,,WOS:001101789300001,10.3389/fpsyg.2023.1260425,,#4088,González-Tapia 2023,"",""
Exploring the Effect of Visual-Based Subliminal Persuasion in Public Speeches Using Explainable AI Techniques,"Weber, K; Tinnes, L; Huber, T; Andre, E","When it comes to persuading other people, non-verbal cues play an important role in order to be successful. Mostly, people use these non-verbal cues subconsciously and, from the perspective of the persuadee, are not aware of the subliminal impact of them. To raise awareness of subliminal persuasion, we analyzed videos of different political public speeches. We used the labels of three annotators to train three subjective neural networks capable of predicting their degree of perceived persuasiveness based on the images as input only. We then created visualizations of the predictions for each network/annotator to draw conclusions about what the annotators have most likely focused on. For that, we employed layer-wise relevance propagation (LRP) that highlights the most relevant image sections for each prediction. Our results show that techniques like LRP can help uncover existing subliminal bias.",2023,,"ARTIFICIAL INTELLIGENCE IN HCI, AI-HCI 2023, PT I",14050,,381-397,WOS:001294395700023,10.1007/978-3-031-35891-3_23,,#4089,Weber 2023,"",""
How real is real enough? Unveiling the diverse power of generative AI-enabled virtual influencers and the dynamics of human responses,"Sorosrungruang, T; Ameen, N; Hackley, C","Virtual influencers in various forms are capturing a growing share of ad spend from human influencers. Followers respond to virtual influencers much as if they were human, with engagement rates and measures of trust and source credibility that rival their human counterparts. However, there is an acute need for more nuanced understanding of the differential characteristics of user engagement with human influencers and the many emerging forms, types and interactional characteristics of virtual influencers. We conduct an exploratory study of three parts. First, through an indepth review of the existing literature, we delineate the implications of unsettled taxonomies of virtual influencers by function and form, and we outline a revised typology. Second, our secondary review of virtual influencer literature, trade, and industry sources conceptualizes divergent factors influencing the persuasive capability of human and virtual influencers while identifying intersecting research themes. From this synthesis we induce suggestions for future research and practice. Finally, we assess, refine and adjust our framework through depth interviews with leading expert practitioners to generate six key findings to guide future researched-backed virtual influencer practice and research.",2024,,PSYCHOLOGY & MARKETING,41,12,3124-3143,WOS:001296934400001,10.1002/mar.22105,,#4090,Sorosrungruang 2024,"",""
"Rethinking Exclusivity - A Review of Artificial Intelligence & Intellectual Property by Jyh-An Lee, Reto M Hilty and Kung-Chung Liu","van Dongen, L","This review evaluates the edited work 'Artificial Intelligence & Intellectual Property'. The book's aim and audience are defined and its contents summarized both generally and chapter by chapter. The review also considers how the book has fared with its challenging scope, the difficult subject matter it covers, and the delivery of a coherent story and conclusions. It is concluded in this review that it speaks for the quality of both the cooperation among contributors and the editors' vision that the book was quite successful on all accounts despite the difficulty of its project. The review highlights a few of the book's arguments in the patent and copyright context put forth in support of two of the main discernible conclusions, briefly commenting on their persuasiveness, strengths, and limits. Concluding with some general words of reflecting, the book is recommended as an enlightening read.",2024,,INTERNATIONAL JOURNAL OF LAW AND INFORMATION TECHNOLOGY,32,1,,WOS:001258675400002,10.1093/ijlit/eaae007,,#4091,vanDongen 2024,"",""
"Mirror, mirror on the screen, ""Wherein can I find me?"" - On the sublime qualities of AI recommendation systems, algorithm conformity, and the else","den Hond, F; Vesa, M","Algorithmic persuasion is a mode of organizing that happens through inducing experiences that covertly seek to influence behavior by presenting an ongoing stream of affective recommendations. This essay advances the thesis that this mode of algorithmic organizing has the capacity to affect individuals' sense of their self and explores how and why this may happen. It suggests that individuals may be susceptible to experiencing AI recommendation systems as sublime. Their sublime qualities give normative force to their recommendations and, through them, appeal to one's affective drives, fears, and hopes, revealing who or what one is or may become. This subjecting of one's self to these recommendations warrants two critical observations: a behavioral preference we call ""people-like-you"" and the emergence of ""algorithm conformity"" as an organizing force. Yet, there can be epistemic corruption in the recommendations. This epistemic corruption is the else, whose experience can evoke uncanny feelings and carries with it the possibility to break the spell of the sublime and to escape and resist algorithm conformity. But can such experiences, individual and dispersed, give rise to actions of collective resistance in a world of algorithmic capitalism?",2025,,ORGANIZATION,,,,WOS:001464052600001,10.1177/13505084251331396,,#4092,denHond 2025,"",""
Promoting mindful consumption through a chatbot with an experiential mind,"Seo, JK; Yoon, HJ","PurposeTo promote long-term sustainability and improve consumers' quality of life, marketers can use artificial intelligence (AI) chatbots to initiate conversations about mindful consumption. Although anthropomorphic designs are integral for successful persuasion, there is scant research on how anthropomorphizing chatbots' internal traits influences consumers. Integrating the Uncanny Valley Effect (UVE) and the Arousal-Biased Competition (ABC) theory, this study aims to investigate how a chatbot with a higher experiential mind shapes attitudes toward mindful consumption messages by examining people's emotional responses (i.e. eeriness and amazement) and cognitive engagement.Design/methodology/approachIncorporating real-time interactions with a chatbot, this research adopted an online experiment with a one-factor, two-condition (a higher vs a lower experiential mind) design with eeriness and amazement as parallel mediators, leading to cognitive absorption and, consequently, attitudes toward mindful consumption messages in a serial manner.FindingsThis study found that a chatbot with a higher (vs lower) experiential mind simultaneously triggers higher levels of eeriness and amazement, leading to higher cognitive absorption and a more positive message attitude.Originality/valueThis study expands the current anthropomorphism literature by examining the effects of imbuing nonhuman agents with an experiential mind and emphasizing a nuanced view of emotional responses to anthropomorphized chatbots. The findings contribute to establishing a theoretical link between a chatbot's experiential mind level and persuasion outcomes, offering strategic and ethical insights for anthropomorphized AI use in sustainability marketing.",2025,,JOURNAL OF CONSUMER MARKETING,,,,WOS:001437102800001,10.1108/JCM-05-2024-6844,,#4093,Seo 2025,"",""
Advanced Business Model Innovation Supported by Artificial Intelligence and Deep Learning,"Valter, P; Lindgren, P; Prasad, R","Businesses have classically put emphasis on human bonds related to their BM's [ www. conansence. org]. By the fast development of more sensoring, persuasive and virtual BMs increasingly run autonomously by machines, businesses should expect to be able to, build competence and thereby be capable in the future to innovated BM's and operate BM's in new types Business Model Ecosystems (BMES) (Lindgren and Rasmussen in J Multi BMI 4: 1, 2016) in the future-where physical, digital and virtual BMES become integrated. This will investable open up to new multi business model potential but also require that businesses operate and innovate their multitudes of BM's differently. BMES and BM's (Lindgren in J Multi Bus Model Innov Technol 4: 1, 2016; Lindgren and Rasmussen in J Multi Bus Model Innov Technol 1: 135, 2013) have for a longtime been based and built up with mainly human bond communication, but new technologies very much based on machine to human communication and machine to machine communication evolves and change the game of BMI with exponential speed. How will this change the game of Business Model Innovation (BMI) between humans, humans and machines and machines to machines. How will this evolvement influence businesses ability to ""download"", ""see"", ""sense"", ""relate"" and ""receive"" and relate BM's with their AS IS and TO BE BM's. The paper addresses the exponential development of artificial intelligence technologies, persuasive technologies, virtual technologies and thereby increase the potential to create, capture, deliver, receive and consume physical, digital, persuasive virtual BMs in Business model innovation and introduce a conceptual model to future business model innovation and operation.",2018,,WIRELESS PERSONAL COMMUNICATIONS,100,1,97-111,WOS:000429568800007,10.1007/s11277-018-5612-x,,#4094,Valter 2018,"",""
MODELING THE NEGOTIATION PARADIGM FOR THE BANKING INDUSTRY,"SADANANDA, R; ACHARYA, SK",Researchers in economics- and business-related industries have shown interest in negotiation paradigms involving interacting agents. Many researchers in artificial intelligence are looking at the possibility of modelling negotiation. It has been viewed as a traversal in a large search space of solutions with the objective of satisfying what appeared in the beginning antagonistic interests. In this paper we briefly review some of the relevant work in the area of negotiation. We discuss a model for the lending process of a banking industry and its implementation. We make some concluding remarks mostly based on this experience.,1993,,COMPUTERS IN INDUSTRY,22,3,263-272,WOS:A1993ME56200003,10.1016/0166-3615(93)90093-G,,#4095,SADANANDA 1993,"",""
The comprehensive unified paradigm for business model innovation,"Kim, IHS","Recognising that there is a growing trend of misfits between a firm's technology/routines and market customer needs due to the exponential technological change and linear-type needs evolution in the age of AI (artificial intelligence), this paper aims at developing a model/theory/paradigm that guarantees to attain the targeted outcome. It firstly draws the necessary conditions of BM/BMI from the natures of AI regime according to which literature review on BM/BMI is done and selects direct causal mechanisms of profit (DCMP) & business model schema (BMS) as the theoretical foundation, classifies all probable circumstances into several contingency settings in terms of environmental changes, technological change, needs evolution and bargaining power, specifies strategic indicators including normative business model (NBM) by contingency setting based on DCMP & BMS, builds the comprehensive unified paradigm (CUP) that introduces new strategising logic 'Seek NBM first & then Get-to-It' through new decision-making mode 'adaptising' with practical rationality, discusses about some vague/dubious notions in strategising, and concludes that CUP works as the general theory of BMI for it holds the universal and contingency rules for BMI simultaneously, asserting that when it comes to BM/BMI, there is nothing more robust, persuasive and practical than the general theory of BMI, CUP.",2023,,TECHNOLOGY ANALYSIS & STRATEGIC MANAGEMENT,35,11,1497-1518,WOS:000728703600001,10.1080/09537325.2021.2011190,,#4096,Kim 2023,"",""
Taking the Person Seriously: Ethically Aware IS Research in the Era of Reinforcement Learning-Based Personalization,"Greene, T; Shmueli, G; Ray, S","Advances in reinforcement learning and implicit data collection on large-scale commercial platforms mark the beginning of a new era of personalization aimed at the adaptive control of human user environments. We present five emergent features of this new paradigm of personalization that endanger persons and societies at scale and analyze their potential to reduce personal autonomy, destabilize social and political systems, and facilitate mass surveillance and social control, among other concerns. We argue that current data protection laws, most notably the European Union's General Data Protection Regulation, are limited in their ability to adequately address many of these issues. Nevertheless, we believe that IS researchers are well-situated to engage with and investigate this new era of personalization. We propose three distinct directions for ethically aware reinforcement learning-based personalization research uniquely suited to the strengths of IS researchers across the sociotechnical spectrum.",2023,,JOURNAL OF THE ASSOCIATION FOR INFORMATION SYSTEMS,24,6,1527-1561,WOS:001108677100001,10.17705/1jais.00800,,#4097,Greene 2023,"",""
Knowledge Complacency and Decision Support Systems,"Rodriguez, SS; Schaffer, JA; O'Donovan, J; Höllerer, T","Decision support systems (DSS), which are often based on complex statistical, machine learning, and AI models, have increasingly become a core part of data analytics and sensemaking processes. Automation complacency - a state characterized by over-trust in intelligent systems - has the potential to result in catastrophic performance failure. An under-investigated factor in automation complacency research is the effect that DSS might have on human learning of domain concepts. In this paper, we perform a comparative analysis of two studies of users interacting with decision aids to understand how knowledge retention is affected by the competence and presentation of a DSS. Our results indicate that while humans have the opportunity to learn and internalize domain concepts while being supported by a DSS, features that make the DSS appear more competent, persuasive, or customizable may lead a user to form incorrect beliefs about a domain.",2019,,2019 IEEE INTERNATIONAL CONFERENCE ON COGNITIVE AND COMPUTATIONAL ASPECTS OF SITUATION MANAGEMENT (COGSIMA),,,43-51,WOS:000475671400006,10.1109/cogsima.2019.8724175,,#4098,Rodriguez 2019,"",""
"Chatbot ads with a human touch: A test of anthropomorphism, interactivity, and narrativity","Sun, Y; Chen, J; Sundar, SS","Powered by artificial intelligence (AI), chatbots are increasingly capable of simulating human-like conversations. But, is this desirable for strategic communications? Will chatbots be more persuasive if they are more humanlike, not only in their appearance but also in their interaction and delivery of advertising content? We explored these questions with a 2 (chatbot profile: human-like vs. machine-like) x 2 (message interactivity: high vs. low) x 2 (ad type: narrative vs. factual) experiment (N = 414). Data reveal that high message interactivity fosters positive attitudes toward the chatbot and the ad by mitigating violated expectancy. Narrative ads promote chatbot advertising through perceived transportation. A three-way interaction revealed that when a chatbot is machine-like in appearance, higher interactivity and adoption of a narrative style of delivery serve to increase ad persuasiveness by heightening social presence. Theoretical and practical implications for chatbot advertising are discussed.",2024,,JOURNAL OF BUSINESS RESEARCH,172,,,WOS:001134571400001,10.1016/j.jbusres.2023.114403,,#4099,Sun 2024,"",""
The missing media The procedural rhetoric of computer games,"Seiffert, J; Nothhaft, H","The discussion about the implications of new or digital media focuses mainly on 'social' media. This reduction is a conceptual shortcoming. In order to fully understand how digital media impact on society and the communication landscape, our conceptualisation needs to include new entertainment media, especially computer games. Interactivity here might mean interaction with the AI (artificial-intelligence) or human players. or both, but the crucial difference lies in the fact that the interaction takes place in a 'world' created by the software. Despite the discussion about 'gamification' in marketing and a tradition of game studies in the humanities, there have been few attempts to treat computer games not only as trivial culture, but as a ""persuasive device"", as a way to shape public opinion. This article explores how the theory of procedural rhetoric, as outlined by Ian Bogost, enhances our understanding of this growing area. (C) 2014 Elsevier Inc. All rights reserved.",2015,,PUBLIC RELATIONS REVIEW,41,2,254-263,WOS:000354665400013,10.1016/j.pubrev.2014.11.011,,#4100,Seiffert 2015,"",""
"The connected workplace: Characteristics and social consequences of work surveillance in the age of datification, sensorization, and artificial intelligence","Mettler, T","Because of COVID-19 lockdowns, managers and administrators have begun to look for new ways to monitor and control their stranded-at-home workforce. Yet long before the pandemic already, advancements in datification, sensorization, and artificial intelligence have given rise to what we call connected workplace surveillance. At the heart of this new mode of employee monitoring and control is the extension of the scope of data collection beyond what is necessary and reasonable for performance appraisals or managerial oversight. This includes treating an employee's body as a data source, disrespecting the boundaries between business and private life, or using gathered surveillance information for subtle persuasion, manipulation, and coercion. This article provides a new perspective on control theory, examining the characteristics of connected surveillance and comparing it to visual or computerized surveillance. Taking an employee-centric position, it also proposes a research agenda for critical, behavioral, and design-oriented scholars who wish to explore the identified issues.",2024,,JOURNAL OF INFORMATION TECHNOLOGY,39,3,547-567,WOS:001070377700001,10.1177/02683962231202535,,#4101,Mettler 2024,"",""
Nature of Users' Persuasion and Exploration in Interactive Storytelling Video Games in the Netflix Games Library,"Dwivedi, U; Misra, M","As trailblazer in streaming entertainment, Netflix has redefined how people consume media, captivating audiences with its original programming. Despite this, the streaming giant could not translate similar success with its video game offering. This paper is an outcome of a unique experimental study which examines the built-in features of interactive storytelling games and their effect on induced persuasion and exploration among game players. This research involves eighty- eight players playing two popular games from the Netflix library. It tests the effects of artificial intelligence, feature interactivity, device responsiveness and personalization features of the game on induced persuasion and exploration among gamers. Using Bayesian regression and correlation, the results help to deduce that while built-in features can effectively persuade players, they fall short in encouraging deeper exploration within the game's narrative. It also illustrates the growing significance of artificial intelligence in human computer interaction. The study also highlights the critical role of storytelling for the gaming business and its significance in developing new visual culture.",2024,,INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION,,,,WOS:001370314800001,10.1080/10447318.2024.2430920,,#4102,Dwivedi 2024,"",""
"Ideological Manipulation on Social Media: Harassment, Deception and Violence in the Digital Environment","Fong, JCG; Cortese, FIG; Villanueva, OMM","This article explores the phenomenon of identity assumption on social media and the influence that artificial intelligence (bots) has so that external agents can take advantage of the vulnerable moments of various individuals. The subject is approached from the perspective offered by Jacques Lacan's and Rene Girard's studies, following the path of media ecology. The research is based on analyzing the phenomenon of manipulation on Twitter around the case of the migrant caravan of 2018 and the spread of hate speech.",2022,,PALABRA CLAVE,25,3,,WOS:000836436800002,10.5294/pacla.2022.25.3.9,,#4103,Fong 2022,"",""
A Study of Integrative Bargaining Model with Argumentation-Based Negotiation,"Park, J; Rahman, HA; Suh, J; Hussin, H","E-commerce is increasingly competitive and there is a constant need for new approaches and technology to facilitate exchange. Emerging techniques include the use of artificial intelligence (AI). One AI tool that has sparked interest in e-commerce is the automated negotiation agent (negotiation-agent). This study examines such agents, and proposes an offer strategy model of integrative negotiation for a negotiation-agent with a focus on negotiation agent-to-human interaction. More specifically, a new offer strategy was developed based on the integrative bargaining model, which emphasizes the importance of exchanging information among negotiators and multi-issue negotiation that includes package offers to achieve an integrative (win-win) outcome. This study incorporated an argumentation-based negotiation and the negotiation tactic of multiple equivalent simultaneous offers, which was programmed into the negotiation-agent. An experiment was conducted performing 49 negotiation-agent-to-human negotiations over three issues in online purchase tasks to demonstrate the effectiveness of the proposed strategy. Experimental results indicated that the proposed offer strategy with agent negotiation can enhance the persuasiveness of an offer and the performance of negotiation outcome (human counterpart's perception toward negotiation process, opponent-agent and desire for future negotiation). The findings confirmed the effectiveness of the proposed design and demonstrated an innovative approach to e-commerce transactions.",2019,,SUSTAINABILITY,11,23,,WOS:000508186400304,10.3390/su11236832,,#4104,Park 2019,"",""
Affective TV: Concepts of Affective Computing Applied to Digital Television,"Valentim, P; Muchaluat-Saade, D","The traditional broadcast TV viewing experience has barely evolved since its inception, remaining mostly static despite many technical advances. Smart TVs show attempts of filling this gap, but present challenges, such as limiting functionalities to specific models and lack of standardization. Privacy concerns arise as smart TVs connect to advertising and monitoring services. In the spectrum of interactivity, an option that stands out is affective computing, an interdisciplinary field that seeks to develop systems capable of recognizing, expressing and responding to human emotions. This work proposes the incorporation of affective computing techniques and concepts to improve the experience and interactivity with digital TV, naming it ""Affective TV"". The work presents a modular architecture, recognition modules developed for multiple modes of interaction and a fully operational implementation of the architecture, developed for the standard digital TV middleware in Brazil, Ginga. Affective TV uses audio and video capturing devices and allows users to set up their environments. Recognition modules capture and classify data, communicating directly to the TV middleware. Proof-of-concept applications, incorporating voice and hand pose interactions with facial expression recognition, were evaluated using the GQM. UEQ-S and TAM questionnaires were employed. Very positive results were obtained, including an excellent UEQ rating, showcasing technical feasibility, attractiveness, user experience, perceived usefulness, and ease of use. The proposal enriches the digital TV experience, providing a novel, interactive model with user-centric customization and emotion-driven responses.",2024,,"DESIGN, USER EXPERIENCE, AND USABILITY, DUXU 2024, PT V",14716,,203-220,WOS:001275716600016,10.1007/978-3-031-61362-3_16,,#4105,Valentim 2024,"",""
KInITVeraAI at SemEval-2023 Task 3: Simple yet Powerful Multilingual Fine-Tuning for Persuasion Techniques Detection,"Hromadka, T; Smolen, T; Remis, T; Pecher, B; Srba, I","This paper presents the best-performing solution to the SemEval 2023 Task 3 on the subtask 3 dedicated to persuasion techniques detection. Due to a high multilingual character of the input data and a large number of 23 predicted labels (causing a lack of labelled data for some language-label combinations), we opted for fine-tuning pre-trained transformer-based language models. Conducting multiple experiments, we find the best configuration, which consists of large multilingual model (XLM-RoBERTa large) trained jointly on all input data, with carefully calibrated confidence thresholds for seen and surprise languages separately. Our final system performed the best on 6 out of 9 languages (including two surprise languages) and achieved highly competitive results on the remaining three languages.",2023,,"17TH INTERNATIONAL WORKSHOP ON SEMANTIC EVALUATION, SEMEVAL-2023",,,629-637,WOS:001281001900085,,,#4106,Hromadka 2023,"",""
Knowledge of automated journalism moderates evaluations of algorithmically generated news,"Jang, W; Kwak, DH; Bucy, E","Drawing on propositions from the HAII-TIME (Human-artificial intelligence [AI] Interaction and the Theory of Interactive Media Effects) and Persuasion Knowledge Model, this study examines how knowledge of automated journalism (AJ) moderates the evaluation of algorithmically generated news. Experiment 1 demonstrates the utility of process-related knowledge in user evaluations of agency: individuals with little knowledge of AJ prefer attributions of human authorship over news stories attributed to algorithms, whereas individuals with high AJ knowledge have an equal or stronger preference for news that is described as algorithmically generated. Experiment 2 conditions these effects to show how prior characterizations of AJ-whether more machine- or human-like-shape evaluations of algorithmically generated news contingent on user age and knowledge level. Effects are found for differing age groups at lower levels of AJ knowledge, where machine-like characterizations enhance evaluations of algorithmically generated news for younger users but ascribing human-like traits enhances evaluations of automated news for older users.",2024,,NEW MEDIA & SOCIETY,26,10,5898-5922,WOS:000903104500001,10.1177/14614448221142534,,#4107,Jang 2024,"",""
To Tell or Not to Tell: Investigating the Persuasive Appeal of Information Transparency for AR-Powered E-Commerce Sites,"Sun, Y; Freeman, J; Shoenberger, H; Shen, FY","In e-commerce, Augmented Reality (AR) employs computer vision and artificial intelligence (AI) techniques to enhance the shopping experience through personalized recommendations based on users' physical data. However, concerns regarding privacy and perceived intrusiveness can undermine the persuasive appeal of personalized AR for e-commerce experiences. Can overtly communicating information transparency mitigate such concerns? Two between-subjects online experiments were conducted, revealing that consumers were drawn to the AR-powered e-commerce site due to its heightened perceived immersion and usefulness but also considered it more intrusive than the non-AR site. However, when both websites were AR-powered, the one with high information transparency significantly enhanced perceived privacy protection, reducing perceived intrusiveness. Perceived transparency positively mediated the effects, particularly among individuals with lower pre-existing trust in algorithms. These findings have implications for theory pertaining to the use of AR in strategic communications and the design of information transparency for AR-powered e-commerce.",2025,,INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION,,,,WOS:001484017900001,10.1080/10447318.2025.2495847,,#4108,Sun 2025,"",""
The Captology of Intelligent Systems,"Balaz, Z; Predavec, D","Captology is an acronym, derived from Computer As Persuasive TechnOLOGY, where the instance persuasive, (lat. persuasibilibus - enticing), refers to the convincing persuasion caused by computer technology. Transitive and interactive technologies as intelligent systems, have imposed, by their persuasivity, ""the cult of information"", after which the information became type of goods that as utilitarian resource need to be quickly and efficiently exploited. Such widely accepted fact resulted as hype, presenting perspective that approach to large amount of information and faster ""digestion"" of their content and sense will enable users to quickly get desired knowledge. Intelligent systems are ubiquitous in almost all segments of society and life, although there are no relevant researches to confirm the claims of all their acceptability. The paper presents the results of research and testing processes of computer persuasion to show that its success is primarily dependent on its factors. The design for ""cloud work"", interactive computer programs, web, desktop and other factors directly affect the user, and its attitudes, beliefs, learning and behavior. That impact can be positive or negative.",2017,,"2017 40TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO)",,,1211-1216,WOS:000426903800212,,,#4109,Balaz 2017,"",""
Goal Setting for Persuasive Information Systems: Five Reference Checklists,"Cham, S; Algashami, A; McAlaney, J; Stefanidis, A; Phalp, K; Ali, R","The concept of goals is prominent in information systems and also artificial intelligence literature such as goal-oriented requirements engineering and self-adaptive systems. Digital motivation systems, e.g. gamification and persuasive technology, utilise the concept of behavioural goals which require a different mind-set on how to elicit and set them up, how to monitor deviation from such goals and how to ensure their completion. Behavioural goals are characterised by a range of factors which are not the main focus in classic information systems and AI literature such as self-efficacy, perceived usefulness. To engineer software supporting goal setting, a concretised taxonomy of goals would help a better-managed analysis and design process. In this paper, we provide a detailed classification of behavioural goals and their associated properties and elements (types, sources, monitoring, feedback, deviation and countermeasures). As a method, we review the literature on goal setting theory and its application in different disciplines. We subsequently develop five reference checklists which would act as a reference point for researchers and practitioners in persuasive and motivational systems.",2019,,"PERSUASIVE TECHNOLOGY: DEVELOPMENT OF PERSUASIVE AND BEHAVIOR CHANGE SUPPORT SYSTEMS, PERSUASIVE 2019",11433,,237-253,WOS:000791098300020,10.1007/978-3-030-17287-9_20,,#4110,Cham 2019,"",""
Types of Dialogue and Burdens of Proof,"Walton, D","Burden of proof has recently come to be a topic of interest in argumentation systems for artificial intelligence (Prakken and Sartor, 2006, 2007, 2009; Gordon and Walton, 2007, 2009), but so far the main work on the subject seems to be in that type of dialogue which has most intensively been investigated generally, namely persuasion dialogue. The most significant exception is probably deliberation dialogue, where some recent work has begun to tentatively investigate burden of proof in that setting. In this paper, I survey work on burden of proof in the artificial intelligence literature on argumentation, and offer some thoughts on how this work might be extended to the other types of dialogue recognized by Walton and Krabbe (1995) that so far do not appear to have been much investigated in this regard.",2010,,COMPUTATIONAL MODELS OF ARGUMENT: PROCEEDINGS OF COMMA 2010,216,,13-24,WOS:000294113000002,10.3233/978-1-60750-619-5-13,,#4111,Walton 2010,"",""
A large language model-based platform for real-time building monitoring and occupant interaction,"Xu, YF; Zhu, SY; Cai, JN; Chen, JL; Li, S","Effective management of indoor environments requires a comprehensive evaluation of health, energy consumption, and thermal comfort. However, real-time assessment of these factors is challenging due to the lack of integrated applications that combine IoT technology, real-time simulation, and user-friendly interfaces for communication. To address these challenges, this research introduces a novel platform specifically designed to manage health, energy consumption, and thermal comfort in smart buildings, leveraging IoT-based building information modeling (BIM), cloud computing, and an AI-powered conversational suggestion system based on the large language model (GPT). The platform integrates real-time monitoring, simulation, alerting, and persuasion capabilities to manage health, energy consumption, and thermal comfort, enabling responsive building environment controls by assessing tradeoffs among these dimensions and providing timely recommendations. Additionally, it employs persuasive techniques to encourage occupants to adopt environmentally-friendly practices. A case study in a university building demonstrated the platform's functionality and visualization capability. A survey assessing the persuasive system revealed high adoption rates-95.59 % for switching rooms to improve indoor air quality and health, and 79.90 % for adjusting clothing to enhance thermal comfort-indicating strong participant willingness to adopt sustainable practices through the platform's strategies. The key contribution of this research is the development of a comprehensive, real-time platform that enhances indoor environmental quality and sustainability through advanced monitoring, analysis, and social interaction.",2025,,JOURNAL OF BUILDING ENGINEERING,100,,,WOS:001403266100001,10.1016/j.jobe.2024.111488,,#4112,Xu 2025,"",""
Recent advances in computational models of natural argument,"Reed, C; Grasso, F","This article reviews recent advances in the interdisciplinary area lying between artificial intelligence and the theory of argumentation. The article has two distinct foci: first, examining the ways in which argumentation has inspired new models of logical and computational intelligence, and second, exploring how At techniques have been used and extended to model and handle real world argument in a wide variety of domains including law, education, medicine, and e-commerce. (c) 2007 Wiley Periodicals, Inc.",2007,,INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS,22,1,1-15,WOS:000242839900001,10.1002/int.20187,,#4113,Reed 2007,"",""
"Design, development, and evaluation of an mHealth app to reduce stress and promote happiness through smiling","Orji, J; Chan, G; Orji, R","The field of mental health application research is growing, yet comprehensive, long-term studies validating claims of stress reduction and mood enhancement are limited, with many apps lacking empirical evidence. The purpose of this study was to evaluate an mHealth application called SmileApp to promote positive mood as a means of reducing stress. The design of SmileApp is grounded in psychological theories and integrates artificial intelligence (AI) and persuasive technology (PT). To evaluate SmileApp, we conducted a two-week in-the-wild study involving 72 participants. This was followed by an optional semi-structured interview with 23 participants. Quantitative results suggest that SmileApp is usable, useful, and encourages users to smile more frequently. Furthermore, qualitative results suggest that SmileApp was a unique design to help users alleviate stress. These results offer valuable insights into innovative approaches for designing mHealth applications that promote positive mood. Moreover, the findings underscore the importance of utilising technology to support emotional well-being. We present a novel approach to promote desired behaviours by motivating users to read supportive messages and playing mobile games through the act of smiling.",2025,,BEHAVIOUR & INFORMATION TECHNOLOGY,,,,WOS:001479168700001,10.1080/0144929X.2025.2494278,,#4114,Orji 2025,"",""
Living With Digital Government: Effects of Technology Anxiety on Public Support for Policy in China,"Xiao, H; He, YL; Ge, W","Living with digital government is less of a technical issue but more of a political process. In political science, one new issue in need of greater theorizing and investigating is public anxiety about the use of big data and artificial intelligence (AI) by digital government which has become an emerging challenge for the country to obtain public support. Employing an online survey in China, we test whether technology anxiety influences public support for policy and examine the mechanisms within them, namely, political persuasion, interaction orientation, and people's happiness. Survey evidence reveals that technology anxiety exerts a significantly negative effect on public support, especially in flexible employment and service industry. Additionally, technology anxiety indirectly influences public support for policy through the three abovementioned mechanisms, with political persuasion based on algorithm demonstrating the most pronounced mediating role. The findings contribute to understanding the relationship between public anxiety and political support in Chinese context and beyond, and enrich the studies of political psychology and legitimacy.",2024,,JOURNAL OF CHINESE POLITICAL SCIENCE,,,,WOS:001327615300001,10.1007/s11366-024-09898-y,,#4115,Xiao 2024,"",""
PERSUASIVE LEGAL WRITING USING LARGE LANGUAGE MODELS,"Curran, D; Levy, I; Mistica, M; Hovy, E",,2024,,LEGAL EDUCATION REVIEW,34,1,,WOS:001409517100001,,,#4116,Curran 2024,"",""
A Behavioral Economics Approach to Digitalisation - The Case of a Principles-based Taxonomy,"Beerbaum, D; Puaschunder, JM","A growing body of academic research in the field of behavioural economics, political science and psychology demonstrate how an invisible hand can nudge people's decisions towards a preferred option. Contrary to the assumptions of the neoclassical economics, supporters of nudging argue that people have problems coping with a complex world, because of their limited knowledge and their restricted rationality. Technological improvement in the age of information has increased the possibilities to control the innocent social media users or penalise private investors and reap the benefits of their existence in hidden persuasion and discrimination. Nudging enables nudgers to plunder the simple uneducated and uninformed citizen and investor, who is neither aware of the nudging strategies nor able to oversee the tactics used by the nudgers (Puaschunder 2017a, b; 2018a, b). The nudgers are thereby legally protected by democratically assigned positions they hold. The law of motion of the nudging societies holds an unequal concentration of power of those who have access to compiled data and coding rules, relevant for political power and influencing the investor's decision usefulness (Puaschunder 2017a, b; 2018a, b). This paper takes as a case the ""transparency technology XBRL (eXtensible Business Reporting Language)"" (Sunstein 2013, 20), which should make data more accessible as well as usable for private investors. It is part of the choice architecture on regulation by governments (Sunstein 2013). However, XBRL is bounded to a taxonomy (Piechocki and Felden 2007). Considering theoretical literature and field research, a representation issue (Beerbaum, Piechocki and Weber 2017) for principles-based accounting taxonomies exists, which intelligent machines applying Artificial Intelligence (AI) (Mwilu, Prat and Comyn-Wattiau 2015) nudge to facilitate decision usefulness. This paper conceptualizes ethical questions arising from the taxonomy engineering based on machine learning systems: Should the objective of the coding rule be to support or to influence human decision making or rational artificiality? This paper therefore advocates for a democratisation of information, education and transparency about nudges and coding rules (Puaschunder 2017a, b; 2018a, b).",2018,,PROCEEDINGS OF THE 10TH INTERNATIONAL RAIS CONFERENCE ON SOCIAL SCIENCES AND HUMANITIES (RAIS 2018),211,,45-53,WOS:000468215200008,,,#4117,Beerbaum 2018,"",""
"A systematic review of artificial intelligence chatbots for promoting physical activity, healthy diet, and weight loss","Oh, YJ; Zhang, JW; Fang, ML; Fukuoka, Y","Background: This systematic review aimed to evaluate Al chatbot characteristics, functions, and core conversational capacities and investigate whether Al chatbot interventions were effective in changing physical activity, healthy eating, weight management behaviors, and other related health outcomes.Methods: In collaboration with a medical librarian, six electronic bibliographic databases (PubMed, EMBASE, ACM Digital Library, Web of Science, PsycINFO, and IEEE) were searched to identify relevant studies. Only randomized controlled trials or quasi-experimental studies were included. Studies were screened by two independent reviewers, and any discrepancy was resolved by a third reviewer. The National Institutes of Health quality assessment tools were used to assess risk of bias in individual studies. We applied the Al Chatbot Behavior Change Model to characterize components of chatbot interventions, including chatbot characteristics, persuasive and relational capacity, and evaluation of outcomes.Results: The database search retrieved 1692 citations, and 9 studies met the inclusion criteria. Of the 9 studies, 4 were randomized controlled trials and 5 were quasi-experimental studies. Five out of the seven studies suggest chatbot interventions are promising strategies in increasing physical activity. In contrast, the number of studies focusing on changing diet and weight status was limited. Outcome assessments, however, were reported inconsistently across the studies. Eighty-nine and thirty-three percent of the studies specified a name and gender (i.e., woman) of the chatbot, respectively. Over half (56%) of the studies used a constrained chatbot (i.e., rule-based), while the remaining studies used unconstrained chatbots that resemble human-to-human communication.Conclusion: Chatbots may improve physical activity, but we were not able to make definitive conclusions regarding the efficacy of chatbot interventions on physical activity, diet, and weight management/loss. Application of AI chatbots is an emerging field of research in lifestyle modification programs and is expected to grow exponentially. Thus, standardization of designing and reporting chatbot interventions is warranted in the near future.",2021,,INTERNATIONAL JOURNAL OF BEHAVIORAL NUTRITION AND PHYSICAL ACTIVITY,18,1,,WOS:000729221300001,10.1186/s12966-021-01224-6,,#4118,Oh 2021,"",""
Which AI doctor would you like to see? Emulating healthcare provider-patient communication models with GPT-4: proof-of-concept and ethical exploration,"Zohny, H; Allen, JW; Wilkinson, D; Savulescu, J","Large language models (LLMs) have demonstrated potential in enhancing various aspects of healthcare, including health provider-patient communication. However, some have raised the concern that such communication may adopt implicit communication norms that deviate from what patients want or need from talking with their healthcare provider. This paper explores the possibility of using LLMs to enable patients to choose their preferred communication style when discussing their medical cases. By providing a proof-of-concept demonstration using ChatGPT-4, we suggest LLMs can emulate different healthcare provider-patient communication approaches (building on Emanuel and Emanuel's four models: paternalistic, informative, interpretive and deliberative). This allows patients to engage in a communication style that aligns with their individual needs and preferences. We also highlight potential risks associated with using LLMs in healthcare communication, such as reinforcing patients' biases and the persuasive capabilities of LLMs that may lead to unintended manipulation.",2025,,JOURNAL OF MEDICAL ETHICS,,,,WOS:001437153100001,10.1136/jme-2024-110256,,#4119,Zohny 2025,"",""
Alternating Recurrent Dialog Model with Large-scale Pre-trained Language Models,"Assoc Computat Linguist; Wu, QY; Zhang, YC; Li, Y; Yu, Z","Existing dialog system models require extensive human annotations and are difficult to generalize to different tasks. The recent success of large pre-trained language models has suggested the effectiveness of incorporating language priors in down-stream NLP tasks. However, how much pre-trained language models can help dialog response generation is still under exploration. In this paper, we propose a simple, general, and effective framework: Alternating Recurrent Dialog Model (ARDM)(1). ARDM models each speaker separately and takes advantage of large pre-trained language models. It requires no supervision from human annotations such as belief states or dialog acts to achieve effective conversations. ARDM outperforms or is on par with the state-of-the-art methods on two popular task-oriented dialog datasets: CamRest676 and MultiWOZ. Moreover, we can generalize ARDM to more challenging, non-collaborative tasks such as persuasion. In the PersuasionForGood task, ARDM is capable of generating human-like responses to persuade people to donate to a charity.",2021,,16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021),,,1292-1301,WOS:000863557001032,,,#4120,AssocComputatLinguist 2021,"",""
What Drives Consumers' Decisions to Use Intelligent Agent Technologies? A Systematic Review,"Sidlauskiene, J","As artificial intelligence continues to advance, it will increasingly empower the successful use of intelligent agent (IA) technologies in marketing practices. The purpose of this paper is to summarize the state-of-the-art literature and present a holistic view of different types of antecedents of IA technology use in marketing from the consumer's perspective. This paper uses the systematic literature review method and covers 107 articles published in scientific journals between 2000 and 2020. The identified antecedents are categorized into IA characteristics, consumer perceptions, external conditions, as well as individual characteristics and analyzed at the individual level of use. Future research should focus on investigating the relative importance of the effects of IA characteristics, consumer perceptions, external, and individual factors on consumers' intentions to use IAs. This paper argues that while extant technology acceptance models contribute to the understanding of IA use, IAs, due to their unique characteristics (e.g., anthropomorphism) and dimensions (e.g., IA as an interface, as a proxy for the system and an autonomous aggregator and agent), require a new lens to explain the drivers of IA use in data-rich and process-rich environments. The traditional technology acceptance theories provide a valuable, yet incomplete understanding of how consumers use IAs. Drawing from representation theory, this paper proposes a theoretical framework of IA use and argues that IAs act as representations to facilitate the primary goal.",2022,,JOURNAL OF INTERNET COMMERCE,21,4,438-475,WOS:000686807800001,10.1080/15332861.2021.1961192,,#4121,Sidlauskiene 2022,"",""
Multi-Agent Reasoning with Large Language Models for Effective Corporate Planning,"IEEE COMPUTER SOC; Tsao, WK","Large Language Models (LLMs) have demonstrated significant capabilities in natural language processing tasks. In this paper, we explore the application of LLMs within a business context. Specifically, we employ LLMs to devise a sales strategy geared towards maximizing customer values (benefits and satisfaction). This sales plan encompasses five iterative stages: market landscape survey, customer profiling, product usage analysis, sales strategy formulation, and crafting persuasive pitches and materials. We leverage LLMs to supplement the limited data available to the company, aiming to enhance the efficacy of each stage and optimize KPIs, including the value-oriented sales conversion and profitability. Due to confidentiality and trade secret concerns, we blend artificial data with genuine data to ensure customer anonymity and protect sales playbooks. Despite these precautions, we effectively demonstrate our methodology of harnessing LLMs to refine the sales planning procedure.",2023,,"2023 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE, CSCI 2023",,,365-370,WOS:001283930300205,10.1109/CSCI62032.2023.00065,,#4122,IEEECOMPUTERSOC 2023,"",""
"PREDICTION, PERSUASION, AND THE JURISPRUDENCE OF BEHAVIOURISM","Pasquale, F; Cashwell, G","There is a growing literature critiquing the unreflective application of big data, predictive analytics, artificial intelligence, and machine-learning techniques to social problems. Such methods may reflect biases rather than reasoned decision making. They also may leave those affected by automated sorting and categorizing unable to understand the basis of the decisions affecting them. Despite these problems, machine-learning experts are feeding judicial opinions to algorithms to predict how future cases will be decided. We call the use of such predictive analytics in judicial contexts a jurisprudence of behaviourism as it rests on a fundamentally Skinnerian model of cognition as a black-boxed transformation of inputs into outputs. In this model, persuasion is passe; what matters is prediction. After describing and critiquing a recent study that has advanced this jurisprudence of behaviourism, we question the value of such research. Widespread deployment of prediction models not based on the meaning of important precedents and facts may endanger the core rule-of-law values.",2018,,UNIVERSITY OF TORONTO LAW JOURNAL,68,,63-81,WOS:000427068000004,10.3138/utlj.2017-0056,,#4123,Pasquale 2018,"",""
Connective life. Digital networks as sociotechnical mirrors of Ibero-America,"Costa, PR; Capoano, E; Ibáñez, DB","Connective life has accelerated since 2020, when the covid-19 pandemic began, which contributed to intensify some digitization processes that have been underway for decades. This connective life also presents new challenges, such as surveillance capitalism, the attention economy, and contingent intellects, formed by powerful persuasive algorithms. In this context, the 147th edition of Chasqui is proposed as an Ibero-American transnational digital culture observatory. To do this, we have selected 10 articles that reveal significant networks, and in which user behaviors are studied; Ibero-American habits, uses and customs are mapped on social networks; Forms of organization in the consumption, production and circulation of content are described; techniques and content used to manipulate information and opinion are analyzed; describe and identify themselves in ways of spreading false news and hate speech; and new theoretical proposals are presented to understand Latin America through the analysis and reading of fields such as big data, machine learning, Artificial Intelligence, algorithms, or data analysis and visualization systems.",2021,,CHASQUI-REVISTA LATINOAMERICANA DE COMUNICACION,,147,33-45,WOS:000688499800003,,,#4124,Costa 2021,"",""
Analysis of the implications of the Moral Machine project as an implementation of the concept of coherent extrapolated volition for building clustered trust in autonomous machines,"Soloducha, K","In this paper, we focus on the analysis of Eliezer Yudkowsky's concept of ""coherent extrapolated volition"" (CEV) as a response to the need for a post-conventional, persuasive morality that meets the criteria of active trust in the sense of Anthony Giddens, which could be used in the case of autonomous machines. Based on the analysis of the results of the Moral Machine project, we formulate some guidelines for transformation of the idea of a coherent extrapolated volition into the concept of a coherent, extrapolated and clustered volition. The argumentation used in the paper is intended to show that the idea of CEV transformed into its clustered version can be used to build a technically and socially efficient decision-making pattern database for autonomous machines.",2022,,ZAGADNIENIA FILOZOFICZNE W NAUCE-PHILOSOPHICAL PROBLEMS IN SCIENCE,,73,231-255,WOS:001222156600011,,,#4125,Soloducha 2022,"",""
ICT-Based Learning Solutions for Children with ASD: A Requirement Engineering Study,"Hasan, N; Nene, MJ","This research explores the explicit requirements to design and develop ICT-based learning solutions for children with Autism Spectrum Disorder (ASD). A requirement elicitation study has been conducted for six weeks of the study's in Pune, India. The study sample size is fifteen (N=15), with an age limit be-tween five to twelve years old. All the participants have been diagnosed with ASD and undergoing a skills development process in the same institution for at least six months. The outcomes of this research are tri-fold. Firstly, identify the twelve explicit requirements to design and develop ICT-based learning solutions considering the challenges due to autism. Secondly, conformity to the existing Multi Agent based Persuasive Education (MAPE) model with revealed requirements. Thirdly, propose an Internet of Things (IoT) based framework to observe and record the learning performance of ASD-affected children. The unique contribution of this study is to develop a Level-5 IoT framework to incorporate the requirements revealed through the participa-tory design approach for implementing ICT-based learning solutions. The proposed framework forms the basis for developing a dataset to identify the learning patterns and new requirements for ASD-affected children through Artificial Intelligence (AI) and Machine Learning (ML).",2022,,INTERNATIONAL JOURNAL OF SPECIAL EDUCATION,37,1,112-126,WOS:000882719700010,10.52291/ijse.2022.37.31,,#4126,Hasan 2022,"",""
An agent-based emotional persuasion model driven by integrated trust assessment,"Wu, JH; Zhang, Y; Cao, RY; Li, Y","Recent research on automated negotiation has primarily focused on improving the artificial intelligence of agents and equipping them with more flexible internal mechanisms to facilitate high-quality negotiations. However, the study on the systematic modeling of human-like psychological and behavioral activities and their role in the negotiation process is still in its early stages. In light of this, this paper proposes an emotional persuasion model that takes into account the effect of negotiators' integrated trust assessments on negotiation. Firstly, the paper presents a negotiation agent with both cognitive and emotional functions, detailing its internal system and operating mechanism. Secondly, the integrated trust of a negotiator is obtained by evaluating multiple single trusts, and the mapping of the integrated trust to the negotiation round parameter is modeled. Integrated trust is also parameterized into the agent's cognitive processes. Finally, the paper introduces a new framework for the generation of emotional persuasive behavior to assist agents in making new proposals. A series of experiments were conducted, yielding the following results: Compared with the non-emotional model, the performance of negotiation rounds and utility differences improved by 7.97 % and 4.81 %, respectively. Furthermore, the trust- driven emotional persuasion model outperformed the several existing competing models by at least 31.1 % in utility difference and 81.0 % in negotiation rounds. Additionally, a case study of human-computer negotiation demonstrated that the agent designed using the proposed method has negotiating capabilities comparable to those of a real human, which further showcases the application effect of the artificial intelligence agent in practice.",2025,,ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE,149,,,WOS:001453787900001,10.1016/j.engappai.2025.110567,,#4127,Wu 2025,"",""
Principles and Validations of an Artificial Intelligence-Based Recommender System Suggesting Acceptable Food Changes,"Vandeputte, J; Herold, P; Kuslii, M; Viappiani, P; Muller, L; Martin, C; Davidenko, O; Delaere, F; Manfredotti, C; Cornuéjols, A; Darcel, N","Background: Along with the popularity of smartphones, artificial intelligence-based personalized suggestions can be seen as promising ways to change eating habits toward more desirable diets. Objectives: Two issues raised by such technologies were addressed in this study. The first hypothesis tested is a recommender system based on automatically learning simple association rules between dishes of the same meal that would make it possible to identify plausible substitutions for the consumer. The second hypothesis tested is that for an identical set of dietary-swaps suggestions, the more the user is-or thinks to be-involved in the process of identifying the suggestion, the higher is their probability of accepting the suggestion.Methods: Three studies are presented in this article, first, we present the principles of an algorithm to mine plausible substitutions from a large food consumption database. Second, we evaluate the plausibility of these automatically mined suggestions through the results of online tests conducted for a group of 255 adult participants. Afterward, we investigated the persuasiveness of 3 suggestion methods of such recommendations in a population of 27 healthy adult volunteers through a custom designed smartphone application.Results: The results firstly indicated that a method based on automatic learning of substitution rules between foods performed relatively well identifying plausible swaps suggestions. Regarding the form that should be used to suggest, we found that when users are involved in selecting the most appropriate recommendation for them, the resulting suggestions were more accepted (OR 1/4 3.168; P < 0.0004).Conclusions: This work indicates that food recommendation algorithms can gain efficiency by taking into account the consumption context and user engagement in the recommendation process. Further research is warranted to identify nutritionally relevant suggestions.",2023,,JOURNAL OF NUTRITION,153,2,598-604,WOS:000951603400001,10.1016/j.tjnut.2022.12.022,,#4128,Vandeputte 2023,"",""
Learning analytics for lifelong career development: a framework to support sustainable formative assessment and self-reflection in programs developing career self-efficacy,"Brass, T; Kennedy, J; Gabriel, F; Neill, B; Devis, D; Leonard, SN","Among myriad complex challenges facing educational institutions in this era of a rapidly evolving job marketplace is the development of career self-efficacy among students. Self-efficacy has traditionally been understood to be developed through the direct experience of competence, the vicarious experience of competence, social persuasion, and physiological cues. These four factors, and particularly the first two, are difficult to build into education and training programs in a context where changing skills make the specific meaning of graduate competence largely unknown and, notwithstanding the other contributions in this collection, largely unknowable. In response, in this paper we argue for a working metacognitive model of career self-efficacy that will prepare students with the skills needed to evaluate their skills, attitudes and values and then adapt and develop them as their career context evolves around them. The model we will present is one of evolving complex sub-systems within an emergent milieu. In identifying various contributing factors, the model provides specific cognitive and affective constructs as important targets for actionable learning analytics for career development.",2023,,FRONTIERS IN ARTIFICIAL INTELLIGENCE,6,,,WOS:001002977600001,10.3389/frai.2023.1173099,,#4129,Brass 2023,"",""
Changes in attitudes toward meat consumption after chatting with a large language model,"Karakas, N; Jaeger, B","Researchers have started to explore the persuasive power of large language models (LLMs) and initial results suggest that LLMs can be as persuasive as humans, even for controversial and moralized topics. We conducted a preregistered proof-of-concept study to test how a brief conversation with ChatGPT-4o influences attitudes and beliefs about meat consumption. We found that participants (n = 101) reported weaker commitment to eating meat and weaker beliefs that eating meat is necessary and natural, but not weaker beliefs that eating meat is normal or nice, after their conversation (vs. before). Our study provides preliminary evidence and can act as a blueprint for future explorations of how conversations with LLMs can change attitudes on meat consumption and related topics.",2025,,SOCIAL INFLUENCE,20,1,,WOS:001441680400001,10.1080/15534510.2025.2475802,,#4130,Karakas 2025,"",""
"SOFT LAW, HARD JUSTICE: REGULATING ARTIFICIAL INTELLIGENCE IN ARBITRATION","Reddy, JS; Singh, V","Artificial Intelligence (hereinafter ""A.I."") is predicated on the notion that a computer programme can mimic all aspects of intellect and learning if they were meticulously documented. A.I. is increasingly being used in international arbitration by various stakeholders, including experts, litigants, tribunals and arbitrators at different stages. However, while A.I. has become increasingly prevalent in arbitration, there is still a regulatory vacuum that needs be bridged. The increasing use of A.I. in arbitration to improve procedural efficiency and decision-making raises serious concerns about the lack of a strong regulatory framework. The use of unregulated A.I. raises multiple technological challenges, which have resulted in some courts mandating the disclosure of A.I. use. These concerns are exacerbated by A.I.s' limited capacity to comprehend cultural nuances. Additionally, legal and ethical considerations arise, such as the permissible extent of A.I. usage in the arbitral process by various players, the duty to verify A.I.-generated work, the question of liability brought upon due to risks of algorithmic bias, or the leak of confidential information. Research indicates a rise in calls for greater transparency in the use of A.I. in arbitration, and the need for regulation. While previous attempts to regulate A.I. certainly provide a starting point for the regulation of A.I. in the arbitral process, they are neither universally recognized, nor implemented across jurisdictions. In this backdrop, there is a need for an international legal instrument that either regulates, or encourages the regulation of A.I. in arbitration. The authors in this paper argue for the regulation of A.I. in arbitration using an internationally-recognised soft-law framework. The flexibility and adaptability provided by soft law frameworks would complement the ""international"" and voluntary nature of arbitration. The proposed soft law framework could materialize in three ways: first, regulators could develop an international legal instrument based on which States can develop their own laws (much like the United Nations Commission on International Trade Law Model Law); second, A.I.-related arbitrations could follow the soft law guidelines as best practices, with the guidelines having persuasive value similar to the International Bar Association (IBA) Rules; or third, soft law could encourage arbitration institutions to incorporate relevant clauses on A.I. use in their procedural rules. The authors also explore the considerations which such a soft law ought to address. The need for such a framework is not to draw boundaries, or control the innovative path of A.I., rather, it is to put in place ethical barriers and dynamic safeguards for identifiable risks, and to work in tandem with the requisite human oversight throughout the life cycles of A.I. processes. This would be a balanced approach which addresses issues of law, ethics, and technology on one hand, while encouraging creativity and flexibility in the field of arbitration on the other.",2024,,CONTEMPORARY ASIA ARBITRATION JOURNAL,17,2,191-236,WOS:001390383600002,,,#4131,Reddy 2024,"",""
ChatGPT as imperfect rhetorical tool in public policy,"Becker, M",,2024,,AI & SOCIETY,,,,WOS:001379328700001,10.1007/s00146-024-02159-9,,#4132,Becker 2024,"",""
Using AI predicted personality to enhance advertising effectiveness,"Shumanov, M; Cooper, H; Ewing, M","PurposeThe purpose of this study is twofold: first to demonstrate the application of an algorithm using contextual data to ascertain consumer personality traits; and second to explore the factors impacting the relationship between personality traits and advertisement persuasiveness.Design/methodology/approachA mixed-method approach that comprises two distinct yet complementary studies. The first uses quantitative methods and is based on a sample of 35,264 retail banking customers. Study 2 explores the findings that emerge from Study 1 using qualitative methods.FindingsThis paper finds that matching consumer personality with congruent advertising messages can lead to more effective consumer persuasion for most personality types. For consumers who exhibit neurotic personality traits, ameliorating perceived risks during purchasing and providing cues for social acceptance and goal attainment are important factors for advertising effectiveness. These factors also had a positive impact on the purchasing behaviour of extroverted consumers.Research limitations/implicationsThis research focusses on understanding purchasing behaviour based on the most dominant personality trait. However, people are likely to exhibit a combination of most or even all of the Big Five personality traits.Practical implicationsBuilding on advances in natural language processing, enabling the identification of personality from language, this study demonstrates the possibility of influencing consumer behaviour by matching machine inferred personality to congruent persuasive advertising. It is one of the few studies to use contextual instead of social media data to capture individual personality. Such data serves to capture an authentic rather than contrived persona. Further, the study identifies the factors that may moderate this relationship and thereby provides an explanation of why some personality traits exhibit differences in purchasing behaviour from those that are anticipated by existing theory.Originality/valueAlthough the idea that people are more likely to be responsive to advertising messages that are congruent with their personality type has already been successfully applied by advertising practitioners and documented by advertising scholars, this study extends existing research by identifying the factors that may moderate this relationship and thereby provides an explanation why some personality traits may exhibit differences in purchasing behaviour from those that are anticipated by existing theory.",2022,,EUROPEAN JOURNAL OF MARKETING,56,6,1590-1609,WOS:000637811700001,10.1108/EJM-12-2019-0941,,#4133,Shumanov 2022,"",""
Ethical Challenges and Risks Caused by the Intelligence Revolution,"Cheng, SM","The consciousness of sharing fostered by the digitizing transformation and development in society has overturned the economic ethical assumptions built upon the consciousness of ownership. The widespread utilization of intelligent machines and artificial agents has presented challenges to labor ethics. Furthermore, the subtle persuasion and manipulation of humans by technologies, such as algorithms, along with the technologization of both the human body and mind have made it challenging to adapt to principles such as fairness, justice, autonomy, and voluntariness. These changes have introduced new potential ethical risks, obscuring the distinction between private and public spaces, transforming cognitive practices into ethical ones, and elevating accountability to a new topic that connects epistemology, ethics, and ontology. Our actions, perceptions, intentions, and morality have become intertwined with modern information technology. Therefore, it is necessary to establish a new ethical framework based on the relational self, consciousness of sharing, leisure labor, and subversion of various dichotomous concepts. This signifies the initiation of the second process of ""a man as a human being.""",2024,,FRONTIERS OF PHILOSOPHY IN CHINA,19,4,336-346,WOS:001397014700002,10.3868/s030-013-024-0020-7,,#4134,Cheng 2024,"",""
On the Edge: The Art of Risking Everything,"Mazo, J","Poker has often been used as a metaphor for international relations and existential threats such as nuclear weapons. Nate Silver's On the Edge: The Art of Risking Everything is a lengthy, often meandering but always entertaining exploration of this metaphor and its salience in the twenty-first century, from the world of professional gambling to existential risks such as climate change, nuclear weapons and artificial intelligence. The book has two entangled but independent threads: a discussion on how to think about risk, and a sociocultural conceit that modern elites, especially in the United States, can be meaningfully divided into two tribes competing for power and influence. What separates these groups are not, as Silver contends, cognitive and psychological traits, but in-group jargon and cultural references. Silver's discussions and insights about how to think about risk do not need this dichotomy to be real or sound; in fact; the conceit offers more distraction than insight.",2024,,SURVIVAL,66,6,153-162,WOS:001445413200013,10.1080/00396338.2024.2432207,,#4135,Mazo 2024,"",""
Antecedents and consequences of fake reviews in a marketing approach: An overview and synthesis,"Sahut, JM; Laroche, M; Braune, E","Fake reviews, characterized as misleading, can be positive, negative, or neutral, varying greatly across sectors and products. Their detrimental effects include reducing the informativeness and credibility of genuine reviews, leading to a distorted perception of products and affecting the development of online product reviews. This literature synthesis proposes a multidisciplinary approach to understand and combat fake reviews, emphasizing the need to differentiate them from genuine feedback through psychological and technological tactics. It outlines the importance of exploring the credibility routes influencing consumer behavior, the dynamics of fake review production, and the consequential effects on businesses and consumers. It also highlights the emergence of artificial intelligence as a powerful tool in identifying and combating fake reviews, advocating for continued exploration of detection strategies to preserve integrity and trust in online marketplaces. Lastly, it suggests avenues of research to deepen our knowledge of the antecedents and consequences of fake reviews, as well as of the various means available to prevent them, including technological, behavioral, and regulatory strategies.",2024,,JOURNAL OF BUSINESS RESEARCH,175,,,WOS:001218571600001,10.1016/j.jbusres.2024.114572,,#4136,Sahut 2024,"",""
Emulating fundamental analysts: Analytical stage-based multi-agent framework enhanced with expert guidance and Preference-Anchored Likelihood Adjustment,"Xu, T; Piao, Z; Mukai, T; Murayama, Y; Izumi, K","With the rapid advancement of large language models (LLMs), some studies have explored their potential for predicting stock prices based on financial texts. However, previous research often overlooked the depth of analysis generated by LLMs, resulting in reasoning processes inferior to those of human analysts. In fundamental investing, which requires in-depth company analysis, conclusions from imperfect reasoning lack persuasiveness. In this study, inspired by the analysis process of human analysts, we propose an ""Analytical Stage-Based Multi-Agent Framework""to enable LLMs to perform in-depth fundamental analysis. This framework divides the analysis into multiple stages, assigning an LLM agent to each. We enhance each agent's capabilities for its specific task through expert guidance or fine-tuning, allowing them to collectively emulate the workflow of human analysts. Furthermore, we introduce Preference-Anchored Likelihood Adjustment, anew method for fine-tuning LLMs. This approach addresses the decline in likelihood of generating correct responses that occurs after using existing preference alignment methods. It employs an objective function with two terms: one to increase likelihood and another to preserve aligned preference. We conducted experiments using our framework to analyze company earnings releases. We evaluated the analysis quality based on comprehensiveness and logical soundness, while correctness was assessed by using stock prices as the ground truth to calculate the Matthews correlation coefficient and F1 score. Results demonstrate that even without expert guidance and fine-tuning, our multi-agent framework can enhance LLMs in both analysis quality and correctness. When combined with expert guidance and fine-tuning, the performance is further improved.",2025,,INTELLIGENT SYSTEMS WITH APPLICATIONS,26,,,WOS:001439640200001,10.1016/j.iswa.2025.200496,,#4137,Xu 2025,"",""
Generating Persuasive Visual Storylines for Promotional Videos,"ACM; Liu, C; Dong, Y; Yu, H; Shen, ZQ; Gao, ZN; Wang, P; Zhang, CG; Ren, PR; Xie, XS; Cui, LZ; Miao, CY","Video contents have become a critical tool for promoting products in E-commerce. However, the lack of automatic promotional video generation solutions makes large-scale video-based promotion campaigns infeasible. The first step of automatically producing promotional videos is to generate visual storylines, which is to select the building block footage and place them in an appropriate order. This task is related to the subjective viewing experience. It is hitherto performed by human experts and thus, hard to scale. To address this problem, we propose WundtBackpack, an algorithmic approach to generate storylines based on available visual materials, which can be video clips or images. It consists of two main parts, 1) the Learnable Wundt Curve to evaluate the perceived persuasiveness based on the stimulus intensity of a sequence of visual materials, which only requires a small volume of data to train; and 2) a clustering-based backpacking algorithm to generate persuasive sequences of visual materials while considering video length constraints. In this way, the proposed approach provides a dynamic structure to empower artificial intelligence (AI) to organize video footage in order to construct a sequence of visual stimuli with persuasive power. Extensive real-world experiments show that our approach achieves close to 10% higher perceived persuasiveness scores by human testers, and 12.5% higher expected revenue compared to the best performing state-of-the-art approach.",2019,,PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19),,,901-910,WOS:000539898200093,10.1145/3357384.3357906,,#4138,ACM 2019,"",""
Can the Internet of Things Persuade Me? An Investigation Into Power Dynamics in Human-Internet of Things Interaction,"Kang, HYJ; Kim, KJ; Wang, S","The advent of artificial intelligence (AI) and the Internet of Things (IoT) has revolutionized user experience with objects. Things can perform social roles and convey persuasive messages to users, posing an important research question for communication and human-computer interaction researchers: What are the factors and underlying mechanisms that shape persuasive effects of IoT? Bridging the reactance theory and the computers are social actors paradigm, this study focuses on how power dynamics are shaped in human-IoT interactions and its implications on persuasion. Specifically, the study examines the effects of the social role assigned to the IoT mobile app agent and the scope of IoT controlled by the app on users' perceived power and subsequent persuasive outcomes. The results reveal that when the mobile IoT app is for controlling a smart home, the servant (vs. companion) agent elicits greater perceived power over IoT for users, leading to less threat-to-freedom and better persuasive outcomes, including attitude, intention, and actual behavior. However, such a difference is not observed when the mobile app is for controlling a single smart device (i.e., smart fridge). The study findings offer valuable implications for communication practitioners interested in using IoT as a persuasive tool.",2022,,FRONTIERS IN PSYCHOLOGY,13,,,WOS:000824154200001,10.3389/fpsyg.2022.883110,,#4139,Kang 2022,"",""
Formal dialogue models for argumentation in education and linguistics,"Walton, D",This paper offers a very short introduction to formal dialogue systems of the kind currently used in artificial intelligence and argumentation theory and applies them to some types of dialogue that are especially important in education. Persuasion dialogue is contrasted with deliberation dialogue. The fundamental problem of how to define relevance in such systems is briefly explained and discussed.,2022,,LEARNING CULTURE AND SOCIAL INTERACTION,36,,,WOS:000864896900003,10.1016/j.lcsi.2020.100388,,#4140,Walton 2022,"",""
SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context Misinformation Detection,"IEEE; Qi, P; Yan, ZH; Hsu, W; Lee, ML","Misinformation is a prevalent societal issue due to its potential high risks. Out-Of-Context (OOC) misinformation, where authentic images are repurposed with false text, is one of the easiest and most effective ways to mislead audiences. Current methods focus on assessing image-text consistency but lack convincing explanations for their judgments, which are essential for debunking misinformation. While Multimodal Large Language Models (MLLMs) have rich knowledge and innate capability for visual reasoning and explanation generation, they still lack sophistication in understanding and discovering the subtle cross-modal differences. In this paper, we introduce SNIFFER, a novel multimodal large language model specifically engineered for OOC misinformation detection and explanation. SNIFFER employs two-stage instruction tuning on Instruct-BLIP. The first stage refines the model's concept alignment of generic objects with news-domain entities and the second stage leverages OOC-specific instruction data generated by language-only GPT-4 to fine-tune the model's discriminatory powers. Enhanced by external tools and retrieval, SNIFFER not only detects inconsistencies between text and image but also utilizes external knowledge for contextual verification. Our experiments show that SNIFFER surpasses the original MLLM by over 40% and outperforms state-of-the-art methods in detection accuracy. SNIFFER also provides accurate and persuasive explanations as validated by quantitative and human evaluations.",2024,,2024 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR),,,13052-13062,WOS:001342442404040,10.1109/CVPR52733.2024.01240,,#4141,IEEE 2024,"",""
Convincing Audio Generation Based on LLM and Speech Tokenization,"Liu, RB; Wang, SX; Liu, ZZ; Zhao, JJ; Ren, YL; Liu, Y","This report describes the work submitted by the ZYZX-AI team to ICAGC 2024. This challenge, titled ""Inspirational and Convincing Audio Generation Challenge 2024,"" is part of the ISC-SLP 2024 Competitions and Challenges track, aims to enhance the persuasiveness and acceptability of synthesized audio, focusing on human alignment convincing and inspirational audio generation. Our solution combines speech discretization, a language modeling approach, and waveform reconstruction by a vocoder based on speech tokens.First, the input audio is mapped to a sequence of discrete tokens, audio generation as a language modeling task in this representational space. Subsequently, a neural audio codec uses the predicted discrete speech tokens in conjunction with the text to be synthesized to achieve high-quality audio generation. These models are trained on diverse datasets including open-source corpora such as wenetspeech4TTS and magicData. Unlike speech recognition tasks, speech synthesis tasks require higher-quality annotations in their training datasets. To address this issue, methods such as speech enhancement, loudness processing, and adjustments to punctuation in text annotations are applied during the data preprocessing stage to improve data quality. Our submission achieved third place on the track1(Inspirational Emotion Modulation), with an average MOS value of 3.56.",2024,,"2024 IEEE 14TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING, ISCSLP 2024",,,591-595,WOS:001414900800120,10.1109/ISCSLP63861.2024.10800064,,#4142,Liu 2024,"",""
Generative AI as Economic Agents,"Immorlica, N; Lucier, B; Slivkins, A","Traditionally, AI has been modeled within economics as a technology that impacts payoffs by reducing costs or refining information for human agents. Our position is that, in light of recent advances in generative AI, it is increasingly useful to model AI itself as an economic agent. In our framework, each user is augmented with an AI agent and can consult the AI prior to taking actions in a game. The AI agent and the user have potentially different information and preferences over the communication, which can result in equilibria that are qualitatively different than in settings without AI.",2024,,ACM SIGECOM EXCHANGES,22,1,93-109,WOS:001349692800005,,,#4143,Immorlica 2024,"",""
"Explanatory classification of CXR images into COVID-19, Pneumonia and Tuberculosis using deep learning and XAI","Bhandari, M; Shahi, TB; Siku, B; Neupane, A","Chest X-ray (CXR) images are considered useful to monitor and investigate a variety of pulmonary disorders such as COVID-19, Pneumonia, and Tuberculosis (TB). With recent technological advancements, such diseases may now be recognized more precisely using computer-assisted diagnostics. Without compromising the classification accuracy and better feature extraction, deep learning (DL) model to predict four different categories is proposed in this study. The proposed model is validated with publicly available datasets of 7132 chest x-ray (CXR) images. Furthermore, results are interpreted and explained using Gradient-weighted Class Activation Mapping (Grad-CAM), Local Interpretable Modelagnostic Explanation (LIME), and SHapley Additive exPlanation (SHAP) for better understandably. Initially, convolution features are extracted to collect high-level object-based information. Next, shapely values from SHAP, predictability results from LIME, and heatmap from Grad-CAM are used to explore the black-box approach of the DL model, achieving average test accuracy of 94.31 +/- 1.01% and validation accuracy of 94.54 +/- 1.33 for 10-fold cross validation. Finally, in order to validate the model and qualify medical risk, medical sensations of classification are taken to consolidate the explanations generated from the eXplainable Artificial Intelligence (XAI) framework. The results suggest that XAI and DL models give clinicians/medical professionals persuasive and coherent conclusions related to the detection and categorization of COVID-19, Pneumonia, and TB.",2022,,COMPUTERS IN BIOLOGY AND MEDICINE,150,,,WOS:000875408800011,10.1016/j.compbiomed.2022.106156,,#4144,Bhandari 2022,"",""
Towards Ethical Argumentative Persuasive Chatbots,"Al Anaissy, C; Vesic, S; Nevejans, N","Argumentative persuasive technologies are technologies that use argumentation in order to persuade the persuadee to believe in something or not, which can later lead the persuadee to perform an action or not. The use of such tools opens numerous ethical considerations. In this paper, we survey the literature on persuasion that might be useful for argumentative persuasive chatbots, we cover the existing legal framework and ethical principles and we critically analyze the new proposal for a regulation on artificial intelligence of the European Commission. We also show how to use argumentation to enhance explainability and transparency of the persuasion systems. We propose to show the graphical representation of the arguments used during the persuasion to the user at the end of the dialogue, containing the relations between the arguments (attacks, supports), their origin (source), who uttered them (i.e. the machine or the human participant) and the persuasive methods employed. Our approach has several benefits. Namely, it makes the system more transparent and enhances the human understanding of the system, which is a benefit per se. Furthermore, the fact that the system is transparent increases the trust of the user, which (apart from being one of the goals of AI in general) can increase the chance that the user is persuaded by the system. Finally, the user can give a feedback on the presented arguments (e.g. how much they believe the arguments are ethical), which can be later used to improve the persuasion system.",2023,,"COORDINATION, ORGANIZATIONS, INSTITUTIONS, NORMS, AND ETHICS FOR GOVERNANCE OF MULTI-AGENT SYSTEMS XVI, COINE 2023",14002,,141-160,WOS:001160581700008,10.1007/978-3-031-49133-7_8,,#4145,AlAnaissy 2023,"",""
A Novel Key Influencing Factors Selection Approach of P2P Lending Investment Risk,"Xia, PF; Ni, ZW; Zhu, XH; Ni, LP","Recent frequent ""thunderstorm incidents"" of P2P lending industry have caused the panic of industry investors. To predict the investment risk of P2P lending, we should scientifically and rationally analyze the key influencing factors of P2P lending investment risk. Existing key influencing factors selection methods mainly involve traditional statistical approaches and artificial intelligence methods. The traditional statistical approaches cannot deal with the high-dimensional nonlinear problems, and it cannot find the exact key influencing factors of the P2P lending investment risk. The artificial intelligence methods cannot recognize and learn the application background, and the selected attributes without active thinking and personal perception may not be the key influencing factors of P2P lending investment risk. To address the above issues, a novel key influencing factors selection approach of P2P lending investment risk is proposed by combining the proposed fireworks coevolution binary glowworm swarm optimization (FCBGSO), multifractal dimension (MFD), probit regression, and artificial prior knowledge. First, multifractal dimension combined with the proposed FCBGSO is used to select the preliminary influencing factors of the investment risk; second, the nonsignificant relevant attributes in the preliminary influencing factors are removed using the probit regression, and we add the influencing factors extracted from the original dataset of P2P lending using the artificial prior knowledge into the retaining influencing factors after removing one by one. A small and reasonable number of influencing factor subsets are achieved. Finally, we evaluate each influencing factors subset using extreme learning machine (ELM), and the subset with the best classification accuracy is efficiently achieved, i.e., it is the key influencing factors of P2P lending investment risk. Experimental results on the real P2P lending dataset from the Renrendai platform demonstrate that the proposed approach performs better than other state-of-the-art methods and that it has validity and effectiveness. It provides a new research idea for the key influencing factors selection of P2P lending investment risk.",2019,,MATHEMATICAL PROBLEMS IN ENGINEERING,2019,,,WOS:000502054400002,10.1155/2019/6086089,,#4146,Xia 2019,"",""
Artificial Intelligence and Deep Learning in a world of humans and persuasive business models,"IEEE; Valter, P; Lindgren, P; Prasad, R","Integration of Communications, Navigation, Sensing and Services (CONANSENSE) [10] has made the possibilities to develop disruptive and persuasive technologies that are increasing with exponential speed and are coursing disruption of businesses, business models (BM) [5],[6] and even Business Model Ecosystems (BMES) [4] every day. Businesses have classically put emphasis on human bonds related to their BM's but by the fast development of more sensoring and persuasive BMs increasingly run autonomously by machines, businesses have to know how these BM's can be innovated and how they can be operated to ensure their full business potential and survival.BMES and BM's have for a longtime been based and built up with human bond communication, but this can vanish within split seconds when these new technologies very much based on machine to human communication evolves. How is and will this change the bonds between humans, humans and machines and machines to machines. How will this evolvement influence humans and machines ability to ""sense"", ""relate"" and ""communicate"" each other. The paper addresses the exponential development of artificial intelligence technologies, persuasive technologies and persuasive BMs in Business model innovation and introduce a conceptual model to future business model innovation and operation.",2017,,2017 GLOBAL WIRELESS SUMMIT (GWS),,,209-214,WOS:000428390800040,,,#4147,IEEE 2017,"",""
"""I Like Your Suggestion!"" the role of humanlikeness and parasocial relationship on the website versus voice shopper's perception of recommendations","Whang, C; Im, H","Voice assistants are changing the way consumers shop. Guided by the anthropomorphism literature and parasocial interaction theory, this study investigated how the new unique relationship between consumers and artificial intelligence-powered voice assistants may affect the way consumers evaluate the recommended products through two experiments. Study 1 (n = 85, students) employed a 2 (shopping medium type: voice assistant vs. website) x 2 (interaction style: task-oriented vs. socially-oriented) between-subjects design lab experiment. Study 2 (n = 418, Mechanical Turk) employed a 2 (shopping medium type: voice assistant vs. website) x 2 (product type: search vs. experience) between-subjects online experiment. The results suggested that consumers may perceive voice assistants as pseudohuman agents detached from the service provider while perceiving websites as a tool or interface used by the provider, resulting in a more positive perception and evaluation of websites. As one of the few studies investigating voice assistants from the consumer perspective, this study contributes to the growing body of research in voice assistants. The study also contributes to anthropomorphism literature and parasocial interaction theory by confirming the causal relationship between humanlikeness and parasocial relationships.",2021,,PSYCHOLOGY & MARKETING,38,4,581-595,WOS:000596964400001,10.1002/mar.21437,,#4148,Whang 2021,"",""
Exploring factors influencing user perspective of ChatGPT as a technology that assists in healthcare decision making: A cross sectional survey study,"Choudhury, A; Elkefi, S; Tounsi, A","As ChatGPT emerges as a potential ally in healthcare decision-making, it is imperative to investigate how users leverage and perceive it. The repurposing of technology is innovative but brings risks, especially since AI's effectiveness depends on the data it's fed. In healthcare, ChatGPT might provide sound advice based on current medical knowledge, which could turn into misinformation if its data sources later include erroneous information. Our study assesses user perceptions of ChatGPT, particularly of those who used ChatGPT for healthcare-related queries. By examining factors such as competence, reliability, transparency, trustworthiness, security, and persuasiveness of ChatGPT, the research aimed to understand how users rely on ChatGPT for health-related decision-making. A web-based survey was distributed to U.S. adults using ChatGPT at least once a month. Bayesian Linear Regression was used to understand how much ChatGPT aids in informed decision-making. This analysis was conducted on subsets of respondents, both those who used ChatGPT for healthcare decisions and those who did not. Qualitative data from open-ended questions were analyzed using content analysis, with thematic coding to extract public opinions on urban environmental policies. Six hundred and seven individuals responded to the survey. Respondents were distributed across 306 US cities of which 20 participants were from rural cities. Of all the respondents, 44 used ChatGPT for health-related queries and decision-making. In the healthcare context, the most effective model highlights 'Competent + Trustworthy + ChatGPT for healthcare queries', underscoring the critical importance of perceived competence and trustworthiness specifically in the realm of healthcare applications of ChatGPT. On the other hand, the non-healthcare context reveals a broader spectrum of influential factors in its best model, which includes 'Trustworthy + Secure + Benefits outweigh risks + Satisfaction + Willing to take decisions + Intent to use + Persuasive'. In conclusion our study findings suggest a clear demarcation in user expectations and requirements from AI systems based on the context of their use. We advocate for a balanced approach where technological advancement and user readiness are harmonized.",2024,,PLOS ONE,19,3,,WOS:001181701200019,10.1371/journal.pone.0296151,,#4149,Choudhury 2024,"",""
An implantable memristor towards biomedical applications,"Zhu, SH; Cao, ZL; Zhou, GD; Tong, GQ; Ma, YM; Yang, WT; Wu, YA; Zhao, Y; Sun, B","As a new type of two-terminal nonlinear nanoelectronic component, memristors have shown significant application prospects in the post Moore's electron era, as they can store and process data in a single cell, further realizing brain-like neuromorphic computing modes and providing hardware support for the development of super artificial intelligence. However, whether memristors can be applied in the biomedical field to achieve information sensing for human-machine interaction is still a research gap. Herein, we demonstrate a ZrOx filmbased flexible memristor, which shows promising applications as an implantable device. In particular, the working mechanisms of the implantable memristor were comprehensively analyzed, in which it has been found that the memristive behavior of the device is mainly determined by carrier tunneling. Reliable electron tunneling parameters were obtained by fitting the experimental data, which provides persuasive supporting for the research of tunneling devices. Furthermore, the memristive behavior of the device is closely related to space charge limited current (SCLC) under bending conditions. Finally, the biomedical and human-machine interaction applications can be achieved based on the implantable memristor. This work not only proves the application feasibility of flexible memristor in the field of implantable biomedicine, but also promotes the rapid development of human-machine interaction.",2024,,APPLIED MATERIALS TODAY,38,,,WOS:001238506000001,10.1016/j.apmt.2024.102214,,#4150,Zhu 2024,"",""
Investigating the Use of an Artificial Intelligence Chatbot with General Chemistry Exam Questions,"Clark, TM","The artificial intelligence chatbot ChatGPT was used to answer questions from final exams administered in two general chemistry courses, including questions with closed -response format and with open-response format. For closed -response questions, ChatGPT was very capable at identifying the concept even when the question included a great deal of chemical symbolism. However, ChatGPT's success at solving problems was only 44%, a value well below the class average of 69%. On open -response questions, ChatGPT's responses displayed strong language processing ability with higher performance on questions that could be solved with more generalizable information compared to questions that required specific skills, especially when those topics or skills were primarily found in lecture. Incorrect responses and flawed explanations were often logically sound and would be persuasive to a novice. The chatbot is currently ill-equipped to provide reliable answers or explanations to students for many representative exam questions, but a potential use is to create assignments in which students analyze and improve ChatGPT's responses.",2023,,JOURNAL OF CHEMICAL EDUCATION,100,5,1905-1916,WOS:000980623100001,10.1021/acs.jchemed.3c00027,,#4151,Clark 2023,"",""
AI-induced hyper-learning in humans,"Glickman, M; Sharot, T","Humans evolved to learn from one another. Today, however, learning opportunities often emerge from interactions with AI systems. Here, we argue that learning from AI systems resembles learning from other humans, but may be faster and more efficient. Such ' hyper learning' ' can occur because AI: (i) provides a high signal-to-noise ratio that facilitates learning, (ii) has greater data processing ability, enabling it to generate persuasive arguments, and (iii) is perceived (in some domains) to have superior knowledge compared to humans. As a result, humans more quickly adopt biases from AI, are often more easily persuaded by AI, and exhibit novel problem-solving strategies after interacting with AI. Greater awareness of AI's ' s influences is needed to mitigate the potential negative outcomes of human-AI interactions.",2025,,CURRENT OPINION IN PSYCHOLOGY,60,,,WOS:001329094800001,10.1016/j.copsyc.2024.101900,,#4152,Glickman 2025,"",""
Estimating the deep replicability of scientific findings using human and artificial intelligence,"Yang, Y; Wu, YY; Uzzi, B","Replicability tests of scientific papers show that the majority of papers fail replication. Moreover, failed papers circulate through the literature as quickly as replicating papers. This dynamic weakens the literature, raises research costs, and demonstrates the need for new approaches for estimating a study's replicability. Here, we trained an artificial intelligence model to estimate a paper's replicability using ground truth data on studies that had passed or failed manual replication tests, and then tested the model's generalizability on an extensive set of out-of-sample studies. The model predicts replicability better than the base rate of reviewers and comparably as well as prediction markets, the best present-day method for predicting replicability. In out-of-sample tests on manually replicated papers from diverse disciplines and methods, the model had strong accuracy levels of 0.65 to 0.78. Exploring the reasons behind the model's predictions, we found no evidence for bias based on topics, journals, disciplines, base rates of failure, persuasion words, or novelty words like ""remarkable"" or ""unexpected."" We did find that the model's accuracy is higher when trained on a paper's text rather than its reported statistics and that n-grams, higher order word combinations that humans have difficulty processing, correlate with replication. We discuss how combining human and machine intelligence can raise confidence in research, provide research self-assessment techniques, and create methods that are scalable and efficient enough to review the ever-growing numbers of publications-a task that entails extensive human resources to accomplish with prediction markets and manual replication alone.",2020,,PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA,117,20,10762-10768,WOS:000535585100028,10.1073/pnas.1909046117,,#4153,Yang 2020,"",""
The effects of anthropomorphic framing on senior news consumers' attitudes towards health AI systems: a mediation of psychological distance,"Xu, YR; Jiang, TT","Introduction. Mass media plays a critical role in demonstrating the advancements of AI technologies to the public. Anthropomorphic framing, a verbal technique involving attributing human characteristics to non-human entities, has been increasingly adopted to describe various health AI systems, but there still lacks empirical evidence regarding its effectiveness in enhancing AI acceptance among senior news consumers. Method. This study conducted a controlled experiment based on a single-factor (human- vs. machine-like framing) within-subject design. 37 senior participants were asked to watch short-form video news discussing health AI systems, and their attitudes towards, intentions to use, and psychological distance from health AI systems were measured using appropriate scales. Results. Describing a health AI system like a human being elicited more positive attitudes towards AI among the elderly, which further increased their intentions to use AI. The positive effect of anthropomorphic framing on AI attitudes was mediated by psychological distance. Conclusions. Anthropomorphic framing has great potential in the AI literacy education for older adults. This study not only extends research on AI anthropomorphism but also provides practical implications for media outlets to create persuasive news content.",2025,,INFORMATION RESEARCH-AN INTERNATIONAL ELECTRONIC JOURNAL,30,,1039-1048,WOS:001452022200045,10.47989/ir30iConf47128,,#4154,Xu 2025,"",""
Using Argument Features to Improve the Argumentation Process,"Budán, MCD; Simari, GI; Simari, GR","Argumentation has become an important topic in artificial intelligence; the basic idea is to identify arguments in favor and against a statement, select the acceptable ones, and determine whether the original statement can be accepted or not. However, the arguments involved in an argumentative discussion may have different relevance degrees; for this reason, argumentation frameworks need to represent the qualities that describe the soundness of an argument in order to refine the acceptability process performed over the argumentation model.",2016,,COMPUTATIONAL MODELS OF ARGUMENT,287,,151-158,WOS:000383377900016,10.3233/978-1-61499-686-6-151,,#4155,Budán 2016,"",""
Four Ways to Evaluate Arguments According to Agent Engagement,"Bisquert, P; Croitoru, M; de Saint-Cyr, FD",In this paper we are interested in the computational and formal analysis of the persuasive impact that an argument can have on a human. We present a preliminary account of the listener mental process (representation and reasoning mechanisms of the dual process cognitive model) as well as her engagement based on the ELM model. This engagement determines the reasoning process that the agent will adopt in order to evaluate and incorporate the uttered argument.,2015,,BRAIN INFORMATICS AND HEALTH (BIH 2015),9250,,445-456,WOS:000363761200043,10.1007/978-3-319-23344-4_43,,#4156,Bisquert 2015,"",""
11th Joint Workshop on Interfaces and Human Decision Making for Recommender Systems (IntRS'24),"ACM; Brusilovsky, P; de Gemmis, M; Felfernig, A; Polignano, M; Semeraro, G; Willemsen, M","The primary goal of Recommender Systems is to suggest the most suitable items to a user, aligning them with the user's interests and needs. RSs are essential for modern e-commerce, helping users discover content and products by predicting suitable items based on their past behavior. However, their success isn't just about advanced algorithms. The design of the user interface and a good integration with the human decision-making process are equally crucial. A well-designed interface enhances the user experience and makes recommendations more effective, while a poor interface can lead to frustration. Recognizing this limitation, recent trends in Recommender Systems (RSs) are increasingly focusing on integrating Symbiotic Human-Machine Decision-Making models. These models aim to offer users a dynamic and persuasive interface that helps them better understand and engage with recommendations. This shift is a crucial step toward developing recommender systems that truly connect with users and offer a more enjoyable, trustworthy, explainable, and user-friendly experience. Although early efforts concentrated on creating systems that could proactively predict user preferences and needs, modern RSs also emphasize the importance of providing users with control and transparency over their recommendations. Finding the right balance between proactivity and user control is essential to ensure that the system supports users without being too intrusive, thus improving their overall satisfaction. As Large Language Models (LLMs) become more integrated into recommender systems, the importance of user-centric interfaces and a deep understanding of decision-making becomes even more critical. Effective integration of LLMs requires interfaces that are both visually and cognitively engaging.These aspects are the main discussion topics of the Joint Workshop on Interfaces and Human Decision Making for Recommender Systems at RecSys'24. In this summary, we introduce the motivation and perspective of the workshop, review its history, and discuss the most critical issues that deserve attention for future research directions.",2024,,"PROCEEDINGS OF THE EIGHTEENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2024",,,1253-1257,WOS:001336908500187,10.1145/3640457.3687098,,#4157,ACM 2024,"",""
"SheffieldVeraAI at SemEval-2023 Task 3: Mono and multilingual approaches for news genre, topic and persuasion technique classification","Wu, B; Razuvayevskaya, O; Heppell, F; Leite, JA; Scarton, C; Bontcheva, K; Song, XY","This paper describes our approach for SemEval2023 Task 3: Detecting the category, the framing, and the persuasion techniques in online news in a multilingual setup. For Subtask 1 (News Genre), we propose an ensemble of fully trained and adapter mBERT models which was ranked joint-first for German, and had the highest mean rank of multi-language teams. For Subtask 2 (Framing), we achieved first place in 3 languages, and the best average rank across all the languages, by using two separate ensembles: a monolingual RoBERTa-MUPPETLARGE' and an ensemble of XLM-RoBERTa(LARGE) with adapters and task adaptive pretraining. For Subtask 3 (Persuasion Techniques), we trained a monolingual RoBERTa-Base model for English and a multilingual mBERT model for the remaining languages, which achieved top 10 for all languages, including 2nd for English. For each subtask, we compared monolingual and multilingual approaches, and considered class imbalance techniques. (1)",2023,,"17TH INTERNATIONAL WORKSHOP ON SEMANTIC EVALUATION, SEMEVAL-2023",,,1995-2008,WOS:001281001900274,,,#4158,Wu 2023,"",""
Speak their Language: Designing Effective Messages to Improve Employees' Information Security Decision Making,"Johnston, AC; Warkentin, M; Dennis, AR; Siponen, M","Employee disinterest in information security remains one of the greatest impediments to effective information security management programs. How can organizations enhance the persuasiveness of the information security messages used to warn employees of threats and encourage employees to take specific actions to improve their security? We use fear appeal theory and the elaboration likelihood model to argue that security messages presented using more personally relevant language are more likely to induce employees to engage in the recommended protective security behaviors. Our strategy uses organization identification theory to segment employees into two groups and then develops security messages that use language aligned with each of the two segments. We tested this strategy within a large U.S. organization, and found that employees were more likely to consider and act upon messages that used language aligned with their organizational identification than messages using language not aligned. The effect size was large. Our results show that subtly changing less than a dozen words in the way a security message was presented without changing its substantive content (e.g., using ""our"" instead of ""your"") has both significant and meaningful effects on how employees think about and respond to it.",2019,,DECISION SCIENCES,50,2,245-284,WOS:000465243700002,10.1111/deci.12328,,#4159,Johnston 2019,"",""
Can Large Language Models Transform Computational Social Science?,"Ziems, C; Held, W; Shaikh, O; Chen, JA; Zhang, ZH; Yang, DY","Large language models (LLMs) are capable of successfully performing many language processing tasks zero-shot (without training data). If zero-shot LLMs can also reliably classify and explain social phenomena like persuasiveness and political ideology, then LLMs could augment the computational social science (CSS) pipeline in important ways. This work provides a road map for using LLMs as CSS tools. Towards this end, we contribute a set of prompting best practices and an extensive evaluation pipeline to measure the zero-shot performance of 13 language models on 25 representative English CSS benchmarks. On taxonomic labeling tasks (classification), LLMs fail to outperform the best fine-tuned models but still achieve fair levels of agreement with humans. On free-form coding tasks (generation), LLMs produce explanations that often exceed the quality of crowdworkers' gold references. We conclude that the performance of today's LLMs can augment the CSS research pipeline in two ways: (1) serving as zero-shot data annotators on human annotation teams, and (2) bootstrapping challenging creative generation tasks (e.g., explaining the underlying attributes of a text). In summary, LLMs are posed to meaningfully participate in social science analysis in partnership with humans.",2023,,COMPUTATIONAL LINGUISTICS,50,1,237-291,WOS:001205186000006,10.1162/coli_a_00502,,#4160,Ziems 2023,"",""
SheffieldVeraAI at SemEval-2024 Task 4: Prompting and fine-tuning a Large Vision-Language Model for Binary Classification of Persuasion Techniques in Memes,"Grimshaw, C; Bontcheva, K; Song, XY","This paper describes our approach for SemEval-2024 Task 4: Multilingual Detection of Persuasion Techniques in Memes. Specifically, we concentrate on Subtask 2b, a binary classification challenge that entails categorizing memes as either ""propagandistic"" or ""non-propagandistic"". To address this task, we utilized the large multimodal pretrained model, LLaVa. We explored various prompting strategies and fine-tuning methods, and observed that the model, when not fine-tuned but provided with a few-shot learning examples, achieved the best performance. Additionally, we enhanced the model's multilingual capabilities by integrating a machine translation model. Our system secured the 2nd place in the Arabic language category.",2024,,"PROCEEDINGS OF THE 18TH INTERNATIONAL WORKSHOP ON SEMANTIC EVALUATION, SEMEVAL-2024",,,2051-2056,WOS:001356736800277,,,#4161,Grimshaw 2024,"",""
Evaluating Intention Detection Capability of Large Language Models in Persuasive Dialogues,"Sakurai, H; Miyao, Y","We investigate intention detection in persuasive multi-turn dialogues employing the largest available Large Language Models (LLMs). Much of the prior research measures the intention detection capability of machine learning models without considering the conversational history. To evaluate LLMs' intention detection capability in conversation, we modified the existing datasets of persuasive conversation and created datasets using a multiple-choice paradigm.(1) It is crucial to consider others' perspectives through their utterances when engaging in a persuasive conversation, especially when making a request or reply that is inconvenient for others. This feature makes the persuasive dialogue suitable for the dataset of measuring intention detection capability. We incorporate the concept of face acts, which categorize how utterances affect mental states. This approach enables us to measure intention detection capability by focusing on crucial intentions and to conduct comprehensible analysis according to intention types.",2024,,"PROCEEDINGS OF THE 62ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1: LONG PAPERS",,,1635-1657,WOS:001356729801041,,,#4162,Sakurai 2024,"",""
Deciphering Deception: How Different Rhetoric of AI Language Impacts Users' Sense of Truth in LLMs,"Yoo, D; Kang, H; Oh, C","Users are increasingly exposed to AI-generated language, presenting potential deception and communication risks. This study delved into the rhetorical aspect of AI-generated language influencing users' truth discernment. We conducted a user study comparing three levels of rhetorical presence and four persuasive rhetorical elements, using interviews to understand users' truth-detection methods. Results showed that outputs with fewer rhetorical elements posed challenges for users in distinguishing truth from false, while those with more rhetoric often misled users into false truths. Users' AI expectations influenced truth judgments, with responses meeting expectations perceived as more truthful. Casual, human-like responses were often deemed false, while technical, precise AI responses were preferred. This research emphasizes that rhetorical elements of AI language can significantly bias individuals regardless of a statement's actual truth. For enhanced transparency in human-AI communication, it is advisable for AI designs to thoughtfully integrate rhetorical elements and establish guiding principles aimed at minimizing the potential for deceptive responses.",2025,,INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION,41,4,2163-2183,WOS:001168383700001,10.1080/10447318.2024.2316370,,#4163,Yoo 2025,"",""
NLPNCHU at SemEval-2024 Task 4: A Comparison of MDHC Strategy and In-domain Pre-training for Multilingual Detection of Persuasion Techniques in Memes,"Guo, SW; Lin, YT; Lu, YA; Fan, YC","This study presents a systematic method for identifying 22 persuasive techniques used in multilingual memes. We explored various finetuning techniques and classification strategies, such as data augmentation, problem transformation, and hierarchical multi-label classification strategies. Identifying persuasive techniques in memes involves a multimodal task. We fine-tuned the XLM-RoBERTA-large-twitter language model1, focusing on domain-specific language modeling, and integrated it with the CLIP visual model's embedding to consider image and text features simultaneously. In our experiments, we evaluated the effectiveness of our approach by using official validation data in English. Our system in the competition, achieving competitive rankings in Subtask1 and Subtask2b across four languages: English, Bulgarian, North Macedonian, and Arabic. Significantly, we achieved 2nd place ranking for Arabic language in Subtask 1.",2024,,"PROCEEDINGS OF THE 18TH INTERNATIONAL WORKSHOP ON SEMANTIC EVALUATION, SEMEVAL-2024",,,1868-1875,WOS:001356736800261,,,#4164,Guo 2024,"",""
"Do chatbots establish ""humanness"" in the customer purchase journey? An investigation through explanatory sequential design","Dwivedi, YK; Balakrishnan, J; Baabdullah, AM; Das, R","Chatbots incorporate various behavioral and psychological marketing elements to satisfy customers at various stages of their purchase journey. This research follows the foundations of the Elaboration Likelihood Model (ELM) and examines how cognitive and peripheral cues impact experiential dimensions, leading to chatbot user recommendation intentions. The study introduced warmth and competence as mediating variables in both the purchase and postpurchase stages, utilizing a robust explanatory sequential mixed-method research design. The researchers tested and validated the proposed conceptual model using a 3 x 3 factorial design, collecting 354 responses in the purchase stage and 286 responses in the postpurchase stage. In the second stage, they conducted in-depth qualitative interviews (Study 2) to gain further insights into the validity of the experimental research (Study 1). The results obtained from Study 1 revealed that ""cognitive cues"" and ""competence"" significantly influence recommendation intentions among chatbot users. On the other hand, ""peripheral cues"" and warmth significantly contribute to positive experiences encountered during the purchase stage. The researchers further identified 69 thematic codes through exploratory research, providing a deeper understanding of the variables. Theoretically, this study extends the ELM by introducing new dimensions to human-machine interactions at the heart of digital transformation. From a managerial standpoint, the study emphasizes the significance of adding a ""humanness"" element in chatbot development to create more engaging and positive customer experiences actively.",2023,,PSYCHOLOGY & MARKETING,40,11,2244-2271,WOS:001050655700001,10.1002/mar.21888,,#4165,Dwivedi 2023,"",""
AI-disclosure en merkattitude De rol van source derogation en affiniteit met technologie,"Derks, S; Anschutz, D; Bosse, T","AI Disclosure and brand attitude: The role of source derogation and technological affinity This study, employing a between-subjects experimental design comparing blogs with and without AI-disclosure, revealed that the inclusion of an AI-disclosure did not significantly impact brand attitude. Furthermore, the results demonstrated that the presence of an AI-disclosure did not lead to a higher degree of source derogation. However, a notable finding was the correlation between a high level of source derogation and a more negative brand attitude. Interestingly, technological affinity was found to have no influence on the observed relationships. The results highlight the nuanced interplay between AI-disclosure, source derogation, and brand attitude, emphasizing the significance of considering individual factors and their collective impact on consumer perceptions in the evolving landscape of AI communication.",2024,,TIJDSCHRIFT VOOR COMMUNICATIEWETENSCHAP,52,3,350-371,WOS:001273865900005,10.5117/TCW2024.3.005.DERK,,#4166,Derks 2024,"",""
Primary Prevention of Sudden Cardiac Death of the Young Athlete: The Controversy About the Screening Electrocardiogram and Its Innovative Artificial Intelligence Solution,"Chang, AC","The preparticipation screening for athlete participation in sports typically entails a comprehensive medical and family history and a complete physical examination. A 12-lead electrocardiogram (ECG) can increase the likelihood of detecting cardiac diagnoses such as hypertrophic cardiomyopathy, but this diagnostic test as part of the screening process has engendered considerable controversy. The pro position is supported by argument that international screening protocols support its use, positive diagnosis has multiple benefits, history and physical examination are inadequate, primary prevention is essential, and the cost effectiveness is justified. Although the aforementioned myriad of justifications for routine ECG screening of young athletes can be persuasive, several valid contentions oppose supporting such a policy, namely, that the sudden death incidence is very (too) low, the ECG screening will be too costly, the false-positive rate is too high, resources will be allocated away from other diseases, and manpower is insufficient for its execution. Clinicians, including pediatric cardiologists, have an understandable proclivity for avoiding this prodigious national endeavor. The controversy, however, should not be focused on whether an inexpensive, noninvasive test such as an ECG should be mandated but should instead be directed at just how these tests for young athletes can be performed in the clinical imbroglio of these disease states (with variable genetic penetrance and phenotypic expression) with concomitant fiscal accountability and logistical expediency in this era of economic restraint. This monumental endeavor in any city or region requires two crucial elements well known to business scholars: implementation and execution. The eventual solution for the screening ECG dilemma requires a truly innovative and systematic approach that will liberate us from inadequate conventional solutions. Artificial intelligence, specifically the process termed ""machine learning"" and ""neural networking,"" involves complex algorithms that allow computers to improve the decision-making process based on repeated input of empirical data (e. g., databases and ECGs). These elements all can be improved with a national database, evidence-based medicine, and in the near future, innovation that entails a Kurzweilian artificial intelligence infrastructure with machine learning and neural networking that will construct the ultimate clinical decision-making algorithm.",2012,,PEDIATRIC CARDIOLOGY,33,3,428-433,WOS:000301984400007,10.1007/s00246-012-0244-5,,#4167,Chang 2012,"",""
Mood Themes the World,"Stenner, J; Ulmer, GL","Apparatus theory (a hybrid of McLuhan and Derrida) hypothesizes that a civiliza-tion of electracy (the digital apparatus) must learn how to thrive in a lifeworld in which the visceral faculty of appetite is hegemonic. The dominant axis of behavior today is fantasy -anxi-ety (attraction/repulsion). We propose that world theming has created a vernacular discourse that may be raised to a second power of expression as vehicle of visceral intelligence. The immediate claim is that theming in digital media augments mood (ambiance) into a power of imagination, just as dialectic in writing augmented logic into a power of reason. Fantasy today is persuasive, just as logical entailment is (was) in the rational order of literacy. Decisions de-termining real events today are being made in worlds of mood.World theming is evident in the vernacular art practices arising from recent advanc-es in artificial intelligence. The availability of commodity GPUs, along with public access to advanced research via GitHub, Kaggle, Hugging Face, and the proliferation of forums such as Reddit, Discord, YouTube, and others, has resulted in a renaissance of public engagement with technology-informed creative practice. In addition, the general availability of Google's previously internal-only development tool, Colab, in late 2017 provided access to cloud-based GPUs and storage systems accessible only to data scientists and academics. In early 2021 Ryan Murdock released a Colab notebook called Big Sleep that combined Ope-nAI's recently published Contrastive Language-Image Pre-training (CLIP) with BigGAN. This model is a paradigmatic example of our observation. By early 2022, multiple derivations of this process incorporated alternative image generation techniques. This paper will demonstrate how the fundamental basis of these methods are distinctly electrate in their use of 'theme' and emphasis on 'mood' in world-building, including a case-study animation called Dissipative Off-ramps.",2023,,AM JOURNAL OF ART AND MEDIA STUDIES,30,,105-137,WOS:001019545800006,10.25038/am.v0i29.556,,#4168,Stenner 2023,"",""
Argumentation schemes in AI and Law,"Atkinson, K; Bench-Capon, T","In this paper we describe the impact that Walton's conception of argumentation schemes had on AI and Law research. We will discuss developments in argumentation in AI and Law before Walton's schemes became known in that community, and the issues that were current in that work. We will then show how Walton's schemes provided a means of addressing all of those issues, and so supplied a unifying perspective from which to view argumentation in AI and Law.",2021,,ARGUMENT & COMPUTATION,12,3,417-434,WOS:000719820300006,10.3233/AAC-200543,,#4169,Atkinson 2021,"",""
Combining the Strengths of LLMs and Persuasive Technology to Combat Cyberhate,"Almaliki, M; Almars, AM; Aljuhani, KO; Atlam, E","Cyberhate presents a multifaceted, context-sensitive challenge that existing detection methods often struggle to tackle effectively. Large language models (LLMs) exhibit considerable potential for improving cyberhate detection due to their advanced contextual understanding. However, detection alone is insufficient; it is crucial for software to also promote healthier user behaviors and empower individuals to actively confront the spread of cyberhate. This study investigates whether integrating large language models (LLMs) with persuasive technology (PT) can effectively detect cyberhate and encourage prosocial user behavior in digital spaces. Through an empirical study, we examine users' perceptions of a self-monitoring persuasive strategy designed to reduce cyberhate. Specifically, the study introduces the Comment Analysis Feature to limit cyberhate spread, utilizing a prompt-based fine-tuning approach combined with LLMs. By framing users' comments within the relevant context of cyberhate, the feature classifies input as either cyberhate or non-cyberhate and generates context-aware alternative statements when necessary to encourage more positive communication. A case study evaluated its real-world performance, examining user comments, detection accuracy, and the impact of alternative statements on user engagement and perception. The findings indicate that while most of the users (83%) found the suggestions clear and helpful, some resisted them, either because they felt the changes were irrelevant or misaligned with their intended expression (15%) or because they perceived them as a form of censorship (36%). However, a substantial number of users (40%) believed the interventions enhanced their language and overall commenting tone, with 68% suggesting they could have a positive long-term impact on reducing cyberhate. These insights highlight the potential of combining LLMs and PT to promote healthier online discourse while underscoring the need to address user concerns regarding relevance, intent, and freedom of expression.",2025,,COMPUTERS,14,5,,WOS:001496719200001,10.3390/computers14050173,,#4170,Almaliki 2025,"",""
Sustainability Disclosure in Integrated Reporting: Does It Matter to Investors? A Cheap Talk Approach,"Camodeca, R; Almici, A; Sagliaschi, U","The purpose of this study is to investigate the value-relevance of corporate sustainability disclosure through integrated reporting. Sustainability disclosure is subject to managers' discretion. Besides, it is often hardly verifiable. In this respect, integrated reporting could provide the means for a verifiable disclosure, otherwise, in the jargon of game theory, it could be considered as a cheap talk. This paper investigates which of these hypotheses is most likely to occur in reality. In order to do this, a simple theoretical framework is introduced, where sustainability of corporate performances is modelled as a tail-risk for shareholders. Costless signaling games (cheap talk) and persuasion games are reviewed within this context, in order to derive competing theories of sustainability disclosure's value relevance through integrated reporting. These alternative theories are tested empirically consistent with the theoretical framework presented, in order to identify key-parameters. In this respect, a systematic textual analysis (artificial intelligence) of integrated reports was employed as to build a synthetic measure of sustainability disclosure. The application of this methodology on a sample of European listed companies showed that sustainability disclosure through integrated reporting has no effect on market-valuations, confirming the null hypothesis of integrated reporting resulting in a cheap talk's babbling equilibrium.",2018,,SUSTAINABILITY,10,12,,WOS:000455338100059,10.3390/su10124393,,#4171,Camodeca 2018,"",""
Rethinking Environmental Disclosure,"Brett, A","Twenty years ago, legal scholars and regulators alike were convinced that information-forcing regulations heralded a new era in environmental law. Coming off the success of the Toxics Release Inventory (TRI), which seemed to decrease toxic chemical pollution solely by forcing industry to disclose if they released certain chemicals, many called information regulation the third wave of environmental law. New information disclosure policies were enacted and old policies reinvigorated, leading to a plethora of informationbased regulations throughout environmental law. Now, twenty years later, the emergence of big data and artificial intelligence (AI) approaches to environmental analysis have only further increased the belief in the benefits of information-forcing approaches. In this time, the central premise that information regulation works to change behavior and improve environmental outcomes has been largely unquestioned. Despite the widespread enthusiasm, after decades of implementation it is increasingly clear that information regulation largely fails to achieve its environmental goals. This Article makes two main contributions. By drawing on quantitative and qualitative case studies of information-forcing regulations, it first answers the question of whether this approach to environmental regulation is effective. It evaluates the success of information-forcing policies, finding that these policies often fail both to change behavior towards improving environmental conditions and to achieve other stated goals. This Article then analyzes the mechanisms behind information forcing in conjunction with these case studies to propose characteristics that determine the success, or failure, of information regulation. It finds that contrary to popular belief, persuasive and economic mechanisms not drive environmental behavior change. Instead, information- forcing regulations with legal mechanisms of action show the most promise and efficacy. Moving beyond sweeping promises of efficiency and transparency to understand the specific characteristics that make these programs successful is essential moving forward into an era of big environmental data.",2024,,CALIFORNIA LAW REVIEW,112,,1535-1589,WOS:001342120800001,10.15779/Z38T727H47,,#4172,Brett 2024,"",""
OtterlyObsessedWithSemantics at SemEval-2024 Task 4: Developing a Hierarchical Multi-Label Classification Head for Large Language Models,"Wunderle, J; Schubert, J; Cacciatore, A; Zehe, A; Pfister, J; Hotho, A","This paper presents our approach to classifying hierarchically structured persuasion techniques used in memes for Task 4 Subtask 1 of SemEval 2024. We developed a custom classification head designed to be applied atop of a Large Language Model, reconstructing hierarchical relationships through multiple fully connected layers. This approach incorporates the decisions of foundational layers in subsequent, more fine-grained layers. To improve performance, we conducted a small hyperparameter search across various models and explored strategies for addressing uneven label distributions including weighted loss and thresholding methods. Furthermore, we extended our preprocessing to compete in the multilingual setup of the task by translating all documents into English. Finally, our system achieved third place on the English dataset and first place on the Bulgarian, North Macedonian and Arabic test datasets.",2024,,"PROCEEDINGS OF THE 18TH INTERNATIONAL WORKSHOP ON SEMANTIC EVALUATION, SEMEVAL-2024",,,602-612,WOS:001356736800090,,,#4173,Wunderle 2024,"",""
eHealth Initiatives for The Promotion of Healthy Lifestyle and Allied Implementation Difficulties,"IEEE; Chatterjee, A; Gerdes, MW; Martinez, S","Research in eHealth has opened a new dimension to improve personal healthcare with the help of information and communication technologies (ICT). eHealth is an 'umbrella term' for the use of ICT for health. Remote care-giving technologies (mHealth, Telehealth, Telemedicine) are an extended branch of eHealth initiatives. The concept of health e-Coaching is another promising initiative of eHealth research for real-time personalized lifestyle support. The focus of eHealth initiatives is to deliver high quality, evidence-based, secure, cost-effective, timely care to support people for sustaining a healthy lifestyle. However, the practical implementation of different eHealth initiatives has often been challenging to establish prophesied benefit. Health monitoring and fitness coaching with artificial intelligence will rule the coming decades. The pillars of e-Coaching initiatives are data collection, analysis of data, recommendation (sending the right message to the right people in the right context) and data security. An optimized system for health e-Coaching, management of a huge amount of health data, ensuring data protection are some big challenges to the eHealth researchers. Prediction of human psychology for effective e-Coaching recommendation is another level of difficulty to overcome as human behavior is constantly changing. Different eHealth initiatives for the promotion of healthy lifestyle and its implementation difficulties have been our primary focus of the review in this paper. This paper is a result of our early stage research related to 'Health e-Coaching recommendation system generation'. This paper will help young eHealth researchers to have a holistic idea on different eHealth technologies, initiatives till date for the promotion of healthy lifestyle and associated implementation challenges to overcome in the future.",2019,,"2019 INTERNATIONAL CONFERENCE ON WIRELESS AND MOBILE COMPUTING, NETWORKING AND COMMUNICATIONS (WIMOB)",,,,WOS:000521763100075,10.1109/wimob.2019.8923324,,#4174,IEEE 2019,"",""
The Language of (Non)Replicable Social Science,"Herzenstein, M; Rosario, S; Oblander, S; Netzer, O","Using publicly available data from 299 preregistered replications from the social sciences, we found that the language used to describe a study can predict its replicability above and beyond a large set of controls related to the article characteristics, study design and results, author information, and replication effort. To understand why, we analyzed the textual differences between replicable and nonreplicable studies. Our findings suggest that the language in replicable studies is transparent and confident, written in a detailed and complex manner, and generally exhibits markers of truthful communication, possibly demonstrating the researchers' confidence in the study. Nonreplicable studies, however, are vaguely written and have markers of persuasion techniques, such as the use of positivity and clout. Thus, our findings allude to the possibility that authors of nonreplicable studies are more likely to make an effort, through their writing, to persuade readers of their (possibly weaker) results.",2024,,PSYCHOLOGICAL SCIENCE,35,9,1048-1061,WOS:001291709600001,10.1177/09567976241254037,,#4175,Herzenstein 2024,"",""
Can You Spot the AI? Incorporating GenAI into Technical Writing Assignments,"Assoc Computing Machinery; Rajabi, P; Kerslake, C","In an effort to foster critical reflection on the usage of generative AI (genAI) during computer science writing assignments, this three-part assignment challenges students to predict whether their peers can detect which essays are generated using AI. Implemented as part of a third-year professional responsibility and technical writing course for N=200 students during Spring 2024, students individually generated two short persuasive essays, one using genAI and the other without. They then combined the two essays into a single document and submitted it for peer-review. Additionally, they formulated a guess on whether their peers would be able to detect which essay was generated as well as a rationale for their guess. Following the peer-review process, students reflected on their own experience trying to detect which essays were generated as well as the outcome of their guess about their peers abilities as well. Feedback indicates its effectiveness in engaging students in their understanding of the potentials and limitations of genAI. Recommended prerequisites include a clear course AI-usage policy and a brief overview of genAI prompt engineering.",2024,,"PROCEEDINGS OF THE 26TH WESTERN CANADIAN CONFERENCE ON COMPUTING EDUCATION, WCCCE 2024",,,,WOS:001256842000023,10.1145/3660650.3660673,,#4176,AssocComputingMachinery 2024,"",""
A Video Is Worth 4096 Tokens: Verbalize Videos To Understand Them In Zero Shot,"Bhattacharyya, A; Sing, YK; Krishnamurthy, B; Shah, RR; Chen, CY","Multimedia content, such as advertisements and story videos, exhibit a rich blend of creativity and multiple modalities. They incorporate elements like text, visuals, audio, and storytelling techniques, employing devices like emotions, symbolism, and slogans to convey meaning. There is a dearth of large annotated training datasets in the multimedia domain hindering the development of supervised learning models with satisfactory performance for real-world applications. On the other hand, the rise of large language models (LLMs) has witnessed remarkable zero-shot performance in various natural language processing (NLP) tasks, such as emotion classification, question-answering, and topic classification. To leverage such advanced techniques to bridge this performance gap in multimedia understanding, we propose verbalizing long videos to generate their descriptions in natural language, followed by performing video-understanding tasks on the generated story as opposed to the original video. Through extensive experiments on fifteen video-understanding tasks, we demonstrate that our method, despite being zero-shot, achieves significantly better results than supervised baselines for video understanding. Furthermore, to alleviate a lack of story understanding benchmarks, we publicly release the first dataset on a crucial task in computational social science on persuasion strategy identification.",2023,,2023 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2023),,,9822-9839,WOS:001378237101025,,,#4177,Bhattacharyya 2023,"",""
Unpacking the impact of AI vs. human-generated review summary on hotel booking intentions,"Jia, SZJ; Chi, OH; Chi, CG","This study investigates the impacts of the source of hotel review summary (AI-generated vs. human-generated) on customers' trust, information processing, and booking intentions through three scenario-based experiments involving 764 participants. Study 1 reveals that human-generated (vs. AI-generated) summaries lead to a higher level of trust, which boosts booking intentions. Study 2 finds that with negative reviews, there's no significant difference in booking intentions between AI and human-generated summaries, suggesting trust isn't the sole mediator. Study 3 proposes that information processing effort is a potential mediator. The findings confirm that when review valence is negative, customers invest more cognitive effort when reading AI-generated compared to human-generated summaries. The results challenge the assumption that human-generated reviews are inherently more persuasive. This research addresses critical gaps in understanding AI-generated content's impact on customer behavior in the hospitality industry, offering both theoretical contributions and practical insights for integrating AI technologies in customer communication strategies.",2025,,INTERNATIONAL JOURNAL OF HOSPITALITY MANAGEMENT,126,,,WOS:001373745600001,10.1016/j.ijhm.2024.104030,,#4178,Jia 2025,"",""
How Instructors Can Teach Students to Collaborate With Generative AI to Craft Effective Written Business Communications,"Zufelt, AH","As businesses begin utilizing generative AI to assist with written communications, professionals will need to have the skills to get the results employers demand. A working strategy to assist students on how to best collaborate with generative AI to create traditional business writing pieces is essential as we move to this new integrated workplace.",2025,,BUSINESS AND PROFESSIONAL COMMUNICATION QUARTERLY,88,2,359-374,WOS:001402780800001,10.1177/23294906241309846,,#4179,Zufelt 2025,"",""
The hallucinating chatbot 'ChatGPT' poorly estimates real bird commonness,"Zmihorski, M","Recent advances in artificial intelligence have led to the development of increasingly sophisticated chatbot technologies, with ChatGPT, developed by OpenAI, gaining significant popularity. As public awareness of environmental issues has grown during recent decades, there is an increasing demand for access to information about the environment. ChatGPT which offers free, real-time information via a user-friendly interface, has the potential to fill this gap. However, empirical evaluations of reliability and quality of information provided by chatbots are needed. In this study, the biological information provided by GPT-3.5 is evaluated. The commonness indices of 199 bird species in Poland, estimated by the ChatGPT, are correlated with the real commonness indices obtained during ornithological survey conducted across 700 1 x 1 km squares. Bird commonness indices pro-vided by ChatGPT were generally positively correlated (r <= 0.6) with bird abundance and occurrence. However, this correlation was not particularly strong. Correlation was especially poor for less common species (i.e., below 1000 individuals recorded during bird monitoring), and some of rare or very rare species were incorrectly identified by ChatGPT as relatively common. Moreover, ChatGPT seemed confident, realistic and persuasive in providing obviously incorrect responses (possibly due to lack of training data), much like it would for correct responses. Generating such false responses due to data deficiency is commonly referred to as ""hallucination"" of a chatbot. While chatbots can potentially be powerful tools for delivering environmental information, better control over the training process is necessary.",2023,,BIOLOGICAL CONSERVATION,288,,,WOS:001113587100001,10.1016/j.biocon.2023.110371,,#4180,Zmihorski 2023,"",""
AI vs. Human Voices: How Delivery Source and Narrative Format Influence the Effectiveness of Persuasion Messages,"Dai, Y; Lee, J; Kim, JW","AI communicators (e.g., AI voice assistants) play an increasingly important role in how individuals receive information, and, sometimes, calling for a more comprehensive understanding of the effectiveness of messages communicated through human and non-human sources. Through a web-based experiment (N = 228), we tested how the persuasive effects of messages are influenced by their format (narrative vs. non-narrative) and the communicator (human voice vs. AI voice) in the scenario of debunking myths about COVID-19 vaccination. The findings revealed that the human communicator was perceived to be more credible and had more influence on participants' attitude than the AI communicator. Further, the human communicator was particularly persuasive than the AI communicator in delivering a narrative persuasive message, but the effect was not mediated by perceived communicator credibility. The findings augment the literature on narrative persuasion by comparing human and non-human communicators as the delivery source. It also reveals the importance of considering non-human information communicators in research on narrative persuasive messages.",2024,,INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION,40,24,8735-8749,WOS:001115143700001,10.1080/10447318.2023.2288734,,#4181,Dai 2024,"",""
Persuading across Diverse Domains: A Dataset and Persuasion Large Language Model,"Jin, CH; Ren, KN; Kong, LZ; Wang, XT; Song, RH; Chen, H","Persuasive dialogue requires multi-turn following and planning abilities to achieve the goal of persuading users, which is still challenging even for state-of-the-art large language models (LLMs). Previous works focus on retrieval-based models or generative models in a specific domain due to a lack of data across multiple domains. In this paper, we leverage GPT-4 to create the first multi-domain persuasive dialogue dataset DailyPersuasion. Then we propose a general method named PersuGPT to learn a persuasion model based on LLMs through intent-to-strategy reasoning, which summarizes the intent of user's utterance and reasons next strategy to respond. Moreover, we design a simulation-based preference optimization, which utilizes a learned user model and our model to simulate next turns and estimate their rewards more accurately. Experimental results on two datasets indicate that our proposed method outperforms all baselines in terms of automatic evaluation metric Win-Rate and human evaluation. The code and data are available at https://persugpt.github.io.",2024,,"PROCEEDINGS OF THE 62ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1: LONG PAPERS",,,1678-1706,WOS:001356729801043,,,#4182,Jin 2024,"",""
Digital Mental Health Apps: Key Features and User Engagement for Better Wellness,"Rocha, C; Martinho, D; Conceicao, L; Novais, P; Marreiros, G","Given the global impact of mental disorders and the increasing prevalence of Major Depressive Disorder (MDD) as one of the main causes of disability, it is imperative to invest in solutions for self-management of mental health. Thus, the evolution of Digital Mental Health reveals a significant impact, with major investment in technologies that drive the development of projects that aim to innovate the benefits and results of this area. As part of the development of the RM4Health project, this work evaluated the role of web, desktop and/or mobile applications in the self-management of mental health, highlighting existing strengths and gaps. The study covered 205 applications for the management of mental health, detailing the panorama of current Behavioral Management practices, Persuasive Systems Design (PSD), Behavioral Economics (BE) principles and Security and Privacy strategies. The results obtained in this survey allow the definition of recommendations for the development of more effective, engaging, accessible and safe solutions, to promote autonomy in the management of the mental health condition. A high diversity of resources was observed, however areas of underutilization were identified, especially in BE approaches. It is recommended to combine Artificial Intelligence, Smart Coach and Gamification strategies with robust security and privacy measures. Furthermore, the development of comprehensive and intuitive solutions that prioritize key behavioral management functionalities, PSD resources and BE principles that involve the user in their own health management, regardless of whether they have been diagnosed with a mental disorder, were suggested. This study could guide future research and development in order to improve the quality of the user experience and drive advances in the field of Digital Mental Health.",2025,,"INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2024, PT I",15346,,434-446,WOS:001422227800039,10.1007/978-3-031-77731-8_39,,#4183,Rocha 2025,"",""
"COPYRIGHT PROTECTION FOR COMPUTER-PROGRAMS, DATABASES, AND COMPUTER-GENERATED WORKS - IS ANYTHING NEW SINCE CONTU","MILLER, AR","In 1976, Congress created the National Commission on New Technological Uses of Copyrighted Works (CONTU) to examine the implications of computer and other information technologies and to advise Congress on whether it would be wise to assimilate these new technologies into the existing copyright regime. Ever since, a number of people have voiced criticisms of CONTU's recommendations, arguing for a modification of the current copyright regime or even a different legal structure for these issues. Although these critics have many different approaches, they share the fear that incorporating these technologies into the current copyright system will lead to overprotection. In this Article, Professor Miller examines these arguments and concludes that CONTU's recommendations were correct and that the current regime is flexible enough to address the critics' concerns. First, Professor Miller surveys the progress of the court decisions involving computer programs, and demonstrates that a set of coherent copyright principles is beginning to develop in this area. Next, Professor Miller discusses the newer phenomenon of artificial intelligence, and utilizes copyright principles that have developed in the areas of computer programs and databases to demonstrate that at its current stage of development, artificial intelligence does not pose any significant obstacles to copyright analysis. Finally, Professor Miller addresses the claim that it eventually will be impossible to assimilate computer-generated works into the copyright system because they may have no obvious human author, and concludes not only that the caselaw contains no persuasive objection to extending copyright protection to these works, but also that such an extension would fulfill the constitutional imperative of promoting Progress in these areas.",1993,,HARVARD LAW REVIEW,106,5,978-1073,WOS:A1993KU51900001,,,#4184,MILLER 1993,"",""
Harnessing Large Language Models for Automatic Evaluation of Mobile Health Applications Based on Persuasive System Design Principles and Mobile Application Rating Scale,"Afsin, Y; Temizel, TT","Mobile applications have seen a growing prevalence in the healthcare sector, yet the absence of comprehensive regulations and preliminary assessments can lead to significant frustration and time loss for users. To address this, Persuasive System Design (PSD) principles and the Mobile App Rating Scale (MARS) have emerged as popular tools for gauging application quality and user engagement. However, their manual assessment requirements hinder scalability, especially given the high volume of mobile health applications in the market. This study introduces a novel automatic evaluation approach designed to enhance the assessment of mobile health applications, leveraging PSD and MARS. The proposed method mainly relies on large language models to filter user reviews and generate sentence embeddings for classifying the PSD principles implemented in these applications. The results, calculated using performance metrics that compare the model's predictions with expert evaluations, demonstrate the feasibility of predicting the application's implementation of PSD principles based on user reviews while also highlighting the limitations of using application descriptions alone for successful prediction. Furthermore, the study augments the predicted classification probabilities of PSD principles with supplementary descriptive data, such as installation counts and user ratings, to predict MARS scores. Regression models, trained using these techniques, consistently outperform basic models, with feature importance scores showing the significant contribution of predicted classification probabilities of PSD principles to the models. In summary, this study suggests that automatic evaluation techniques can effectively assess the quality and user engagement of mobile health applications, offering a viable alternative to manual assessments.",2024,,"PERSUASIVE TECHNOLOGY, PERSUASIVE 2024",14636,,1-14,WOS:001280411900001,10.1007/978-3-031-58226-4_1,,#4185,Afsin 2024,"",""
Controllable Mixed-Initiative Dialogue Generation through Prompting,"Chen, M; Yu, X; Shi, WY; Awasthi, U; Yu, Z","Mixed-initiative dialogue tasks involve repeated exchanges of information and conversational control. Conversational agents gain control by generating responses that follow particular dialogue intents or strategies, prescribed by a policy planner. The standard approach has been fine-tuning pre-trained language models to perform generation conditioned on these intents. However, these supervised generation models are limited by the cost and quality of data annotation. We instead prompt large language models as a drop-in replacement to fine-tuning on conditional generation. We formalize prompt construction for controllable mixed-initiative dialogue. Our findings show improvements over fine-tuning and ground truth responses according to human evaluation and automatic metrics for two tasks: PersuasionForGood and Emotional Support Conversations.",2023,,"61ST CONFERENCE OF THE THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 2",,,951-966,WOS:001181088800082,,,#4186,Chen 2023,"",""
An Improved Artificial Colony Algorithm Model for Forecasting Chinese Electricity Consumption and Analyzing Effect Mechanism,"Wang, JM; Zhang, J; Nie, J","Electricity consumption forecast is perceived to be a growing hot topic in such a situation that China's economy has entered a period of new normal and the demand of electric power has slowed down. Therefore, exploring Chinese electricity consumption influence mechanism and forecasting electricity consumption are crucial to formulate electrical energy plan scientifically and guarantee the sustainable economic and social development. Research has identified medium and long term electricity consumption forecast as a difficult study influenced by various factors. This paper proposed an improved Artificial Bee Colony (ABC) algorithm which combined with multivariate linear regression (MLR) for exploring the influencing mechanism of various factors on Chinese electricity consumption and forecasting electricity consumption in the future. The results indicated that the improved ABC algorithm in view of the various factors is superior to traditional models just considering unilateralism in accuracy and persuasion. The overall findings cast light on this model which provides a new scientific and effective way to forecast the medium and long term electricity consumption.",2016,,MATHEMATICAL PROBLEMS IN ENGINEERING,2016,,,WOS:000382629700001,10.1155/2016/8496971,,#4187,Wang 2016,"",""
Emotional Reframing of Economic News using a Large Language Model,"ACM; Jeng, JH; Kasangu, GAB; Starke, AD; Trattner, C","News media framing can shape public perception and potentially polarize views. Emotional language can exacerbate these framing effects, as a user's emotional state can be an important contextual factor to use in news recommendation. Our research explores the relation between emotional framing techniques and the emotional states of readers, as well as readers' perceived trust in specific news articles. Users (N = 200) had to read three economic news articles from the Washington Post. We used ChatGPT-4 to reframe news articles with specific emotional languages (Anger, Fear, Hope), compared to a neutral baseline reframed by a human journalist. Our results revealed that negative framing (Anger, Fear) elicited stronger negative emotional states among users than the neutral baseline, while Hope led to little changes overall. In contrast, perceived trust levels varied little across the different conditions. We discuss the implications of our findings and how emotional framing could affect societal polarization issues.",2024,,"ADJUNCT PROCEEDINGS OF THE 32ND ACM CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION, UMAP 2024",,,231-235,WOS:001263797000047,10.1145/3631700.3665191,,#4188,ACM 2024,"",""
Virtual education strategies in the context of sustainable health care and medical education: A topic modelling analysis of four decades of research,"Lee, JHY; Kim, H; Kron, F","BackgroundThe growing importance of sustainability has led to the current literature being saturated with studies on the necessity of, and suggested topics for, education for sustainable health care (ESH). Even so, ESH implementation has been hindered by educator unpreparedness and resource scarcity. A potential resolution lies in virtual education. However, research on the strategies needed for successfully implementing virtual education in the context of sustainable health care and medical education is sparse; this study aims to fill the gap.MethodsTopic modelling, a computational text-mining method for analysing recurring patterns of co-occurring word clusters to reveal key topics prevalent across the texts, was used to examine how sustainability was addressed in research in medicine, medical education, and virtual education. A total of 17 631 studies, retrieved from Web of Science, Scopus and PubMed, were analysed.ResultsSustainability-related topics within health care, medical education and virtual education provided systematic implications for Sustainable Virtual Medical Education (SVME)-ESH via virtual platforms in a sustainable way. Analyses of keywords, phrases, topics and their associated networks indicate that SVME should address the three pillars of environmental, social and economic sustainability and medical practices to uphold them; employ different technologies and methods including simulations, virtual reality (VR), artificial intelligence (AI), cloud computing, distance learning; and implement strategies for collaborative development, persuasive diffusion and quality assurance.ConclusionsThis research suggests that sustainable strategies in virtual education for ESH require a systems approach, encompassing components such as learning content and objectives, evaluation, targeted learners, media, methods and strategies. The advancement of SVME necessitates that medical educators and researchers play a central and bridging role, guiding both the fields of sustainable health care and medical education in the development and implementation of SVME. In this way, they can prepare future physicians to address sustainability issues that impact patient care.",2024,,MEDICAL EDUCATION,58,1,47-62,WOS:001075396100001,10.1111/medu.15202,,#4189,Lee 2024,"",""
Enhancing mechanical performance of steel-tube-encased HSC composite walls: Experimental investigation and analytical modeling,"Zy, C; Wang, RY; Meng, YH; Wu, HK; Lai, B; Chen, T","This paper discusses the study of concrete composite walls of algorithmic modeling, in which steel tubes are embedded. The load-bearing capacity of STHC composite walls increases with the increase of axial load coefficient, but its ductility decreases. The load-bearing capacity can be improved by increasing the strength of the steel pipes; however, the elasticity of STHC composite walls was found to be slightly reduced. As the shear stress coefficient increases, the load-bearing capacity of STHC composite walls decreases significantly, while the deformation resistance increases. By analyzing actual cases, we demonstrate the effectiveness of the research results in real situations and enhance the persuasiveness of the conclusions. The research results can provide a basis for future research, inspire more explorations on seismic design and construction, and further advance the development of this field. Emphasize the importance of research results, promote interdisciplinary cooperation in the fields of structural engineering, earthquake engineering, and materials science, and improve overall seismic resistance. The emphasis on these aspects will help highlight the practical impact of the research results, further strengthen the conclusions, and promote progress in the design and construction of earthquake-resistant structures. The goals of this work are access to adequate, safe and affordable housing and basic services, promotion of inclusive and sustainable urbanization and participation, implementation of sustainable and disaster-resilient architecture, sustainable planning and management of human settlements. Simulation results of linear and nonlinear structures show that this method can detect structural parameters and their changes due to damage and unknown disturbances. Therefore, it is believed that with the further development of fuzzy neural network artificial intelligence theory, this goal will be achieved in the near future.",2024,,STEEL AND COMPOSITE STRUCTURES,52,6,647-656,WOS:001330580500004,10.12989/scs.2024.52.6.647,,#4190,Zy 2024,"",""
Unveiling Information Through Narrative In Conversational Information Seeking,"ASSOC COMPUTING MACHINERY; Javadi, VS; Trippas, JR; Flek, L","Searching through conversational interactions has been emphasized as the next frontier. Nowadays, conversational agents can generate natural language responses, transforming how we search for information. A key challenge in conversational information-seeking is how these agents present information: should they only reflect facts, cater to human cognitive preferences, or strike a balance between them? These challenges raise questions about aligning conversational agents with human cognitive processes. Our position paper emphasizes the role of narrative in addressing these questions. We explore how narratives influence human comprehension and propose a framework for optimal conversational narratives. These narratives aim to enhance interaction between humans and conversational agents in explanatory information-seeking scenarios.",2024,,"PROCEEDINGS OF THE 6TH CONFERENCE ON ACM CONVERSATIONAL USER INTERFACES, CUI 2024",,,,WOS:001270693400057,10.1145/3640794.3665884,,#4191,ASSOCCOMPUTINGMACHINERY 2024,"",""
Empowering Calibrated (Dis-)Trust in Conversational Agents: A User Study on the Persuasive Power of Limitation Disclaimers vs. Authoritative Style,"ACM; Metzger, L; Miller, L; Baumann, M; Kraus, J","While conversational agents based on Large Language Models (LLMs) can drive progress in many domains, they are prone to generating faulty information. To ensure an efficient, safe, and satisfactory user experience maximizing benefits of these systems, users must be empowered to judge the reliability of system outputs. In this, both disclaimers and agents' communicative style are pivotal design instances. In an online study with 594 participants, we investigated how these affect users' trust and a mock-up agent's persuasiveness, based on an established framework from social psychology. While prior information on potential inaccuracies or faulty information did not affect trust, an authoritative communicative style elicited more trust. Also, a trusted agent was more persuasive resulting in more positive attitudes regarding the subject of the conversation. Results imply that disclaimers on agents' limitations fail to effectively alter users' trust but can be supported by appropriate communicative style during interaction.",2024,,"PROCEEDINGS OF THE 2024 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYTEMS, CHI 2024",,,,WOS:001255317904023,10.1145/3613904.3642122,,#4192,ACM 2024,"",""
Affect intensity and the consumer's attitude toward high impact emotional advertising appeals,"Moore, DJ; Harris, WD","Subjects scoring high on the Affect Intensity Measurement (AIM) scale responded with greater emotional intensity than low AI subjects to both positive and negative emotional appeals. These high AI individuals also expressed more positive attitudes and higher Levels of enjoyment of the positive emotional appeal. However, in response to the negative emotional appeal, high AI and low AI subjects did not differ in ad enjoyment level or attitude toward the ad. Emotional responses mediated the effects of affect intensity on attitude toward the ad only when subjects were exposed to the positive emotional appeal. Theoretical and managerial implications of the effect of affect intensity on the recipient's attitude toward high impact emotional advertising appeals are discussed.",1996,,JOURNAL OF ADVERTISING,25,2,37-50,WOS:A1996VB73600003,10.1080/00913367.1996.10673498,,#4193,Moore 1996,"",""
Snarci at SemEval-2024 Task 4: Themis Model for Binary Classification of Memes,"Zedda, L; Perniciano, A; Loddo, A; Di Ruberto, C; Sanguinetti, M; Atzori, M","This paper introduces an approach developed for multimodal meme analysis, specifically targeting the identification of persuasion techniques embedded within memes. Our methodology integrates Large Language Models (LLMs) and contrastive learning image encoders to discern the presence of persuasive elements in memes across diverse platforms. By capitalizing on the contextual understanding facilitated by LLMs and the discriminative power of contrastive learning for image encoding, our framework provides a robust solution for detecting and classifying memes with persuasion techniques. The system was used in Task 4 of Semeval 2024, precisely for Substask 2b (binary classification of presence of persuasion techniques). It showed promising results overall, achieving a Macro-F-1 = 0.7986 on the English test data (i.e., the language the system was trained on) and Macro-F-1 = 0.66777/0.47917/0.5554, respectively, on the other three ""surprise"" languages proposed by the task organizers, i.e., Bulgarian, North Macedonian and Arabic. The paper provides an overview of the system, along with a discussion of the results obtained and its main limitations.",2024,,"PROCEEDINGS OF THE 18TH INTERNATIONAL WORKSHOP ON SEMANTIC EVALUATION, SEMEVAL-2024",,,853-858,WOS:001356736800122,,,#4194,Zedda 2024,"",""
Influencer marketing and the growth of affiliates: The effects of language features on engagement behavior,"Syrdal, HA; Myers, S; Sen, S; Woodroof, PJ; McDowell, WC","Although most major brands are utilizing affiliate marketing programs, potential drivers of engagement with influencer affiliate marketing content have yet to be explored. To address this gap, the authors apply the Elaboration Likelihood Model to propose that linguistic characteristics of the text within influencers' affiliate marketing posts motivate either peripheral or central route processing, which in turn impacts behavioral in-teractions with the content. To empirically test these relationships, text mining and natural language processing are used to construct a large dataset of influencers' affiliate marketing posts from their Instagram feeds. The analysis reveals certain linguistic styles can enhance engagement, while others negatively impact these behav-iors. In addition to advancing understanding of influencer affiliate marketing and social media engagement, the findings offer important insights for both brands and influencers participating in affiliate marketing.",2023,,JOURNAL OF BUSINESS RESEARCH,163,,,WOS:000984730100001,10.1016/j.jbusres.2023.113875,,#4195,Syrdal 2023,"",""
Deception detection in educational AI: challenges for Japanese middle school students in interacting with generative AI robots,"Salem, A; Sumi, K","Educational materials that utilize generative AI (e.g., ChatGPT) have been developed, thus, allowing students to learn through conversations with robots or agents. However, if these artificial entities provide incorrect information (hallucinating), it could lead to confusion among students. To investigate whether students can detect lies from these artificial entities, we conducted an experiment using the social robot Furhat and we make it engage in various types of deceptive interactions. Twenty-two Japanese middle school students participated in ten teaching sessions with Furhat using a human and an anime facial appearances while employing different types of deception: Lying, Paltering, Pandering, and Bullshit. The results revealed that the majority of students were deceived by those lies. Additionally, the robot's facial appearance (i.e., social agency) affected both the learning effectiveness and the likelihood of being deceived. We conclude that an anime robot face is recommended to be used as it excelled in learning effectiveness as it attracts students attention. An anime face also provided protection against deceptive techniques due to its low social agency which leads to ineffectiveness in persuasion and deception. This study underscores the importance of preparing AI-based educational tools and scripts carefully to prevent the dissemination of false information produced through generative AI hallucinations to students.",2024,,FRONTIERS IN ARTIFICIAL INTELLIGENCE,7,,,WOS:001387445600001,10.3389/frai.2024.1493348,,#4196,Salem 2024,"",""
An Analysis of the Interaction Between Intelligent Software Agents and Human Users,"Burr, C; Cristianini, N; Ladyman, J","Interactions between an intelligent software agent (ISA) and a human user are ubiquitous in everyday situations such as access to information, entertainment, and purchases. In such interactions, the ISA mediates the user's access to the content, or controls some other aspect of the user experience, and is not designed to be neutral about outcomes of user choices. Like human users, ISAs are driven by goals, make autonomous decisions, and can learn from experience. Using ideas from bounded rationality (and deploying concepts from artificial intelligence, behavioural economics, control theory, and game theory), we frame these interactions as instances of an ISA whose reward depends on actions performed by the user. Such agents benefit by steering the user's behaviour towards outcomes that maximise the ISA's utility, which may or may not be aligned with that of the user. Video games, news recommendation aggregation engines, and fitness trackers can all be instances of this general case. Our analysis facilitates distinguishing various subcases of interaction (i.e. deception, coercion, trading, and nudging), as well as second-order effects that might include the possibility for adaptive interfaces to induce behavioural addiction, and/or change in user belief. We present these types of interaction within a conceptual framework, and review current examples of persuasive technologies and the issues that arise from their use. We argue that the nature of the feedback commonly used by learning agents to update their models and subsequent decisions could steer the behaviour of human users away from what benefits them, and in a direction that can undermine autonomy and cause further disparity between actions and goals as exemplified by addictive and compulsive behaviour. We discuss some of the ethical, social and legal implications of this technology and argue that it can sometimes exploit and reinforce weaknesses in human beings.",2018,,MINDS AND MACHINES,28,4,735-774,WOS:000452516200006,10.1007/s11023-018-9479-0,,#4197,Burr 2018,"",""
"""THE TRIBUNE OF STRASTNOY BOULEVARD"": THE LANGUAGE PERSONALITY OF THE PUBLICIST MIKHAIL KATKOV","Perevalova, EV; Petrushina, MV","The article attempts to analyze the language personality of the authoritative conservative publicist Mikhail Katkov, who in 1863-1887 was the editor-publisher of the influential newspaper Moskovskie Vedomosti. The relevance of the stated problem is due to the growing interest in modern science in the study of the conservative press of the second half of the 19th century, its influence on public consciousness and the formation of ideological attitudes of the audience. The scientific novelty of the research consists in the introduction of new, previously unexplored material into scholarly discourse, in the analysis of Katkov's journalistic texts for the purpose of studying the structure and content of his language personality. The methodological basis of the study consists of works of Yu.N. Karaulov, W. von Humboldt, V.V. Vinogradov, E.D. Polivanov, M.M. Bakhtin, G.I. Bogin, V.A. Maslova, V.V. Ledeneva, T.V. Shmeleva. The level model of language personality proposed by Yu.N. Karaulov was implemented in the study of Katkov's language personality in the form of a comprehensive analysis of all three components: lexicon, thesaurus, and pragmaticon. The analysis of the thesaurus allowed us to demonstrate how Katkov's views were embodied in the concepts he implemented, the hierarchy of these concepts, as a result of the publicist's political preferences. The article presents a full range of language tools and techniques, with special attention paid to metaphor, which allowed us to conclude that Katkov's texts generated a type of journalistic metaphor new for that time, the main function of which is evaluation. A detailed study of the thesaurus and the lexicon that embodies its features allowed us to conclude that the highest level of Katkov's language personality - the pragmatist - reflects the national specifics and features of the publicist's linguistic and axiological picture of the world. In the course of the analysis, it became obvious that a large role in Katkov's texts, and therefore in the structure of his language personality, is played by various means of syntax. First of all, this represents such an important feature of Katkov as the logical presentation. The main functional type of text used by Katkov is reasoning; the syntactic forms and structures used by the publicist implement a variety of strategies and tactics of persuasion, which allows us to consider his language personality as the quintessence of oratorical skill. It is revealed that the language personality of Katkov reflects the peculiarities of his worldview, scientific and logical thinking, moral and ethical ideas, political views, national and cultural mentality. The linguostylistic and pragmatic analysis of the texts of Katkov's publications allowed us to conclude that his language personality is characterized by a variety of linguistic representations and a variety of possibilities in the expression of meanings, which was one of the reasons for such a strong influence of his journalistic texts on the audience.",2024,,TEKST KNIGA KNIGOIZDANIE-TEXT BOOK PUBLISHING,36,,,WOS:001422813000004,10.17223/23062061/36/4,,#4198,Perevalova 2024,"",""
"Whately on Authority, Deference, Presumption and Burden of Proof","Walton, D; Koszowy, M","This paper shows how Whately's view of presumption as a preoccupation of the ground plays an indispensable role in the study of persuasive aspects of appeals to authority and deference. This is done by showing how important connections among arguments from authority, presumption, burden of proof, and deference can be precisely defined, combined, and fitted into a formal argumentation framework for responding to arguments from expert opinion and analyzing the ad verecundiam fallacy. As the inquiry into Whately's ideas also reveals links between Aristotelian topics and dialectic later brought out by Perelman, it constitutes an illustration showing how the study of various historically important rhetorical ideas allows us to develop contemporary models of arguments.",2018,,RHETORICA-A JOURNAL OF THE HISTORY OF RHETORIC,36,2,179-204,WOS:000434761600004,10.1525/rh.2018.36.2.179,,#4199,Walton 2018,"",""
Leveraging ChatGPT for Automated Human-centered Explanations in Recommender Systems,"Assoc Computing Machinery; Silva, I; Marinho, LB; Said, A; Willemsen, M","The adoption of recommender systems (RSs) in various domains has become increasingly popular, but concerns have been raised about their lack of transparency and interpretability. While significant advancements have been made in creating explainable RSs, there is still a shortage of automated approaches that can deliver meaningful and contextual human-centered explanations. Numerous researchers have evaluated explanations based on human-generated recommendations and explanations to address this gap. However, such approaches do not scale for real-world systems. Building on recent research that exploits Large Language Models (LLMs) for RSs, we propose leveraging the conversational capabilities of ChatGPT to provide users with personalized, human-like, and meaningful explanations for recommended items. Our paper presents one of the first user studies that measure users' perceptions of ChatGPT-generated explanations while acting as an RS. Regarding recommendations, we assess whether users prefer ChatGPT over random (but popular) recommendations. Concerning explanations, we assess users' perceptions of personalization, effectiveness, and persuasiveness. Our findings reveal that users tend to prefer ChatGPT-generated recommendations over popular ones. Additionally, personalized rather than generic explanations prove to be more effective when the recommended item is unfamiliar.",2024,,"PROCEEDINGS OF 2024 29TH ANNUAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2024",,,597-608,WOS:001209687500038,10.1145/3640543.3645171,,#4200,AssocComputingMachinery 2024,"",""
Formal systems for persuasion dialogue,"Prakken, H","This article reviews formal systems that regulate persuasion dialogues. In such dialogues two or more participants aim to resolve a difference of opinion, each trying to persuade the other participants to adopt their point of view. Systems for persuasion dialogue have found application in various fields of computer science, such as non-monotonic logic, artificial intelligence and law, multi-agent systems, intelligent tutoring and computer-supported collaborative argumentation. Taking a game-theoretic view on dialogue systems, this review proposes a formal specification of the main elements of dialogue systems for persuasion and then uses it to critically review some of the main formal systems for persuasion. The focus of this review will be on regulating the interaction between agents rather than on the design and behaviour of individual agents within a dialogue.",2006,,KNOWLEDGE ENGINEERING REVIEW,21,2,163-188,WOS:000240572500003,10.1017/S0269888906000865,,#4201,Prakken 2006,"",""
A dialogue system specification for explanation,"Walton, D","This paper builds a dialectical system of explanation with speech act rules that define the kinds of moves allowed, like requesting and offering an explanation. Pre and post-condition rules for the speech acts determine when a particular speech act can be put forward as a move in the dialogue, and what type of move or moves must follow it. A successful explanation has been achieved when there has been a transfer of understanding from the party giving the explanation to the party asking for it. The dialogue has an opening stage, an explanation stage and a closing stage. Whether a transfer of understanding has taken place is tested by a dialectical shift to an examination dialogue.",2011,,SYNTHESE,182,3,349-374,WOS:000294542100002,10.1007/s11229-010-9745-z,,#4202,Walton 2011,"",""
Analysis and classification of spam email using Artificial Intelligence to identify cyberthreats,"Martino, F","of the Ph.D. thesis written by Francisco Ja & nacute;ez Martino and supervised by Prof. Dra. Roc & imath;o Alaiz Rodr & imath;guez and Dr. V & imath;ctor Gonzalez Castro at Universidad de Leon. The defense of the thesis was in Leon (Spain) in 21st of December 2023 by a committee formed by Dr. Arturo Montejo Raez (Universidad de Jaen, Spain), Dr. Petr Motlicek (Idiap Research Institute, Switzerland), and Dra. Laura Fernandez Robles (Universidad de Leon, Spain). An international mention was garnered following a six-month tenure at the Universita di Bologna under the supervision of Dr. Alberto Barron Cede & nacute;o. This Ph.D. thesis was awarded an outstanding Cum Laude grade.",2024,,PROCESAMIENTO DEL LENGUAJE NATURAL,,72,155-158,WOS:001196288500004,10.26342/2024-72-12,,#4203,Martino 2024,"",""
AI recommendation vs. crowdsourced recommendation vs. travel expert recommendation: The moderating role of consumption goal on travel destination decision,"Park, YE; Son, H","This research investigates the effects of recommender type (AI versus crowdsourcing versus travel expert) and consumption goal (utilitarian versus hedonic) on consumer responses to travel destination recommendation email advertisements. Across two experiments, findings reveal that consumers held the most favorable attitude toward email advertisements featuring travel expert recommendations compared to crowdsourced or AI-generated suggestions. Notably, this study highlights the moderating role of consumption goal type (utilitarian vs. hedonic) in shaping attitudes toward the recommendation source. Specifically, consumers preferred ads featuring AI-generated recommendations for utilitarian travel goals (e.g., business trips), while for hedonic travel goals (e.g., romantic getaways), they favored ads with crowdsourced suggestions. Through serial mediation (Study 1) and moderated serial mediation (Study 2), this research further elucidates the underlying psychological mechanisms driving these effects.",2025,,PLOS ONE,20,3,,WOS:001449697200035,10.1371/journal.pone.0318719,,#4204,Park 2025,"",""
Sponsorship Disclosure in Virtual Influencer Marketing: Assessing Users' Sentiment and Engagement Toward Virtual Influencer Endorsements,"Looi, J; Kim, E; Zihang, E","This study evaluates how sponsorship disclosure affects users' parasocial interaction with virtual influencers (VIs). Sentiment analysis of 48,147 comments (sponsored = 20,411, non-sponsored = 27,736) indicated that users expressed more positive sentiment toward the VI's sponsorship disclosure. Topic modeling revealed that, regardless of sponsorship disclosure, users were confused about the VI's identity and expressed mixed emotions. Users also behaved differently toward the VI's sponsorship disclosure. An online experiment (N = 159) found that users who encountered non-sponsored content displayed greater likelihood for parasocial interaction and post engagement. The mediating role of persuasion knowledge was non-significant, challenging the persuasion knowledge model.",2025,,JOURNAL OF ADVERTISING RESEARCH,,,,WOS:001477900000001,10.1080/00218499.2025.2464300,,#4205,Looi 2025,"",""
MELODI at SemEval-2023 Task 3: In-domain Pre-training for Low-resource Classification of News Articles,"Devatine, N; Müller, P; Braud, C","This paper describes our approach to Subtask 1 ""News Genre Categorization"" of SemEval2023 Task 3 ""Detecting the Category, the Framing, and the Persuasion Techniques in Online News in a Multi-lingual Setup"", which aims to determine whether a given news article is an opinion piece, an objective report, or satirical. We fine-tuned the domain-specific language model POLITICS, which was pre-trained on a large-scale dataset of more than 3.6M English political news articles following ideology-driven pre-training objectives. In order to use it in the multilingual setup of the task, we added as a pre-processing step the translation of all documents into English. Our system ranked among the top systems overall in most language, and ranked 1st on the English dataset.",2023,,"17TH INTERNATIONAL WORKSHOP ON SEMANTIC EVALUATION, SEMEVAL-2023",,,108-113,WOS:001281001900013,,,#4206,Devatine 2023,"",""
"Continuity of Topic, Interaction, and Query: Learning to Quote in Online Conversations","Assoc Computat Linguist; Wang, LZ; Jing, L; Zeng, XS; Zhang, HS; Wong, KF","Quotations are crucial for successful explanations and persuasions in interpersonal communications. However, finding what to quote in a conversation is challenging for both humans and machines. This work studies automatic quotation generation in an online conversation and explores how language consistency affects whether a quotation fits the given context. Here, we capture the contextual consistency of a quotation in terms of latent topics, interactions with the dialogue history, and coherence to the query turn's existing content. Further, an encoder-decoder neural framework is employed to continue the context with a quotation via language generation. Experiment results on two large-scale datasets in English and Chinese demonstrate that our quotation generation model outperforms the state-of-the-art models. Further analysis shows that topic, interaction, and query consistency are all helpful to learn how to quote in online conversations.",2020,,PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP),,,6640-6650,WOS:000855160706071,,,#4207,AssocComputatLinguist 2020,"",""
Prognostication of waste water treatment plant performance using efficient soft computing models: An environmental evaluation,"Najafzadeh, M; Zeinolabedini, M","The chief purpose of designing the wastewater treatment plant (WWTP) is to provide a suitable system which is capable of eliminating the excessive impurities or pollutants found in the influent to the desired level. In this way, daily flow rates is one of the most crucial components to contribute in order to design wastewater treatment processes and plant units. So, in the present research work, various soft computing approaches including feed forward back propagation neural network (FFBP-NN), radial basis function neural network (RBF-NN), adaptive neuro-fuzzy inference system (ANFIS), and support vector machine (SVM) were employed to predict daily flow rates for the WWTP. To develop artificial intelligence models, flow rates datasets has been used over a five-year period. The performance of the proposed models were assessed for training and testing stages using statistical error indicators. Performance of techniques indicated that SVM (RMSE = 1435.4 and MAE = 1031.1) and FFBP-NN (RMSE = 1445.9 and MAE = 1036.7) techniques have provided more precise prediction of flow rates compared to the ANFIS (RMSE = 1515.6 and MAE = 1075.4) and RBF-NN (RMSE = 1501 and MAE = 1048.7). This study was proven that soft computing techniques, as robust tools, can be efficiently applied to design the flow rates in the WWTP with a persuasive degree of accuracy. (C) 2019 Elsevier Ltd. All rights reserved.",2019,,MEASUREMENT,138,,690-701,WOS:000464636400064,10.1016/j.measurement.2019.02.014,,#4208,Najafzadeh 2019,"",""
Enrichment of Turkish question answering systems using knowledge graphs,"Çiftçi, O; Soygazi, F; Tekir, S","Recent capabilities of large language models (LLMs) have transformed many tasks in Natural Language Processing (NLP), including question answering. The state-of-the-art systems do an excellent job of responding in a relevant, persuasive way but cannot guarantee factuality. Knowledge graphs, representing facts as triplets, can be valuable for avoiding errors and inconsistencies with real-world facts. This work introduces a knowledge graph-based approach to Turkish question answering. The proposed approach aims to develop a methodology capable of drawing inferences from a knowledge graph to answer complex multihop questions. We construct the Beyazperde Movie Knowledge Graph (BPMovieKG) and the Turkish Movie Question Answering dataset (TRMQA) to answer questions in the movie domain. We evaluate our proposed question answering pipeline against a baseline study. Furthermore, we compare it with a question answering system built upon GPT-3.5 Turbo to answer the 1-hop questions from TRMQA. The experimental results confirm that link prediction on a knowledge graph is quite effective in answering questions that require reasoning paths. Finally, we provide insights into the pros and cons of the provided solution through a qualitative study.",2024,,TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES,32,4,,WOS:001280878700002,10.55730/1300-0632.4085,,#4209,Çiftçi 2024,"",""
Predicting reward-based crowdfunding success with multimodal data: A theory-guided framework,"Bao, LQ; Chen, G; Liu, ZX; Xiao, SY; Zhao, HM","There is a growing need to investigate the impact of multimodal data, which are becoming increasingly prevalent on crowdfunding platforms, on prediction of fundraising outcomes. However, a prediction framework drawing upon rational theoretical foundations to leverage multimodal data in crowdfunding is still lacking. Guided by relevant theories, we explore the ideational, interpersonal, and textual metafunctions of multimodal data geared toward fundraising success prediction. Our empirical evaluation demonstrates superior predictive utilities of various metafunction-based multimodal features over purely data-driven ones. Our results also reveal that the multiple data modalities interact complementarily and synergistically to improve the prediction performance. Specifically, combining metafunctions improved prediction performance by 2-15 % over a single metafunction, while multimodality outperformed single data modality by 7-18 % within each metafunction.",2025,,INFORMATION & MANAGEMENT,62,4,,WOS:001443677600001,10.1016/j.im.2025.104131,,#4210,Bao 2025,"",""
The STAR-C Intelligent Coach: A Cross-Disciplinary Design Process of a Behavior Change Intervention in Primary Care,"Lindgren, H; Guerrero, E; Jingar, M; Lindvall, K; Nawi, NG; Sundberg, LR; Santosa, A; Weinehall, L","A broad range of aspects are needed to be taken into consideration in the design and development of personalized coaching systems based on artificial intelligence methodologies. This research presents the initial phase of joining different professional and stakeholder perspectives on behavior change technologies into a flexible design proposal for a digital coaching system. The diversity and sometimes opposed views on content, behavior, purposes and context were managed using a structured argument-based design approach, which also feed into the behavior of the personalized system. Results include a set of personalization strategies that will be further elaborated with the target user group to manage sensitive issues such as ethics, social norms, privacy, motivation, autonomy and social relatedness.",2020,,PHEALTH 2020: PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON WEARABLE MICRO AND NANO TECHNOLOGIES FOR PERSONALIZED HEALTH,273,,203-208,WOS:000648601600025,10.3233/SHTI200640,,#4211,Lindgren 2020,"",""
Persuasion Model and Its Evaluation Based on Positive Change Degree of Agent Emotion,"Wu, JH; Lu, WG; Meng, HL","For it can meet needs of negotiation among organizations take place in different time and place, and for it can make its course more rationality and result more ideal, persuasion based on agent can improve cooperation among organizations well. Integrated emotion change in agent persuasion can further bring agent advantage of artificial intelligence into play. Emotion of agent persuasion is classified, and the concept of positive change degree is given. Based on this, persuasion model based on positive change degree of agent emotion is constructed, which is explained clearly through an example. Finally, the method of relative evaluation is given, which is also verified through a calculation example. (C) 2012 Published by Elsevier B.V. Selection and/or peer-review under responsibility of Garry Lee",2012,,INTERNATIONAL CONFERENCE ON SOLID STATE DEVICES AND MATERIALS SCIENCE,25,,1654-1659,WOS:000305960300250,10.1016/j.phpro.2012.03.290,,#4212,Wu 2012,"",""
How do users adopt AI-generated content (AIGC)? An exploration of content cues and interactive cues,"Li, CX; Lin, YX; Chen, RQ; Chen, J","Despite the growing adoption of AI-generated content (AIGC), its full potential remains underexplored. This study investigates the factors driving AIGC adoption and uncovers the psychological mechanisms underlying this process, grounded on the Information Adoption Model (IAM) integrated with the Cognition-Motivation-Emotion framework. Based on Structural Equation Modeling analysis, we find that AIGC adoption is shaped by content cues (perceived intelligence and anthropomorphism) and interactive cues (performance and effort expectancy), with emotions mediating the adoption process. This study enriches information processing literature by advancing IAM to accommodate the dynamic and iterative nature of AIGC adoption. It also establishes AIGC as a distinct category of digital content for the digital content adoption literature. Moreover, it shifts the focus of AI adoption research from technology adoption to content adoption.",2025,,TECHNOLOGY IN SOCIETY,81,,,WOS:001428531600001,10.1016/j.techsoc.2025.102830,,#4213,Li 2025,"",""
Robot Games for Elderly,"IEEE; Hansen, ST","This video presents a study on how a physical game based on a mobile robot can be used as a persuasive tool for promoting physical activity among elderly. The goal of the game is to take a ball from a robot, and afterwards try to hand it back while the robot moves. The robot records the behavior patterns of each individual player and gradually adapts the challenge of the game to the player's skill. The game was investigated in two independent field studies. The primary goal was to observe how the robot adapts to players with different mobility problems, secondly to obtain knowledge about the different play patterns and get ideas about future improvements of the game. The video shows different examples of how the elderly would play with the robot and illustrates the variety of play styles.",2011,,PROCEEDINGS OF THE 6TH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTIONS (HRI 2011),,,413-413,WOS:000393313200140,10.1145/1957656.1957808,,#4214,IEEE 2011,"",""
"FORCEFUL PERSUASION - COERCIVE DIPLOMACY AS AN ALTERNATIVE TO WAR - GEORGE,AI",[Anonymous],,1992,,ORBIS-A JOURNAL OF WORLD AFFAIRS,36,3,459-459,WOS:A1992HZ04500023,,,#4215,[Anonymous] 1992,"",""
Cognitive Aspects of Persuasion in Marketing Discourse a Cognitive Linguistic Study,"Al-Shboul, OK; Al-Khawaldeh, NN; Alkhawaldeh, AA; JHamdan, H; Al-Oliemat, AS","The use of language in digital discourse for marketing has rapidly developed through mass media. This paper elucidates how advertisers employ various pragmatic strategies to persuade the recipient to take action (behavior) by purchasing specific products. This study utilized different theoretical and conceptual frameworks (Theory of Reasoned Action and Aristotle's Models of Persuasion) in an attempt to address the shortcomings of the social cognitive approach in studying persuasion, to investigate how language of advertisements can influence the recipient's thinking of a product from a psychological perspective. Guided by the principles of TRA, the present study argues that persuasion in advertisements is structured by three dimensions: attraction (through language features and appeals), evaluation (through beliefs, attitudes, and intention), and behavior (social acceptance or reluctance). This study revealed eight persuasion techniques employed by advertisers including demonstrating distinction, honoring commitment, expressing authority, hyperbolizing, glorification, providing proofs, expressing solidarity and proving success. Showing distinction and Honoring commitment were the most frequently used strategies. Additionally, the study found that strategies of persuasion involved ethical, logical, and emotional appeals for their large effect on the recipient as they contribute to the recipient's positive evaluations. Appealing to reasoning (logic) is the most common one in slogans.",2024,,EURASIAN JOURNAL OF APPLIED LINGUISTICS,10,1,81-91,WOS:001217439600006,10.32601/ejal.10108,,#4216,Al-Shboul 2024,"",""
"We need to understand ""when"" not ""if"" generative AI can enhance personalized persuasion","Teeny, JD; Matz, SC",,2024,,PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA,121,43,,WOS:001352088800017,10.1073/pnas.2418005121,,#4217,Teeny 2024,"",""
Envisioning the Theory of Transforming Wellbeing Transforming Technology and Sociotech Design,"IEEE; Stibe, A","The Theory of Transforming Wellbeing (TTW) is emerging as an inevitable response to the ever-growing imbalance in our lives across the globe. Over the decades, we have been advancing technologies to make our lives better. The fundamental question still remains: with all the evolving innovations, are we gaining decent success in achieving happier and more sustainable societies? All the crucial domains of our lives continuously provide evidence of things getting disbalanced despite us making huge progress in building increasingly capable technological innovations, such as artificial intelligence, blockchain, augmented reality, autonomous vehicles, and drones, just to name a few. The TTW advances scientific knowledge and its practical applications to transform lives. Due to its strong fundament that blends technological innovations with human nature, TTW is applicable in many essential life contexts, including health, education, sustainability, equality, governance, safety, emergency, ecology, and economy.",2018,,2018 7TH MEDITERRANEAN CONFERENCE ON EMBEDDED COMPUTING (MECO),,,6-6,WOS:000644432200004,,,#4218,IEEE 2018,"",""
Digital chameleons - Automatic assimilation of nonverbal gestures in immersive virtual environments,"Bailenson, JN; Yee, N","Previous research demonstrated social influence resulting from mimicry ( the chameleon effect); a confederate who mimicked participants was more highly regarded than a confederate who did not, despite the fact that participants did not explicitly notice the mimicry. In the current study, participants interacted with an embodied artificial intelligence agent in immersive virtual reality. The agent either mimicked a participant's head movements at a 4-s delay or utilized prerecorded movements of another participant as it verbally presented an argument. Mimicking agents were more persuasive and received more positive trait ratings than nonmimickers, despite participants' inability to explicitly detect the mimicry. These data are uniquely powerful because they demonstrate the ability to use automatic, indiscriminate mimicking (i.e., a computer algorithm blindly applied to all movements) to gain social influence. Furthermore, this is the first study to demonstrate social influence effects with a nonhuman, nonverbal mimicker.",2005,,PSYCHOLOGICAL SCIENCE,16,10,814-819,WOS:000232101200012,10.1111/j.1467-9280.2005.01619.x,,#4219,Bailenson 2005,"",""
Data-centered persuasion: Nudging user's prosocial behavior and designing social innovation,"Shin, Y; Kim, J","By employing individuals' behavioral data collected from routinely used devices, a more effective 'nudging' toward changes in individuals' attitudes and behavior can be implemented. To examine the persuasive effect on inducing prosocial behaviors, two types of system concepts were designed, namely shared value systems. We manipulated the usage context of these systems and tested the effects with two independent variables: the status of the system agent and the valence of the agent's feedback. As a result, this study revealed that users' satisfaction and intention for prosocial behavior increased after they experienced the shared value system based on the concept of self-preferential value. Interaction effects were also found between the status of the system agent and the valence of the agent's feedback. (C) 2017 Elsevier Ltd. All rights reserved.",2018,,COMPUTERS IN HUMAN BEHAVIOR,80,,168-178,WOS:000423650100017,10.1016/j.chb.2017.11.009,,#4220,Shin 2018,"",""
Reply to Teeny and Matz: Toward the robust measurement of personalized persuasion with generative AI,"Hackenburg, K; Margetts, H",,2024,,PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA,121,43,,WOS:001352088800007,10.1073/pnas.2418817121,,#4221,Hackenburg 2024,"",""
Cloud Neural Fuzzy PID Hybrid Integrated Algorithm of Flatness Control,"Jia, CY; Bai, T; Shan, XY; Cui, FJ; Xu, SJ","In connection with the characteristics of multi-disturbance and nonlinearity of a system for flatness control in cold rolling process, a new intelligent PID control algorithm was proposed based on a cloud model, neural network and fuzzy integration. By indeterminacy artificial intelligence, the problem of fixing the membership functions of input variables and fuzzy rules was solved in an actual fuzzy system and the nonlinear mapping between variables was implemented by neural network. The algorithm has the adaptive learning ability of neural network and the indeterminacy of a cloud model in processing knowledge, which makes the fuzzy system have more persuasion in the process of knowledge inference, realizing the online adaptive regulation of PID parameters and avoiding the defects of the traditional PID controller. Simulation results show that the algorithm is simple, fast and robust with good control performance and application value.",2014,,JOURNAL OF IRON AND STEEL RESEARCH INTERNATIONAL,21,6,559-564,WOS:000337656600001,10.1016/S1006-706X(14)60087-X,,#4222,Jia 2014,"",""
E-petition popularity: Do linguistic and semantic factors matter?,"Hagen, L; Harrison, TM; Uzuner, Ö; May, W; Fake, T; Katragadda, S","E-petitioning technology platforms elicit the participation of citizens in the policy-making process but at the same time create large volumes of unstructured textual data that are difficult to analyze. Fortunately, computational tools can assist policy analysts in uncovering latent patterns from these large textual datasets. This study uses such computational tools to explore e-petitions, viewing them as persuasive texts with linguistic and semantic features that may be related to the popularity of petitions, as indexed by the number of signatures they attract. Using We the People website data, we analyzed linguistic features, such as extremity and repetition, and semantic features, such as named entities and topics, to determine whether and to what extent they are related to petition popularity. The results show that each block of variables independently explains statistically significant variation in signature accumulation, and that 1) language extremity is persistently and negatively associated with petition popularity, 2) petitions with many names tend not to become popular, and 3) petition popularity is associated with petitions that include topics familiar to the public or about important social events. We believe explorations along these lines will yield useful strategies to address the wicked problem of too much text data and to facilitate the enhancement of public participation in policy-making. (C) 2016 Elsevier Inc. All rights reserved.",2016,,GOVERNMENT INFORMATION QUARTERLY,33,4,783-795,WOS:000391081600018,10.1016/j.giq.2016.07.006,,#4223,Hagen 2016,"",""
The persuasive role of generic-you in online interactions,"Niu, MX; Provost, EM; Jurgens, D; Gelman, SA; Kross, E; Orvell, A","Persuasion plays a crucial role in human communication. Yet, convincing someone to change their mind is often challenging. Here, we demonstrate that a subtle linguistic device, generic-you (i.e., ""you"" that refers to people in general, e.g., ""You win some, you lose some""), is associated with successfully shifting people's pre-existing views in a naturalistic context. Leveraging Large Language Models, we conducted a preregistered study using a large (\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$N_{trials}$$\end{document} = 204,120) online debate dataset. Every use of generic-you in an argument was associated with an up to 14% percent increase in the odds of successful persuasion. These findings underscore the need to distinguish between the specific and generic uses of ""you"" in large-scale linguistic analyses, an aspect that has been overlooked in the literature. The robust association between generic-you and persuasion persisted with the inclusion of various covariates, and above and beyond other pronouns (i.e., specific-you, I or we). However, these findings do not imply causality. In Supplementary Experiment 2, arguments with generic-you (vs. first-person singular pronouns, e.g., I) were rated as more persuasive by open-minded individuals. In Supplementary Experiment 3, generic-you (vs. specific-you) arguments did not differentially predict attitude change. We discuss explanations for these results, including differential mechanisms, boundary conditions, and the possibility that people intuitively draw on generic-you when expressing more persuasive ideas. Together, these findings add to a growing literature on the interpersonal implications of broadening one's perspective via a subtle shift in language, while motivating future research on contextual and individual differences that may moderate these effects.",2025,,SCIENTIFIC REPORTS,15,1,,WOS:001394303000020,10.1038/s41598-024-83440-1,,#4224,Niu 2025,"",""
Task-related errors as a catalyst for empathy towards embodied pedagogical agents,"Rehren, O; Jansen, S; Seemann, M; Ohler, P","Introduction The increasing integration of digital tools in education highlights the potential of embodied pedagogical agents. This study investigates how task-related errors and language cues from a robot influence human perception, specifically examining their impact on anthropomorphism and subsequent empathy, and whether these perceptions affect persuasion.Methods Thirty-nine participants interacted with a NAO robot during a quiz. Employing a 3 x 2 mixed design, we manipulated the robot's error rate (above average, human-like, below average) between subjects and language style (humble, dominant) within subjects. We measured perceived anthropomorphism, empathy, sympathy, and persuasion. Data were analyzed using multilevel modeling to assess the relationships between manipulated variables and outcomes.Results Our findings indicate that human-like error rates significantly increased perceived anthropomorphism in the robot, which in turn led to higher levels of empathy and sympathy towards it. However, perceived anthropomorphism did not directly influence persuasion. Furthermore, the manipulated language styles did not show a significant direct effect on perceived anthropomorphism, empathy, sympathy, or persuasion in the main experiment, despite pretest results indicating differences in perceived personality based on language cues.Discussion These results have important implications for the design of embodied pedagogical agents. While strategic implementation of human-like error rates can foster empathy and enhance the perception of humanness, this alone may not directly translate to greater persuasiveness. The study highlights the complex interplay between perceived competence, likability, and empathy in human-robot interaction, particularly within educational contexts. Future research should explore these dynamics further, utilizing larger samples, diverse robot designs, and immersive environments to better understand the nuances of how errors and communication styles shape learner engagement with pedagogical agents.",2025,,FRONTIERS IN VIRTUAL REALITY,5,,,WOS:001400535700001,10.3389/frvir.2024.1412039,,#4225,Rehren 2025,"",""
Pre-suasive and persuasive strategies in the tweets of the Saudi Ministry of Health during the 2020 coronavirus pandemic: A corpus linguistic exploration,"Ibrahim, WMA; Abaalalaa, HS; Hardie, A","In this study, we assess the applicability and usefulness of a particular theoretical framework for qualitative analysis of communicative strategies in discourses from beyond the English language. The theory in question is Cialdini's model of persuasion (and the related concept of pre-suasion). We present an operationalisation of this framework in terms of concrete linguistic features, which is implemented using the computer-assisted methods of corpus linguistics. As a case study, we explore a particular type of Arabic-language online public discourse surrounding an issue of pressing contemporary concern, namely the COVID-19 Pandemic. Specifically, we use a large collection of texts produced by the Ministry of Health of Saudi Arabia via the medium of the Ministry's official Twitter account. The tweets in question were produced in the context of a campaign to persuade the public to modify their behavior to comply with policies on protective measures. While the use of corpus-assisted linguistic approaches to examine public discourses around socially or culturally prominent issues is well-developed in the Anglosphere, it remains much more rarely utilized in the Arab World context, and especially in application to discourses in the Arabic language itself. In addition to the contribution arising from the improvements generated in our understanding of the particular issue at hand, this paper aims to contribute to the broader field of Arabic linguistics by modeling a suitable approach-albeit one whose use we show to be subject to some complicating factors-to address other questions in the study of persuasive language in Arabic.",2022,,FRONTIERS IN COMMUNICATION,7,,,WOS:000860787900001,10.3389/fcomm.2022.984651,,#4226,Ibrahim 2022,"",""
Convolutional Neural Networks: A Promising Deep Learning Architecture for Biological Sequence Analysis,"John, C; Sahoo, J; Madhavan, M; Mathew, OK","The deep learning arena explores new dimensions once considered impossible to human intelligence. Recently, it has taken footsteps in the biological data world to deal with the diverse patterns of data derived from biomolecules. The convolutional neural networks, one of the most employed and persuasive deep learning architectures, can unravel the sequestered truths from these data, especially from the biological sequences. These neural network variants outperform traditional bioinformatics tools for the enduring tasks associated with such sequences.This work imparts an exciting preface to the basics of convolutional neural network architecture and how it can be instrumented to deal with biological sequence analysis.The approach followed in this paper can provide the reader with an enhanced view of convolutional neural networks, their basic working principles and how they apply to biological sequences.A detailed view of critical steps involved in deep learning, starting from the data preprocessing, architecture designing, model training, hyperparameter tuning, and evaluation metrics, are portrayed. A comparative analysis of convolutional neural network architectures developed for protein family classification is also discussed.This review contributes significantly to understanding the concepts behind deep learning architectures and their applications in biological sequence analysis. It can lift the barrier of limited knowledge to a great extent on the deep learning concepts and their implementation, especially for people who are dealing with pure biology.",2023,,CURRENT BIOINFORMATICS,18,7,537-558,WOS:001072778200001,10.2174/1574893618666230320103421,,#4227,John 2023,"",""
Before and after Dung: Argumentation in AI and Law,"Bench-Capon, TJM","Dung's abstract argumentation frameworks have had a very significant role in the rise in interest in argumentation throughout this century. In this paper we will explore the impact of this seminal idea on a specific application domain, AI and Law. Argumentation is central to legal reasoning and there had been a considerable amount of work on it in AI and Law before Dung's paper. It had, however, been rather fragmented. We argue that the abstract argumentation frameworks had a unifying effect by offering a means of relating previously diverse work. We also discuss how the particular demands of legal systems have led to developments building on the basic notions of abstract argumentation.",2020,,ARGUMENT & COMPUTATION,11,1-2,221-238,WOS:000536787800007,10.3233/AAC-190477,,#4228,Bench-Capon 2020,"",""
"Fabulation, Machine Agents, and Spiritually Authorizing Encounters","Loewen-Colón, J; Mosurinjohn, SC","This paper uses a Tavesian model of religious experience to make a modest theorization about the role of ""fabulation"", an embodied and affective process, to understand how some contemporary AI and robotics designers and users consider encounters with these technologies to be spiritually ""authorizing"". By ""fabulation"", we mean the Bergsonian concept of an evolved capacity that allows humans to see the potentialities of complex action within another object-in other words, an interior agential image, or ""soul""; and by ""authorizing"", we mean ""deemed as having some claim to arbitration, persuasion, and legitimacy"" such that the user might make choices that affect their life or others in accordance with the AI or might have their spiritual needs met. We considered two case studies where this agency took on a spiritual or religious valence when contextualized as such for the user: a robotic Buddhist priest known as Mindar, and a chatbot called The Spirituality Chatbot. We show how understanding perceptions of AI or robots as being spiritual or religious in a way that authorizes behavioral changes requires understanding tendencies of the human body more so than it does any metaphysical nature of the technology itself.",2022,,RELIGIONS,13,4,,WOS:000785522900001,10.3390/rel13040333,,#4229,Loewen-Colón 2022,"",""
Effects of cultural cues on perceptions of HPV vaccination messages among parents and guardians of American Indian youth,"Yzer, M; Rhodes, K; McCann, M; Harjo, J; Nagler, RH; LoRusso, SM; Gollust, SE","The encouragement of human papillomavirus (HPV) vaccination is an important goal for interventions among American Indians (AIs), given the significant disparities AIs face with respect to HPV cancers. Tailoring intervention messages to the culture of message recipients has been proposed as a potentially useful intervention approach, yet cultural tailoring of HPV messages has never been tested among AIs. The objective of this research was to test the effectiveness of cultural tailoring in positively affecting two variables that have been proposed as mechanisms of tailoring effects, namely identification with the message and perceptions of message effectiveness. We conducted a between subjects randomized experiment among 300 parents of AI children. Participants saw one of three messages that differed in the extent to which the message contained cues to AI culture. Analysis of variance (anova) showed that participants identified more strongly (partial eta2=0.10) with messages that included stronger AI cultural features and thought these messages were more convincing (partial eta(2)=0.14) and pleasant (partial eta(2)=0.11) compared to messages that included weaker cultural cues. Effects on message identification and convincingness were moderated by AI identity, such that the more participants identified themselves with AI culture, the stronger the effects of the culturally-tailored messages were (R-change(2)=0.043 and 0.020 in hierarchical regression analyses). These findings suggest good potential for cultural tailoring to encourage HPV vaccination among AIs.",2018,,PREVENTIVE MEDICINE,115,,104-109,WOS:000444003100016,10.1016/j.ypmed.2018.08.021,,#4230,Yzer 2018,"",""
"MESSAGE FRAMING, SELF-DISCREPANCIES, AND YIELDING TO PERSUASIVE MESSAGES - THE MOTIVATIONAL SIGNIFICANCE OF PSYCHOLOGICAL SITUATIONS","TYKOCINSKI, O; HIGGINS, ET; CHAIKEN, S","Subjects possessing two distinct types of self-discrepancies, actual:ideal (AI) and actual:ought (AO), read a persuasive message about the importance of eating breakfast, framed in terms of either positive or negative outcomes. On the basis of an analysis of each discrepancy type as a chronic, individual motivational force and each frame as a momentary, situational motivational force, the positive outcome frame was predicted to be more effective than the negative outcome frame in motivating AO subjects to change their eating patterns; the opposite was predicted for AI subjects. The results supported this prediction. AO subjects' thoughts, feelings, and intentions showed a stronger persuasive effect of positive outcome framing than of negative outcome framing; the opposite was true for AI subjects. The predicted interaction was also found on an immediate behavioral commitment measure. On a delayed action measure, only the effect predicted for AO subjects was found.",1994,,PERSONALITY AND SOCIAL PSYCHOLOGY BULLETIN,20,1,107-115,WOS:A1994MU28700011,10.1177/0146167294201011,,#4231,TYKOCINSKI 1994,"",""
Cognitive Aspects of Persuasion in Marketing Discourse a Cognitive Linguistic Study,"Al-Shboul, OK; Al-Khawaldeh, NN; Alkhawaldeh, AA; Hamdan, HJ; Al-Oliemat, AS","The use of language in digital discourse for marketing has rapidly developed through mass media. This paper elucidates how advertisers employ various pragmatic strategies to persuade the recipient to take action (behavior) by purchasing specific products. This study utilized different theoretical and conceptual frameworks (Theory of Reasoned Action and Aristotle's Models of Persuasion) in an attempt to address the shortcomings of the social cognitive approach in studying persuasion, to investigate how language of advertisements can influence the recipient's thinking of a product from a psychological perspective. Guided by the principles of TRA, the present study argues that persuasion in advertisements is structured by three dimensions: attraction (through language features and appeals), evaluation (through beliefs, attitudes, and intention), and behavior (social acceptance or reluctance). This study revealed eight persuasion techniques employed by advertisers including demonstrating distinction, honoring commitment, expressing authority, hyperbolizing, glorification, providing proofs, expressing solidarity and proving success. Showing distinction and Honoring commitment were the most frequently used strategies. Additionally, the study found that strategies of persuasion involved ethical, logical, and emotional appeals for their large effect on the recipient as they contribute to the recipient's positive evaluations. Appealing to reasoning (logic) is the most common one in slogans. (c) 2023 EJAL & the Authors. Published by Eurasian Journal of Applied Linguistics (EJAL). This is an open -access article distributed under the terms and conditions of the Creative Commons Attribution license (CC BY-NC-ND) (http://creativecommons.org/licenses/by-nc-nd/4.0/).",2023,,EURASIAN JOURNAL OF APPLIED LINGUISTICS,9,3,196-206,WOS:001222110300003,10.32601/ejal.903017,,#4232,Al-Shboul 2023,"",""
Lies and consequences The effect of lie detection on communication outcomes,"Balbuzanov, I","I study a strategic-communication game between an informed sender and an uninformed receiver with partially aligned preferences. The receiver is endowed with the ability to probabilistically detect if the sender is lying. Specifically, if the sender is making a false claim about her type, with some commonly known probability p the receiver additionally observes a private signal indicating that the sender is lying. The main result is that the receiver's stochastic lie-detection ability makes fully revealing equilibria-the best outcome for the receiver-possible, even for small p (less than 12. Additionally, if the language consists of precise messages, fully revealing equilibria exist only for p=1and for a set of intermediate values of p that is bounded away from 0 and 1, making the maximal ex-ante expected equilibrium utility of the receiver non-monotone in p. If vague messages are allowed, full revelation can be supported for all large enough p, overturning the non-monotonicity and improving communication outcomes relative to the precise-language case.",2019,,INTERNATIONAL JOURNAL OF GAME THEORY,48,4,1203-1240,WOS:000492032400008,10.1007/s00182-019-00679-z,,#4233,Balbuzanov 2019,"",""
Artificial emotions for charity collection: A serial mediation through perceived anthropomorphism and social presence,"Lee, S; Park, G; Chung, J","Despite the broad application of chatbot agents in online interactions, an ongoing debate persists regarding their persuasive role and human-like emotional disclosure. Our study adds to this debate by exploring the effect of chatbot agents' emotional disclosure on people's willingness to donate to a charitable cause, and by examining individual and serial mediation between the main effects of perceived anthropomorphism and social presence. To this end, two types of artificial intelligence chatbot agents-one disclosing factual information and another disclosing human-like emotion-were developed and trained using Dialogflow, a natural language processing en-gine. A total of 619 US residents were recruited through Amazon Mechanical Turk, an online crowdsourcing platform. Of these, 593 participants completed the required conversation with either version of the chatbot agent (factual vs. emotional), as well as the survey questionnaire, and therefore, were included in the final analysis. The participants exhibited a higher willingness to donate when they interacted with a chatbot disclosing human-like emotions than when they were only exposed to factual information. Moreover, this study found both individual and serial mediating roles of perceived anthropomorphism and social presence. Concerning the implications, theoretically, this study adds to the understanding of applying the notion of human interaction to that involving humans and chatbots. Practically, our findings can be of great help in increasing willingness to donate thereby enhancing fund-raising activities.",2023,,TELEMATICS AND INFORMATICS,82,,,WOS:001060277800001,10.1016/j.tele.2023.102009,,#4234,Lee 2023,"",""
ProHealth eCoach: user-centered design and development of an eCoach app to promote healthy lifestyle with personalized activity recommendations,"Chatterjee, A; Prinz, A; Gerdes, M; Martinez, S; Pahari, N; Meena, YK","Background Regular physical activity (PA), healthy habits, and an appropriate diet are recommended guidelines to maintain a healthy lifestyle. A healthy lifestyle can help to avoid chronic diseases and long-term illnesses. A monitoring and automatic personalized lifestyle recommendation system (i.e., automatic electronic coach or eCoach) with considering clinical and ethical guidelines, individual health status, condition, and preferences may successfully help participants to follow recommendations to maintain a healthy lifestyle. As a prerequisite for the prototype design of such a helpful eCoach system, it is essential to involve the end-users and subject-matter experts throughout the iterative design process. Methods We used an iterative user-centered design (UCD) approach to understend context of use and to collect qualitative data to develop a roadmap for self-management with eCoaching. We involved researchers, non-technical and technical, health professionals, subject-matter experts, and potential end-users in design process. We designed and developed the eCoach prototype in two stages, adopting different phases of the iterative design process. In design workshop 1, we focused on identifying end-users, understanding the user's context, specifying user requirements, designing and developing an initial low-fidelity eCoach prototype. In design workshop 2, we focused on maturing the low-fidelity solution design and development for the visualization of continuous and discrete data, artificial intelligence (AI)-based interval forecasting, personalized recommendations, and activity goals. Results The iterative design process helped to develop a working prototype of eCoach system that meets end-user's requirements and expectations towards an effective recommendation visualization, considering diversity in culture, quality of life, and human values. The design provides an early version of the solution, consisting of wearable technology, a mobile app following the ""Google Material Design"" guidelines, and web content for self-monitoring, goal setting, and lifestyle recommendations in an engaging manner between the eCoach app and end-users. Conclusions The adopted iterative design process brings in a design focus on the user and their needs at each phase. Throughout the design process, users have been involved at the heart of the design to create a working research prototype to improve the fit between technology, end-user, and researchers. Furthermore, we performed a technological readiness study of ProHealth eCoach against standard levels set by European Union (EU).",2022,,BMC HEALTH SERVICES RESEARCH,22,1,,WOS:000849484000001,10.1186/s12913-022-08441-0,,#4235,Chatterjee 2022,"",""
"Effects of age, need for cognition, and affective intensity on advertising effectiveness","McKay-Nesbitt, J; Manchanda, RV; Smith, MC; Huhmann, BA",This paper explores how individual characteristics of age need for cognition (NFC) and affective intensity (AI) interact with each other and with advertising appeal frames (i e rational positive-emotional negative-emotional) to influence ad attitudes involvement and recall The mixed design study reveals that younger adults recall emotional messages especially negative ones better than rational ones but recall does not differ for older adults across appeal frames Older adults prefer rational and positive messages to negative-emotional messages but ad attitudes do not differ among younger adults across appeal frames Finally age Interacts with AI but not NFC to influence ad responsiveness Both age and AI influence ad attitudes such that older adults exhibit the most positive ad attitudes across all appeal frames (C) 2009 Elsevier Inc All rights reserved,2011,,JOURNAL OF BUSINESS RESEARCH,64,1,12-17,WOS:000285899200004,10.1016/j.jbusres.2009.09.013,,#4236,McKay-Nesbitt 2011,"",""
Modal stability and warrant (Keith DeRose),"Ruloff, CP","Keith DeRose believes that it is a strength of his contextualist analysis that it explains why the recently much-discussed skeptical Argument from Ignorance ( AI) is so persuasive. Not only that, however; DeRose also believes that he is able to explain the underlying dynamics of AI by utilizing solely the epistemological and linguistic resources contained within his contextualist analysis. DeRose believes, in other words, that his contextualist analysis functions as a genuinely self-contained explanation of skepticism. But does it? In this paper I argue that DeRose's analysis does not function as a self-contained explanation of skepticism since, as it turns out, DeRose's analysis is simply irrelevant to the main concerns of the skeptic. To the extent that DeRose's analysis is irrelevant in this way, I conclude that such an analysis cannot be considered a satisfactory treatment of AI.",2006,,PHILOSOPHIA,34,2,173-188,WOS:000253091000008,10.1007/s11406-006-9023-y,,#4237,Ruloff 2006,"",""
Effect of Robot's Title in Human-Robot Interaction,"IEEE; Jung, YB; Park, T; Hong, A","The collaboration between humans and intelligent agents keeps increasing as the technology advances. In this sense, each can rely on the other's strengths to achieve the best overall performance. But as intelligent agents play an increasingly escalating role as a partner rather than mere tools, it is imperative that we understand how humans are influenced by such agents. This is so as to achieve a certain level of persuasiveness to ensure human compliance with intelligent agents in times of need, and also prevent over-reliance on such agents, which may make humans susceptible to manipulation. Reviewing the literature from human-computer interaction, persuasion, and decision-making processes, this study examined the effect of labelling source expertise (i.e., title) on the human decision-making process, when there is not an agreement between human and robot partners. Specifically, we conducted an experiment (n = 88) to investigate how perceived expertise of a robot resulted in the attractiveness, intelligence and credibility of the robot, and how these perceptions influence the level of cooperation and compliance in a desert survival game. The results showed that participants evaluated the robot as more credible when labelled as expert, compared to when labelled as novice. The results of a mediation analysis also showed that perceived credibility successfully mediated the effect of title on cooperation and compliance when there was a conflict in the ranking order of items between each participant and the robot. Implications for future development of artificial intelligence and future research directions are discussed.",2014,,2014 11TH INTERNATIONAL CONFERENCE ON UBIQUITOUS ROBOTS AND AMBIENT INTELLIGENCE (URAI),,,28-32,WOS:000383742100008,,,#4238,IEEE 2014,"",""
Burden of Proof in Deliberation Dialogs,"Walton, D","The literature in argumentation and artificial intelligence has distinguished five types of burden of proof in persuasion dialogs, but there appears to have been no serious investigation so far on how burdens of proof should be modeled in deliberation dialogs. The work in this paper is directed toward filling that gap by extending existing formal models of deliberation dialog to analyze four examples of deliberation dialog where burden of proof is at issue or poses an interesting problem. The examples are used to show (1) that the eight stages in the formal model of Hitchcock, McBurney and Parsons (2007) need to be divided into three more general stages, an opening stage, an argumentation stage and a closing stage, (2) that deliberation dialog shifts to persuasion dialog during the argumentation stage, and (3) that burden of proof is only operative during the argumentation stage. What is shown in general is that deliberation is, in the typical type of case, a mixed dialog in which there is a shift to persuasion dialog in the middle.",2010,,ARGUMENTATION IN MULTI-AGENT SYSTEMS,6057,,1-22,WOS:000280471900001,,,#4239,Walton 2010,"",""
The Internet as Cognitive Enhancement,"Voinea, C; Vica, C; Mihailov, E; Savulescu, J","The Internet has been identified in human enhancement scholarship as a powerful cognitive enhancement technology. It offers instant access to almost any type of information, along with the ability to share that information with others. The aim of this paper is to critically assess the enhancement potential of the Internet. We argue that unconditional access to information does not lead to cognitive enhancement. The Internet is not a simple, uniform technology, either in its composition, or in its use. We will look into why the Internet as an informational resource currently fails to enhance cognition. We analyze some of the phenomena that emerge from vast, continual fluxes of information-information overload, misinformation and persuasive design-and show how they could negatively impact users' cognition. Methods for mitigating these negative impacts are then advanced: individual empowerment, better collaborative systems for sorting and categorizing information, and the use of artificial intelligence assistants that could guide users through the informational space of today's Internet.",2020,,SCIENCE AND ENGINEERING ETHICS,26,4,2345-2362,WOS:000524387800001,10.1007/s11948-020-00210-8,,#4240,Voinea 2020,"",""
An Improved and Adaptive Approach in ANFIS to Predict Knee Diseases,"Kaur, R; Kaur, K; Khamparia, A; Anand, D","Artificial intelligence is emerging as a persuasive tool in the field of medical science. This research work also primarily focuses on the development of a tool to automate the diagnosis of inflammatory diseases of the knee joint. The tool will also assist the physicians and medical practitioners for diagnosis. The diseases considered for this research under inflammatory category are osteoarthritis, rheumatoid arthritis and osteonecrosis. A five-layer adaptive neuro-fuzzy (ANFIS) architecture was used to model the system. The ANFIS system works by mapping input parameters to the input membership functions, input membership functions are mapped to the rules generated by the ANFIS model which are further mapped to the output membership function. A comparative performance analysis of fuzzy system and ANFIS system is also done and results generated shows that the ANFIS system outperformed fuzzy system in terms of testing accuracy, sensitivity and specificity.",2020,,INTERNATIONAL JOURNAL OF HEALTHCARE INFORMATION SYSTEMS AND INFORMATICS,15,2,22-37,WOS:000508355300003,10.4018/IJHISI.2020040102,,#4241,Kaur 2020,"",""
How intelligent neurotechnology can be epistemically unjust. An exploration into the ethics of algorithms,"Schleidgen, S; Friedrich, O; Wolkenstein, A","Recently, the epistemic quality of algorithms and its normative implications have come under scrutiny. While general questions of justice have been addressed in this context, specific issues of epistemic (in)justice have so far been neglected. We aim to fill this gap by analyzing some potential implications of behavioral intelligent neurotechnology (B-INT). We claim that B-INT exhibits a number of epistemic features implying the potential for certain epistemic problems, which, in turn, are likely to result in instances of epistemic injustice. To support this claim, we will first introduce and specify the terminology and technology behind B-INT. Second, we will present four fictitious scenarios of using B-INT and highlight a number of epistemic issues that might arise. Third, we will discuss their relation to the concept of epistemic justice, as well as potential instances thereof. Thus, we will show some important and morally relevant implications of the epistemic properties of INT.",2022,,REVIEW OF SOCIAL ECONOMY,80,1,106-126,WOS:000705439600001,10.1080/00346764.2021.1979241,,#4242,Schleidgen 2022,"",""
Experience design,"McLellan, H","It is essential to think about education online as comprehensively as possible. Experience design offers designers of online courses a comprehensive model informed by research and development in a number of areas that can provide a foundation for the effective design of online experiences that are functional and purposeful-and also engaging, compelling, memorable, and enjoyable. Experience design is an ancient practice, going back to the earliest human impulse to develop rituals, ceremonies, drama, and even architecture. But the design of experiences has become much more pervasive during the twentieth century. Media has played a central role, including radio, television, multimedia, and virtual reality. But experience design is also informed by new ideas in economics, especially Pine and Gilmore's notion of the emerging experience economy. And it draws upon ideas from artificial intelligence, the psychology of optimal experiences, sociology, and other areas, including electronic commerce, persuasive, human-computer interface design, drama, and digital storytelling. This article discusses key concepts and theories from all of these areas and explains how they can be adapted to the design of online learning experiences.",2000,,CYBERPSYCHOLOGY & BEHAVIOR,3,1,59-69,WOS:000168232600007,10.1089/109493100316238,,#4243,McLellan 2000,"",""
Deepest Mediatization? Inventing the Autonomous Vehicle,"Miller, J","The fully autonomous vehicle (AV) promises to be both a prototypic example of deep mediatization in the built environment and the apotheosis of the mediatized automobile. Autonomy has been an elusive goal, however. Its achievement will depend on a persuasive sociotechnical imaginary (STI), along with breakthroughs in digital technology. The latter involve advanced artificial intelligence, of course, but also the transformation of the nature of media, a dynamic that goes well beyond the mere proliferation of in-car media. After exploring ""media"" and automotive deep mediatization, this article dwells on neglected examples of existing mobile autonomy. It then turns to STIs in general, which are visionary articulations of pioneering communities, and the American AV STI in particular. This is constructed through a close reading of recent semipopular publications that mostly promote the desirability of vehicular autonomy. The article concludes critically, with analysis of the unpersuasiveness of the current American AV STI, the vehicle in AV, and the transformation of media.",2023,,INTERNATIONAL JOURNAL OF COMMUNICATION,17,,4236-4254,WOS:001028803200013,,,#4244,Miller 2023,"",""
"Lights, camera, engagement! The role of personalized video as a marketing strategy in capturing consumer attention","Dennis, M; Kizer, TH","Personalized video marketing is increasingly leveraged as advertisers employ artificial intelligence and machine learning to tailor content to target audiences. Grounded in self-reference theory and the Elaboration Likelihood Model, this study examines the impact of video personalization on consumer engagement. Partnering with Vidyard, a video hosting platform, we analyzed historical video data to assess how personalized content influences persuasion pathways. Using a mixed-methods approach, we identified significant differences in engagement and elaboration between personalized and non-personalized videos. Findings indicate that personalized videos yield higher message downloads, rewatch likelihood, and click-through rates, aligning with central processing. Additionally, open-ended surveys from firms using personalized video identified three key benefits: increased engagement, heightened viewer attention, and competitive differentiation. The study concludes with a comparative analysis of results and discusses both theoretical and managerial implications.",2025,,JOURNAL OF MARKETING COMMUNICATIONS,,,,WOS:001454936100001,10.1080/13527266.2025.2478571,,#4245,Dennis 2025,"",""
Algorithms and Complexity Results for Persuasive Argumentation,"Kim, EJ; Ordyniak, S; Szeider, S","Value-based argumentation frameworks, as introduced by Bench-Capon, allow the abstract representation of persuasive argumentation. This formalism takes into account the relative strength of arguments with respect to some ordering which represents an audience. Deciding subjective or objective acceptance (i.e., acceptance with respect to at least one or with respect to all orderings) are intractable computational problems.In this paper we study the computational complexity of testing the subjective or objective acceptance for problem instances that obey certain restrictions. We consider structural restrictions in terms of the underlying graph structure of the value-based argumentation framework and in terms of properties of the equivalence relation formed by arguments with the same relative strength. We identify new tractable fragments where subjective and objective acceptance can be tested in polynomial time. Furthermore we show the intractability of some fragments that are located at the boundary to tractability. Our results disprove two conjectures of Dunne (Artificial Intelligence 171, 2007).",2010,,COMPUTATIONAL MODELS OF ARGUMENT: PROCEEDINGS OF COMMA 2010,216,,311-322,WOS:000294113000027,10.3233/978-1-60750-619-5-311,,#4246,Kim 2010,"",""
The critical need for expert oversight of ChatGPT: Prompt engineering for safeguarding child healthcare information,"Leslie-Miller, CJ; Simon, SL; Dean, K; Mokhallati, N; Cushing, CC","Objective ChatGPT and other large language models have the potential to transform the health information landscape online. However, lack of domain-specific expertise and known errors in large language models raise concerns about the widespread adoption of content generated by these tools for parents making healthcare decisions for their children. The aim of this study is to determine if health-related text generated by ChatGPT under the supervision of an expert is comparable to that generated by an expert regarding persuasiveness and credibility from the perspective of a parent.Methods In a cross-sectional study 116 parents aged 18-65 years (M = 45.02, SD = 10.92) were asked to complete a baseline assessment of their behavioral intentions regarding pediatric healthcare topics. Subsequently, participants were asked to rate text generated by either an expert or by ChatGPT under supervision of an expert.Results Results indicate that prompt engineered ChatGPT is capable of impacting behavioral intentions for medication, sleep, and diet decision-making. Additionally, there was little distinction between prompt engineered ChatGPT and content experts on perceived morality, trustworthiness, expertise, accuracy, and reliance. Notably, when differences were present, prompt engineered ChatGPT was rated as higher in trustworthiness and accuracy, and participants indicated they would be more likely to rely on the information presented by prompt engineered ChatGPT compared to the expert.Discussion Given that parents will trust and rely on information generated by ChatGPT, it is critically important that human domain-specific expertise be applied to healthcare information that will ultimately be presented to consumers (e.g., parents).",2024,,JOURNAL OF PEDIATRIC PSYCHOLOGY,49,11,812-817,WOS:001311872300001,10.1093/jpepsy/jsae075,,#4247,Leslie-Miller 2024,"",""
Explainable AI meets persuasiveness: Translating reasoning results into behavioral change advice,"Dragoni, M; Donadello, I; Eccher, C","Explainable AI aims at building intelligent systems that are able to provide a clear, and human understandable, justification of their decisions. This holds for both rule-based and data-driven methods. In management of chronic diseases, the users of such systems are patients that follow strict dietary rules to manage such diseases. After receiving the input of the intake food, the system performs reasoning to understand whether the users follow an unhealthy behavior. Successively, the system has to communicate the results in a clear and effective way, that is, the output message has to persuade users to follow the right dietary rules. In this paper, we address the main challenges to build such systems: (i) the Natural Language Generation of messages that explain the reasoner inconsistency; and, (ii) the effectiveness of such messages at persuading the users. Results prove that the persuasive explanations are able to reduce the unhealthy users' behaviors.",2020,,ARTIFICIAL INTELLIGENCE IN MEDICINE,105,,,WOS:000538797900001,10.1016/j.artmed.2020.101840,,#4248,Dragoni 2020,"",""
AI-enabled persuasive personal health assistant,"Donadello, I; Dragoni, M","This paper discusses the use of the HORUS.AI solution, an AI-enabled persuasive personal health assistant built upon the integration of semantic web technologies and persuasive techniques, for motivating people to adopt a healthy lifestyle and for supporting them to cope with the self-management of chronic diseases associated with bad lifestyle habits. The solution collects data from users' devices, explicit users' inputs, or from the external environment (e.g., facts of the world), and interacts with users by using a goal-based metaphor. Persuasive dialogues are used for proposing persuasion goals to users that, through a mobile application, are able to provide the required information and to receive contextual motivational messages helping them to achieve the proposed goals. In this paper, we focus on how behavioral change strategies have been exploited for providing a personalized support concerning the adoption of healthy lifestyle or the management of their chronic diseases based on the results of personal data processing. Such results are produced by reasoning operations, briefly mentioned in this paper, and coded into motivational strategies and messages by a dialogue-based persuasive layer. This layer manages dialogues and generates persuasive messages based on (i) the information provided by the reasoner, (ii) the user's behavior and profile, and (iii) the implemented behavioral change strategies. This way, messages are tailored to specific users. HORUS.AI has been validated within the context of the Key To Health project. Results demonstrated how the use of proposed approach supported users about improving their habits from the health perspectives as well as the overall good acceptability of the system by the users involved in the pilot study. Finally, the analysis of system's efficiency shows how HORUS.AI can be deployed within a real-world scenarios.",2022,,SOCIAL NETWORK ANALYSIS AND MINING,12,1,,WOS:000837696400001,10.1007/s13278-022-00935-3,,#4249,Donadello 2022,"",""
Does ChatGPT Write Like a Student? Engagement Markers in Argumentative Essays,"Jiang, F; Hyland, K","ChatGPT has created considerable anxiety among teachers concerned that students might turn to large language models (LLMs) to write their assignments. Many of these models are able to create grammatically accurate and coherent texts, thus potentially enabling cheating and undermining literacy and critical thinking skills. This study seeks to explore the extent LLMs can mimic human-produced texts by comparing essays by ChatGPT and student writers. By analyzing 145 essays from each group, we focus on the way writers relate to their readers with respect to the positions they advance in their texts by examining the frequency and types of engagement markers. The findings reveal that student essays are significantly richer in the quantity and variety of engagement features, producing a more interactive and persuasive discourse. The ChatGPT-generated essays exhibited fewer engagement markers, particularly questions and personal asides, indicating its limitations in building interactional arguments. We attribute the patterns in ChatGPT's output to the language data used to train the model and its underlying statistical algorithms. The study suggests a number of pedagogical implications for incorporating ChatGPT in writing instruction.",2025,,WRITTEN COMMUNICATION,,,,WOS:001479386000001,10.1177/07410883251328311,,#4250,Jiang 2025,"",""
Examining the Ordering of Rhetorical Strategies in Persuasive Requests,"Shaikh, O; Chen, JA; Saad-Falcon, J; Chau, DH; Yang, DY","Interpreting how persuasive language influences audiences has implications across many domains like advertising, argumentation, and propaganda. Persuasion relies on more than a message's content. Arranging the order of the message itself (i.e., ordering specific rhetorical strategies) also plays an important role. To examine how strategy orderings contribute to persuasiveness, we first utilize a Variational Autoencoder model to disentangle content and rhetorical strategies in textual requests from a large-scale loan request corpus. We then visualize interplay between content and strategy through an attentional LSTM that predicts the success of textual requests. We find that specific (orderings of) strategies interact uniquely with a request's content to impact success rate, and thus the persuasiveness of a request.",2020,,"FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020",,,1299-1306,WOS:001181866500020,,,#4251,Shaikh 2020,"",""
AI-Driven Mediation Strategies for Audience Depolarisation in Online Debates,"ACM; Govers, J; Velloso, E; Kostakos, V; Goncalves, J","Online polarisation can tear the fabric of civility through reinforcing social media's perceptions of division and discord. Social media platforms often rely on content-moderation to combat polarisation, contingent on the reactive removal or fagging of content. However, this approach often remains agnostic of the underlying debate's ideas and stifes open discourse. In this study, we use prompt-tuned language models to mediate social media debates, applying the strategies of the Thomas-Kilmann Confict Mode Instrument (TKI). We evaluate multiple mediation strategies in providing targeted responses to the debates, as shown to a debate audience. Our findings show that high-cooperativeness TKI strategies ofered more persuasive arguments, while an accommodating argument strategy was the most successful at depolarising the audience's opinion. Furthermore, high-cooperativeness strategies also increased the perception that the debaters will reach a consensus. Our work paves the way for scalable and personalised tools that mediate social media debates to encourage depolarisation.",2024,,"PROCEEDINGS OF THE 2024 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYTEMS, CHI 2024",,,,WOS:001255317907045,10.1145/3613904.3642322,,#4252,ACM 2024,"",""
When and Why is Persuasion Hard? A Computational Complexity Result,"Association for the Advancement of Artificial Intelligence; Wojtowicz, Z","As generative foundation models improve, they also tend to become more persuasive, raising concerns that AI automation will enable governments, firms, and other actors to manipulate beliefs with unprecedented scale and effectiveness at virtually no cost. The full economic and social ramifications of this trend have been difficult to foresee, however, given that we currently lack a complete theoretical understanding of why persuasion is costly for human labor to produce in the first place. This paper places human and AI agents on a common conceptual footing by formalizing informational persuasion as a mathematical decision problem and characterizing its computational complexity. A novel proof establishes that persuasive messages are challenging to discover (NP-Hard) but easy to adopt if supplied by others (NP). This asymmetry helps explain why people are susceptible to persuasion, even in contexts where all relevant information is publicly available. The result also illuminates why litigation, strategic communication, and other persuasion-oriented activities have historically been so human capital intensive, and it provides a new theoretical basis for studying how AI will impact various industries.",2024,,"PROCEEDINGS OF THE SEVENTH AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, AIES 2024",,,1591-1594,WOS:001447715300137,,,#4253,AssociationfortheAdvancementofArtificialIntelligence 2024,"",""
"The Design and Development of a Personalized Leisure Time Physical Activity Application Based on Behavior Change Theories, End-User Perceptions, and Principles From Empirical Data Mining","Sporrel, K; De Boer, RDD; Wang, SH; Nibbeling, N; Simons, M; Deutekom, M; Ettema, D; Castro, PC; Dourado, VZ; Kröse, B","Introduction: Many adults do not reach the recommended physical activity (PA) guidelines, which can lead to serious health problems. A promising method to increase PA is the use of smartphone PA applications. However, despite the development and evaluation of multiple PA apps, it remains unclear how to develop and design engaging and effective PA apps. Furthermore, little is known on ways to harness the potential of artificial intelligence for developing personalized apps. In this paper, we describe the design and development of the Playful data-driven Active Urban Living (PAUL): a personalized PA application.Methods: The two-phased development process of the PAUL apps rests on principles from the behavior change model; the Integrate, Design, Assess, and Share (IDEAS) framework; and the behavioral intervention technology (BIT) model. During the first phase, we explored whether location-specific information on performing PA in the built environment is an enhancement to a PA app. During the second phase, the other modules of the app were developed. To this end, we first build the theoretical foundation for the PAUL intervention by performing a literature study. Next, a focus group study was performed to translate the theoretical foundations and the needs and wishes in a set of user requirements. Since the participants indicated the need for reminders at a for-them-relevant moment, we developed a self-learning module for the timing of the reminders. To initialize this module, a data-mining study was performed with historical running data to determine good situations for running.Results: The results of these studies informed the design of a personalized mobile health (mHealth) application for running, walking, and performing strength exercises. The app is implemented as a set of modules based on the persuasive strategies ""monitoring of behavior,"" ""feedback,"" ""goal setting,"" ""reminders,"" ""rewards,"" and ""providing instruction."" An architecture was set up consisting of a smartphone app for the user, a back-end server for storage and adaptivity, and a research portal to provide access to the research team.Conclusions: The interdisciplinary research encompassing psychology, human movement sciences, computer science, and artificial intelligence has led to a theoretically and empirically driven leisure time PA application. In the current phase, the feasibility of the PAUL app is being assessed.",2021,,FRONTIERS IN PUBLIC HEALTH,8,,,WOS:000618224300001,10.3389/fpubh.2020.528472,,#4254,Sporrel 2021,"",""
Algorithms as conversational partners: Looking at Google auto-predict through the lens of symbolic interaction,"Markham, A","This article showcases a speculative methodology for recreating interactions between a human and Google Search's Auto-Predict interface as conversations, to explore how AI-based systems are both persuasive and deeply personal. Using ethnomethodology tools and a symbolic interactionist lens, the paper presents three versions of a single Google search, each variation building a slightly different angle on the plausible utterances and interpersonal dynamics of the human and nonhuman partners. This thought experiment emerges from a decade of classroom-based digital literacy exercises with young adults, training them to analyze their lived experiences with digital media, algorithms, and devices. Transforming information exchanges into personal conversations provides a creative method for analyzing how relations are co-constructed in the granular processes of interaction, through which mutual intelligibility is built, meaning about the world is made, and identities are formed. This critical analysis extends methods for human-machine communication studies and elaborates notions of algorithmic identity.",2024,,NEW MEDIA & SOCIETY,26,9,5059-5080,WOS:001303163500024,10.1177/14614448241251800,,#4255,Markham 2024,"",""
A DATA-INFORMED ANALYSIS OF ARGUMENT MINING,"Cabrio, E","Argument Mining (AM) is the research area aiming at extracting natural language arguments and their relations from text, with the final goal of providing machine-processable structured data for computational models of argument. This research topic has started to attract the attention of a small community of researchers around 2014, and it is nowadays counted as one of the most promising research areas in Artificial Intelligence and Natural Language Processing in terms of growing of the community, funded projects, and involvement of companies. Recently, this research area includes also further forms of processing natural language arguments than mining, i.e., searching for arguments on the Web, argument generation and synthesis, and assessing the quality of arguments with respect to specific criteria like persuasiveness. In this chapter, we start by describing the classic argument mining tasks, and then we present the new tasks proposed lately in the literature. We discuss the obtained results in the area from a data-driven perspective. An open discussion highlights the main weaknesses suffered by the existing work in the literature, and proposes open challenges to be faced in the future.",2022,,JOURNAL OF APPLIED LOGICS-IFCOLOG JOURNAL OF LOGICS AND THEIR APPLICATIONS,9,4,757-785,WOS:000836601100001,,,#4256,Cabrio 2022,"",""
914isthebest at SemEval-2024 Task 4: CoT-based Data Augmentation Strategy for Persuasion Techniques Detection,"Li, DL; Wang, CH; Zou, X; Wang, JL; Chen, P; Wang, J; Yang, L; Lin, HF","Memes are commonly used in online disinformation campaigns, particularly on social media platforms. They are primarily effective on social media platforms since they can easily reach many users. Semeval2024-Task4(Dimitrov et al., 2024), ""Multilingual detection of persuasion techniques in memes"", focuses on detecting persuasive methods across four languages: English, Bulgarian, North Macedonian and Arabic. Subtask 1 aims to identify the given text fragments of memes and which of the 20 persuasion techniques it uses, organized in a hierarchy. For the difficulty of this task and the fundamental role of text in the artificial intelligence area, we concentrate solely on this task. We develop a system using CoT-based data augmentation methods,in-domain pretraining and ensemble strategy that combines the strengths of both RoBERTa and DeBERTa models. Our solution achieved the top ranking among 33 teams in the English track during the official assessments. We also analyze the impact of architectural decisions, data construction and training strategies. We release our code at https://github.com/ldlbest/semeval2024-task4",2024,,"PROCEEDINGS OF THE 18TH INTERNATIONAL WORKSHOP ON SEMANTIC EVALUATION, SEMEVAL-2024",,,1315-1321,WOS:001356736800190,,,#4257,Li 2024,"",""
Evaluating the Effectiveness of Bayesian Knowledge Tracing Model-Based Explainable Recommender,"Takami, K; Flanagan, B; Dai, YL; Ogata, H","Explainable recommendation, which provides an explanation about why a quiz is recommended, helps to improve transparency, persuasiveness, and trustworthiness. However, little research examined the effectiveness of the explainable recommender, especially on academic performance. To survey its effectiveness, the authors evaluate the math academic performance among middle school students (n=115) by giving pre- and post-test questions based evaluation techniques. During the pre- and post-test periods, students were encouraged to use the Bayesian Knowledge Tracing model based explainable recommendation system. To evaluate how well the students were able to do what they could not do, the authors defined growth rate and found recommended quiz clicked counts had a positive effect on the total number of solved quizzes (R=0.343, P=0.005) and growth rate (R=0.297, P=0.017) despite no correlation between the total number of solved quizzes and growth rate. The results suggest that the use of an explainable recommendation system that learns efficiently will enable students to do what they could not do before.",2024,,INTERNATIONAL JOURNAL OF DISTANCE EDUCATION TECHNOLOGIES,22,1,,WOS:001160903100001,10.4018/IJDET.337600,,#4258,Takami 2024,"",""
On the Computation of Top-k Extensions in Abstract Argumentation Frameworks,"Jabbour, S; Raddaoui, B; Sais, L; Salhi, Y","Formal argumentation has received a lot of attention during the last two decades, since abstract argumentation framework provides the basis for various reasoning problems in Artificial Intelligence. Unfortunately, the exponential number of its possible semantics extensions makes some reasoning problems intractable in this framework. In this paper, we investigate the pivotal issue of efficient computation of acceptable arguments called extensions according to a given semantics. In particular, we address this aspect by applying a strategy of how to use preferences at the semantics level in order to determine what are ""desirable"" outcomes of the argumentation process. Then, we present a new approach for computing the Top-k extensions of an abstract argumentation framework, according to a user-specified preference relation. Indeed, an extension is a Top-k extension for a given semantics if it admits less than k extensions preferred to it with respect to a preference relation. Our experiments on various datasets demonstrate the effectiveness and scalability of our approach and the accuracy of the proposed enumeration method.",2016,,ECAI 2016: 22ND EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE,285,,913-920,WOS:000385793700107,10.3233/978-1-61499-672-9-913,,#4259,Jabbour 2016,"",""
Multi-Modal Dialogue Policy Learning for Dynamic and Co-operative Goal Setting,"IEEE; Tiwari, A; Saha, T; Saha, S; Sengupta, S; Maitra, A; Ramnani, R; Bhattacharyya, P","Developing an adequate and human-like virtual agent has been one of the primary applications of artificial intelligence. In the last few years, task-oriented dialogue systems have gained huge popularity because of their upsurging relevance and positive outcomes. In real-world, users may not always have a predefined and rigid task goal beforehand; they upgrade/downgrade/change their goal component dynamically depending upon their utility value and agent's serving capability. However, existing virtual agents fail to incorporate this dynamic behavior, leading to either unsuccessful task completion or an ungratified user experience. The paper presents an end to end multimodal dialogue system for dynamic and co-operative goal setting, which incorporates i) a multi-modal semantic state representation in policy learning to deal with multi-modal inputs, ii) a goal manager module in a traditional dialogue manager for handling dynamic and goal unavailability scenarios effectively, iii) an accumulative reward (task/persona/sentiment) for task success, personalized persuasion and user-adaptive behavior, respectively. The obtained experimental results and the comparisons with baselines firmly establish the need and efficacy of the proposed system.",2021,,2021 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN),,,,WOS:000722581704084,10.1109/IJCNN52387.2021.9533878,,#4260,IEEE 2021,"",""
Disparate Impact Diminishes Consumer Trust Even for Advantaged Users,"Draws, T; Szlávik, Z; Timmermans, B; Tintarev, N; Varshney, KR; Hind, M","Systems aiming to aid consumers in their decision-making (e.g., by implementing persuasive techniques) are more likely to be effective when consumers trust them. However, recent research has demonstrated that the machine learning algorithms that often underlie such technology can act unfairly towards specific groups (e.g., by making more favorable predictions for men than for women). An undesired disparate impact resulting from this kind of algorithmic unfairness could diminish consumer trust and thereby undermine the purpose of the system. We studied this effect by conducting a between-subjects user study investigating how (gender-related) disparate impact affected consumer trust in an app designed to improve consumers' financial decision-making. Our results show that disparate impact decreased consumers' trust in the system and made them less likely to use it. Moreover, we find that trust was affected to the same degree across consumer groups (i.e., advantaged and disadvantaged users) despite both of these consumer groups recognizing their respective levels of personal benefit. Our findings highlight the importance of fairness in consumer-oriented artificial intelligence systems.",2021,,PERSUASIVE TECHNOLOGY (PERSUASIVE 2021),12684,,135-149,WOS:000788285600011,10.1007/978-3-030-79460-6_11,,#4261,Draws 2021,"",""
Towards Demystifying Subliminal Persuasiveness: Using XAI-Techniques to Highlight Persuasive Markers of Public Speeches,"Weber, K; Tinnes, L; Huber, T; Heimerl, A; Reinecker, ML; Pohlen, E; André, E","The literature provides evidence for the importance of nonverbal cues when it comes to persuading other people and developing persuasive robots. Mostly, people use these non-verbal cues subconsciously and, more importantly, are not aware of the subliminal impact of them. To raise awareness of subliminal persuasion and to explore a way for investigating persuasive cues for the development of persuasive robots and agents, we have analyzed videos of political public speeches and trained a neural network capable of predicting the degree of perceived convincingness based on visual input only. We then created visualizations of the predictions by making use of the explainable artificial intelligence methods Grad-CAM and layer-wise relevance propagation that highlight the most relevant image sections and markers. Our results show that the neural network learned to focus on the person, more specifically their posture and contours, as well as on their hands and face. These results are in line with existing literature and, thus, show the practical potential of our approach.",2020,,"EXPLAINABLE, TRANSPARENT AUTONOMOUS AGENTS AND MULTI-AGENT SYSTEMS (EXTRAAMAS 2020)",12175,,113-128,WOS:000695272300007,10.1007/978-3-030-51924-7_7,,#4262,Weber 2020,"",""
Lessons on Using Computationally Generated Influence for Shaping Narrative Experiences,"Roberts, DL; Isbell, CL","In this paper, we present computational models for generating influence that allow story managers to shape players' decisions in interactive narrative experiences. Our approach uses concepts from social psychology, discourse analysis, and natural language generation. We describe an abstract formalism to operationalize tools of social psychological influence described by Cialdini (Influence: The Psychology of Persuasion, NewYork, NY, USA: Harper-Collins, 1998) and evaluate two example implementations that enable a storytelling system to generate influence on the fly (with varying degrees of success), thereby adapting stories to realize goals specified by authors. These implementations are used in an interactive story where influence is generated dynamically as players' experiences unfold. We present the results of a user study to characterize the effectiveness of these models. Results did not indicate the presence of any significant differences in players' sense of control over the story with, or without, the use of influence. Further, the use of influence resulted in a set of stories experienced by players that more closely matched the author's goals.",2014,,IEEE TRANSACTIONS ON COMPUTATIONAL INTELLIGENCE AND AI IN GAMES,6,2,188-202,WOS:000337901800009,10.1109/TCIAIG.2013.2287154,,#4263,Roberts 2014,"",""
First encounter with robot Alpha: How individual differences interact with vocal and kinetic cues in users' social responses,"Xu, K","The Computers are Social Actors (CASA) paradigm was proposed more than two decades ago to understand humans' interaction with computer technologies. Today, as emerging technologies like social robots become more personal and persuasive, questions of how users respond to them socially, what individual factors leverage the relationship, and what constitutes the social influence of these technologies need to be addressed. A lab experiment was conducted to examine the interactions between individual differences and social robots' vocal and kinetic cues. Results suggested that users developed more trust in a social robot with a human voice than with a synthetic voice. Users also developed more intimacy and interest in the social robot when it was paired with humanlike gestures. Moreover, individual differences including users' gender, attitudes toward robots, and robot exposure affected their psychological responses. The theoretical, practical, and ethical value of the findings was further discussed in the study.",2019,,NEW MEDIA & SOCIETY,21,11-12,2522-2547,WOS:000485297300011,10.1177/1461444819851479,,#4264,Xu 2019,"",""
An Empirical Study on Group Fairness Metrics of Judicial Data,"Li, YJ; Huang, H; Guo, XW; Yuan, YY","Group fairness means that different groups have an equal probability of being predicted for one aspect. It is a significant fairness definition, which is conducive to maintaining social harmony and stability. Fairness is a vital issue when an artificial intelligence software system is used to make judicial decisions. Either data or algorithm alone may lead to unfair results. Determining the fairness of the dataset is a prerequisite for studying the fairness of algorithms. This paper focuses on the dataset to research group fairness from both micro and macro views. We propose a framework to determine the sensitive attributes of a dataset and metrics to measure the fair degree of sensitive attributes. We conducted experiments and statistical analysis of the judicial data to demonstrate the framework and metric approach better. The framework and metric approach can be applied to datasets of other domains, providing persuasive evidence for the effectiveness and availability of algorithmic fairness research. It opens up a new way for the research of the fairness of the dataset.",2021,,IEEE ACCESS,9,,149043-149049,WOS:000716686700001,10.1109/ACCESS.2021.3122443,,#4265,Li 2021,"",""
"It is only for your own good, or is it? Ethical Considerations for Designing Ethically Conscious Persuasive Information Systems Completed Research","Assoc Informat Syst; Benner, D; Schöbel, S; Janson, A","Persuasive designs, including gamification and digital nudging, have become well renowned during the last years and have been implemented successfully across different sectors including education, e-health, e-governance, e-finance and general information systems. In this regard, persuasive design can support desirable changes in attitude and behavior of users in order to achieve their own goals. However, such persuasive influence on individuals raises ethical questions as persuasive designs can impair the autonomy of users or persuade the user towards goals of a third party and hence lead to unethical decision-making processes. In human-computer interaction this is especially significant with the advent of advanced artificial intelligence that can emulate human behavior and thus bring new dynamics into play. Therefore, we conduct a systematic literature analysis with the goal to compile an overview of ethical considerations for persuasive system design, derive potential guidelines for ethical persuasive designs and shed light on potential research gaps.",2021,,DIGITAL INNOVATION AND ENTREPRENEURSHIP (AMCIS 2021),,,,WOS:000672599801073,,,#4266,AssocInformatSyst 2021,"",""
Exploring Discourse Structures for Argument Impact Classification,"Assoc Computat Linguist; Liu, X; Ou, JF; Song, YQ; Jiang, X","Discourse relations among arguments reveal logical structures of a debate conversation. However, no prior work has explicitly studied how the sequence of discourse relations influence a claim's impact. This paper empirically shows that the discourse relations between two arguments along the context path are essential factors for identifying the persuasive power of an argument. We further propose DISCOC to inject and fuse the sentence-level structural discourse information with contextualized features derived from large-scale language models. Experimental results and extensive analysis show that the attention and gate mechanisms that explicitly model contexts and texts can indeed help the argument impact classification task defined by Durmus et al. (2019), and discourse structures among the context path of the claim to be classified can further boost the performance.",2021,,"59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1",,,3958-3969,WOS:000698679200106,,,#4267,AssocComputatLinguist 2021,"",""
Puer at SemEval-2024 Task 4: Fine-tuning Pre-trained Language Models for Meme Persuasion Technique Detection,"Dao, JX; Li, ZY; Su, YB; Gong, WS","The paper summarizes our research on multilingual detection of persuasion techniques in memes for the SemEval-2024 Task 4. Our work focused on English-Subtask 1, implemented based on a roberta-large pre-trained model provided by the transforms tool that was fine-tuned into a corpus of social media posts. Our method significantly outperforms the officially released baseline method, and ranked 7th in English-Subtask 1 for the test set. This paper also compares the performances of different deep learning model architectures, such as BERT, ALBERT, and XLM-RoBERTa, on multilingual detection of persuasion techniques in memes. The experimental source code covered in the paper will later be sourced from Github.",2024,,"PROCEEDINGS OF THE 18TH INTERNATIONAL WORKSHOP ON SEMANTIC EVALUATION, SEMEVAL-2024",,,64-69,WOS:001356736800011,,,#4268,Dao 2024,"",""
UMUTeam at SemEval-2024 Task 4: Multimodal Identification of Persuasive Techniques in Memes through Large Language Models,"Pan, RH; García-Díaz, JA; Valencia-García, R","In this manuscript we describe the UMUTeam's participation in SemEval-2024 Task 4, a shared task to identify different persuasion techniques in memes. The task is divided into three subtasks. One is a multimodal subtask of identifying whether a meme contains persuasion or not. The others are hierarchical multi-label classifications that consider textual content alone or a multimodal setting of text and visual content. This is a multilingual task, and we participated in all three subtasks but we focus only on the English dataset. Our approach is based on a fine-tuning approach with the pre-trained RoBERTa-large model. In addition, for multimodal cases with both textual and visual content, we used the LMM called LlaVa to extract image descriptions and combine them with the meme text. Our system performed well in three subtasks, achieving the tenth best result with an Hierarchical F1 of 64.774%, the fourth best in Subtask 2a with an Hierarchical F1 of 69.003%, and the eighth best in Subtask 2b with a Macro F1 of 78.660%.",2024,,"PROCEEDINGS OF THE 18TH INTERNATIONAL WORKSHOP ON SEMANTIC EVALUATION, SEMEVAL-2024",,,655-666,WOS:001356736800096,,,#4269,Pan 2024,"",""
Innovative Quantum PlasmoVision-Based Imaging for Real-Time Deepfake Detection,"Maheshwari, RU; Jayasudha, AR; Pandey, BK; Pandey, D","In recent years, the proliferation of deepfake images has posed a substantial threat to media credibility, security, and privacy. Contemporary detection techniques, predominantly reliant on deep learning algorithms, fail to identify the nuanced pixel-level discrepancies inherent in deepfake material. This study introduces PlasmoVision, an innovative quantum-enhanced plasmonic imaging technology that incorporates AI-driven deep learning for highly sensitive real-time deepfake detection. Deepfakes alter digital images and videos to produce very persuasive fraudulent content, rendering traditional detection methods ineffective. Plasmonic surface resonance technology, in conjunction with quantum dots, has the capacity to capture intricate image features that can disclose such alterations. Integrating deep learning into this detection system improves the accuracy and velocity of analysis. The PlasmoVision technology employs quantum dot-enhanced plasmonic arrays to detect sub-pixel-level resonance shifts resulting from light interaction with the image surface. The optical signals are analyzed with a sophisticated convolutional neural network (CNN) that categorizes images according to the plasmonic resonance data. The AI model is trained on a varied dataset of genuine and deepfake photos, attaining an ideal equilibrium between detection sensitivity and speed. Real-time picture analysis is accomplished by swift plasmonic scanning and AI-driven classification. The suggested device attained an accuracy rate of 98.6% in identifying deepfakes within a test dataset, exhibiting a false positive rate of 1.2% and a false negative rate of 0.5%. The quantum-enhanced plasmonic system identified pixel abnormalities with a sensitivity of up to 10 nm, markedly surpassing conventional deepfake detection technologies. PlasmoVision real-time analysis capacity decreased processing time by 35% relative to traditional approaches, rendering it exceptionally appropriate for extensive and real-time applications. The amalgamation of quantum dot plasmonic sensing and AI-driven deep learning in PlasmoVision provides an innovative solution for the precise and instantaneous identification of deepfake images. The device's elevated sensitivity, swift detection capability, and minimal error rates represent a notable progression in picture authentication, offering strong protection against deepfake alterations across multiple sectors, including digital media and biometric security systems.",2025,,PLASMONICS,,,,WOS:001443634600001,10.1007/s11468-025-02846-3,,#4270,Maheshwari 2025,"",""
The Earth is Flat because...: Investigating LLMs' Belief towards Misinformation via Persuasive Conversation Ethical Disclaimer: May Contain Misinformation in the Following Content,"Xu, RW; Lin, BS; Yang, SJ; Zhang, TQ; Shi, WY; Zhang, TW; Fang, ZX; Xu, W; Qiu, H","Large language models (LLMs) encapsulate vast amounts of knowledge but still remain vulnerable to external misinformation. Existing research mainly studied this susceptibility behavior in a single-turn setting. However, belief can change during a multi-turn conversation, especially a persuasive one. Therefore, in this study, we delve into LLMs' susceptibility to persuasive conversations, particularly on factual questions that they can answer correctly. We first curate the Farm (i.e., Fact to Misinform) dataset, which contains factual questions paired with systematically generated persuasive misinformation. Then, we develop a testing framework to track LLMs' belief changes in a persuasive dialogue. Through extensive experiments, we find that LLMs' correct beliefs on factual knowledge can be easily manipulated by various persuasive strategies.",2024,,"PROCEEDINGS OF THE 62ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1: LONG PAPERS",,,16259-16303,WOS:001391776307017,,,#4271,Xu 2024,"",""
CHASE: Commonsense-Enriched Advertising on Search Engine with Explicit Knowledge,"ACM; Zhang, C; Zhou, JB; Zang, XL; Xu, Q; Yin, L; He, X; Liu, LY; Xiong, H; Dou, DJ","While online advertising is one of the major sources of income for search engines, pumping up the incomes from business advertisements while ensuring the user experience becomes a challenging but emerging area. Designing high-quality advertisements with persuasive content has been proved as a way to increase revenues through improving the Click-Through Rate (CTR). However, it is difficult to scale up the design of high-quality ads, due to the lack of automation in creativity. In this paper, we present Commonsense-Enriched Advertisement on Search Engine (CHASE) - a system for the automatic generation of persuasive ads. CHASE adopts a specially designed language model that fuses the keywords, commonsenserelated texts, and marketing contents to generate persuasive advertisements. Specifically, the language model has been pre-trained using massive contents of explicit knowledge and fine-tuned with well-constructed quasi-parallel corpora with effective control of the proportion of commonsense in the generated ads and fitness to the ads' keywords. The effectiveness of the proposed method CHASE has been verified by real-world web traffics for search and manual evaluation. In A/B tests, the advertisements generated by CHASE would bring 11.13% CTR improvement. The proposed model has been deployed to cover three advertisement domains (which are kid education, psychological counseling, and beauty e-commerce) at Baidu, the world's largest Chinese search engine, with adding revenue of about 1 million RMB (Chinese Yuan) per day.",2021,,"PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021",,,4352-4361,WOS:001054156204039,10.1145/3459637.3481902,,#4272,ACM 2021,"",""
Social Media Analytics and Its Applications in Marketing,"Moon, S; Iacobucci, D","The rise of the Internet and smartphones in the 21st century has created and developed social media as an extremely effective means of communication in society. In life, business, sports, and politics, social media facilitates the democratization of ideas like never before. Social media content gives consumers different information sources that they must decipher to discern its trustworthiness and influence in their own opinions. Marketers must be savvy about using social media in their attempts to persuade consumers and build brand equity.As social media has permeated our everyday lives, scholars in various disciplines are actively conducting research into this aspect regarding our way of life. In this scholarly endeavor, marketing has taken a leading role in this research endeavor as a discipline involving human communications and idea persuasion. Thus, rather than considering social media broadly across multiple disciplines, in this monograph, we concentrate on social media analytics in marketing.This monograph comprises the following four sections:First, we provide an overview of social media and social media analytics (SMA). While much has already been said about social media generally, relatively less has been said about social media analytics. Thus, much of our focus is on SMA in terms of contributing to the current understanding of SMA in the field.Second, we concentrate on social media analytics in marketing. We discuss practical industry perspectives and examples, as well as recent marketing research by academics. Notably, we show how analytics may be used to address concerns about social media privacy and help detect fake reviews.Third, we summarize common tools for social media analytics in marketing. These methods can be complex, but they must be mastered for sound SMA practice. They encompass big data, artificial intelligence, machine learning, deep learning, text analytics, and visual analytics.Fourth, we discuss trends and a future research agenda. We also discuss how SMA might be better integrated into higher education.",2022,,FOUNDATIONS AND TRENDS IN MARKETING,15,4,213-292,WOS:000763478000001,10.1561/1700000073,,#4273,Moon 2022,"",""
Active Inference or Control as Inference? A Unifying View,"Imohiosen, A; Watson, J; Peters, J","Active inference (AI) is a persuasive theoretical framework from computational neuroscience that seeks to describe action and perception as inference-based computation. However, this framework has yet to provide practical sensorimotor control algorithms that are competitive with alternative approaches. In this work, we frame active inference through the lens of control as inference (CaI), a body of work that presents trajectory optimization as inference. From the wider view of 'probabilistic numerics', CaI offers principled, numerically robust optimal control solvers that provide uncertainty quantification, and can scale to nonlinear problems with approximate inference. We show that AI may be framed as partially-observed CaI when the cost function is defined specifically in the observation states.",2020,,"ACTIVE INFERENCE, IWAI 2020",1326,,12-19,WOS:001446861900002,10.1007/978-3-030-64919-7_2,,#4274,Imohiosen 2020,"",""
An improved artificial fish swarm algorithm optimized by particle swarm optimization algorithm with extended memory,"Duan, QC; Mao, MX; Duan, P; Hu, B","Purpose - The purpose of this paper is to solve the problem that the standard particle swarm optimization (PSO) algorithm has a low success rate when applied to the optimization of multidimensional and multi-extreme value functions, the authors would introduce the extended memory factor to the PSO algorithm. Furthermore, the paper aims to improve the convergence rate and precision of basic artificial fish swarm algorithm (FSA), a novel FSA optimized by PSO algorithm with extended memory (PSOEM-FSA) is proposed.Design/methodology/approach - In PSOEM-FSA, the extended memory for PSO is introduced to store each particle' historical information comprising of recent places, personal best positions and global best positions, and a parameter called extended memory effective factor is employed to describe the importance of extended memory. Then, stability region of its deterministic version in a dynamic environment is analyzed by means of the classic discrete control theory. Furthermore, the extended memory factor is applied to five kinds of behavior pattern for FSA, including swarming, following, remembering, communicating and searching.Findings - The paper proposes a new intelligent algorithm. On the one hand, this algorithm makes the fish swimming have the characteristics of the speed of inertia; on the other hand, it expands behavior patterns for the fish to choose in the search process and achieves higher accuracy and convergence rate than PSO-FSA, owning to extended memory beneficial to direction and purpose during search. Simulation results verify that these improvements can reduce the blindness of fish search process, improve optimization performance of the algorithm.Research limitations/implications - Because of the chosen research approach, the research results may lack persuasion. In the future study, the authors will conduct more experiments to understand the behavior of PSOEM-FSA. In addition, there are mainly two aspects that the performance of this algorithm could be further improved.Practical implications - The proposed algorithm can be used to many practical engineering problems such as tracking problems.Social implications - The authors hope that the PSOEM-FSA can increase a branch of FSA algorithm, and enrich the content of the intelligent algorithms to some extent.Originality/value - The novel optimized FSA algorithm proposed in this paper improves the convergence speed and searching precision of the ordinary FSA to some degree.",2016,,KYBERNETES,45,2,210-222,WOS:000370004500001,10.1108/K-09-2014-0198,,#4275,Duan 2016,"",""
"Consumers' persuasion knowledge of algorithms in social media advertising: identifying consumer groups based on awareness, appropriateness, and coping ability","Voorveld, HAM; Meppelink, CS; Boerman, SC","Advertising and brand communication in social media are increasingly driven by algorithms. Theoretically rooted in the Persuasion Knowledge Model, we aim to identify and investigate the prevalence of specific consumer groups that differ in their awareness levels, critical evaluations, and abilities to cope with such algorithmic persuasion in social media, as well as to investigate the predictors of these groups. By performing an online survey among a Dutch sample (n = 450) and a two-step cluster analysis, we identified four groups: the Control Paradox (the largest group), Fatigued, Uninformed but Critical, and Skilled and Critical. The four groups differed in respect to gender, age, education level, internet skills, self-reported knowledge of algorithms, privacy concerns, and perceived personalization of branded social media messages. Theoretically, this paper contributes to our understanding of algorithmic persuasion by proposing a consumer typology and discussing implications for the Persuasion Knowledge Model. Practically, this study provides evidence-based recommendations for policymakers on how to empower different types of consumers.",2024,,INTERNATIONAL JOURNAL OF ADVERTISING,43,6,960-986,WOS:001080390200001,10.1080/02650487.2023.2264045,,#4276,Voorveld 2024,"",""
Noticed and appreciated? The role of argument diversity in enhancing news credibility and reader satisfaction,"Zerback, T; Schneiders, P","Although viewpoint diversity is a keyvalue for audiences, journalism and media policy, not much is known about how audiences process and evaluate it. This is critical because any positive effect we might expect from a broad range of views (e.g., on opinion formation) requires that recipients recognize and appreciate it as a part of news content. The current study examines how news readers process and evaluate argument diversity as a specific aspect of viewpoint diversity. In a 2 x 2 x 2 between-subject experiment, 1363 subjects were exposed to news reports containing a diverse or homogenous set of arguments in the context of two currently debated issues (artificial intelligence and immigration). Reports were either published by a single or multiple media outlets to determine potential differences between internal and external argument diversity. We find that readers not only recognize the presence of argument diversity, but that it leads to an increase in overall news satisfaction. This increase can be attributed to a higher credibility of news reports with diverse arguments.",2024,,JOURNALISM,25,12,2523-2542,WOS:001136967200001,10.1177/14648849231226030,,#4277,Zerback 2024,"",""
Genetic algorithm for fuel spill identification,"Lavine, BK; Brzozowski, D; Moores, AJ; Davidson, CE; Mayfield, HT","Gas chromatography is frequently used to fingerprint fuel spills, with the gas chromatograms of the spill sample and the different candidate fuels compared visually in order to seek a best match. However, visual analysis of gas chromatograms is subjective and is not always persuasive in a court of law. Pattern recognition methods offer a better approach to the problem of matching gas chromatograms of weathered fuels. Pattern recognition methods involve less subjectivity in the interpretation of the data and are capable of identifying fingerprint patterns within gas chromatographic (GC) data characteristic of fuel-type, even if the fuel samples comprising the training set have been subjected to a variety of conditions. In this paper, We report on the development of a genetic algorithm (GA) for pattern recognition analysis of GC fuel spill data. The pattern recognition GA incorporates aspects of artificial intelligence and evolutionary computations to yield a ""smart"" one-pass procedure for feature selection. Its efficacy is demonstrated by way of two studies recently completed in our laboratory on fuel spill identification. (C) 2001 Elsevier Science B.V. All rights reserved.",2001,,ANALYTICA CHIMICA ACTA,437,2,233-246,WOS:000169646000008,10.1016/S0003-2670(01)00946-1,,#4278,Lavine 2001,"",""
Does it pay to be honest? The effect of retailer-provided negative feedback on consumers' product choice and shopping experience,"Merle, A; St-Onge, A; Sénécal, S","This research aims at investigating the potential double-edged sword effect of a retailer's negative feedback, which may not only lead consumers to alter their purchase decisions, but also provide a shopping experience that is more effortful and thus be of less utilitarian value. Three experiments were performed involving 678 participants. Overall, results suggest a double-edged sword effect of negative feedback in online and offline retail contexts. When compared to no feedback, neutral feedback, or positive feedback, negative feedback leads consumers to change their initial product choice whatever their choice uncertainty and whatever the feedback source (human advisor or algorithmic advisor). However, it also leads to the perception of more cognitive effort and reduced utilitarian value, resulting in lower purchase and word-of-mouth intentions. The only situation in which negative feedback does not degrade the utilitarian value of the shopping experience is when consumers are highly uncertain about their initial product choice.",2022,,JOURNAL OF BUSINESS RESEARCH,147,,532-543,WOS:000799247400020,10.1016/j.jbusres.2022.03.031,,#4279,Merle 2022,"",""
A quantitative argumentation-based Automated eXplainable Decision System for fake news detection on social media,"Chi, HX; Liao, BS","Social media is flooded with rumors, which make fake news detection a pressing problem. Many black box approaches have been proposed to automatically predict the veracity of claims. These methods are lack of interpretability. Thus, we propose a Quantitative Argumentation-based Automated eXplainable Decision-making System (QA-AXDS) to tackle this problem and provide users with explanations about the results. The system is fully data-driven in its processes, which allows our models to make greater use of data and be more automatic and scalable than other quantitative framework models. In terms of interpretability, the system can automatically acquire human-level knowledge, and interact with users in the form of dialog trees through explanatory models, thus helping them understand the internal reasoning process of the system. The experimental results show that our system has better transparency and interpretability than other approaches based on the pure machine learning methods, and performs competitively in accuracy among others. In addition, the explanation model provides a way to improve the algorithms when some problems are identified by checking the explanations. (C)& nbsp;2022 Elsevier B.V. All rights reserved.",2022,,KNOWLEDGE-BASED SYSTEMS,242,,,WOS:000788156100004,10.1016/j.knosys.2022.108378,,#4280,Chi 2022,"",""
Toward the Prevention of Privacy Threats: How Can We Persuade Our Social Network Platform Users?,"Ruiz-Dolz, R; Alemany, J; Heras, S; Garcia-Fornes, A","Complex decision-making problems, such as the privacy policy selection, when sharing content in online social network (OSN) platforms can significantly benefit from artificial intelligence systems. With the use of computational argumentation, it is possible to persuade human users to modify their initial decisions to avoid potential privacy threats and violations. In this paper, we present a study performed with the participation of 186 teenage users aimed at analyzing their behaviors when we try to persuade them to modify the post/publication of sensitive content on OSN platforms with different arguments. The results of the study revealed that the personality traits and the social interaction data (e.g., number of comment posts, friends, and likes) of our participants were significantly correlated with the persuasive power of the arguments. Therefore, these sets of features can be used to model OSN users and estimate the persuasive power of different arguments when used in human-computer interactions. The findings presented in this paper are helpful for personalizing decision support systems aimed at educating and preventing privacy violations on OSN platforms using arguments.",2024,,HUMAN-CENTRIC COMPUTING AND INFORMATION SCIENCES,14,,,WOS:001363020200001,10.22967/HCIS.2024.14.046,,#4281,Ruiz-Dolz 2024,"",""
Towards a Persuasive Recommender for Bike Sharing Systems: A Defeasible Argumentation Approach,"Diez, C; Palanca, J; Sanchez-Anguix, V; Heras, S; Giret, A; Julián, V","This work proposes a persuasion model based on argumentation theory and users' characteristics for improving the use of resources in bike sharing systems, fostering the use of the bicycles and thus contributing to greater energy sustainability by reducing the use of carbon-based fuels. More specifically, it aims to achieve a balanced network of pick-up and drop-off stations in urban areas with the help of the users, thus reducing the dedicated management trucks that redistribute bikes among stations. The proposal aims to persuade users to choose different routes from the shortest route between a start and an end location. This persuasion is carried out when it is not possible to park the bike in the desired station due to the lack of parking slots, or when the user is highly influenceable. Differently to other works, instead of employing a single criteria to recommend alternative stations, the proposed system can incorporate a variety of criteria. This result is achieved by providing a defeasible logic-based persuasion engine that is capable of aggregating the results from multiple recommendation rules. The proposed framework is showcased with an example scenario of a bike sharing system.",2019,,ENERGIES,12,4,,WOS:000460667700088,10.3390/en12040662,,#4282,Diez 2019,"",""
What the Metaverse Is (Really) and Why We Need to Know About It,"Riva, G; Wiederhold, BK","Major technology companies are investing significant sums of money in the creation of the metaverse whose main feature will be the fusion between the virtual world and the physical world. To allow this possibility is one of the less obvious features of the metaverse: the metaverse works like our minds. This ability makes the metaverse a significantly different technology from its predecessors. If television and social media are persuasive technologies, because of their ability to influence people's attitudes and behaviors, the metaverse is instead a transformative technology, capable of modifying what people think reality is. To achieve this goal, the technologies of the metaverse hack different key cognitive mechanisms: the experience of being in a place and in a body, the processes of brain-to-brain attunement and synchrony, and the ability of experiencing and inducing emotions. Clearly, these possibilities define totally new scenarios with positive and negative outcomes. Educating ourselves as to its promise, and the challenges it may present, is a necessity. This requires a ""humane,"" integrated, and multidisciplinary approach, with stakeholders at the supranational level joining in the conversation.",2022,,CYBERPSYCHOLOGY BEHAVIOR AND SOCIAL NETWORKING,25,6,355-359,WOS:000816203100004,10.1089/cyber.2022.0124,,#4283,Riva 2022,"",""
"Checking the Fact-Checkers: The Role of Source Type, Perceived Credibility, and Individual Differences in Fact-Checking Effectiveness","Liu, XY; Qi, L; Wang, L; Metzger, MJ","This study investigates fact-checking effectiveness in reducing belief in misinformation across various types of fact-check sources (i.e., professional fact-checkers, mainstream news outlets, social media platforms, artificial intelligence, and crowdsourcing). We examine fact-checker credibility perceptions as a mechanism to explain variance in fact-checking effectiveness across sources, while taking individual differences into account (i.e., analytic thinking and alignment with the fact-check verdict). An experiment with 859 participants revealed few differences in effectiveness across fact-checking sources but found that sources perceived as more credible are more effective. Indeed, the data show that perceived credibility of fact-check sources mediates the relationship between exposure to fact-checking messages and their effectiveness for some source types. Moreover, fact-checker credibility moderates the effect of alignment on effectiveness, while analytic thinking is unrelated to fact-checker credibility perceptions, alignment, and effectiveness. Other theoretical contributions include extending the scope of the credibility-persuasion association and the MAIN model to the fact-checking context, and empirically verifying a critical component of the two-step motivated reasoning model of misinformation correction.",2023,,COMMUNICATION RESEARCH,,,,WOS:001088445300001,10.1177/00936502231206419,,#4284,Liu 2023,"",""
Using Distributional Models for Studying the Influence of School Textbooks in Children Bias,"Ruzzetti, ES; Venditti, D; Zanzotto, FM; Fallucchi, F","School textbooks have a profound influence on shaping the thoughts of young individuals. Reducing sex, gender, and race bias in these educational materials is then an imperative social goal. Despite efforts to address bias, historical and contemporary textbooks have been found to perpetuate stereotyped associations: efficient techniques like word embeddings can be used to analyze a wide range of school textbooks to assess the presence of stereotyped biases. In this paper, we use Artificial Intelligence to test what happens if people are exposed to some textbooks or others. Our procedure can be used for in-silico testing of the persuasive power of textbooks. For this purpose, we introduce ChildDM, a model constructed from a corpus of children's free-produced language, and its domain-adapted version, ChildDM-School, trained on a collection of school textbooks. Leveraging the Word Embedding Association Test (WEAT) framework, we investigate how biases evolve in the language of children after exposition to historical textbooks. While historical textbooks tend to avoid explicit gender-based stereotypes in the scientific and artistic domains, they still conceal biases. Specifically, women are associated with caregiving and family-related activities.",2024,,IEEE ACCESS,12,,158207-158214,WOS:001346690100001,10.1109/ACCESS.2024.3413291,,#4285,Ruzzetti 2024,"",""
The Post-advertising Condition. A Socio-Semiotic and Semio-Pragmatic Approach to Algorithmic Capitalism,"Eugeni, R","The primary hypothesis of this paper is that recent years have seen a shift from digital advertising to post-advertising: thanks to the growing role of machine learning algorithms in communicational processes, advertising has been losing the character of explicitly persuasive addresses to assume that of friendly and open proposals and advice, or even the simple facilitation of everyday purchasing practices. The paper seeks to understand if and under what conditions the socio-semiotic and semio-pragmatic approaches developed in relation to traditional advertising can still be applied to post-advertising phenomena. The paper is divided into three parts. In the first one, the advent of the post-advertising condition is considered. In the second one, Amazon's Alexa, an example of a post-advertising dispositive, is analyzed. In the third part, the question of the use of traditional semiotic concepts and methods for the analysis of post-advertising is examined. The final answer to this question is affirmative, but on the condition that some new conceptual and methodological tools be introduced.",2019,,"SOCIAL COMPUTING AND SOCIAL MEDIA: COMMUNICATION AND SOCIAL COMMUNITIES, SCSM 2019, PT II",11579,,291-302,WOS:000656414500023,10.1007/978-3-030-21905-5_23,,#4286,Eugeni 2019,"",""
ChainSmith: Automatically Learning the Semantics of Malicious Campaigns by Mining Threat Intelligence Reports,"IEEE; Zhu, ZY; Dumitras, T","Modern cyber attacks consist of a series of steps and are generally part of larger campaigns. Large-scale field data provides a quantitative measurement of these campaigns. On the other hand, security practitioners extract and report qualitative campaign characteristics manually. Linking the two sources provides new insights about attacker strategies from measurements. However, this is a time-consuming task because qualitative measurements are generally reported in natural language and are not machine-readable.We propose an approach to bridge measurement data with manual analysis. We borrow the idea from threat intelligence: we define campaigns using a 4-stage model, and describe each stage using IOCs (indicators of compromise), e.g. URLs and IP addresses. We train a multi-class classifier to extract IOCs and further categorize them into different stages. We implement these ideas in a system called ChainSmith. Our system can achieve 91.9% precision and 97.8% recall in extracting IOCs, and can determine the campaign roles for 86.2% of IOCs with 78.2% precision and 80.7% recall. We run ChainSmith on 14,155 online security articles, from which we collect 24,653 IOCs. The semantic roles allow us to link manual attack analysis with large scale field measurements. In particular, we study the effectiveness of different persuasion techniques used on enticing user to download the payloads. We find that the campaign usually starts from social engineering and ""missing codec"" ruse is a common persuasion technique that generates the most suspicious downloads each day.",2018,,2018 3RD IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY (EUROS&P 2018),,,458-472,WOS:000568604800031,10.1109/EuroSP.2018.00039,,#4287,IEEE 2018,"",""
When does culture matter? Effects of personal knowledge on the correction of culture-based judgments,"Briley, DA; Aaker, JL","Four experiments demonstrate that culture-based differences in persuasion arise when a person processes information in a cursory, spontaneous manner, but-these differences dissipate when a person's intuitions are supplemented by more deliberative processing. North Americans are persuaded more by promotion-focused information, and Chinese people are persuaded more by prevention-focused information, but only when initial, automatic reactions to messages are given. Corrections to these default judgments occur when processing is thoughtful. These results underscore the idea that culture does not exert a constant, unwavering effect on consumer judgments. A key factor in determining whether culture-based effects loom large or fade is the extent to which a person draws on cultural versus more personal, knowledge when he or she is forming judgments.",2006,,JOURNAL OF MARKETING RESEARCH,43,3,395-408,WOS:000239878300010,10.1509/jmkr.43.3.395,,#4288,Briley 2006,"",""
Weakly-Supervised Hierarchical Models for Predicting Persuasion Strategies in Good-faith Textual Requests,"Assoc Advancement Artificial Intelligence; Chen, JA; Yang, DY","Modeling persuasive language has the potential to better facilitate our decision-making processes. Despite its importance, computational modeling of persuasion is still in its infancy, largely due to the lack of benchmark datasets that can provide quantitative labels of persuasive strategies to expedite this line of research. To this end, we introduce a large-scale multi-domain text corpus for modeling persuasive strategies in good-faith text requests. Moreover, we design a hierarchical weakly-supervised latent variable model that can leverage partially labeled data to predict such associated persuasive strategies for each sentence, where the supervision comes from both the overall document-level labels and very limited sentence-level labels. Experimental results showed that our proposed method outperformed existing semi-supervised baselines significantly. We have publicly released our code at https://github.com/GT-SALT/Persuasion_Strategy_WVAE.",2021,,"THIRTY-FIFTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, THIRTY-THIRD CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE AND THE ELEVENTH SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE",35,,12648-12656,WOS:000681269804036,,,#4289,AssocAdvancementArtificialIntelligence 2021,"",""
LMEME at SemEval-2024 Task 4: Teacher Student Fusion - Integrating CLIP with LLMs for Enhanced Persuasion Detection,"Li, SY; Wang, YK; Yang, L; Zhang, SW; Lin, HF","This paper describes our system used in the SemEval-2024 Task 4 Multilingual Detection of Persuasion Techniques in Memes. Our team proposes a detection system that employs a Teacher Student Fusion framework. Initially, a Large Language Model serves as the teacher, engaging in abductive reasoning on multimodal inputs to generate background knowledge on persuasion techniques, assisting in the training of a smaller downstream model. The student model adopts CLIP as an encoder for text and image features, and we incorporate an attention mechanism for modality alignment. Ultimately, our proposed system achieves a Macro-F1 score of 0.8103, ranking 1st out of 20 on the leaderboard of Subtask 2b in English. In Bulgarian, Macedonian and Arabic, our detection capabilities are ranked 1/15, 3/15 and 14/15.",2024,,"PROCEEDINGS OF THE 18TH INTERNATIONAL WORKSHOP ON SEMANTIC EVALUATION, SEMEVAL-2024",,,628-633,WOS:001356736800092,,,#4290,Li 2024,"",""
How do emotions affect giving? Examining the effects of textual and facial emotions in charitable crowdfunding,"Lu, BZ; Xu, TL; Fan, WG","Drawing on emotional contagion theory and language-mediated association theory, this study develops a research model to examine how textual and facial emotions affect charitable crowdfunding performance. We use computer-aided techniques to extract and measure specific textual and facial emotions in pitches. The proposed model is tested via regression analysis with a sample of 1372 campaigns collected from the largest charitable crowdfunding platform in China-Tencent Gongyi. Moreover, we conducted a fuzzy-set qualitative comparative analysis to examine the complementarity of textual and facial emotions, which supplements the regression analysis results. Our findings show that both textual and facial emotions can impact funding outcomes. However, the effects of specific emotions vary: some (e.g., textual sadness and facial anger) are positive, some (e.g., textual anger and facial fear) are negative, and others (e.g., textual fear, textual disgust, and facial sadness) are insignificant. Moreover, facial emotions complement textual emotions in their effects on funding outcomes. This research outlines a framework to offer a more detailed and comprehensive understanding of emotions in charitable crowdfunding. It also contributes to existing research by revealing the vital but complex role of emotions in the persuasive process of prosocial behaviors and by uncovering the different cognitive mechanisms underlying the impacts of textual and facial emotions.",2024,,FINANCIAL INNOVATION,10,1,,WOS:001230221100001,10.1186/s40854-024-00630-6,,#4291,Lu 2024,"",""
Neural signatures of social conformity: A coordinate-based activation likelihood estimation meta-analysis of functional brain imaging studies,"Wu, HY; Luo, Y; Feng, CL","People often align their behaviors with group opinions, known as social conformity. Many neuroscience studies have explored the neuropsychological mechanisms underlying social conformity. Here we employed a coordinate-based meta-analysis on neuroimaging studies of social conformity with the purpose to reveal the convergence of the underlying neural architecture. We identified a convergence of reported activation foci in regions associated with normative decision-making, including ventral striatum (VS), dorsal posterior medial frontal cortex (dorsal pMFC), and anterior insula (AI). Specifically, consistent deactivation of VS and activation of dorsal pMFC and AI are identified when people's responses deviate from group opinions. In addition, the deviation-related responses in dorsal pMFC predict people's conforming behavioral adjustments. These are consistent with current models that disagreement with others might evoke ""error"" signals, cognitive imbalance, and/or aversive feelings, which are plausibly detected in these brain regions as control signals to facilitate subsequent conforming behaviors. Finally, group opinions result in altered neural correlates of valuation, manifested as stronger responses of VS to stimuli endorsed than disliked by others. (C) 2016 Elsevier Ltd. All rights reserved.",2016,,NEUROSCIENCE AND BIOBEHAVIORAL REVIEWS,71,,101-111,WOS:000390502100007,10.1016/j.neubiorev.2016.08.038,,#4292,Wu 2016,"",""
Unveiling the Power of Argument Arrangement in Online Persuasive Discussions,"Mirzakhmedova, N; Kiesel, J; Al-Khatib, K; Stein, B","Previous research on argumentation in online discussions has largely focused on examining individual comments and neglected the interactive nature of discussions. In line with previous work, we represent individual comments as sequences of semantic argumentative unit types. However, because it is intuitively necessary for dialogical argumentation to address the opposing viewpoints, we extend this model by clustering type sequences into different argument arrangement patterns and representing discussions as sequences of these patterns. These sequences of patterns are a symbolic representation of argumentation strategies that capture the overall structure of discussions. Using this novel approach, we conduct an in-depth analysis of the strategies in 34,393 discussions from the online discussion forum Change My View and show that our discussion model is effective for persuasiveness prediction, outperforming LLM-based classifiers on the same data. Our results provide valuable insights into argumentation dynamics in online discussions and, through the presented prediction procedure, are of practical importance for writing assistance and persuasive text generation systems.",2023,,FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EMNLP 2023),,,15659-15671,WOS:001378234407057,,,#4293,Mirzakhmedova 2023,"",""
The Sustainability Game: AI Technology as an Intervention for Public Understanding of Cooperative Investment,"IEEE; Theodorou, A; Bandt-Law, B; Bryson, JJ","Cooperative behaviour is a fundamental strategy for survival; it positively affects economies, social relationships, and makes larger societal structures possible. People vary, however, in their willingness to engage in cooperative behaviour in a particular context. Here we examine whether AI can be effectively used to to alter individuals' implicit understanding of cooperative dynamics, and hence increase cooperation and participation in public goods projects. We developed an intervention-the Sustainability Game (SG)-to allow players to experience the consequences of individual investment strategies on a sustainable society. Results show that the intervention significantly increases individuals' cooperative behaviour in partially anonymised public goods contexts, but enhances competition one-on-one. This indicates our intervention does improve transparency of the systemic consequences of individual cooperative behaviour.",2019,,2019 IEEE CONFERENCE ON GAMES (COG),,,,WOS:000843154300070,,,#4294,IEEE 2019,"",""
Appeal for attention at SemEval-2023 Task 3: Data augmentation and extension strategies for detection of online news persuasion techniques,"Sergiu, A; Laura, C; George, S","In this paper, we proposed and explored the impact of four different dataset augmentation and extension strategies that we used for solving the subtask 3 of SemEval-2023 Task 3: multi-label persuasion techniques classification in a multi-lingual context. We consider two types of augmentation methods (one based on a modified version of synonym replacement and one based on translations) and two ways of extending the training dataset (using filtered data generated by GPT-3 and using a dataset from a previous competition). We studied the effects of the aforementioned techniques by using the augmented and/or extended training dataset to fine-tune a pretrained XLM-RoBERTa-Large model. Using the augmentation methods alone, we managed to obtain 3rd place for English, 13th place for Italian and between the 5th to 9th places for the other 7 languages during the competition.",2023,,"17TH INTERNATIONAL WORKSHOP ON SEMANTIC EVALUATION, SEMEVAL-2023",,,616-623,WOS:001281001900083,,,#4295,Sergiu 2023,"",""
Prompt-Based Monte-Carlo Tree Search for Goal-oriented Dialogue Policy Planning,"Yu, X; Chen, M; Yu, Z","Planning for goal-oriented dialogue often requires simulating future dialogue interactions and estimating task progress. Many approaches thus consider training neural networks to perform look-ahead search algorithms such as A* search and Monte Carlo Tree Search (MCTS). However, this training often requires abundant annotated data, which creates challenges when faced with noisy annotations or low-resource settings. We introduce GDP- ZERO, an approach using Open-Loop MCTS to perform goal-oriented dialogue policy planning without any model training. GDP-ZERO prompts a large language model to act as a policy prior, value function, user simulator, and system model during the tree search. We evaluate GDP- ZERO on the goal-oriented task PersuasionForGood, and find that its responses are preferred over ChatGPT up to 59.32% of the time, and are rated more persuasive than Chat-GPT during interactive evaluations(1).",2023,,"2023 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, EMNLP 2023",,,7101-7125,WOS:001275019907017,,,#4296,Yu 2023,"",""
A Novel Diagnostic Decision Support System for Medical Professionals: Prospective Feasibility Study,"Timiliotis, J; Blümke, B; Serfözö, PD; Gilbert, S; Ondrésik, M; Türk, E; Hirsch, MC; Eckstein, J","Background: Continuously growing medical knowledge and the increasing amount of data make it difficult for medical professionals to keep track of all new information and to place it in the context of existing information. A variety of digital technologies and artificial intelligence-based methods are currently available as persuasive tools to empower physicians in clinical decision-making and improve health care quality. A novel diagnostic decision support system (DDSS) prototype developed by Ada Health GmbH with a focus on traceability, transparency, and usability will be examined more closely in this study.Objective: The aim of this study is to test the feasibility and functionality of a novel DDSS prototype, exploring its potential and performance in identifying the underlying cause of acute dyspnea in patients at the University Hospital Basel.Methods: A prospective, observational feasibility study was conducted at the emergency department (ED) and internal medicine ward of the University Hospital Basel, Switzerland. A convenience sample of 20 adult patients admitted to the ED with dyspnea as the chief complaint and a high probability of inpatient admission was selected. A study physician followed the patients admitted to the ED throughout the hospitalization without interfering with the routine clinical work. Routinely collected health-related personal data from these patients were entered into the DDSS prototype. The DDSS prototype's resulting disease probability list was compared with the gold-standard main diagnosis provided by the treating physician.Results: The DDSS presented information with high clarity and had a user-friendly, novel, and transparent interface. The DDSS prototype was not perfectly suited for the ED as case entry was time-consuming (1.5-2 hours per case). It provided accurate decision support in the clinical inpatient setting (average of cases in which the correct diagnosis was the first diagnosis listed: 6/20, 30%, SD 2.10%; average of cases in which the correct diagnosis was listed as one of the top 3: 11/20, 55%, SD 2.39%; average of cases in which the correct diagnosis was listed as one of the top 5: 14/20, 70%, SD 2.26%) in patients with dyspnea as the main presenting complaint.Conclusions: The study of the feasibility and functionality of the tool was successful, with some limitations. Used in the right place, the DDSS has the potential to support physicians in their decision-making process by showing new pathways and unintentionally ignored diagnoses. The DDSS prototype had some limitations regarding the process of data input, diagnostic accuracy, and completeness of the integrated medical knowledge. The results of this study provide a basis for the tool's further development. In addition, future studies should be conducted with the aim to overcome the current limitations of the tool and study design.",2022,,JMIR FORMATIVE RESEARCH,6,3,,WOS:000854073700056,10.2196/29943,,#4297,Timiliotis 2022,"",""
Will There Be a Neurolaw Revolution?,"Kolber, AJ","The central debate in the field of neurolaw has focused on two claims. Joshua Greene and Jonathan Cohen argue that we do not have free will and that advances in neuroscience will eventually lead us to stop blaming people for their actions. Stephen Morse, by contrast, argues that we have free will and that the kind of advances Greene and Cohen envision will not and should not affect the law. I argue that neither side has persuasively made the case for or against a revolution in the way the law treats responsibility.There will, however, be a neurolaw revolution of a different sort. It will not necessarily arise from radical changes in our beliefs about criminal responsibility but from a wave of new brain technologies that will change society and the law in many ways, three of which I describe here: First, as new methods of brain imaging improve our ability to measure distress, the law will ease limitations on recoveries for emotional injuries. Second, as neuroirrzaging gives us better methods of inferring people's thoughts, we will have more laws to protect thought privacy but less actual thought privacy. Finally, improvements in artificial intelligence will systematically change how law is written and interpreted.",2014,,INDIANA LAW JOURNAL,89,2,807-845,WOS:000331849900007,,,#4298,Kolber 2014,"",""
Predicting online participation and adoption of autism unproven interventions: a case study of dietary interventions,"Ni, ZN; Qian, YX; Li, H; Mao, J; Ma, FC","Family caregivers of autistic children are susceptible to unconfirmed fads and false claims regarding to the efficacy of unproven interventions. This study aims to predict family caregivers' participation and adoption of unproven interventions in online communities. Based on the Diffusion of Innovations theory, we first divided the family caregivers' adoption process into five stages: awareness, persuasion, decision, implementation, and confirmation. Social network analysis and natural language processing methods were subsequently utilised to characterise personal, environmental, and behavioural factors for predicting the formation of last three stage. The results indicated promising evidence for the application of machine learning algorithms in predicting family caregivers' decision (AUC = 0.823), implementation (AUC = 0.887), and confirmation (AUC = 0.921). Furthermore, the results showed that factors such as social interaction, social persuasion, and modelling significantly contributed to family caregivers' online community participation and facilitated the adoption process of unproven interventions. Family caregivers with stronger negative emotions expressed were more likely to adopt unproven interventions and recommend these interventions to other community members, thereby accelerating the diffusion of these interventions.",2023,,BEHAVIOUR & INFORMATION TECHNOLOGY,,,,WOS:001105668000001,10.1080/0144929X.2023.2284241,,#4299,Ni 2023,"",""
Unisa at SemEval-2023 Task 3: A SHAP-based method for Propaganda Detection,"Bangerter, M; Fenza, G; Gallo, M; Loia, V; Volpe, A; De Maio, C; Stanzione, C","This paper presents proposed solutions for addressing two subtasks in SemEval-2023 Task 3: ""Detecting the Genre, the Framing, and the Persuasion techniques in online news in a multilingual setup"". In subtask 1, ""News Genre Categorisation"", the goal is to classify a news article as an opinion, a report, or a satire. In subtask 3, ""Detection of Persuasion Technique"", the system must reveal persuasion techniques used in each news article paragraph choosing among 23 defined methods.Solutions leverage the application of the eXplainable Artificial Intelligence (XAI) method, Shapley Additive Explanations (SHAP). In subtask 1, SHAP was used to understand what was driving the model to fail so that it could be improved accordingly. In contrast, in subtask 3, a re-calibration of the Attention Mechanism was realized by extracting critical tokens for each persuasion technique. The underlying idea is the exploitation of XAI for countering the overfitting of the resulting model and attempting to improve the performance when there are few samples in the training data. The achieved performance on English for subtask 1 ranked 6th with an F1-score of 58.6% (despite 78.4% of the 1st) and for subtask 3 ranked 12th with a micro-averaged F1-score of 29.8% (despite 37.6% of the 1st).",2023,,"17TH INTERNATIONAL WORKSHOP ON SEMANTIC EVALUATION, SEMEVAL-2023",,,885-891,WOS:001281001900121,,,#4300,Bangerter 2023,"",""
Authentically Fake? How Consumers Respond to the Influence of Virtual Influencers,"Lou, C; Kiew, STJ; Chen, T; Lee, TYM; Ong, JEC; Phua, Z","Artificially created characters - virtual influencers - amass millions of followers on social media and affect digital natives' engagement and decisionmaking in remarkable ways. Guided by the Uses and Gratification (U&G) approach and the Uncanny Valley Theory, this study seeks to understand this phenomenon. By looking into followers' engagement with virtual influencers, this study identifies and conceptualizes six primary motivations - namely, novelty, information, entertainment, surveillance, esthetics, and integration and social interaction. Furthermore, we found that most followers perceive virtual influencers as uncanny and authentically fake. However, followers also express acceptance of their staged fabrication where curated flaws and self-justification have been found to mitigate the effect of the uncanny valley. Virtual influencers are considered effective in building brand image and boosting brand awareness, but lack the persuasive ability to incite purchase intention due to a lack of authenticity, a low similarity to followers, and their weak parasocial relations with followers. These findings advance the extant literature on U&G, influencer advertising, and virtual influencers in the era of artificial intelligence; provide insights into the mitigating factors of the uncanny valley; and yield theoretical and practical implications for the efficacy of virtual influencers in advertising campaigns.",2023,,JOURNAL OF ADVERTISING,52,4,540-557,WOS:000902965800001,10.1080/00913367.2022.2149641,,#4301,Lou 2023,"",""
Audio Mining: The Role of Vocal Tone in Persuasion,"Wang, X; Lu, SJ; Li, X; Khamitov, M; Bendle, N","Persuasion success is often related to hard-to-measure characteristics, such as the way the persuader speaks. To examine how vocal tones impact persuasion in an online appeal, this research measures persuaders' vocal tones in Kickstarter video pitches using novel audio mining technology. Connecting vocal tone dimensions with real-world funding outcomes offers insight into the impact of vocal tones on receivers' actions. The core hypothesis of this paper is that a successful persuasion attempt is associated with vocal tones denoting (1) focus, (2) low stress, and (3) stable emotions. These three vocal tone dimensions-which are in line with the stereotype content model-matter because they allow receivers to make inferences about a persuader's competence. The hypotheses are tested with a large-scale empirical study using Kickstarter data, which is then replicated in a different category. In addition, two controlled experiments provide evidence that perceptions of competence mediate the impact of the three vocal tones on persuasion attempt success. The results identify key indicators of persuasion attempt success and suggest a greater role for audio mining in academic consumer research.",2021,,JOURNAL OF CONSUMER RESEARCH,48,2,189-211,WOS:000692566700001,10.1093/jcr/ucab012,,#4302,Wang 2021,"",""
CoQuiAAS: A Constraint-based Quick Abstract Argumentation Solver,"IEEE; Lagniez, JM; Lonca, E; Mailly, JG","Nowadays, argumentation is a salient keyword in artificial intelligence. The use of argumentation techniques is particularly convenient for thematics such that multiagent systems, where it allows to describe dialog protocols (using persuasion, negotiation,...) or on-line discussion analysis; it also allows to handle queries where a single agent has to reason with conflicting information (inference in the presence of inconsistency, inconsistency measure). This very rich framework gives numerous reasoning tools, thanks to several acceptability semantics and inference policies.On the other hand, the progress of SAT solvers in the recent years, and more generally the progress on Constraint Programming paradigms, lead to some powerful approaches that permit to tackle theoretically hard problems.The needs of efficient applications to solve the usual reasoning tasks in argumentation, together with the capabilities of modern Constraint Programming solvers, lead us to study the encoding of usual acceptability semantics into logical settings. We propose diverse use of Constraint Programming techniques to develop a software library dedicated to argumentative reasoning. We present a library which offers the advantages to be generic and easily adaptable. We finally describe an experimental study of our approach for a set of semantics and inference tasks, and we describe the behaviour of our solver during the First International Competition on Computational Models of Argumentation.",2015,,2015 IEEE 27TH INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE (ICTAI 2015),,,928-935,WOS:000374592500120,10.1109/ICTAI.2015.134,,#4303,IEEE 2015,"",""
A new model for knowledge representation and automatic deduction for A.I applications,"Ahmed, K","In spite of the variety of the given Artificial intelligence definitions, those definitions remain all rights on the fact that the purpose of A.I, is to translate the intelligent human behaviour to the computer. This do necessary, the modelling of the said intelligent human behaviour. However, the modelling task is not at all evident one. When the considered application is related to the human intuition (i.e acquiring and use knowledge), the modelling process move away from formal, and depends essentially on the expert perception of the human comportment to be modelled. Note that the expert perception mights be incomplete, and depends on research results given on each domain related to the human cognition. In spite of that, results given by some models conceived and applied in A.I domain, gave an encouraging results. Most persuasive example can be the neural networks. In this paper, we will present a simple model oriented to knowledge acquiring and use, we mean by use, the task commonly called ""deduction"". We based our model on some underlined human cognition behaviours. The main remarkable characteristics of that model can be the high level of abstraction of the model, the flexibility to adjunction, suppression and substitution, the graphical simple representation, and the tolerance to errors which can occur during knowledge acquisition.",2002,,"6TH WORLD MULTICONFERENCE ON SYSTEMICS, CYBERNETICS AND INFORMATICS, VOL XIII, PROCEEDINGS: CONCEPTS AND APPLICATIONS OF SYSTEMICS, CYBERNETICS AND INFORMATICS III",,,324-329,WOS:000179458900059,,,#4304,Ahmed 2002,"",""
Constraint representation towards precise data-driven storytelling,"IEEE COMPUTER SOC; Shi, YZ; Li, HT; Ruan, LC; Qu, HM","Data-driven storytelling serves as a crucial bridge for communicating ideas in a persuasive way. However, the manual creation of data stories is a multifaceted, labor-intensive, and case-specific effort, limiting their broader application. As a result, automating the creation of data stories has emerged as a significant research thrust. Despite advances in Artificial Intelligence, the systematic generation of data stories remains challenging due to their hybrid nature: they must frame a perspective based on a seed idea in a top-down manner, similar to traditional storytelling, while coherently grounding insights of given evidence in a bottom-up fashion, akin to data analysis. These dual requirements necessitate precise constraints on the permissible space of a data story. In this viewpoint, we propose integrating constraints into the data story generation process. Defined upon the hierarchies of interpretation and articulation, constraints shape both narrations and illustrations to align with seed ideas and contextualized evidence. We identify the taxonomy and required functionalities of these constraints. Although constraints can be heterogeneous and latent, we explore the potential to represent them in a computation-friendly fashion via Domain-Specific Languages. We believe that leveraging constraints will facilitate both artistic and scientific aspects of data story generation.",2024,,"2024 IEEE VIS WORKSHOP ON DATA STORYTELLING IN AN ERA OF GENERATIVE AI, GEN4DS",,,4-12,WOS:001447760600002,10.1109/GEN4DS63889.2024.00006,,#4305,IEEECOMPUTERSOC 2024,"",""
When E-Commerce Personalization Systems Show and Tell: Investigating the Relative Persuasive Appeal of Content-Based versus Collaborative Filtering,"Liao, MQ; Sundar, SS","In the e-commerce context, are we persuaded more by a product recommendation that matches our preferences (content filtering) or by one that is endorsed by others like us (collaborative filtering)? We addressed this question by conceptualizing these two filtering types as cues that trigger cognitive heuristics (mental shortcuts), following the heuristic-systematic model in social psychology. In addition, we investigated whether the degree to which the recommendation matches user preferences (or other users' endorsements) provides an argument for systematic processing, especially for those who need deeper insights into the accuracy of the algorithm, particularly in product categories where quality is subjective. Data from a 2 (algorithm type: content vs. collaborative filtering) x 3 (percentage match: low vs. medium vs. high) x 2 (product category: search vs. experience) + 2 (control: search and experience) between-subjects experiment (N = 469) reveal that for experience products, consumers prefer content-based filtering with higher percentage matches, because it is perceived as offering more transparency. This is especially true for individuals with high need for cognition. For search products, however, collaborative filtering leads to more positive evaluations by triggering the ""bandwagon effect."" These findings have implications for theory pertaining to the use of artificial intelligence in strategic communications and design of algorithms for e-commerce recommender systems.",2022,,JOURNAL OF ADVERTISING,51,2,256-267,WOS:000624718400001,10.1080/00913367.2021.1887013,,#4306,Liao 2022,"",""
EARS 2020: The 3rd International Workshop on ExplainAble Recommendation and Search,"ACM; Zhang, YF; Chen, X; Zhang, Y; Zhang, M; Shah, C","Explainable recommendation and search attempt to develop models or methods that not only generate high-quality recommendation or search results, but also interpretability of the models or explanations of the results for users or system designers, which can help to improve the system transparency, persuasiveness, trustworthiness, and effectiveness, etc. This is even more important in personalized search and recommendation scenarios, where users would like to know why a particular product, web page, news report, or friend suggestion exists in his or her own search and recommendation lists. The workshop focuses on the research and application of explainable recommendation, search, and a broader scope of IR tasks. It will gather researchers as well as practitioners in the field for discussions, idea communications, and research promotions. It will also generate insightful debates about the recent regulations regarding AI interpretability, to a broader community including but not limited to IR, machine learning, AI, Data Science, and beyond.",2020,,PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20),,,2472-2474,WOS:000722377700368,10.1145/3397271.3401468,,#4307,ACM 2020,"",""
Explaining the distribution of implicit means of misrepresentation: A case study on Italian immigration discourse,"Coschignano, S; Minnema, G; Zanchi, C","This study analyzes Fillmore's frames in a large corpus of Italian news headlines concerning migrations, dating from 2013 to 2021 and taken from newspapers of diverse ideological stances. Our goal is to assess whether, how, and why migrants' representation varies over time and across ideological stances. Our approach combines corpus-assisted critical discourse analysis with cognitive linguistics. We present a new methodology that exploits SOCIOFILLMORE, a tool integrating a novel Natural Language Processing model for automatic frame annotation into a web-based user interface for exploring frame-annotated corpora. In our corpus, the frequency distribution of frames varies over time according to detectable contextual factors. Across political stances, instead, the most frequent frames remain more constant: both right-winged and left-winged news providers contribute to reifying migrants into non-agentive entities. Further, in religious (Christian) press migrants are given a more humanizing depiction, but they still often appear in non-agentive roles. The distributions of frames can be explained by the fact that the latter act as indirect, routinized, and implicit means of (mis)representation. We suggest that framing entails inferential operations that take place unconsciously and can therefore escape the cognitive screening not only of those who receive discourse, but also of those who (re)produce it. & COPY; 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).",2023,,JOURNAL OF PRAGMATICS,213,,107-125,WOS:001040655500001,10.1016/j.pragma.2023.06.002,,#4308,Coschignano 2023,"",""
Putting your best pet forward: Language patterns of persuasion in online pet advertisements,"Markowitz, DM","This paper evaluates persuasion dynamics of animal adoption using text data from a large archive of online pet advertisements. In Study 1, 184,805 adoption profiles from Petfinder indicated how long a pet will remain online and unadopted. Consistent with evidence from related persuasion settings such as peer-to-peer lending, pets spent less time online if profile writers had an analytic thinking style and advertisements contained few peripheral processing cues such as social words. Study 2 (N = 676,004 adoption profiles) replicated Study 1 patterns and found that adopted pet profiles contained more markers of analytic thinking and fewer social words than unadopted pet profiles. In an experiment (Study 3, N = 987), participants read an adoption advertisement typical of adopted or unadopted pets. Participants self-reported that they would be more likely to adopt a pet and visit its shelter after reading a more analytic and less social adoption profile (indicators of adopted pets) than a less analytic and more social profile (indicators of unadopted pets). Finally, Study 4 (N = 3,245 Tweets) demonstrated that more analytic and less social word patterns relate to increased engagement online, such as likes and retweets. These data suggest pet adoption that begins online is a social and psychological process, enhanced by messages with markers of complex thinking and few humanizing references. Advances to persuasion theory are discussed, underscored by the implications for pet adoption and how language patterns in online advertisements can reflect influence at scale.",2020,,JOURNAL OF APPLIED SOCIAL PSYCHOLOGY,50,3,160-173,WOS:000504339900001,10.1111/jasp.12647,,#4309,Markowitz 2020,"",""
EARS 2019: The 2nd International Workshop on ExplainAble Recommendation and Search,"ACM; Zhang, YF; Zhang, Y; Zhang, M; Shah, C","Explainable recommendation and search attempt to develop models or methods that not only generate high-quality recommendation or search results, but also interpretability of the models or explanations of the results for users or system designers, which can help to improve the system transparency, persuasiveness, trustworthiness, and effectiveness, etc. This is even more important in personalized search and recommendation scenarios, where users would like to know why a particular product, web page, news report, or friend suggestion exists in his or her own search and recommendation lists. The workshop focuses on the research and application of explainable recommendation, search, and a broader scope of IR tasks. It will gather researchers as well as practitioners in the field for discussions, idea communications, and research promotions. It will also generate insightful debates about the recent regulations regarding AI interpretability, to a broader community including but not limited to IR, machine learning, AI, Data Science, and beyond.",2019,,PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19),,,1438-1440,WOS:000501488900247,10.1145/3331184.3331649,,#4310,ACM 2019,"",""
Decisions During Negatively-Framed Messages Yield Smaller Risk-Aversion-Related Brain Activation in Substance-Dependent Individuals,"Fukunaga, R; Bogg, T; Finn, PR; Brown, JW","A sizable segment of addiction research investigates the effects of persuasive message appeals on risky and deleterious behaviors. However, to date, little research has examined how various forms of message framing and corresponding behavioral choices might by mediated by risk-related brain regions. Using event-related functional MRI, we investigated brain regions hypothesized to mediate the influence of message appeals on decision making in substance-dependent (SD) compared with nonsubstance-dependent (non-SD) individuals. The Iowa Gambling Task (IGT) was modified to include positively-framed, negatively-framed, and control messages about long-term deck payoffs. In the positively-framed condition, the SD and non-SD groups showed improved decision-making performance that corresponded to higher risk-aversion-related brain activity in the anterior cingulate cortex (ACC) and anterior insula (AI). In contrast, in the negatively-framed condition, the SD group showed poorer performance that corresponded to lower risk-aversion-related brain activity in the AI region. In addition, only the non-SD group showed a positive association between decision quality and greater risk-related activity in the ACC, regardless of message type. The findings suggest substance-dependent individuals may have reduced neurocognitive sensitivity in the ACC and AI regions involved in risk perception and aversion during decision-making, especially in response to framed messages that emphasize reduced prospects for long-term gains.",2013,,PSYCHOLOGY OF ADDICTIVE BEHAVIORS,27,4,1141-1152,WOS:000329044500025,10.1037/a0030633,,#4311,Fukunaga 2013,"",""
Behavior Change Support Systems for Self-Treating Procrastination: Systematic Search in App Stores and Analysis of Motivational Design Archetypes,"Kirchner-Krath, J; Schmidt-Kraepelin, M; Schmähl, K; Schütz, C; Morschheuser, B; Sunyaev, A","Background: The phenomenon of procrastination refers to an individual's conscious decision to postpone the completion of tasks despite being aware of its adverse consequences in the future. Extant research in this field shows that procrastination is associated with increased levels of anxiety and stress and the likelihood of developing depression and calls for the development of suitable interventions that support individuals in making lasting positive changes to their procrastination behaviors. In parallel, practice has produced a plethora of behavior change support systems (BCSSs) that aim to provide a low-threshold, accessible alternative to in-person therapeutic approaches. Most of these BCSSs can be considered motivational BCSSs that combine functional, utilitarian components with hedonic and eudaimonic design elements to empower self-treatment. Although early studies have suggested the potential benefits of such BCSSs, research on understanding their specific design characteristics and support of individuals in self-treating procrastination is still in its infancy. Objective: In response to this gap between practice and research, we aimed to analyze and systemize the multitude of practical design efforts in motivational BCSSs for the self-treatment of procrastination and identify the main design archetypes that have emerged. Methods: We conducted a 3-step research approach. First, we identified 127 behavior change support apps for procrastination through a systematic screening process in theGerman and USAppleApp Store and Google Play Store. Second, we systematically coded the identified apps in terms of the behavior change techniques targeted by their functional design and hedonic or eudaimonic design elements. Third, we conducted a 2-step cluster analysis to identify archetypes of motivational design in behavior change support apps to combat procrastination. Results: A variety of motivational designs have been developed and implemented in practice, and our analysis identified five mainarchetypes: (1) structured progressmonitor, (2) self-improvementguide, (3) productivity adventure, (4) emotional wellness coach, and (5) social focus companion. The identified archetypes target different psychological determinants of procrastination and successfully use a variety of hedonic and eudaimonic design elements that extend beyond the current state of research. Conclusions:The results of our study provide a foundation for future research endeavors that aim to examine the comparative effects of motivational design archetypes and develop more effective interventions tailored to individual needs. For practitioners, the findings reveal the contemporary design space of motivational BCSSs to support the self-treatment of procrastination and may serve as blueprints that can guide the design of future systems. For individuals seeking support and health professionals treating procrastination, our study systemizes the landscape of apps, thereby facilitating the selection of one that best aligns with the patient's individual needs.",2025,,JOURNAL OF MEDICAL INTERNET RESEARCH,27,,,WOS:001434936200001,10.2196/65214,,#4312,Kirchner-Krath 2025,"",""
Automatic rating of therapist facilitative interpersonal skills in text: A natural language processing application,"Zech, JM; Steele, R; Foley, VK; Hull, TD","BackgroundWhile message-based therapy has been shown to be effective in treating a range of mood disorders, it is critical to ensure that providers are meeting a consistently high standard of care over this medium. One recently developed measure of messaging quality-The Facilitative Interpersonal Skills Task for Text (FIS-T)-provides estimates of therapists' demonstrated ability to convey psychotherapy's common factors (e.g., hopefulness, warmth, persuasiveness) over text. However, the FIS-T's scoring procedure relies on trained human coders to manually code responses, thereby rendering the FIS-T an unscalable quality control tool for large messaging therapy platforms.ObjectiveIn the present study, researchers developed two algorithms to automatically score therapist performance on the FIS-T task.MethodsThe FIS-T was administered to 978 messaging therapists, whose responses were then manually scored by a trained team of raters. Two machine learning algorithms were then trained on task-taker messages and coder scores: a support vector regressor (SVR) and a transformer-based neural network (DistilBERT).ResultsThe DistilBERT model had superior performance on the prediction task while providing a distribution of ratings that was more closely aligned with those of human raters, versus SVR. Specifically, the DistilBERT model was able to explain 58.8% of the variance (R-2 = 0.588) in human-derived ratings and realized a prediction mean absolute error of 0.134 on a 1-5 scale.ConclusionsAlgorithms can be effectively used to ensure that digital providers meet a consistently high standard of interactions in the course of messaging therapy. Natural language processing can be applied to develop new quality assurance systems in message-based digital psychotherapy.",2022,,FRONTIERS IN DIGITAL HEALTH,4,,,WOS:001034030800001,10.3389/fdgth.2022.917918,,#4313,Zech 2022,"",""
Using ChatGPT and Persuasive Technology for Personalized Recommendation Messages in Hotel Upselling,"Remountakis, M; Kotis, K; Kourtzis, B; Tsekouras, GE","Recommender systems have become indispensable tools in the hotel hospitality industry, enabling personalized and tailored experiences for guests. Recent advancements in large language models (LLMs), such as ChatGPT, and persuasive technologies have opened new avenues for enhancing the effectiveness of those systems. This paper explores the potential of integrating ChatGPT and persuasive technologies for automating and improving hotel hospitality recommender systems. First, we delve into the capabilities of ChatGPT, which can understand and generate human-like text, enabling more accurate and context-aware recommendations. We discuss the integration of ChatGPT into recommender systems, highlighting the ability to analyze user preferences, extract valuable insights from online reviews, and generate personalized recommendations based on guest profiles. Second, we investigate the role of persuasive technology in influencing user behavior and enhancing the persuasive impact of hotel recommendations. By incorporating persuasive techniques, such as social proof, scarcity, and personalization, recommender systems can effectively influence user decision making and encourage desired actions, such as booking a specific hotel or upgrading their room. To investigate the efficacy of ChatGPT and persuasive technologies, we present pilot experiments with a case study involving a hotel recommender system. Our inhouse commercial hotel marketing platform, eXclusivi, was extended with a new software module working with ChatGPT prompts and persuasive ads created for its recommendations. In particular, we developed an intelligent advertisement (ad) copy generation tool for the hotel marketing platform. The proposed approach allows for the hotel team to target all guests in their language, leveraging the integration with the hotel's reservation system. Overall, this paper contributes to the field of hotel hospitality by exploring the synergistic relationship between ChatGPT and persuasive technology in recommender systems, ultimately influencing guest satisfaction and hotel revenue.",2023,,INFORMATION,14,9,,WOS:001075636000001,10.3390/info14090504,,#4314,Remountakis 2023,"",""
Confronting Core Issues: A Critical Assessment of Attitude Polarization Using Tailored Experiments,"Velez, YR; Liu, P","A long-standing debate in political psychology considers whether individuals update their beliefs and attitudes in the direction of evidence or grow more confident in their convictions when confronted with counter-attitudinal arguments. Though recent studies have shown that instances of the latter tendency, which scholars have termed attitude polarization and ""belief backfire,"" are rarely observed in settings involving hot-button issues or viral misinformation, we know surprisingly little about how participants respond to information targeting deeply held attitudes, a key condition for triggering attitude polarization. We develop a tailored experimental design that measures participants' core issue positions and exposes them to personalized counter-attitudinal information using the large language model GPT-3. We find credible evidence of attitude polarization, but only when arguments are contentious and vitriolic. For lower valence counter-attitudinal arguments, attitude polarization is not detected. We conclude by discussing implications for the study of political cognition and the measurement of attitudes.",2025,,AMERICAN POLITICAL SCIENCE REVIEW,119,2,1036-1053,WOS:001284611200001,10.1017/S0003055424000819,,#4315,Velez 2025,"",""
"Lost in persuasion A multidisciplinary approach for developing usable, effective, and reproducible persuasive technology for health promotion","IEEE; Henkemans, OAB; van Empelen, P; Paradies, GL; Looije, R; Neerincx, MA","Despite its acknowledged benefits for health promotion, the full potential of persuasive technology is not (yet) reached in regard to usability, effectiveness, and reproducibility. It often lacks an effective combination of technical features and behavior change strategies. This paper presents a multidisciplinary approach, addressing both aspects. It builds on the frameworks of situated Cognitive Engineering and Intervention Mapping. The approach generates building blocks from theory originating from different relevant disciplines; it specifies change objectives and requirements, described in the context of use, for intervention (strategy) and interaction (technology); it evaluates process, effect and impact, whereby claims on interaction and intervention are validated. To cope with language barriers between developers from different disciplines, the approach is presented as a guideline, illustrated with a case study. This approach is expected to contribute to a sound design rationale, a broad reach and ongoing use of the technology, and larger results in regard to health promotion.",2015,,PROCEEDINGS OF THE 2015 9TH INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING TECHNOLOGIES FOR HEALTHCARE (PERVASIVEHEALTH),,,49-56,WOS:000379199200008,10.4108/icst.pervasivehealth.2015.259161,,#4316,IEEE 2015,"",""
Loose and Tight: Creative Formation but Rigid Use of Nominal Compounds in Conspiracist Texts,"Miani, A; van der Plas, L; Bangerter, A","Conspiracy theories (CTs) are spectacular narratives, widely spread, that pose societal threats. We test whether CTs might be linguistically creative products, which would facilitate their transmission and thereby account for their widespread popularity. We analyzed nominal compounds (e.g., mind control, carbon dioxide; N = 1,713,568) from a large corpus of conspiracist and mainstream texts matched by topic. In conspiracist texts, compounds showed greater originality, divergence, and sophistication, but they were used with lower frequency and were more often repeated in different contexts. This pattern suggests a creative aspect in the generation of compounds, coupled with rigidity in their use. We interpret these findings as an effect of loosely defined conceptual boundaries among conspiracist writers, in conjunction with social functions like status or group signaling. Our findings not only contribute to the discourse on creativity in CTs but also provide insights into the communicative advantage of CTs.",2024,,JOURNAL OF CREATIVE BEHAVIOR,58,1,114-127,WOS:001136302000001,10.1002/jocb.633,,#4317,Miani 2024,"",""
StayFocused: Examining the Effects of Reflective Prompts and Chatbot Support on Compulsive Smartphone Use,"ACM; Li, ZY; Liang, MH; Ray, LC; Luo, YH","Amidst the increasingly prevalent smartphone addiction, we introduce StayFocused, a mobile app to help people focus on their tasks at hand by reducing compulsive smartphone use. Besides guiding people to set focus sessions for non-screen time, we incorporated reflective prompts probing individuals' phone-checking intentions whenever they check their phones and a chatbot to deliver these prompts. To examine the effects of the refective prompts and the chatbot support, we designed three versions of StayFocused: baseline, reflection, and reflection-chatbot, and conducted a stage-based between-subjects study with 36 college students over five weeks. We found that participants who received the reflective prompts were able to focus longer and resist distractions, and those with chatbot support seemed to better maintain their smartphone use reduction. By highlighting how participants reflected on their focus session activities and their preferences for the chatbot, we discuss the implications of designing persuasive conversational interfaces to reduce unintended behaviors.",2024,,PROCEEDINGS OF THE 2024 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYTEMS (CHI 2024),,,,WOS:001259864901035,10.1145/3613904.3642479,,#4318,ACM 2024,"",""
Unlocking the power of multimodal online reviews: A multisensory perspective,"Sun, SL; Sun, HQ; Xu, HZ; Li, HY; Wang, SY","Multimodal online reviews have been an essential marketing tool for dominating consumer perception. However, the precise impact of visual, auditory, tactile, gustatory, and olfactory cues in multimodal content on consumers' perceived review usefulness remains unclear. This study aims to fill this gap by exploring how text and image contents affect review usefulness from a multisensory perspective. To this end, we proposed a framework that combined machine learning and multimodal large language models to quantify the multisensory elements conveyed through review text and images. Based on the Poisson regression model, the estimation results show that while multisensory elements in text and images have a generally consistent impact on consumer perception, each sensory element carries distinct value. Furthermore, the sensory discrepancy in text and images has a negative effect on the perceived review usefulness. Our findings contribute theoretically to enhancing review persuasion effect and sensory marketing literature.",2025,,TOURISM MANAGEMENT,111,,,WOS:001485940600001,10.1016/j.tourman.2025.105206,,#4319,Sun 2025,"",""
Decomposing Argumentative Essay Generation via Dialectical Planning of Complex Reasoning,"He, YH; Bao, JZ; Sun, Y; Liang, B; Yang, M; Qin, B; Xu, RF","Argumentative Essay Generation (AEG) is a challenging task in computational argumentation, where detailed logical reasoning and effective rhetorical skills are essential. Previous methods on argument generation typically involve planning prior to generation. However, the planning strategies in these methods overlook the exploration of the logical reasoning process. Inspired by argument structure-related theories, we propose an argumentative planning strategy for prompting large language models (LLMs) to generate high-quality essays. This strategy comprises two stages: (1) Sketch planning, which creates a rough outline of the essay, and (2) Dialectical planning, which refines the outline through critical self-reflection. Such a planning strategy enables LLMs to write argumentative essays that are more logical, diverse, and persuasive. Furthermore, due to the scarcity of existing AEG datasets, we construct three new datasets. These datasets are from two domains: exam essays and news editorials, covering both Chinese and English. Automatic and manual evaluation on four datasets show that our method can generate more dialectical and persuasive essays with higher diversity compared to several strong baselines1.",2024,,FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: ACL 2024,,,12305-12322,WOS:001391786804001,,,#4320,He 2024,"",""
BCAmirs at SemEval-2024 Task 4: Beyond Words: A Multimodal and Multilingual Exploration of Persuasion in Memes,"Abaskohi, A; Dabiriaghdam, A; Wang, L; Carenini, G","Memes, combining text and images, frequently use metaphors to convey persuasive messages, shaping public opinion. Motivated by this, our team engaged in SemEval-2024 Task 4, a hierarchical multi-label classification task designed to identify rhetorical and psychological persuasion techniques embedded within memes. To tackle this problem, we introduced a caption generation step to assess the modality gap and the impact of additional semantic information from images, which improved our result. Our best model utilizes GPT-4 generated captions alongside meme text to fine-tune RoBERTa as the text encoder and CLIP as the image encoder. It outperforms the baseline by a large margin in all 12 subtasks. In particular, it ranked in top-3 across all languages in Subtask 2a, and top-4 in Subtask 2b, demonstrating quantitatively strong performance. The improvement achieved by the introduced intermediate step is likely attributable to the metaphorical essence of images that challenges visual encoders. This highlights the potential for improving abstract visual semantics encoding.(1)",2024,,"PROCEEDINGS OF THE 18TH INTERNATIONAL WORKSHOP ON SEMANTIC EVALUATION, SEMEVAL-2024",,,1412-1423,WOS:001356736800203,,,#4321,Abaskohi 2024,"",""
Unveiling Emotional Intensity in Online Reviews: Adopting Advanced Machine Learning Techniques,"Lee, SJ; de Villiers, R","The digital revolution has spurred significant growth in online reviews and user-generated content. Traditional methods used in Marketing for analysing large datasets have limitations, emphasising the need for improved analytical approaches, particularly with the advent of artificial intelligence technology. This research used a state-of-the-art transformer model to analyse extensive online book reviews to accurately identify six specific emotions in the reviews of both fiction (hedonic) and nonfiction (utilitarian) genres. This study collected 3,157,703 reviews of 15,293 books voted 'best book of the year' on GoodReads.com over the past decade. Our findings reveal noticeable differences in emotional intensity across genres, with nonfiction displaying a slightly higher level of joy, and fiction showing higher levels of anger, sadness and surprise. Joy emerged as the dominant emotion across genres; however, it does not necessarily have a direct impact on book ratings. This study emphasises the intricacies of reader emotions, serving as a significant case study for marketers and publishers aiming to optimise their strategies in the contemporary literary market. The study contributes to the literature on the impact of consumers' emotional responses, how they are reflected in social review commentary for high-involvement online products, and their impact on product ratings.",2025,,AUSTRALASIAN MARKETING JOURNAL,33,1,75-86,WOS:001197867000001,10.1177/14413582241244808,,#4322,Lee 2025,"",""
From Persuasion Theory to Climate Action: Insights and Future Directions for Increasing Climate-Friendly Behavior,"Miller, LB","Combatting climate change requires motivating individuals to adopt climate-friendly behaviors, whether to make individual lifestyle changes, vote for environmental policy, or accept technological innovations. Efforts to promote such behaviors can be more effective when informed by theoretically and empirically driven insights into human behavior change-an endeavor led by persuasion research. This review explores the intersection of persuasion research and climate-friendly behavior, demonstrating how persuasion theory can be applied to encourage climate action. Key theoretical approaches are examined, including the theory of planned behavior, social norms, narrative-based persuasion, framing, and emotional appeals, along with considerations for their practical applications. Additionally, promising future directions for integrating persuasion research into climate change interventions are highlighted; these include tailoring messages based on moral foundations theory and the transtheoretical model, as well as leveraging artificial intelligence to personalize climate-friendly recommendations. By synthesizing insights across persuasion and environmental research, this review provides valuable guidance for environmental researchers, policymakers, intervention designers, communication strategists, and environmental activists in developing robust and effective strategies to increase climate action at a time when accelerating these behaviors is more urgent than ever.",2025,,SUSTAINABILITY,17,7,,WOS:001465621000001,10.3390/su17072832,,#4323,Miller 2025,"",""
The emergence of explainability of intelligent systems: Delivering explainable and personalized recommendations for energy efficiency,"Sardianos, C; Varlamis, I; Chronis, C; Dimitrakopoulos, G; Alsalemi, A; Himeur, Y; Bensaali, F; Amira, A","The recent advances in artificial intelligence namely in machine learning and deep learning, have boosted the performance of intelligent systems in several ways. This gave rise to human expectations, but also created the need for a deeper understanding of how intelligent systems think and decide. The concept of explainability appeared, in the extent of explaining the internal system mechanics in human terms. Recommendation systems are intelligent systems that support human decision making, and as such, they have to be explainable to increase user trust and improve the acceptance of recommendations. In this study, we focus on a context-aware recommendation system for energy efficiency and develop a mechanism for explainable and persuasive recommendations, which are personalized to user preferences and habits. The persuasive facts either emphasize on the economical saving prospects (Econ) or on a positive ecological impact (Eco) and explanations provide the reason for recommending an energy saving action. Based on a study conducted using a Telegram bot, different scenarios have been validated with actual data and human feedback. Current results show a total increase of 19% on the recommendation acceptance ratio when both economical and ecological persuasive facts are employed. This revolutionary approach on recommendation systems, demonstrates how intelligent recommendations can effectively encourage energy saving behavior.",2021,,INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS,36,2,656-680,WOS:000580453900001,10.1002/int.22314,,#4324,Sardianos 2021,"",""
Algorithms and complexity results for persuasive argumentation,"Kim, EJ; Ordyniak, S; Szeider, S","The study of arguments as abstract entities and their interaction as introduced by Dung (1995) [1] has become one of the most active research branches within Artificial Intelligence and Reasoning. A main issue for abstract argumentation systems is the selection of acceptable sets of arguments. Value-based argumentation, as introduced by Bench-Capon (2003) [8]. extends Dung's framework. It takes into account the relative strength of arguments with respect to some ranking representing an audience: an argument is subjectively accepted if it is accepted with respect to some audience, it is objectively accepted if it is accepted with respect to all audiences.Deciding whether an argument is subjectively or objectively accepted, respectively, are computationally intractable problems. In fact, the problems remain intractable under structural restrictions that render the main computational problems for non-value-based argumentation systems tractable. In this paper we identify nontrivial classes of value-based argumentation systems for which the acceptance problems are polynomial-time tractable. The classes are defined by means of structural restrictions in terms of the underlying graphical structure of the value-based system. Furthermore we show that the acceptance problems are intractable for two classes of value-based systems that where conjectured to be tractable by Dunne (2007) [12]. (C) 2011 Elsevier B.V. All rights reserved.",2011,,ARTIFICIAL INTELLIGENCE,175,9-10,1722-1736,WOS:000292222400012,10.1016/j.artint.2011.03.001,,#4325,Kim 2011,"",""
"The Internet of No Things: Making the Internet Disappear and ""See the Invisible""","Maier, M; Ebrahimzadeh, A; Rostami, S; Beniiche, A","Future emerging communication technologies are anticipated to fold into our surroundings, helping us get our noses off the smartphone screens and back into our environments. In doing so, they make us more (rather than less) present in the world around us. While 5G was supposed to be about the Internet of Everything, to be transformative 6G might be just about the opposite of Everything, that is, Nothing or, more technically, No Things. Building on the invisible-to-visible technology concept, this article explores how the full potential of multisensory extended reality (XR) experiences may be unleashed in Multiverse cross-reality environments. We exploit the convergence of artificial-intelligence-enhanced multi-access edge computing, intelligent mobile robots, and blockchain technologies to help realize the Internet of No Things as an important stepping stone toward ushering in the 6G post-smartphone era. In our experiments, we consider locally connected human-avatar/robot collectives and investigate our proposed extrasensory perception network, which integrates the three evolutionary mobile computing stages of ubiquitous, pervasive, and persuasive computing. As an illustrative example of advanced XR experiences, we study the delivery of sixth-sense perceptions that transverse the boundary between Multiverse realms in order to mimic the quantum realm.",2020,,IEEE COMMUNICATIONS MAGAZINE,58,11,76-82,WOS:000594214700013,10.1109/MCOM.001.2000098,,#4326,Maier 2020,"",""
The art of persuasion: Theorizing as argumentation,"Bhardwaj, A","In a marketplace of ideas where theories can act as substitutes, theorists seek to persuade peers to engage with their theories. Given this critical role of persuasion, how do theorists do so? To address this question, the current study adopts a pragmatist perspective and employs the Toulmin model of arguments to examine how Oliver Williamson persuaded his peers to engage with transaction cost economics. The study unpacks how Williamson structured his arguments, introduced new constructs and language, and employed analogies and metaphors to foster a consensus, giving rise to an epistemic community. The study highlights that not only do values influence how arguments are crafted and evaluated, but also appealing to them plays a key role in persuasion. In doing so, the study considers both the rational and non-rational aspects of theorizing and persuasion. Finally, the study discusses the significance of argumentation in the context of AI and theorizing in strategic management.",2025,,STRATEGIC ORGANIZATION,,,,WOS:001416733000001,10.1177/14761270251316028,,#4327,Bhardwaj 2025,"",""
"Dashboard stories: How narratives told by predictive analytics reconfigure roles, risk and sociality in education","Jarke, J; Macgilchrist, F","In this paper, we explore how the development and affordances of predictive analytics may impact how teachers and other educational actors think about and teach students and, more broadly, how society understands education. Our particular focus is on the data dashboards of learning support systems which are based on Machine Learning (ML). While previous research has focused on how these systems produce credible knowledge, we explore here how they also produce compelling, persuasive and convincing narratives. Our main argument is that particular kinds of stories are written by predictive analytics and written into their data dashboards. Based on a case study of a leading predictive analytics system, we explore how data dashboards imply causality between the 'facts' they are visualising. To do so, we analyse the stories they tell according to their spatial and temporal dimensions, characters and events, sequentiality as well as tellability. In the stories we identify, teachers are managers, students are at greater or lesser risk, and students' sociality is reduced to machine-readable interactions. Overall, only data marked as individual behaviours becomes relevant to the system, rendering structural inequalities invisible. Reflecting on the implications of these systems, we suggest ways in which the uptake of these systems can interrupt such stories and reshape them in other directions.",2021,,BIG DATA & SOCIETY,8,1,,WOS:000688414100001,10.1177/20539517211025561,,#4328,Jarke 2021,"",""
'What matters to Andrew'. The problem of premissary relevance in automated health advisors. Insights from pragma-dialectics,"Rubinelli, S; Labrie, NHM; O'Keefe, DJ","Objective: To influence health behavior, communication has to be relevant on an individual level and, thus, fulfill the requirement of premissary relevance. This paper attempts to enrich the design of automated health advisors by, first, reviewing main solutions to the challenge of premissary relevance found in the literature and, second, highlighting the value in this field of the theory of argumentation known as pragma-dialectics.Methods: A conceptual paper grounded in persuasion research and argumentation theory.Results: Automated health advisors enable argumentative exchanges with users. But there is a need to design these systems as to make them work in an audience-centered perspective. The theory of pragma-dialectics can be used to analyze the factors that favor or hinder the agreement of users to engage in certain health behaviors, and to identify argumentation strategies targeted to behavior change.Conclusion: Pragma-dialectics can be used to enhance the design of automated health advisors as it operationalizes the dialogical nature of the reasoning process that can influence health behavior.Practice implications: Premissary relevance is a challenge of communication for health promotion at large that can be promisingly addressed through synergies among persuasion research, argumentation theory and Artificial Intelligence. (C) 2013 Elsevier Ireland Ltd. All rights reserved.",2013,,PATIENT EDUCATION AND COUNSELING,92,2,218-222,WOS:000323806100013,10.1016/j.pec.2013.04.013,,#4329,Rubinelli 2013,"",""
Sustaining Scalable Sustainability: Human-Centered Green Technology for Community-wide Carbon Reduction,"ASSOC COMPUTING MACHINERY; Mohanty, V; Fang, JC; Lee-Kan, SM; Alavi, HS; Salas, J; Patterson, G; Churchill, E; Wu, CC; Shamma, DA","Escalating global CO2 emissions highlights the immediate need for scalable sustainable practices. Corporate and policy roles aside, there's a need for carbon-neutrality-based systems and practices to bridge the disconnect between actions and the perceived impact on the environment. This one-day workshop focuses on individuals and communities, advocating for human-centered tools to bridge this awareness-action gap. While Human-AI Interaction (HAI), cognitive science theories, and social computing tools have shown promise in various domains, their potential remains largely unexplored in the context of sustainability. This workshop aims to delve into these avenues for crafting tractable systems for effective, contextually relevant interventions and driving sustainable behaviors. By engaging multidisciplinary researchers, we aim to intertwine local insights with behavioral theory and technology, fostering intrinsic carbon literacy and a sustainability ethos, ensuring lasting and scalable impacts.",2024,,"EXTENDED ABSTRACTS OF THE 2024 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2024",,,,WOS:001227587700048,10.1145/3613905.3636314,,#4330,ASSOCCOMPUTINGMACHINERY 2024,"",""
USING ARGUMENTATION IN TEXT GENERATION,"ELHADAD, M","Text generation is a field of artificial intelligence aiming at producing computer models of natural language production. This paper discusses the use of the theory of 'Argumentation in Language' in the field of Text Generation, Most text generators follow the same sequence of steps to produce a coherent paragraph: content determination - selecting of information to include in the text from an underlying computer database; content organization - structuring of the propositions to be included in the text according to an appropriate rhetorical plan; finally lexical choice and syntactic realization - phrasing of the information using appropriate lexical items and syntactically correct constructions. The paper provides examples of the use of argumentative features to influence the generator's decisions throughout the generation process. The introduction of argumentative features allows the designer of a text generator to account for linguistic decisions that were not addressed in previous work, such as the selection of judgment determiners (many, few), scalar adjectives (interesting, difficult), connotative verbs (require, necessitate, enjoy, struggle) and connectives (but, therefore). Argumentative features are also used to organize the paragraph in a coherent manner. They are finally used to select appropriate information from a database to satisfy a given persuasive goal. The paper shows how the same descriptive device - the topoi introduced by Anscombre and Ducrot - can serve as the unifying representation level during the whole generation process and build a bridge between the conceptual and linguistic components of the generator.",1995,,JOURNAL OF PRAGMATICS,24,1-2,189-220,WOS:A1995RK43900012,10.1016/0378-2166(94)00096-W,,#4331,ELHADAD 1995,"",""
Explaining Reasoning Algorithms with Persuasiveness: a Case Study for a Behavioural Change System,"ACM; Donadello, I; Dragoni, M; Eccher, C","Explainable AI aims at building intelligent systems that are able to provide a clear, and human understandable, justification of their decisions. This holds for both rule-based and data-driven methods. In management of chronic diseases, the users of such systems are patients that follow strict dietary rules to manage such diseases. After receiving the input of the intake food, the system performs reasoning to understand whether the users follow an unhealthy behaviour. Successively, the system has to communicate the results in a clear and effective way, that is, the output message has to persuade users to follow the right dietary rules. In this paper, we address the main challenges to build such systems: i) the natural language generation of messages that explain the reasoner inconsistency; ii) the effectiveness of such messages at persuading the users. Results prove that the persuasive explanations are able to reduce the unhealthy users' behaviours.",2020,,PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING (SAC'20),,,646-653,WOS:000569720900095,10.1145/3341105.3373910,,#4332,ACM 2020,"",""
Speculative Design with Generative AI Applying Stable Diffusion and ChatGPT to Imagine Climate Change Futures,"Lc, R; Tang, YY","Policy mandates in addressing climate change are hindered by a lack of intrinsic motivation amongst participants to take collective action. Instead of overt persuasion, this study applied generative AI tools to speculative imagining of future climate scenarios and their adaptation strategies, using a workshop to encourage participants to align themselves with climate action. Participants used text-to-image tools to generate visions of the future in speculative scenarios, then prompted ChatGPT for potential solutions in these scenarios. They then asked text-to-image again to visualize the ChatGPT suggestions. Participants encountered difficulties editing or removing visual elements, dealt with the lack of transparency in the generation process by specifying the physical layout as opposed to the semantics, and collaboratively developed linguistic strategies for visual depiction of novel artifacts. This work shows how generative tools can be used to prototype future scenarios and envision designs that serve social purposes.",2023,,"PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON DIGITAL AND INTERACTIVE ARTS, ARTECH 2023",,,,WOS:001211709700036,10.1145/3632776.3632827,,#4333,Lc 2023,"",""
Privacy in Personalized Advertising: A Comprehensive Review and Future Agenda,"De, SJ; Chattopadhyay, M","While personalized advertising may increase customers' desire to engage with a firm, privacy concerns over how firms process data for personalization may reduce their engagement and lead to ad avoidance. As marketers increasingly benefit from personalized advertising, the domain of privacy in personalized advertising (PPA) is gaining attention from researchers in both Marketing and Information Systems areas. In this study, we conduct a comprehensive review of extant literature, combining bibliometric analysis and systematic literature review to explore the current state, primary themes, and future prospects of the PPA literature. Our research indicates that PPA research is in its early stages of development. While existing literature has predominantly examined privacy, personalization, trust, advertising, social media, and e-commerce, there has been a growing emphasis on targeted advertising and artificial intelligence in more recent studies. PPA is grounded in theoretical frameworks from privacy like Privacy Calculus Theory and from marketing such as the Persuasion Knowledge Model. Given that customer privacy concerns and trust in a firm can influence ad outcomes negatively, it is essential for researchers to explore scenarios where personalization might prove ineffective. In addition, examining firm strategies regarding personalized ads to mitigate negative ad outcomes is crucial.",2025,,COMMUNICATIONS OF THE ASSOCIATION FOR INFORMATION SYSTEMS,56,,,WOS:001474729200001,10.17705/1CAIS.05613,,#4334,De 2025,"",""
Rethinking Health Recommender Systems for Active Aging: An Autonomy-Based Ethical Analysis,"Tiribelli, S; Calvaresi, D","Health Recommender Systems are promising Articial-Intelligence-based tools endowing healthy lifestyles and therapy adherence in healthcare and medicine. Among the most supported areas, it is worth mentioning active aging. However, current HRS supporting AA raise ethical challenges that still need to be properly formalized and explored. This study proposes to rethink HRS for AA through an autonomy-based ethical analysis. In particular, a brief overview of the HRS' technical aspects allows us to shed light on the ethical risks and challenges they might raise on individuals' well-being as they age. Moreover, the study proposes a categorization, understanding, and possible preventive/mitigation actions for the elicited risks and challenges through rethinking the AI ethics core principle of autonomy. Finally, elaborating on autonomy-related ethical theories, the paper proposes an autonomy-based ethical framework and how it can foster the development of autonomy-enabling HRS for AA.",2024,,SCIENCE AND ENGINEERING ETHICS,30,3,,WOS:001232846000001,10.1007/s11948-024-00479-z,,#4335,Tiribelli 2024,"",""
Using Instrumental Mechanisms to Support Humanistic Goals: The Case of Two Intelligent Personal Assistants,"Cranefield, J; Doyle, C; Ekandjo, T","Calls have been made for information systems to go beyond supporting the instrumental outcomes traditionally associated with business imperatives to foster more humanistic outcomes. This study explores the mechanisms used by two intelligent personal assistants (IPAs) to promote humanistic goals such as pro-social behaviour. We identify four key mechanisms through which the IPAs support humanistic goals and draw on humanistic management literature to identify the humanistic goals supported. The mechanisms are (1) humanistic framing of analytics and goals, ( 2) persuasion, (3) automation of humanistic actions, and (4) anchoring humanistic goals to instrumental outcomes. The study raises issues about the moral implications of instrumentalising humanistic outcomes and suggests a need for theory to understand the role of Human-AI interaction in promoting humanistic outcomes. We propose a need for investigations into how and whether human-AI interactions can foster authentic humanistic outcomes in practice.",2023,,PROCEEDINGS OF THE 56TH ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES,,,6198-6207,WOS:001301786706025,,,#4336,Cranefield 2023,"",""
KEEP IT SIMPLE. THE IMPACT OF LANGUAGE ON CROWDFUNDING SUCCESS,"Adamska-Mieruszewska, J; Mrzyglód, U; Suchanek, M; Fornalska-Skurczynska, A","The success of a crowdfunding campaign depends on obtaining funds provided by the online community. More precisely, the success of a campaign is defined as achieving its financial goal built upon convincing a relatively large number of people in a fundraiser's idea. Thus, efficient communication with ""the crowd"" is necessary to obtain its expected positive attitude change. In this respect, we argue that beyond the standard campaign features such as the number of supporters, the financing goal and the campaign duration, project's description becomes critical for a campaign's success. The goal of this paper is to investigate the relation between the readability, the length of a description and the funding success of a campaign in the reward-based crowdfunding model. Along with standard statistical measures, we conduct logit regression on the dataset comprising over 2800 projects published on one of the largest Polish crowdfunding platforms. Our results provide evidence that both description's length and text readability significantly influence the fundraising outcome. We interpret these results in the light of the persuasion effects as a longer text encompasses a higher number of arguments. Furthermore, a more detailed description decreases information asymmetry between the crowd and the project's author as well as induces the level of trust towards the latter. Finally, although the readability level of campaigns' descriptions in our sample is moderate, still the projects with a clearer description are preferred by the online community.",2021,,ECONOMICS & SOCIOLOGY,14,1,130-144,WOS:000637546100009,10.14254/2071-789X.2021/14-1/9,,#4337,Adamska-Mieruszewska 2021,"",""
"""The assumption of separate senses"": Pervasive? Perhaps - Persuasive? Hardly!","Vereijken, B; Whiting, HTA","We show that Stoffregen & Bardy's arguments against the assumption of separately functioning senses have more historical antecedents than they give credit for, and that multimodal functioning-primitive in percept ai and brain development-does not require Iis assumption. What is needed is evidence that biological organisms are indeed detecting and acting upon information in a multimodal (or global) array.",2001,,BEHAVIORAL AND BRAIN SCIENCES,24,2,242-+,WOS:000170177900034,10.1017/S0140525X01533944,,#4338,Vereijken 2001,"",""
Investigating the cognitive process of attention while watching sports advertisements in interested and non-interested people using Electroencephalogram technology,"Aminiroshan, Z; Gholamian, J; Mahmoudi, A; Pirjamadi, S","This study aims to investigate the attention cognitive process while watching sports advertisements in interested and non-interested people using electroencephalogram technology. The research method was semi-experimental and the population included 30 students of Birjand University who were selected randomly as a sample. To collect data, the General Health and Sanchez-Torres Questionnaire (2021) was used. Then to record the brain signal, the 21-channel Electroencephalography Instrument was used. The results revealed a significant difference in attention index (AI) between sports advertising and non-sport advertising. Also, the attention index in people who were interested in sports showed a significant difference compared to those who were not. It can be concluded that sports are a suitable platform for advertising products so that it can create a positive effect through increasing the customers' attention. The level of interest also in sports may be a persuasive calculation of consideration for publicizing.",2024,,INTERDISCIPLINARY JOURNAL OF MANAGEMENT STUDIES,17,2,393-408,WOS:001185908300019,10.22059/ijms.2023.337628.674912,,#4339,Aminiroshan 2024,"",""
Health Communication in the Latino Community: Issues and Approaches,"Elder, JP; Ayala, GX; Parra-Medina, D; Talavera, GA","With reference to the Communication-Persuasion model, we describe various research issues and challenges when considering the health of Latinos, and implications for designing and evaluating health communication and behavior change efforts in this population. Latinos, collectively the nations largest minority group, vary substantially in terms of socioeconomic and legal status, their country of origin and the extent of ongoing contact with that country, their region of residence within the United States, their generation status and levels of acculturation, and psychosocial factors. Health communication efforts with Latinos need to focus on family, cultural traditions, and collectivism while attending to acculturation, language, generation and national origin. The most extensive intervention topic in Latino health promotion has been die application of the Jay health advisor model. This and other fundamental communication approaches, as well as audience and population characteristics, need to be considered within the context of dynamic and complex societal changes.",2009,,ANNUAL REVIEW OF PUBLIC HEALTH,30,,227-251,WOS:000268071900014,10.1146/annurev.publhealth.031308.100300,,#4340,Elder 2009,"",""
"Fact-Checking, Fake News, Propaganda, Media Bias, and the COVID-19 Infodemic","ASSOC COMP MACHINERY; Nakov, P; Martino, GD; Alam, F","Social media have democratized content creation and have made it easy for anybody to spread information online. However, stripping traditional media from their gate-keeping role has left the public unprotected against biased, deceptive and disinformative content, which could now travel online at breaking-news speed and influence major public events. For example, during the COVID-19 pandemic, a new blending of medical and political disinformation has given rise to the first global infodemic. We offer an overview of the emerging and inter-connected research areas of fact-checking, disinformation, ""fake news"", propaganda, and media bias detection. We explore the general fact-checking pipeline and important elements thereof such as check-worthiness estimation, spotting previously fact-checked claims, stance detection, source reliability estimation, detection of persuasion techniques, and detecting malicious users in social media. We also cover large-scale pre-trained language models, and the challenges and opportunities they offer for generating and for defending against neural fake news. Finally, we discuss the ongoing COVID-19 infodemic.",2022,,WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING,,,1632-1634,WOS:000810504300192,10.1145/3488560.3501395,,#4341,ASSOCCOMPMACHINERY 2022,"",""
Becoming More Reflective about the Role of Design in Communication,"Jackson, S; Aakhus, M","Robert Craig's constitutive meta-model of communication reminds us that while communication scholarship may feel like discovery of communication's natural properties, it is also often (if not always) on a path to invention of new possibilities and reconstitution. The constitutive meta-model suggests that every theory of communication is also a design language for communication, and that design itself may be a path to theory development. Design inquiry can be conducted in all subdisciplines of communication, incorporating and contributing to widely disparate communication theories. Design work itself takes many forms, producing artifacts as diverse as individual messages, persuasive campaigns, interaction protocols, large-scale participation frameworks for public decision-making, and more. This special issue explores design scholarship in the field of communication, with five original essays representing different subfields and different theoretical approaches. In this introduction, we argue that design work is more than application of theory; design itself is a theory-building enterprise. It is a distinct form of inquiry that builds new knowledge, complementary to, but different in kind from, empirical and critical scholarship.",2014,,JOURNAL OF APPLIED COMMUNICATION RESEARCH,42,2,125-134,WOS:000333870300001,10.1080/00909882.2014.882009,,#4342,Jackson 2014,"",""
Similarity and rules: distinct? exhaustive? empirically distinguishable?,"Hahn, U; Chater, N","The distinction between rule-based and similarity-based processes in cognition is of fundamental importance for cognitive science, and has been the focus of a large body of empirical research. However, intuitive uses of the distinction are subject to theoretical difficulties and their relation to empirical evidence is not clear. We propose a 'core' distinction between rule-and similarity-based processes, in terms of the way representations of stored information are 'matched' with the representation of a novel item. This explication captures the intuitively clear-cut cases of processes of each type, and resolves apparent problems with the rule/similarity distinction. Moreover, it provides a clear target for assessing the psychological and Al literatures. We show that many lines of psychological evidence are less conclusive than sometimes assumed, but suggest that converging lines of evidence may be persuasive. that the Al literature suggests that approaches which combine rules and similarity are an important new focus for empirical work. (C) 1998 Elsevier Science B.V.",1998,,COGNITION,65,2-3,197-230,WOS:000072422500005,10.1016/S0010-0277(97)00044-9,,#4343,Hahn 1998,"",""
Debate Chatbots to Facilitate Critical Thinking on YouTube: Social Identity and Conversational Style Make A Difference,"ACM; Tanprasert, T; Fels, S; Sinnamon, L; Yoon, D","Exposure to diverse perspectives is helpful for bursting the filter bubble in online public video platforms. The recent advancement of Large Language Models (LLMs) illuminates the potential of creating a debate chatbot that prompts users to critically examine their stances on a topic formed by watching videos. However, whether the viewer is influenced by the chatbot may depend on its persona. In this paper, we investigated the effect of two relevant persona attributes - social identity and rhetorical styles - on critical thinking. In a mixed-methods study (n=36), we found that chatbots with outgroup (vs. ingroup) identity (t(33)=-2.33, p=0.03) and persuasive (vs. eristic) rhetoric (t(44)=1.98, p=0.05) induced critical thinking most effectively, making participants re-examine their arguments. However, participants' stances remain largely unaffected, likely due to the chatbot's lack of contextual knowledge and human touch. Our paper provides empirical groundwork for designing chatbot persona for remedying filter bubbles in online communities.",2024,,PROCEEDINGS OF THE 2024 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYTEMS (CHI 2024),,,,WOS:001259864902012,10.1145/3613904.3642513,,#4344,ACM 2024,"",""
Glossing an argument: Reformulation and exemplification in L2 Master's theses,"Guziurová, T","Following a large body of research on metadiscourse in academic writing, this paper explores one feature of textual metadiscourse, code glosses, in English L2 academic texts written by Czech university students. The study draws on Hyland's metadiscourse model (2005), which characterizes code glosses as devices that elaborate propositional meanings by rephrasing or explaining what has been said. Thus, they can help readers understand the writer's intended meaning or contribute to the formation of persuasive arguments. The corpus consists of 48 English L2 Master's theses representing three disciplines - linguistics, literature and English language teaching (ELT) methodology, totalling almost 950,000 words. The results are compared with professional writing represented by English L1 research articles from the same disciplines. The findings reveal differences in the frequency and functions of several code glosses, as novice writers are shown to overuse certain devices. The findings also indicate cross-disciplinary variation, as reformulation and exemplification proved to be much more prominent in linguistics and methodology than in literary studies.",2022,,TOPICS IN LINGUISTICS,23,2,18-35,WOS:000904839700002,10.2478/topling-2022-0009,,#4345,Guziurová 2022,"",""
Discernibility in explanations: Designing more acceptable and meaningful machine learning models for medicine,"Wang, HM; Aligon, J; May, J; Doumard, E; Labroche, N; Delpierre, C; Soulé-Dupuy, C; Casteilla, L; Planat-Benard, V; Monsarrat, P","Although the benefits of machine learning are undeniable in healthcare, explainability plays a vital role in improving transparency and understanding the most decisive and persuasive variables for prediction. The challenge is to identify explanations that make sense to the biomedical expert. This work proposes discernibility as a new approach to faithfully reflect human cognition, based on the user's perception of a relationship between explanations and data for a given variable. A total of 50 participants (19 biomedical experts and 31 data scientists) evaluated their perception of the discernibility of explanations from both synthetic and human-based datasets (National Health and Nutrition Examination Survey). The low inter-rater reliability of discernibility (Intraclass Correlation Coefficient < 0.5), with no significant difference between areas of expertise or levels of education, highlights the need for an objective metric of discernibility. Thirteen statistical coefficients were evaluated for their ability to capture, for a given variable, the relationship between its values and its explanations using Passing-Bablok regression. Among these, dcor was shown to be a reliable metric for assessing the discernibility of explanations, effectively capturing the clarity of the relationship between the data and their explanations, and providing clues to underlying pathophysiological mechanisms not immediately apparent when examining individual predictors. Discernibility can also serve as an evaluation metric for model quality, helping to prevent overfitting and aiding in feature selection, ultimately providing medical practitioners with more accurate and persuasive results.",2025,,COMPUTATIONAL AND STRUCTURAL BIOTECHNOLOGY JOURNAL,27,,1800-1808,WOS:001489943000001,10.1016/j.csbj.2025.04.021,,#4346,Wang 2025,"",""
PersuAIDE ! An Adaptive Persuasive Text Generation System for Fashion Domain,"ACM; Munigala, V; Mishra, A; Tamilselvam, SG; Khare, S; Dasgupta, R; Sankaran, A","Persuasiveness is a creative art which aims at inducing certain set of beliefs in the target audience. In an e-commerce setting, for a newly launched product, persuasive descriptions are often composed to motivate an online buyer towards a successful purchase. Such descriptions can be catchy taglines, product-summaries, style-tips etc.. In this paper, we present PersuAIDE! - a persuasive system based on linguistic creativity to generate various forms of persuasive sentences from the input product specification. To demonstrate the effectiveness of the proposed system, we have applied the technology to fashion domain, where, for a given fashion product like ""red collar shirt"" we were able to generate descriptive sentences that not only explain the item but also garner positive attention, making it persuasive.PersuAIDE! identifies fashion related keywords from input specifications and intelligently expands the keywords to creative phrases. Once such compatible phrases are obtained, persuasive descriptions are synthesized from the set of phrases and input keywords with the help of a neural language model trained on a large domain-specific fashion corpus. We evaluate the system on a large fashion corpus collected from different sources using (a) automatic text generation metrics used for Machine Translation and Automatic Summarization evaluation and Readability measurement, and (b) human judgment scores evaluating the persuasiveness and fluency of the generated text. Experimental results and qualitative analysis show that an unsupervised system like ours can produce more creative and better constructed persuasive output than supervised generative counterparts based on neural sequence-to-sequence models and statistical machine translation.",2018,,COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018),,,335-342,WOS:000692102800103,10.1145/3184558.3186345,,#4347,ACM 2018,"",""
A randomised controlled trial of a telephone administered brief HIV risk reduction intervention amongst men who have sex with men prescribed post-exposure prophylaxis for HIV after sexual exposure in the UK: Project PEPSE,"Llewellyn, CD; Abraham, C; Pollard, A; Jones, CI; Bremner, S; Miners, A; Smith, H","BackgroundIn western countries, men who have sex with men (MSM) are most affected by HIV and increasingly likely to engage in risky sexual behaviour. MSM who experience a potential sexual exposure to HIV (PEPSE) and receive a preventative regimen of anti-HIV treatment are at particularly high risk of acquiring HIV and could potentially benefit from targeted risk reduction behavioural interventions such as motivational interviewing (MI).PurposeThe aim of this trial was to examine the impact of augmented MI (MI plus information provision and behavioural skills building), over and above routine care, on reducing risky sexual behaviour in MSM prescribed PEPSE. Secondary aims of the research were to examine whether the intervention reduced sexually transmitted infections (STI) and further requests for PEP.MethodsA parallel-group pragmatic randomised controlled trial was conducted with 175 MSM recruited from five sexual health (SH) clinics in the south east of England. The intervention was two fixed-duration sessions of telephone administered augmented MI. A manual guided the selection of individualised persuasive communication strategies based on underlying change mechanisms specified by the Information, Motivation and Behavioural Skills (IMB) model. Primary outcomes were the number of receptive and active anal intercourse (AI) partners, the use of condoms every time during receptive and active AI and the use of condoms sometimes during receptive and active AI.ResultsThere were no significant impacts on sexual risk behaviour or any of the psychological measures, and no discernible reduction in requests for repeat PEP or rates of STIs within a year.ConclusionOur behavioural intervention of augmented MI did not affect risky sexual behaviour, rates of further PEP and STIs, and psychological factors, in MSM prescribed PEPSE.",2019,,PLOS ONE,14,5,,WOS:000468775700032,10.1371/journal.pone.0216855,,#4348,Llewellyn 2019,"",""
Introducing the logic and law corner,"Bench-Capon, T; Prakken, H","In this article we introduce the Logic and Law corner of this journal. We will discuss a number of ways in which logic has been used in AI and Law, and give some of the key references to previous work on these topics. We will also list some important questions which we see as ready for further exploration. We encourage contributions on these, and other, Logic and Law issues.",2008,,JOURNAL OF LOGIC AND COMPUTATION,18,1,1-12,WOS:000252718100001,10.1093/logcom/exm060,,#4349,Bench-Capon 2008,"",""
"Rhetoric, Neurocognitive Poetics, and the Aesthetics of Adaptation","Nicklas, P; Jacobs, AM","Rhetorical effects in speech and writing have a great strategic importance in achieving the communicative end of being persuasive: they are key in the exertion of power through language. Persuasion occurs by cognitive-affective stimulation, relying on specific psychosomatic perceptual patterns which are used on all levels of speech reception in cultural and political contexts. This makes rhetorically conspicuous texts efficient as stimulus material for empirical research into neurocognitive modeling of how poetic texts are read. Adaptations as revisitations of prior works share with the rhetorical repertoire of repetition similar cognitive-affective properties, because both function via recognition of sameness or similarity. Recent paradigm shifts in adaptation studies have much enlarged the field of research, so Linda Hutcheon's as yet empirically unsupported insight that adaptation is the norm and not the exception in human imagination finds an unexpectedly large field of application. This shift away from the narrow standard paradigm of novels adapted for the screen to a more fundamental aesthetics of adaptation has also helped establish connections between adaptation studies and the experiment-based methodologies of empirical aesthetics and neuroaesthetics with a view to developing cognitive and affective models of the processes underlying the reception of adaptations.",2017,,POETICS TODAY,38,2,393-412,WOS:000403740400009,10.1215/03335372-3869311,,#4350,Nicklas 2017,"",""
Where Do People Tell Stories Online? Story Detection Across Online Communities,"Antoniak, M; Mire, J; Sap, M; Ash, E; Piper, A","Story detection in online communities is a challenging task as stories are scattered across communities and interwoven with non-storytelling spans within a single text. We address this challenge by building and releasing the StorySeeker toolkit, including a richly annotated dataset of 502 Reddit posts and comments, a detailed codebook adapted to the social media context, and models to predict storytelling at the document and span levels. Our dataset is sampled from hundreds of popular English-language Reddit communities ranging across 33 topic categories, and it contains fine-grained expert annotations, including binary story labels, story spans, and event spans. We evaluate a range of detection methods using our data, and we identify the distinctive textual features of online storytelling, focusing on storytelling spans, which we introduce as a new task. We illuminate distributional characteristics of storytelling on a large community-centric social media platform, and we also conduct a case study on r/ChangeMyView, where storytelling is used as one of many persuasive strategies, illustrating that our data and models can be used for both inter- and intra-community research. Finally, we discuss implications of our tools and analyses for narratology and the study of online communities.",2024,,"PROCEEDINGS OF THE 62ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1: LONG PAPERS",,,7104-7130,WOS:001356729807016,,,#4351,Antoniak 2024,"",""
Detecting Persuasion Attempts on Social Networks: Unearthing the Potential of Loss Functions and Text Pre-Processing in Imbalanced Data Settings,"Teimas, R; Saias, J","The rise of social networks and the increasing amount of time people spend on them have created a perfect place for the dissemination of false narratives, propaganda, and manipulated content. In order to prevent the spread of disinformation, content moderation is needed. However, manual moderation is unfeasible due to the large amount of daily posts. This paper studies the impact of using different loss functions on a multi-label classification problem with an imbalanced dataset, consisting of 20 persuasion techniques and only 950 samples, provided by SemEval's 2021 Task 6. We used machine learning models, such as Naive Bayes and Decision Trees, and a custom deep learning architecture, based on DistilBERT and Convolutional Layers. Overall, the machine learning models achieved far worse results than the deep learning model, using Binary Cross Entropy, which we considered our baseline deep learning model. To address the class imbalance problem, we trained our model using different loss functions, such as Focal Loss and Asymmetric Loss. The latter providing the best results, particularly for the least represented classes.",2023,,ELECTRONICS,12,21,,WOS:001100305000001,10.3390/electronics12214447,,#4352,Teimas 2023,"",""
A WISER intervention to combat the influence of misinformation on social media,"Schneider, AB; Stornelli, J; Chugani, S; Luchs, MG; Vu, T; Kaur, T; Mick, DG","PurposeMisinformation is a major threat to individual, organizational and societal well-being. Combating it requires change on multiple levels. The purpose of this paper is to describe two co-created initiatives designed to holistically reduce the prevalence and effects of misinformation on social media.Design/methodology/approachThe authors adopted a co-creation approach by convening a stakeholder group including social media, advertising, artificial intelligence and advocacy leaders. The authors also engaged social media users to collectively generate, test and implement an anti-misinformation strategy. These stakeholders shaped the development of the tools described in this paper.FindingsFirst, the authors present a Social Media Ecosystem Map and Incentive Analysis that achieve impact by documenting avenues for action. Second, the authors illustrate impact at the user level by developing and disseminating the WISER framework, which delivers an implementable and memorable anti-misinformation strategy.Research limitations/implicationsStrategies tailored to the needs and characteristics of stakeholders are most likely to be persuasive. The discoveries and conclusions incorporate the contexts of the stakeholders with whom the authors collaborated. Future work will reveal recommendations for a broader audience.Practical implicationsThe Social Media Ecosystem Map, Incentive Analysis and WISER framework represent promising foundations to spark novel insights and actions for ways to be WISER about information on social media.Originality/valueImpact is often limited because strategies are developed in academic, corporate or policy silos. The authors adopt an original approach by exchanging knowledge among industry, academia and users with the aim of maximizing effectiveness and adoption.",2025,,EUROPEAN JOURNAL OF MARKETING,,,,WOS:001451018200001,10.1108/EJM-04-2024-0335,,#4353,Schneider 2025,"",""
Is a picture worth a thousand views? Measuring the effects of travel photos on user engagement using deep learning algorithms,"Yim, D; Malefyt, T; Khuntia, J","Travel photos inform and inspire consumers by conveying a first-hand destination experience. Despite the proliferation of consumer-generated travel photos in online travel review sites, deconstructing the effects of photos on consumer engagement remains a challenge to the tourism industry. We provide a framework to process and interpret various photographic elements on user engagement using deep learning algorithms. We posit that a photo can invoke consumers' subjective interpretations of photos representing authentic, creative, or emotional dimensions of the destination experience. A structured crowdsourced categorization process was deployed to measure the interpretive dimensions of the photos. The objects in photographs are identified using a novel deep learning algorithm for controls. We use narrative framing concepts to theorize their influence on user engagement in an online travel review site setting. Relevant three sets of hypotheses are tested using a large dataset of photo-based travel reviews sampled between 2012 and 2014. A negative zero-inflated binomial regression is used to estimate the effect of subjective interpretation of photos on user engagement, accounting for overdispersed excess zeros associated with count outcomes. Results support the hypotheses. The additional analyses explore other plausible influential attributes to user engagements to complement our main findings. We discuss the theoretical contributions to the online-image-persuasion stream of research and practical implications for online tourist review sites.",2021,,ELECTRONIC MARKETS,31,3,619-637,WOS:000635852800001,10.1007/s12525-021-00472-5,,#4354,Yim 2021,"",""
Enhancing Transformative Learning and Innovation Skills Using Remote Learning for Sustainable Architecture Design,"Avsec, S; Jagiello-Kowalczyk, M; Zabicka, A","The currently used educational technology with artificial-intelligence-powered solutions, although rather instrumental, may lead to discontinuity in learning, as it lacks social and emotional value, which is an essential part of education for sustainable development and results in an immersive experience through which higher-order thinking skills can be adopted. This paper aims to explore transformative learning (TL) and innovation skill improvement accommodated by transactional distance theory in a 16-week remote sustainable architecture design course. The analysis identified the following: (a) significant progress in students' attitudes toward uncertainty and criticality while social support differs due to the influence of classmates, faculty staff, teamwork, writing and reading assignments, promoters from industry and extracurricular activities; (b) significant progress in TL achievement while innovation skill development differs significantly across the groups in which online collaborative learning was found as an influencer in creativity and motivation; (c) self-efficacy influenced by feedback in and on actions, such as essay and other writing assignments, verbal persuasions and positive social comparisons; (d) lack of development of situational awareness, continuity of learning and interactions/situations to empower teammates in handling conflicts to develop leadership ability; (e) decrease in risk-taking ability, especially in a group of students in which social support was limited due to the absence of challenging situations and tasks. The results support the use of remote intervention directed at prosocial motivations and action-focused group goals.",2022,,SUSTAINABILITY,14,7,,WOS:000781940700001,10.3390/su14073928,,#4355,Avsec 2022,"",""
Using Technology to Persuade: Visual Representation Technologies and Consensus Seeking in Virtual Teams,"Peng, CH; Lurie, NH; Slaughter, SA","Although Fogg's ideas of persuasive technologies are widely accepted, few attempts have been made to test his ideas, particularly in a team context. In this article, we (1) theoretically extend Fogg's ideas by identifying contexts in which virtual teams are more likely to use persuasive technologies; (2) empirically measure technology visualness, a factor that likely makes technologies more or less persuasive; and (3) assess the association between the use of persuasive technologies, judgment shifts, and forecast performance in a real-world virtual team context. We identify visual representation technologies (VRTs) as a class of technologies used by virtual teams to select, transform, and present data in a rich visual format. We propose that such technologies play a persuasive, as well as diagnostic, role in virtual team decisions. Over a three-year period, we examine the daily chat room discussions and decisions of a virtual team that makes smog forecasts with large economic and health consequences. We supplement regression models of field data with an experiment, interviews with team members, and analyses of imagery processing and group cohesion in team language use. Experiment results show that, relative to non-VRTs, the use of a VRT in a forecasting task increases imagery processing. Field data results show that team members increase their use of VRTs during chat room discussions when initial team consensus is low and the environment is more exacting. Greater use of VRTs in team discussions relates to greater shifts in the initial to final consensus forecasts of the team and greater odds of the team shifting its forecast policy to issue a smog alert. Increased use of VRTs is associated with lower forecast bias but is not significantly associated with forecast accuracy. VRT use is also associated with greater imagery processing and increased group cohesion, as shown through language use.",2019,,INFORMATION SYSTEMS RESEARCH,30,3,948-962,WOS:000488276800014,10.1287/isre.2019.0843,,#4356,Peng 2019,"",""
Humane Visual AI: Telling the Stories Behind a Medical Condition,"So, W; Bogucka, EP; Scepanovic, S; Joglekar, S; Zhou, K; Quercia, D","A biological understanding is key for managing medical conditions, yet psychological and social aspects matter too. The main problem is that these two aspects are hard to quantify and inherently difficult to communicate. To quantify psychological aspects, this work mined around half a million Reddit posts in the sub -communities specialised in 14 medical conditions, and it did so with a new deep -learning framework. In so doing, it was able to associate mentions of medical conditions with those of emotions. To then quantify social aspects, this work designed a probabilistic approach that mines open prescription data from the National Health Service in England to compute the prevalence of drug prescriptions, and to relate such a prevalence to census data. To finally visually communicate each medical condition's biological, psychological, and social aspects through storytelling, we designed a narrative -style layered Martini Glass visualization. In a user study involving 52 participants, after interacting with our visualization, a considerable number of them changed their mind on previously held opinions: 10% gave more importance to the psychological aspects of medical conditions, and 27% were more favourable to the use of social media data in healthcare, suggesting the importance of persuasive elements in interactive visualizations.",2021,,IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS,27,2,678-688,WOS:000706330100054,10.1109/TVCG.2020.3030391,,#4357,So 2021,"",""
Functional Brain Connectivity During Narrative Processing Relates to Transportation and Story Influence,"Vaccaro, AG; Scott, B; Gimbel, SI; Kaplan, JT","Engaging with narratives involves a complex array of cognitive and affective processes. These processes make stories persuasive in ways that standard arguments are not, though the underlying reasons for this remain unclear. Transportation theory proposes a potential explanation for this: narratives are processed in a way which makes individuals feel immersed in the world of a story, which in turn leads people to resonate emotionally with the events of the story. Recent fMRI studies have shown that the posterior medial cortex (PMC) and anterior insula (AI) play important roles in understanding the meaning of stories and experiencing the feelings they produce. In this study, we aimed to explore the AI's and PMC's role in narrative processing by measuring their functional connectivity with the rest of the brain during story listening, and how connectivity changes as a function of narrative transportation and the persuasiveness of the story. We analyzed data from 36 right-handed subjects who listened to two stories, obtained from podcasts, inside the fMRI scanner. After the scan, subjects were asked a series of questions, including a measure of how transported into the story they felt, how likely they would be to donate to causes related to the messages of the stories. We used searchlight multivariate pattern analysis (MVPA) to classify functional connectivity maps using seeds in both the AI and PMC and to compare these maps between participants who differed in transportation and prosocial intention. We found that connectivity to various regions successfully distinguished between high and low ratings on each of these behavioral measures with accuracies over 75%. However, only one pattern of connectivity was consistent across both stories: PMC-inferior frontal gyrus connectivity successfully distinguished high and low ratings of narrative transportation in both stories. All other findings were not consistent across stories. Instead, we found that patterns of connectivity may relate more to the specific content of the story rather than to a universal way in which narratives are processed.",2021,,FRONTIERS IN HUMAN NEUROSCIENCE,15,,,WOS:000674265800001,10.3389/fnhum.2021.665319,,#4358,Vaccaro 2021,"",""
Engagement in Translation: Interactional Metadiscourse Markers in American Presidential Debates,"Farghal, M; Kalakh, B","With an audience in mind, politicians draw a political persona whereby their speech is engineered to involve receivers in a promised future. From their vocabulary arsenal, they choose words and structures that maintain a deliberately devised stream of thoughts to urge the electorate to vote. Based on a large corpus, this paper examines a selected number of engaging English expressions including (listener) pronouns, appeals to shared knowledge, directives, questions, and personal asides in order to firstly understand how they function metadiscursively in American presidential debates and, secondly, how they lend themselves to translation into Arabic. The analysis is based on Hyland's (2005) model of metadiscourse markers and Wieczorek's (2013) Clusivity in political discourse, with an eye to Nord's (2007) concept of metacommunication in translation. The findings indicate that omissions and misinterpretations of subtle engagement markers that speak to an audience can disturb the metadiscursive channel as they may shift focus and miscommunicate the messages in terms of the phatic and persuasive functions. In particular, the fact that, unlike English, Arabic is a highly inflectional language, and still lacks research models of metadiscourse markers, places an extra burden on translators between English and Arabic in this sensitive area.",2020,,JORDAN JOURNAL OF MODERN LANGUAGES & LITERATURE,12,1,102-121,WOS:000546998600007,,,#4359,Farghal 2020,"",""
Which Side Are You On? A Multi-task Dataset for End-to-End Argument Summarisation and Evaluation,"Li, H; Wu, YP; Schlegel, V; Batista-Navarro, R; Madusanka, T; Zahid, I; Zeng, JY; Wang, XC; He, XR; Li, YZ; Nenadic, G","With the recent advances of large language models (LLMs), it is no longer infeasible to build an automated debate system that helps people to synthesise persuasive arguments. Previous work attempted this task by integrating multiple components. In our work, we introduce an argument mining dataset that captures the end-to-end process of preparing an argumentative essay for a debate, which covers the tasks of claim and evidence identification (Task 1 ED), evidence convincingness ranking (Task 2 ECR), argumentative essay summarisation and human preference ranking (Task 3 ASR) and metric learning for automated evaluation of resulting essays, based on human feedback along argument quality dimensions (Task 4 SQE). Our dataset contains 14k examples of claims that are fully annotated with the various properties supporting the aforementioned tasks. We evaluate multiple generative baselines for each of these tasks, including representative LLMs. We find, that while they show promising results on individual tasks in our benchmark, their end-to-end performance on all four tasks in succession deteriorates significantly, both in automated measures as well as in human-centred evaluation. This challenge presented by our proposed dataset motivates future research on end-to-end argument mining and summarisation. The repository of this project is available at https://github.com/HarrywillDr/ArgSum-Datatset",2024,,FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: ACL 2024,,,133-150,WOS:001356731800009,,,#4360,Li 2024,"",""
The persuasion of borrowers' voluntary information in peer to peer lending: An empirical study based on elaboration likelihood model,"Han, JT; Chen, Q; Liu, JG; Luo, XL; Fan, WG","This paper investigates the persuasive process of borrowers' controllable voluntary information which can be easily manipulated and is particularly valuable for borrowers to persuade lenders and enhance the likelihood of funding success in P2P lending marketplace. Using a large scale data set from a Chinese leading P2P lending platform, namely Renrendai, based on a dual-processing persuasion theory Elaboration Likelihood Model, we introduce four newly persuasive features (Completeness, Sentiment, Language intensity, The number of certificates) with central and peripheral cues in voluntary information. The results show that the persuasion of borrowers' voluntary information can be accomplished via two distinct routes in P2P lending, suggesting that not only central cues but also peripheral cues have significant effect on lenders' decision making. Specially, negative sentiment is negatively associated with funding success which is contradictory to the findings in fund-raising appeals say using negative emotions can evoke ""empathy-helping"". Moreover, we find a negative interaction effect on funding success between Completeness and The number of certificates. Our study shed some light for deeply understanding the dual-route persuasive process in P2P lending. (C) 2017 Elsevier Ltd. All rights reserved.",2018,,COMPUTERS IN HUMAN BEHAVIOR,78,,200-214,WOS:000417656700020,10.1016/j.chb.2017.09.004,,#4361,Han 2018,"",""
Deciding Staged Battles of the Past: On the Rhetorics of Olaf Muller's Historical Philosophy of Science,"Hampe, M","Since Plato's massive critique of the Sophists rhetoric's ill repute runs through the history of western philosophy denunciating methods of rhetoric as in large part dishonest persuasion strategies which are at most marginally interested in dealing with truths. This judgement falls way too short insofar as it distorts the historically grown stock labeled rhetoric not only in the Aristotelian work. With reference to Olaf Muller's philosophical book (Mehr Licht: Goethe mit Newton im Streit um die Farben, S. Fischer, Frankfurt am Main, 2015) addressing the controversy between Goethe and Newton about the nature of light, I will study the different rhetorical models and methods used by Newton and Goethe and also Muller himself. It becomes apparent that even works attempting to decide who was right in the long run do far more than trying to evoke true representations of facts or truths in the reader. The specific use of language patterns provides deeper insight into an author's mindset towards the subject area discussed in his work and generally speaking the investigation of the rhetoric of science and philosophy leads to a better understanding of different epistemic cultures both in philosophy and science.",2018,,JOURNAL FOR GENERAL PHILOSOPHY OF SCIENCE,49,4,569-580,WOS:000450499500007,10.1007/s10838-017-9397-5,,#4362,Hampe 2018,"",""
Metadiscursive nouns in academic argument: ChatGPT vs student practices,"Jiang, F; Hyland, K","The ability of ChatGPT to create grammatically accurate and coherent texts has generated considerable anxiety among those concerned that students might use such large language models (LLMs) to write their assignments. The extent to which LLMs can mimic human writers is starting to be explored, but we know little about their ability to use nominal resources to create effective academic texts. This study investigates metadiscursive nouns in argumentative essays, comparing how ChatGPT and university students employ these devices to organise text, express stance, and construct persuasive arguments. By analysing 145 essays from each source, we examine the syntactic patterns, interactive functions, and interactional uses of metadiscursive nouns. The analysis reveals that while overall frequencies were similar, ChatGPT has distinct preferences for simpler syntactic constructions (particularly the determiner + N pattern) and relies heavily on anaphoric references, whereas students demonstrate more balanced syntactic distribution and greater use of cataphoric references. Interactionally, ChatGPT prefers manner nouns for descriptive precision, while students favour status nouns for evaluative reasoning and evidential nouns for empirical grounding. These findings show that, while structurally coherent, LLMgenerated texts often lack the rhetorical flexibility and evaluative sophistication of human academic writing, offering valuable insights for EAP pedagogy.",2025,,JOURNAL OF ENGLISH FOR ACADEMIC PURPOSES,75,,,WOS:001471158600001,10.1016/j.jeap.2025.101514,,#4363,Jiang 2025,"",""
Digital transformation and pollution emission of enterprises: Evidence from China's micro-enterprises,"Li, GQ; Jin, YP; Gao, X","Based on pollution emission data and digital product import data of Chinese industrial enterprises from 2000 to 2013, this paper takes enterprise digital imported products as a natural experiment to build a model of multiple phase difference in difference (DID) to investigate the pollution reduction effect of enterprise digital transformation. The research results show that the digital transformation of enterprises can significantly reduce their pollution emissions. The strong persuasive and robustness of the model results are verified by substituting variables, eliminating interference value, excluding other factors, time lag effect and factor sensitivity analysis. When the overall digital transformation level of non-polluting enterprises in the city where polluting enterprises are located is used as an instrumental variable to deal with the potential endogeneity problem, the results still hold. Due to the relatively high level of environmental regulation in the eastern region, the central and western regions undertake low-end manufacturing industries and have limited economic development. So, the environmental governance effect of enterprises in the eastern region is more significant than that in the central and western regions. The strong agglomeration in coastal areas makes the emission reduction effect more significant. The environmental governance effect of enterprise digitization is mainly reflected in foreign capital, collective and large and medium-sized enterprises. Enterprise digitization and technological innovation jointly promote the pollution reduction of enterprises, and enterprise digitization transformation only has the ""end treatment""effect.(c) 2022 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).",2023,,ENERGY REPORTS,9,,552-567,WOS:000904678800001,10.1016/j.egyr.2022.11.169,,#4364,Li 2023,"",""
Chatbot symbolic recovery and customer forgiveness: a moderated mediation model,"Zaki, HS; Al-Romeedy, BS","Purpose - Artificial intelligence-based chatbots are frequently used to handle customer complaints in the hospitality and tourism sectors; however, little is known about their recovery strategies. Further, the widespread usage of chatbots is anticipated to affect customers' favorable responses. Therefore, this study aims to examine how chatbots' symbolic recovery influences customer forgiveness through customer empathy and explore the moderating effect of time pressure on it. Moreover, it investigates the effect of customer forgiveness on customer reconciliation and customer continuous trust.Design/methodology/approach - Structural equation modeling was used to analyze data collected from 994 customers who have experienced chatbot recovery in tourism and hospitality during the past four months.Findings - The results show that chatbots' symbolic recovery stimulates customer forgiveness, which subsequently positively affects customer reconciliation and customer continuous trust. Moreover, customer empathy partially mediates the effect of chatbots' symbolic recovery on customer forgiveness, and time pressure plays a moderating role in the relationship between chatbots' symbolic recovery and customer forgiveness.Practical implications - The results offer highly persuasive insights that may be used to promote chatbots' symbolic recovery in tourism organizations. The effectiveness of chatbots' symbolic recovery in achieving customer forgiveness will motivate tourism organizations to use chatbots efficiently in service recovery.Originality/value - This study extends the theoretical scope of chatbot research by investigating the symbolic recovery capabilities of chatbots. Moreover, it expands the application of SOR theory in the context of chatbot service recovery and reveals the underlying mechanism behind the impact of chatbots' symbolic recovery on customer forgiveness, thus building and testing an integrative model of chatbot service recovery.",2024,,JOURNAL OF HOSPITALITY AND TOURISM TECHNOLOGY,15,4,610-628,WOS:001244021500001,10.1108/JHTT-11-2023-0374,,#4365,Zaki 2024,"",""
Behavioral Nudges as Patient Decision Support for Medication Adherence: The ENCOURAGE Randomized Controlled Trial,"Horne, BD; Muhlestein, JB; Lappe, DL; May, HT; Le, VT; Bair, TL; Babcock, D; Bride, D; Knowlton, KU; Anderson, JL","Background Medication adherence is generally low and challenging to address because patient actions control healthcare delivery outside of medical environments. Behavioral nudging changes clinician behavior, but nudging patient decision-making requires further testing. This trial evaluated whether behavioral nudges can increase statin adherence, measured as the proportion of days covered (PDC).Methods In a 12-month parallel-group, unblinded, randomized controlled trial, adult patients in Intermountain Healthcare cardiology clinics were enrolled. Inclusion required an indication for statins and membership in SelectHealth insurance. Subjects were randomized 1:1 to control or nudges. Nudge content, timing, frequency, and delivery route were personalized by CareCentra using machine learning of subject motivations and abilities from psychographic assessment, demographics, social determinants, and the Intermountain Mortality Risk Score. PDC calculation used SelectHealth claims data.Results Among 182 subjects, age averaged 63.2 +/- 8.5 years, 25.8% were female, baseline LDL-C was 82.5 perpendicular to 32.7 mg/dL, and 93.4% had coronary disease. Characteristics were balanced between nudge ( n = 89) and control arms ( n = 93). The statin PDC was greater at 12 months in the nudge group (PDC: 0.742 +/- 0.318) compared to controls (PDC: 0.639 +/- 0.358, P = 0.042). Adherent subjects (PDC >= 80%) were more concentrated in the nudge group (66.3% vs controls: 50.5%, P = 0.036) while a composite of death, myocardial infarction, stroke, and revascularization was non-significantConclusions Persuasive behavioral nudges driven by artificial intelligence resulted in a clinically important increase in statin adherence in general cardiology patients. This precision patient decision support utilized computerized nudge design and delivery with minimal on-going human input.",2022,,AMERICAN HEART JOURNAL,244,,125-134,WOS:000799321400015,10.1016/j.ahj.2021.11.001,,#4366,Horne 2022,"",""
"Influencer Marketing, Narrative Transportation, and Consumer Well-Being: An Exploration of How Virtual Influencers Impact Followers' Well-Being","Jain, R; Schuster, L; Luck, E; Jin, HS","With recent advancements in technologies such as artificial intelligence and computer-generated imagery, virtual influencers (VIs) have become prominent branding tools that command high engagement rates. Most extant research explores the marketing outcomes of using VIs in brand campaigns. However, little is known about how interacting with VIs on social media platforms may affect consumers' well-being. This research takes a comprehensive approach, developing a nuanced understanding of whether (and how) human-like VIs (HVIs) impact consumers' well-being. We employ a conceptual development approach drawing on scholarship from influencer marketing, narrative transportation, and consumer well-being and gather additional support for the conceptual framework from data collected by interviewing 25 followers of HVIs. The conceptual framework proposes that when interacting with influencers' social media posts, followers experience narrative transportation, which positively influences followers' hedonic and eudaimonic well-being. However, the conceptual framework also proposes that these relationships are moderated by the type of influencer (human vs. virtual) sharing the post. Specifically, we suggest that interactions with HVIs provide followers with enjoyment (hedonic well-being) and support their self-acceptance, personal growth, relationships, and autonomy (eudaimonic well-being). We also provide initial evidence of the favorable marketing outcomes of enhanced well-being from engagement with HVIs, including contemplation of brand purchase. The study thus advances extant VI literature by proposing a theoretically and empirically informed conceptual model that examines HVIs' influence on consumer well-being. Also, it contributes to addressing the broader calls for research on the impact of social media and influencer marketing on consumer well-being.",2024,,INTERNATIONAL JOURNAL OF CONSUMER STUDIES,48,6,,WOS:001368942100001,10.1111/ijcs.13105,,#4367,Jain 2024,"",""
The softening of Chinese digital propaganda: Evidence from the People's Daily Weibo account during the pandemic,"Zhang, C; Zhang, DC; Shao, HL","IntroductionSocial media infuses modern relationships with vitality and brings a series of information dissemination with subjective consciousness. Studies have indicated that official Chinese media channels are transforming their communication style from didactic hard persuasion to softened emotional management in the digital era. However, previous studies have rarely provided valid empirical evidence for the communicational transformation. The study fills the gap by providing a longitudinal time-series analysis to reveal the pattern of communication of Chinese digital Chinese official media from 2019 to 2022. MethodThe study crawler collected 43,259 posts from the People's Daily's Weibo account from 2019 to 2021. The study analyzed the textual data with using trained artificial intelligence models. ResultsThis study explored the practices of the People's Daily's Weibo account from 2019 to 2021, COVID-19 is hardly normalized as it is still used as the justification for extraordinary measures in China. This study confirmed that People's Daily's Weibo account posts are undergoing softenization transformation, with the use of soft news, positive energy promotion, and the embedding of sentiment. Although the outburst of COVID-19 temporarily increased the media's use of hard news, it only occur at the initial stage of the pandemic. Emotional posts occupy a nonnegligible amount of the People's Daily Weibo content. However, the majority of posts are emotionally neutral and contribute to shaping the authoritative image of the party press. DiscussionOverall, the People's Daily has softened their communication style on digital platforms and used emotional mobilization, distraction, and timely information provision to balance the political logic of building an authoritative media agency and the media logic of constructing audience relevance.",2023,,FRONTIERS IN PSYCHOLOGY,14,,,WOS:000953504500001,10.3389/fpsyg.2023.1049671,,#4368,Zhang 2023,"",""
Will virtual rehabilitation replace clinicians: a contemporary debate about technological versus human obsolescence,"Krasovsky, T; Lubetzky, AV; Archambault, PS; Wright, WG","This article is inspired by a pseudo Oxford-style debate, which was held in Tel Aviv University, Israel at the International Conference on Virtual Rehabilitation (ICVR) 2019, which is the official conference of the International Society for Virtual Rehabilitation. The debate, between two 2-person teams with a moderator, was organized by the ICVR Program committee to address the question ""Will virtual rehabilitation replace clinicians?"" It brought together five academics with technical, research, and/or clinical backgrounds-Gerry Fluet, Tal Krasovsky, Anat Lubetzky, Philippe Archambault, W. Geoffrey Wright-to debate the pros and cons of using virtual reality (VR) and related technologies to help assess, diagnose, treat, and track recovery, and more specifically investigate the likelihood that advanced technology will ultimately replace human clinicians. Both teams were assigned a side to defend, whether it represented their own viewpoint or not, and to take whatever positions necessary to make a persuasive argument and win the debate. In this paper we present a recapitulation of the arguments presented by both sides, and further include an in-depth consideration of the question. We attempt to judiciously lay out a number of arguments that fall along a spectrum from moderate to extreme; the most extreme and/or indefensible positions are presented for rhetorical and demonstrative purposes. Although there may not be a clear answer today, this paper raises questions which are related to the basic nature of the rehabilitation profession, and to the current and potential role of technology within it.",2020,,JOURNAL OF NEUROENGINEERING AND REHABILITATION,17,1,,WOS:000597258600001,10.1186/s12984-020-00769-0,,#4369,Krasovsky 2020,"",""
Human-Side Strategies in the Werewolf Game Against the Stealth Werewolf Strategy,"Bi, XH; Tanaka, T","The werewolf game contains unique features, such as persuasion and deception, which are not included in games that have been previously studied in AI research. Studying the werewolf game could be one of the next challenging targets for AI research. In this paper, we concentrate on a werewolf-side strategy called the ""stealth werewolf"" strategy. With this strategy, each of the werewolf-side players behaves like a villager, and the player does not pretend to have a special role. Even though the strategy is thought to be suboptimal, so far this has not been proved. In this paper, we limit the human-side strategies such that the seer reveals his/her role on the first day and the bodyguard never reveals his/her role. So, the advantage of the werewolves in determining the player to be eliminated by vote is nullified. We calculated the epsilon-Nash equilibrium of strategies for both sides under this limitation. The solution shows that the winning rates of the human-side are more than half when the number of werewolves is assigned as in common play. Since it is thought to be fair and interesting for the winning rate to stay near 50%, the result suggests that the ""stealth werewolf"" strategy is not a good strategy for werewolf-side players. Furthermore, the result also suggests that there exist unusual actions in the strategies that result in an epsilon-Nash equilibrium.",2016,,"COMPUTERS AND GAMES, CG 2016",10068,,93-102,WOS:000462541200009,10.1007/978-3-319-50935-8_9,,#4370,Bi 2016,"",""
Dairy veterinarians' skills in motivational interviewing are linked to client verbal behavior,"Svensson, C; Forsberg, L; Emanuelson, U; Reyher, KK; Bard, AM; Betnér, S; von Brömssen, C; Wickström, H","Veterinarians often give advice in a persuasive form, a style that has been shown to evoke resistance to change in clients experiencing psychological ambivalence (i.e. those who see both advantages and disadvantages to changing). With this style of communication, veterinarians run the risk of counteracting their purpose to encourage clients to follow recommendations. Motivational interviewing(MI)is a client-centered communication methodology that aims to facilitate clients' internal motivation to change. In MI,Change Talkrepresents clients' own statements expressing consideration of, motivation for or commitment to behavior change and has been shown to be strongly correlated with behavior change.Sustain Talkis corresponding statements related to maintaining thestatus quo. The aim of this exploratory study was to evaluate the potential of MI to facilitate behavior change in veterinary herd health management(VHHM)by investigating the effect of dairy cattle veterinarians' MI skills on clientChangeandSustain Talk. We recorded VHHM consultancies on 170 Swedish cattle farms performed by 36 veterinarians, randomly distributed into 2 groups: MI veterinarians (n= 18) had received 6-month training in MI and control veterinarians (n= 18) had not received any training. Veterinarians' MI skills were assessed using the Motivational Interviewing Treatment Integrity coding system 4.2.1 and categorized as poor_untrained, poor_trained, near moderate and moderate. Client communication was coded using the Client Language Easy Rating coding system. The effect of MI skills onChange Talk, Sustain TalkandProportion of Change Talk(Change Talkdivided by the sum ofSustain TalkplusChange Talk)was investigated using cross-classified regression models with random intercepts for veterinarian and client (farm). The models also included additional explanatory variables (e.g. type of veterinarian and client's satisfaction with the consultation). The veterinarian's MI skills were associated with the client'sChange Talk,but results regardingSustain TalkorProportion of Change Talkwere inconclusive. Clients of veterinarians reaching the highest (i.e. moderate) MI skills expressed 1.5 times moreChange Talkthan clients of untrained veterinarians. Clients of general large animal practitioners expressed lessSustain Talkthan clients of animal health veterinarians and had higherProportion of Change Talk.Results indicate that learning to practice MI may be one means to improve adherence to veterinary recommendations and to improve efficiency in VHHM services.",2020,,ANIMAL,14,10,2167-2177,WOS:000571176200019,10.1017/S175173112000107X,,#4371,Svensson 2020,"",""
The Direct Effect of Managerial Responses: When Politeness Backfires,"Jin, HF; Wang, LL; Liu, YY; Tong, Y","Managerial responses, which represent firms' public replies to online reviews, are commonly employed in customer communications. Using a dataset collected from a leading mobile game app platform in China, this research examines the effect of managerial responses on the review updates of customers who receive them, that is, the direct effect of managerial responses. Platform users can update their reviews, and complete records of review updates are observable, which allows us to utilize variations in the same customer's review ratings of a single game both before and after receiving a managerial response. Addressing concerns regarding the endogeneity of managerial responses, improvements in game quality, and censored data in rating updates, we find that users who update their reviews after receiving managerial responses upgrade their ratings by an average of one star. In addition, we find that the positive direct effect of managerial responses is negatively moderated by the level of response politeness, measured separately using both machine learning and large language models. By conducting a survey study, we further show that as the level of politeness increases, the likelihood of reviewers perceiving a managerial response as an attempt to persuade them also increases. These findings highlight the positive direct effect of managerial response and the importance of response style, specifically politeness, which can produce a backfire effect in online communications.",2025,,PRODUCTION AND OPERATIONS MANAGEMENT,,,,WOS:001401631300001,10.1177/10591478241309439,,#4372,Jin 2025,"",""
The future of cognitive strategy-enhanced persuasive dialogue agents: new perspectives and trends,"Chen, MQ; Guo, B; Wang, H; Li, HY; Zhao, Q; Liu, JQ; Ding, YS; Pan, Y; Yu, ZW","Persuasion, as one of the crucial abilities in human communication, has garnered extensive attention from researchers within the field of intelligent dialogue systems. Developing dialogue agents that can persuade others to accept certain standpoints is essential to achieving truly intelligent and anthropomorphic dialogue systems. Benefiting from the substantial progress of Large Language Models (LLMs), dialogue agents have acquired an exceptional capability in context understanding and response generation. However, as a typical and complicated cognitive psychological system, persuasive dialogue agents also require knowledge from the domain of cognitive psychology to attain a level of human-like persuasion. Consequently, the cognitive strategy-enhanced persuasive dialogue agent (defined as CogAgent), which incorporates cognitive strategies to achieve persuasive targets through conversation, has become a predominant research paradigm. To depict the research trends of CogAgent, in this paper, we first present several fundamental cognitive psychology theories and give the formalized definition of three typical cognitive strategies, including the persuasion strategy, the topic path planning strategy, and the argument structure prediction strategy. Then we propose a new system architecture by incorporating the formalized definition to lay the foundation of CogAgent. Representative works are detailed and investigated according to the combined cognitive strategy, followed by the summary of authoritative benchmarks and evaluation metrics. Finally, we summarize our insights on open issues and future directions of CogAgent for upcoming researchers.",2025,,FRONTIERS OF COMPUTER SCIENCE,19,5,,WOS:001362461400011,10.1007/s11704-024-40057-x,,#4373,Chen 2025,"",""
Legitimating falsehood in social media: A discourse analysis of political fake news,"Igwebuike, EE; Chimuanya, L","Digital peddling of fake news is influential to persuasive political participation, with veritable social media platforms. Social media, with their instantaneous and widespread usage, have been exploited by 'anonymous' political influencers who fabricate and inundate internet community with unverified and false information. Using van Leeuwen's Discourse Legitimation approach and insights from Discourse Analysis, this study analyses 120 purposively sampled fake news posts on Whatsapp, Facebook and Twitter, shared during the 2019 general elections in Nigeria. WhatsApp allows for the easy and fast sharing of fake news as it pulled the largest occurrence of legitimation strategies, followed by Facebook. Authorisation is the highest occurring legitimation strategy at 46.6% frequency; this is followed by Moralisation which has 27% and Rationalisation at 26.4%; while Mythopoesis did not feature at all in the sampled data, leaving it at 0%. In particular, expert and role model authority are most often deployed to validate fake news such as the demise and cloning of President Buhari, ruling party's plan to rig and destabilise the 2019 election, massive corruption in the current administration and imminent ethnic violence. The study argues that these strategies are viable persuasive tools owing to their use of discourse markers like make-believe images, emotive language, appeal to emotions, rational conclusions, hateful comments, verbal indictment and coercive verbs.",2021,,DISCOURSE & COMMUNICATION,15,1,42-58,WOS:000598408100001,10.1177/1750481320961659,,#4374,Igwebuike 2021,"",""
"Fake News, Disinformation, Propaganda, and Media Bias","ACM; Nakov, P; Da San Martino, G","The rise of Internet and social media changed not only how we consume information, but it also democratized the process of content creation and dissemination. Despite the hugely positive impact, this situation had the downside that the public was left unprotected against biased, deceptive, and disinformative content, which could now travel online at breaking-news speed and allegedly influence major events such as political elections, or disturb the efforts of governments and health officials to fight the ongoing COVID-19 pandemic. The research community responded to the issue, proposing a number of inter-connected research directions such as factchecking, disinformation, misinformation, fake news, propaganda, and media bias detection. Below, we cover the mainstream research, and we also pay attention to less popular, but emerging research directions, such as propaganda detection, check-worthiness estimation, detecting previously fact-checked claims, and multimodality, which are of interest to human fact-checkers and journalists. We further cover relevant topics such as stance detection, source reliability estimation, detection of persuasion techniques in text and memes, and detecting malicious users in social media. Moreover, we discuss large-scale pre-trained language models, and the challenges and opportunities they offer for generating and for defending against neural fake news. Finally, we explore some recent efforts aiming at flattening the curve of the COVID-19 infodemic.",2021,,"PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021",,,4862-4865,WOS:001054156204109,10.1145/3459637.3482026,,#4375,ACM 2021,"",""
Quotation Recommendation for Multi-party Online Conversations Based on Semantic and Topic Fusion,"Wang, LZ; Zeng, XS; Wong, KF","Quotations are crucial for successful explanations and persuasions in interpersonal communications. However, finding what to quote in a conversation is challenging for humans. This work studies automatic quotation recommendation for online conversations. Unlike the previous works that only consider semantic-level modeling, we adopt topic-level representation to facilitate the recommendation. A hierarchical architecture that is based on a pretrained language model is adopted to model the semantic-level conversation representation, and a neural topic model is employed to learn the topic-level representation. Moreover, the semantic-level conversation modeling is enhanced by a topic-aware attention mechanism, which is adopted to capture the interactive conversation structure from the perspective of word co-occurrence. The joint training of semantic- and topic-based recommendation leads to significantly better performance than the state-of-the-art models on two large-scale datasets. Apart from the novel and advanced recommendation framework, we conduct extensive quantitative experiments to investigate the difficulty of the quotation recommendation task, validate the topic-based recommendation assumption, and explore the stability of the recommendation. Some qualitative experiments and analyses are also included to interpret the quotation and topic distribution for some instances. All the extensive experiments and analyses provide persuasive explanations and interpretations of the module design and the recommendation results.",2023,,ACM TRANSACTIONS ON INFORMATION SYSTEMS,41,4,,WOS:001068685300013,10.1145/3594633,,#4376,Wang 2023,"",""
Emergent impoliteness and persuasive emotionality in Polish media discourses,"Lewandowska-Tomaszczyk, B; Pezik, P","The focus of the paper is to identify and discuss cases of what we call emergent impoliteness and persuasive emotionality based on selected types of discourse strategies in Polish media which contribute to increasingly high negative emotionality in audiences and to the radicalization of language and attitudes when addressing political opponents. The role and function of emotional discourse are particularly foregrounded to identify its persuasive role in media discourses and beyond. Examples discussed are derived from current Polish media texts. The materials are collected from the large Polish monitor media corpus monco.frazeo.pl (Pezik 2020). The analysis is conducted in terms of quantitative corpus tools (Pezik 2012, 2014), concerning emotive and media discourse approaches (Lewandowska-Tomaszczyk and Wilson 2013, Lewandowska-Tomaszczyk 2015, 2017a, 2017b). The analysis includes a presentation of the ways mass media construe events (Langacker 1987/1991) in terms of their ideological framing, understood as particular imposed/constructed event models and structures (cf. Gans 1979). Special attention is paid to the negative axiological evaluation of people and events in terms of mostly implicitly persuasive and offensive discourse, including the role emotion clusters of harm, hurt and offence, anger and contempt play in the media persuasive tactics. The research outcomes provide a research basis and categorization of types of emergent impoliteness and persuasive emotionality, which involve implicit persuasion directed at negative emotionality raising with the media public, as identifiedin the analyzed media texts.",2021,,RUSSIAN JOURNAL OF LINGUISTICS,25,3,685-704,WOS:000701706600006,10.22363/2687-0088-2021-25-3-685-704,,#4377,Lewandowska-Tomaszczyk 2021,"",""
Decision support system for evaluating the role of music in network-based game for sustaining effectiveness,"Yu, YL; Wang, D; Faisal, M; Jabeen, F; Johar, S","The development of music in games brings attractiveness and spreads the gaming industry. Music plays a vital role in the games to attract user attitudes toward gaming. The gaming industry is more beneficial than any other industry, like the film industry using music in-game. The evolution of music in games started a few decades ago and brought a lot of enhancement in gaming. Nowadays, a player likes music-based games more than any other game because while playing music-based games, it releases stress and keeps comfortable of player's mind. The music in games changes the previous gaming style and advances, which help the young generation, learn something new from different games. Music is used to attract user attitudes and ultimately involve users in gaming during playing games. Music is utilized in-game to develop a more attractive and memorable game to enhance users' interest in playing games. In addition, the usage of background music in games is also a primary part of successful games because, at a similar time, game developers and those who play games hope that video games can be more persuasive. After studying the previous paper, it identified that music in games positively impacts players' performance and achievement, improves the player's skills, and keeps players relaxed during playing games. The current research has considered the decision support system (DSS) for evaluating the role of music in games for sustained effectiveness. Results of the study have shown the efficacy of the study.",2022,,SOFT COMPUTING,26,20,10775-10788,WOS:000777441900004,10.1007/s00500-022-06992-2,,#4378,Yu 2022,"",""
"Emerging trends: Unfair, biased, addictive, dangerous, deadly, and insanely profitable","Church, K; Schoene, A; Ortega, JE; Chandrasekar, R; Kordoni, V","There has been considerable work recently in the natural language community and elsewhere on Responsible AI. Much of this work focuses on fairness and biases (henceforth Risks 1.0), following the 2016 best seller: Weapons of Math Destruction. Two books published in 2022, The Chaos Machine and Like, Comment, Subscribe, raise additional risks to public health/safety/security such as genocide, insurrection, polarized politics, vaccinations (henceforth, Risks 2.0). These books suggest that the use of machine learning to maximize engagement in social media has created a Frankenstein Monster that is exploiting human weaknesses with persuasive technology, the illusory truth effect, Pavlovian conditioning, and Skinner's intermittent variable reinforcement. Just as we cannot expect tobacco companies to sell fewer cigarettes and prioritize public health ahead of profits, so too, it may be asking too much of companies (and countries) to stop trafficking in misinformation given that it is so effective and so insanely profitable (at least in the short term). Eventually, we believe the current chaos will end, like the lawlessness in Wild West, because chaos is bad for business. As computer scientists, this paper will summarize criticisms from other fields and focus on implications for computer science; we will not attempt to contribute to those other fields. There is quite a bit of work in computer science on these risks, especially on Risks 1.0 (bias and fairness), but more work is needed, especially on Risks 2.0 (addictive, dangerous, and deadly).",2023,,NATURAL LANGUAGE ENGINEERING,29,2,483-508,WOS:000900779400001,10.1017/S1351324922000481,,#4379,Church 2023,"",""
Nego-Bot: A Human-Robot Negotiation System,"Rincon, JA; Costa, A; Julian, V; Carrascosa, C; Novais, P","In this paper we present a platform composed of a low-cost robot and a multi-agent system that uses deep learning algorithms, whose objective is to establish a negotiation process and persuasively sell items, maximising their price, thus gain. To do this, we have focused on developing an interactive process that is able to interact with humans using a camera, microphone and speaker, to establish all negotiation process without physical contact. This is relevant due to the current COVID-19 situation and arisen issues of human contact. Validation processes with university students have revealed high interest and success in products' negotiation.",2021,,"ADVANCES IN PRACTICAL APPLICATIONS OF AGENTS, MULTI-AGENT SYSTEMS, AND SOCIAL GOOD: THE PAAMS COLLECTION, PAAMS 2021",12946,,376-379,WOS:000791045800036,10.1007/978-3-030-85739-4_36,,#4380,Rincon 2021,"",""
A Theory-Driven Approach to Fake News/Information Disorder Analysis and Explanation via Target-Based Emotion-Stance Analysis (TESA) and Interpretive Graph Generation (IGG),"Chen, XK; Na, JC","Information disorder (IDO) presents a persistent challenge to society, necessitating innovative approaches to understanding its dynamics beyond just merely detecting it. This study introduces a theory-driven framework that integrates advanced natural language processing (NLP) with deep learning, utilizing the target-based emotion-stance analysis (TESA) approach to analyze emotion and stance dynamics within IDO content. Complementing TESA, interactive graph generation (IGG) is applied for scalable and interpretable qualitative analyses. Employing a mixed-methods approach, the study leverages TESA for target-centric emotion and stance analysis, evaluating target-based classifiers on both human-annotated and synthetic datasets. Additionally, the study explores synthetic data generation using generative AI to enrich the analysis, applying IGG to map complex data interactions. The study also found that integrating synthetic data developed from human annotations enhanced model performance, particularly for emotion classification tasks. Results demonstrate that IDO narratives significantly differ from non-IDO narratives, frequently leveraging negative emotions such as anger and disgust to manipulate public perception. TESA proved effective in capturing these nuanced variations, while IGG facilitated the triangulation of such findings via the scalable interpretation of emotional narratives, revealing that IDO content often amplifies polarizing and antagonistic perspectives. By combining TESA and IGG, this research emphasizes the importance of using NLP to extract and examine the emotional and stance nuances toward targets of interest within IDO context. This approach not only deepens theoretical insights into IDO's persuasive mechanisms but also supports the development of practical tools for analyzing and managing the influence of IDO on public discourse.",2025,,SOCIAL SCIENCE COMPUTER REVIEW,,,,WOS:001480380600001,10.1177/08944393251338403,,#4381,Chen 2025,"",""
Applying Machine Learning in Personality-based Persuasion Marketing,"Christodoulou, E; Gregoriades, A","Personality based persuasion marketing often use consumers' psychological characteristics to influence purchasing behaviour. When done in an ethical manner it can bring benefits to all involved parties. Personality can be inferred from consumers' information available online, such as text in electronic word-of-mouth (eWOM) or likes from social media. This paper utilizes natural language processing to extract consumers' personality and opinions for eWOM and utilise these to optimize persuasiveness of advertising communication. The approach is based on the self-congruence theory postulating that consumers respond more positively to brands and messages that are in line with their personalities. Such insights can assist marketers in developing effective persuasion marketing strategies. The methodology combines text-based personality extraction with topic modelling, ensemble classification and explainable AI, and is applied on restaurants' reviews from Tripadvisor. EWOM text is vectorized by expressing each review as a vector of topics' proportions from the learned topic model. Personalities of consumers are recognised using a deep learning classifier, fine tuned on labeled data from the MBTI personality model. Four binary XGBoost (eXtreme Gradient Boosting) classifiers are trained and validated, one for each personality trait, using reviews' embeddings (topics) as predictors and personality labels as class variables. The logic of each XGBoost model is extracted using an explainable AI technique, namely, Shapley Additive Explanations (SHAP). Shapley values form SHAP global explanations give rise to eWOM topics that could resonate more with each personality trait. Results can help marketers design advertising messages based on the consumer personality that they target. The findings are compared against the literature of persuasion marketing and consumer behavior.",2023,,"2023 23RD IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOPS, ICDMW 2023",,,16-23,WOS:001164077500003,10.1109/ICDMW60847.2023.00010,,#4382,Christodoulou 2023,"",""
Interaction strategies in online learning: Insights from text analytics on iMOOC,"Wang, W; Zhao, YY; Wu, YJ; Goh, M","Learners engaged in large-scale online learning often pose questions in which their peers or instructors can answer using various means of textual interaction topics. This paper assesses the effects of the text interaction strategies in online learning through the lens of the language expectancy theory at three levels: whether to respond to the questions, the identity of the respondents, and the textual interaction topics. Using 112,680 learning records of 610 courses from 71,948 learners crawled from the online learning programming platform iMOOC as the corpus, text mining is used to identify the interaction strategies. Using grounded theory, the textual interaction topics are divided into 2 groups (providing solutions, and encouragement & evaluation for the learners), and sub-divided into 6 topic clusters (code writing, operation guidance, providing references, encouragement, normative interpretation, and opinion exchange). The responses are classified by text mining. The results of the econometric model suggest that responding to the questions online fosters learning and reduces the dropout rate. The online learner benefits more from peer learning than from the instructors. On the text interaction topics, the topic ""providing solutions"" is more effective in reducing the learner's dropout rate than the topic ""encouragement & evaluation"". Further, code writing is more effective over providing references, encouragement, and normative interpretation. This study enriches our understanding of the interaction strategies between learners and instructors in iMOOC, and provides a reference for improving the online learning journey and retain learners.",2023,,EDUCATION AND INFORMATION TECHNOLOGIES,28,2,2145-2172,WOS:000840287600001,10.1007/s10639-022-11270-7,,#4383,Wang 2023,"",""
"""I Am Here to Assist You Today"": The Role of Entity, Interactivity and Experiential Perceptions in Chatbot Persuasion","Ischen, C; Araujo, T; van Noort, G; Voorveld, H; Smit, E","Online users are increasingly exposed to chatbots as one form of AI-enabled media technologies, employed for persuasive purposes, e.g., making product/service recommendations. However, the persuasive potential of chatbots has not yet been fully explored. Using an online experiment (N = 242), we investigate the extent to which communicating with a stand-alone chatbot influences affective and behavioral responses compared to interactive Web sites. Several underlying mechanisms are studied, showing that enjoyment is the key mechanism explaining the positive effect of chatbots (vs. Web sites) on recommendation adherence and attitudes. Contrary to expectations, perceived anthropomorphism seems not to be particularly relevant in this comparison.",2020,,JOURNAL OF BROADCASTING & ELECTRONIC MEDIA,64,4,615-639,WOS:000596641400001,10.1080/08838151.2020.1834297,,#4384,Ischen 2020,"",""
The full story: Understanding how films affect environmental change through the lens of narrative persuasion,"McCormack, CM; Martin, JK; Williams, KJH","1. Researchers in conservation fields have recently highlighted the potential for visual storytelling to convey environmental messages to large audiences. However, an effective model for how such narratives can produce environmental outcomes, such as human-nature connection and pro-environmental behaviour (PEB), has not yet been developed.2. Substantial evidence now suggests that narrative is an effective means of changing beliefs, attitudes and behaviours. This effect is demonstrated in diverse disciplines and understood within the theoretical frameworks of narrative persuasion.3. We propose a conceptual framework for understanding the impacts of environmental films on environmental behaviours, and connection with nature. Linking insights from the narrative persuasion field with those of conservation psychology, we identify three promising pathways through which environmental films might influence their audiences: (a) reduced resistance to environmental messages, (b) interactions with audience identity and (c) meaningful media experiences.4. This analysis raises key questions and illuminates priority areas for future research, with an aim to complement and extend existing calls to better appreciate the role of film in addressing environmental problems. Research moving forward should focus on understanding the role environmental films can play in connecting people with nature, promoting PEB and the relationship between the two. Specifically, more attention should be paid to the role of deictic shift in encouraging environmental outcomes, the relation between audiences and characters and the power for film to support self-expansion. A free Plain Language Summary can be found within the Supporting Information of this article.",2021,,PEOPLE AND NATURE,3,6,1193-1204,WOS:000710873500001,10.1002/pan3.10259,,#4385,McCormack 2021,"",""
Feature engineering from the perspective of agenda setting for predicting the success of online petitions,"Lee, PTY; Lu, AY; E, FY; Chau, M","This study draws on the issue expansion model and symbolism, both of which are influential concepts in the literature of public policy and agenda setting, to generate textual features for developing a predictive model of online petition success. Using a real-life dataset of an online petition platform, we show that the proposed model performs well in several important evaluation metrics when compared with benchmark models. This study offers several contributions. First, we present how to translate these concepts into textual features of petitions that can be understood by computers to improve prediction of petition success. The predictive models developed and the patterns of online petitioning identified enhance our understanding of collective actions on online petition platforms. In addition, we demonstrate that we can develop a better predictive model by adopting both supervised and unsupervised approaches of model development together with datasets that are exogenous from online petition platforms. Further examination of the predictive models in future may enable us to define vague concepts in a systematic way. On practical implications, our proposed text-mining model enables policy makers to handle a large volume of social data in a relatively objective manner. This is conducive to civic participation in edemocracy. The model may help policy makers identify potentially popular issues and prevent issue expansion at an early stage to mitigate the possible incursion of social cost. Moreover, by developing a predictive model based on our approach, citizens can compare different petition texts to determine their chances of success and post texts that have a higher predicted rate of success.",2024,,GOVERNMENT INFORMATION QUARTERLY,41,2,,WOS:001241741900001,10.1016/j.giq.2024.101937,,#4386,Lee 2024,"",""
Attitude Roots and Jiu Jitsu Persuasion: Understanding and Overcoming the Motivated Rejection of Science,"Hornsey, MJ; Fielding, KS","There is a worryingly large chasm between scientific consensus and popular opinion. Roughly one third of Americans are skeptical that humans are primarily responsible for climate change; rates of some infectious diseases are climbing in the face of anti-immunization beliefs; and significant numbers of the population worldwide are antievolution creationists. It is easy to assume that resistance to an evidence-based message is a result of ignorance or failure to grasp evidence (the ""deficit model"" of science communication). But increasingly, theorists understand there are limits to this approach, and that if people are motivated to reject science, then repeating evidence will have little impact. In an effort to create a transtheoretical language for describing these underlying motivations, we introduce the notion of ""attitude roots."" Attitude roots are the underlying fears, ideologies, worldviews, and identity needs that sustain and motivate specific ""surface"" attitudes like climate skepticism and creationism. It is the antiscience attitude that people hear and see, but it is the attitude root-what lies under the surface-that allows the surface attitudes to survive even when they are challenged by evidence. We group these attitude roots within 6 themes-worldviews, conspiratorial ideation, vested interests, personal identity expression, social identity needs, and fears and phobias-and review literature relevant to them. We then use these insights to develop a ""jiu jitsu"" model of persuasion that places emphasis on creating change by aligning with (rather than competing with) these attitude roots.",2017,,AMERICAN PSYCHOLOGIST,72,5,459-473,WOS:000406286700009,10.1037/a0040437,,#4387,Hornsey 2017,"",""
Clicks and tricks: The dark art of online persuasion,"Fagan, P","Internet users are inundated with attempts to persuade, including digital nudges like defaults, friction, and reinforcement. When these nudges fail to be transparent, optional, and beneficial, they can become 'dark patterns', categorised here under the acronym FORCES (Frame, Obstruct, Ruse, Compel, Entangle, Seduce). Elsewhere, psychological principles like negativity bias, the curiosity gap, and fluency are exploited to make social content viral, while more covert tactics including astroturfing, meta-nudging, and inoculation are used to manufacture consensus. The power of these techniques is set to increase in line with technological advances such as predictive algorithms, generative AI, and virtual reality. Digital nudges can be used for altruistic purposes including protection against manipulation, but behavioural interventions have mixed effects at best.",2024,,CURRENT OPINION IN PSYCHOLOGY,58,,,WOS:001274497600001,10.1016/j.copsyc.2024.101844,,#4388,Fagan 2024,"",""
Improving Students' Argumentation Skills Using Dynamic Machine-Learning-Based Modeling,"Wambsganss, T; Janson, A; Söllner, M; Koedinge, K; Leimeister, JM","Argumentation is an omnipresent rudiment of daily communication and thinking. The ability to form convincing arguments is not only fundamental to persuading an audience of novel ideas but also plays a major role in strategic decision making, negotiation, and constructive, civil discourse. However, humans often struggle to develop argumentation skills, owing to a lack of individual and instant feedback in their learning process, because providing feedback on the individual argumentation skills of learners is timeconsuming and not scalable if conducted manually by educators. Grounding our research in social cognitive theory, we investigate whether dynamic technology -mediated argumentation modeling improves students' argumentation skills in the short and long term. To do so, we built a dynamic machine -learning (ML)-based modeling system. The system provides learners with dynamic writing feedback opportunities based on logical argumentation errors irrespective of instructor, time, and location. We conducted three empirical studies to test whether dynamic modeling improves persuasive writing performance more so than the benchmarks of scripted argumentation modeling (H1) and adaptive support (H2). Moreover, we assess whether, compared with adaptive support, dynamic argumentation modeling leads to better persuasive writing performance on both complex and simple tasks (H3). Finally, we investigate whether dynamic modeling on repeated argumentation tasks (over three months) leads to better learning in comparison with static modeling and no modeling (H4). Our results show that dynamic behavioral modeling significantly improves learners' objective argumentation skills across domains, outperforming established methods like scripted modeling, adaptive support, and static modeling. The results further indicate that, compared with adaptive support, the effect of the dynamic modeling approach holds across complex (large effect) and simple tasks (medium effect) and supports learners with lower and higher expertise alike. This work provides important empirical findings related to the effects of dynamic modeling and social cognitive theory that inform the design of writing and skill support systems for education. This paper demonstrates that social cognitive theory and dynamic modeling based on ML generalize outside of math and science domains to argumentative writing.",2024,,INFORMATION SYSTEMS RESEARCH,,,,WOS:001251334200001,10.1287/isre.2021.0615,,#4389,Wambsganss 2024,"",""
Energy Management in an Agile Workspace using AI-driven Forecasting and Anomaly Detection,"IEEE; Manzoor, HU; Khan, AR; Al-Quraan, M; Mohjazi, L; Taha, A; Abbas, H; Hussain, S; Imran, MA; Zoha, A","Smart building technologies transform buildings into agile, sustainable, and health-conscious ecosystems by leveraging IoT platforms. In this regard, we have developed a Persuasive Energy Conscious Network (PECN) at the University of Glasgow to understand the user-centric energy consumption patterns in an agile workspace. PECN consists of desk-level energy monitoring sensors that enable us to develop user-centric models that can be exploited to characterize the normal energy usage behavior of an office occupant. In this study, we make use of staked long short-term memory (LSTM) to forecast future energy demands. Moreover, we employed statistical techniques to automate the detection of anomalous power consumption patterns. Our experimental results indicate that post-anomaly resolution leads to 6.37% improvement in the forecasting accuracy.",2022,,"2022 IEEE 4TH GLOBAL POWER, ENERGY AND COMMUNICATION CONFERENCE (IEEE GPECOM2022)",,,644-649,WOS:000854056400112,10.1109/GPECOM55404.2022.9815599,,#4390,IEEE 2022,"",""
Framing photos in the digital dark age: towards a socio-technological 'ecology of images',"Caldwell, S; Gedeon, T","The binary question of photography as science or art has been raging since Daguerre invented silver halide photography in 1839. Never has this controversy been more crucial, or been raised to such a fever pitch as in today's socio-technological world, in which uncertain images are consumed like candy and the evidentiary status of photographs is precarious at best. The 'offline' society of last century is behind us, where a philosopher like Sontag could confidently state that ""a photograph passes for incontrovertible proof that something exists, or did exist, which is like what's in the picture"" [1]. The 'ecology of images' of which she spoke is urgently needed now if we are to establish a framework within which the daily onslaught of uncertain imagery can be understood, the invidious action of image-based partisan persuasion can be combatted, pioneering achievements in image artistry can be celebrated, and a reliable photographic record of our current and future real world can be preserved.We may be better positioned now than at any time in the past to attempt such a task. Imaging technologies (ubiquitous digital photography, sophisticated camera sensors, image editing, synthetic image generation) have brought to fruition the use of photographic images to expand into a wide range of 'ecological' niches with varying impacts on individuals and societies. Other technologies (physiological signal processing, artificial intelligence), provide us with the means to gain insight into human perspectives and conscious/subliminal perceptions of these images. The contexts that apply to image distribution (digital platforms, social engineering, governmental regulation, communities of interest, commercial interests) are daily news. Early attempts to address image integrity (authenticity initiatives, fact-checking organisations) highlight the desire of humans to illuminate the age in which we find ourselves, a 'digital dark ages' [2] of eroding authenticity of our traditional knowledge artefacts.Drawing together reflections on the role of images in our century as well as a range of investigations over several years into aspects of the human-image nexus, we outline some of the technological and social features of a potential 'ecology of images' that may help shine light on the panoply of images of our times.",2021,,APPLICATIONS OF DIGITAL IMAGE PROCESSING XLIV,11842,,,WOS:000759326900020,10.1117/12.2598440,,#4391,Caldwell 2021,"",""
Improving logical flow in English-as-a-foreign-language learner essays by reordering sentences,"Putra, JWG; Teufel, S; Tokunaga, T","Argumentation is ubiquitous in everyday discourse, and it is a skill that can be learned. In our society, it is also one that must be learned: education systems all over the world agree on the importance of argumentation skills. However, writing effective argumentation is difficult, and even more so if it has to be expressed in a foreign language. Existing artificial intelligence systems for language learning can help learners: they can provide objective feedback (e.g., concerning grammar and spelling), as well as providing learners with opportunities to identify errors and subsequently improve their texts. Even so, systems aiming at higher discourse-level skills, such as persuasiveness and content organisation, are still limited. In this article, we propose the novel task of sentence reordering for improving the logical flow of argumentative essays. To train such a computational system, we present a new corpus called ICNALE-AS2R, containing essays written by English-as -foreign-language learners from various Asian countries, that have been annotated with argumentative structure and sentence reordering. We also propose a novel method to automatically reorder sentences in imperfect essays, which is based on argumentative structure analysis. Given an input essay and its corresponding argumentative structure, we cast the reordering task as a traversal problem. Our sentence reordering system first determines the pairwise ordering relation between pairs of sentences that are connected by argumentative relations. In the second step, the system traverses the argumentative structure that has been augmented with pairwise ordering information, in order to generate the final output text. Empirical evaluation shows that in the task of reconstructing the final reordered essays in the dataset, our reordering system achieves .926 and .879 in longest common subsequence ratio and Kendall's Tau metrics, respectively. The system is also able to perform the reordering operation selectively, that is, it reorders sentences when necessary and retains the original input order when it is already optimal.(c) 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons .org /licenses /by-nc -nd /4 .0/).",2023,,ARTIFICIAL INTELLIGENCE,320,,,WOS:001006514300001,10.1016/j.artint.2023.103935,,#4392,Putra 2023,"",""
A Research Roadmap: Connected Health as an Enabler of Cancer Patient Support,"Signorelli, GR; Lehocki, F; Fernández, MM; O'Neill, G; O'Connor, D; Brennan, L; Monteiro-Guerra, F; Rivero-Rodriguez, A; Hors-Fraile, S; Munoz-Penas, J; Dalmau, MB; Ll, JM; Oliveira, RB; Mrinakova, B; Putekova, S; Muro, N; Zambrana, F; Garcia-Gomez, JM","The evidence that quality of life is a positive variable for the survival of cancer patients has prompted the interest of the health and pharmaceutical industry in considering that variable as a final clinical outcome. Sustained improvements in cancer care in recent years have resulted in increased numbers of people living with and beyond cancer, with increased attention being placed on improving quality of life for those individuals. Connected Health provides the foundations for the transformation of cancer care into a patient-centric model, focused on providing fully connected, personalized support and therapy for the unique needs of each patient. Connected Health creates an opportunity to overcome barriers to health care support among patients diagnosed with chronic conditions. This paper provides an overview of important areas for the foundations of the creation of a new Connected Health paradigm in cancer care. Here we discuss the capabilities of mobile and wearable technologies; we also discuss pervasive and persuasive strategies and device systems to provide multidisciplinary and inclusive approaches for cancer patients for mental well-being, physical activity promotion, and rehabilitation. Several examples already show that there is enthusiasm in strengthening the possibilities offered by Connected Health in persuasive and pervasive technology in cancer care. Developments harnessing the Internet of Things, personalization, patient-centered design, and artificial intelligence help to monitor and assess the health status of cancer patients. Furthermore, this paper analyses the data infrastructure ecosystem for Connected Health and its semantic interoperability with the Connected Health economy ecosystem and its associated barriers. Interoperability is essential when developing Connected Health solutions that integrate with health systems and electronic health records. Given the exponential business growth of the Connected Health economy, there is an urgent need to develop mHealth (mobile health) exponentially, making it both an attractive and challenging market. In conclusion, there is a need for user-centered and multidisciplinary standards of practice to the design, development, evaluation, and implementation of Connected Health interventions in cancer care to ensure their acceptability, practicality, feasibility, effectiveness, affordability, safety, and equity.",2019,,JOURNAL OF MEDICAL INTERNET RESEARCH,21,10,,WOS:000493441300001,10.2196/14360,,#4393,Signorelli 2019,"",""
Can biased search results change people's opinions about anything at all? a close replication of the Search Engine Manipulation Effect (SEME),"Epstein, R; Li, J","In previous experiments we have conducted on the Search Engine Manipulation Effect (SEME), we have focused on the ability of biased search results to shift voting preferences. In three new experiments with a total of 1,137 US residents (mean age = 33.2), we sought to determine whether biased search rankings could shift people's opinions on topics that do not involve candidates or elections. Each of the new experiments looked at a different topic, and participants were pre-screened to make sure they didn't have strong opinions about these topics. The topics were: Is artificial intelligence useful or dangerous? Is fracking helpful or dangerous? And: Are people born gay or do they choose to be gay? All participants were first asked various demographic questions, then shown brief summaries of the ""pro"" and ""anti"" views on each topic, and then asked their opinions about each topic. Next, participants were allowed to conduct an online search using our mock search engine (Kadoodle) lasting up to 15 minutes. In each experiment, one-third of the participants saw biased search results favoring one perspective; one-third saw biased search results favoring the opposing perspective; and one-third (the control group) saw mixed search results. After completing their search, participants were again asked for their opinions about the topic. Our primary dependent variable was Manipulation Power (MP), the percentage increase in the number of participants favoring one viewpoint after having viewed search rankings favoring that viewpoint. The MPs in the three experiments were 25.0%, 30.9%, and 17.8%, respectively. Corresponding shifts were also found for how persuasive participants found each viewpoint to be and for how much they trusted each viewpoint. We conclude that search rankings favoring one viewpoint on a wide range of topics might be able to cause people who have not yet formulated a strong opinion on such topics to adopt the favored perspective. If our findings prove to be robust, we are exposing what might be considered an unforeseen consequence of the creation of search engines, namely that even without human interference, search algorithms will inevitably alter the thinking and behavior of billions of people worldwide on perhaps any topic for which they have not yet formed strong opinions.",2024,,PLOS ONE,19,3,,WOS:001191627500025,10.1371/journal.pone.0300727,,#4394,Epstein 2024,"",""
The University as an Augmentation of Aesthetic Experience: In Defense of the Printed Book,"Petrenko, VV","The article discusses the difficult question of whether the Book will lose its significance in the era of universal digitalization and artificial intelligence. The article considers the prospects for interpreting the Book as a special material entity responsible for establishing social ties within the university community, in the logic of object-oriented ontology. Being a visual - victorious - cultural and material form of Modernism, the Book has long been in the status of a truly authorial principle and embodied the very spirit of the Enlightenment and freedom of one's own inalienable statement. The Book has always been on the side of positive social forces. The question that remains open in the era of media, social networks and digital gadgets: will the Book be able to retain the place in the institutional breakdown of the social field, which it held quite firmly and for quite a long time? The article presents the central conceptually loaded concepts in a single discursive context, reflecting the choice of a common thematic horizon - ""University"", ""university community"", ""aesthetic experience"", ""library/ Book"". As a result, we come to the following conclusions: 1) Methodologically, the concept of the University (university community) can be conceptualized in the same way as social and cultural anthropology in general, no matter what it addresses. 2) Already in this formulation of the question, one of the constitutive concepts, largely fulfilling the function of the supporting structure, is designated - the concept of ""community"". The article shows that it is worth taking into account the material component of those partly ethnomethodological, partly habitual dispositions and the corresponding theoretical optics. It is in them that the ""university community"" expresses itself in the expected way as a collective identity. Removing the ""natural attitude"" and making the Book a mandatory condition for the existence of a horizontal network structure in the person of the university community, we gain additional access to the codification of the codes of the habitual order (P. Bourdieu). They are associated with the features of the organization, functioning, ""capitalization"" and the final institutionalization of this community. By exploring horizontal network structures of any level and degree of generality, we can return to them that focus of aesthetically presented authenticity and persuasiveness that is often lost in the abstract mode of thinking that is familiar to philosophy.",2024,,TOMSK STATE UNIVERSITY JOURNAL,,509,76-80,WOS:001443823400007,10.17223/15617793/509/7,,#4395,Petrenko 2024,"",""
Predicting Decisions in Language Based Persuasion Games,"Apel, R; Erev, I; Reichart, R; Tennenholtz, M","Sender-receiver interactions, and specifically persuasion games, are widely researched in economic modeling and artificial intelligence, and serve as a solid foundation for powerful applications. However, in the classic persuasion games setting, the messages sent from the expert to the decision-maker are abstract or well-structured application-specific signals rather than natural (human) language messages, although natural language is a very common communication signal in real-world persuasion setups. This paper addresses the use of natural language in persuasion games, exploring its impact on the decisions made by the players and aiming to construct effective models for the prediction of these decisions.For this purpose, we conduct an online repeated interaction experiment. At each trial of the interaction, an informed expert aims to sell an uninformed decision-maker a vacation in a hotel, by sending her a review that describes the hotel. While the expert is exposed to several scored reviews, the decision-maker observes only the single review sent by the expert, and her payoff in case she chooses to take the hotel is a random draw from the review score distribution available to the expert only. The expert's payoff, in turn, depends on the number of times the decision-maker chooses the hotel. We also compare the behavioral patterns in this experiment to the equivalent patterns in similar experiments where the communication is based on the numerical values of the reviews rather than the reviews' text, and observe substantial differences which can be explained through an equilibrium analysis of the game.We consider a number of modeling approaches for our verbal communication setup, differing from each other in the model type (deep neural network (DNN) vs. linear classifier), the type of features used by the model (textual, behavioral or both) and the source of the textual features (DNN-based vs. hand-crafted). Our results demonstrate that given a prefix of the interaction sequence, our models can predict the future decisions of the decision-maker, particularly when a sequential modeling approach and hand-crafted textual features are applied. Further analysis of the hand-crafted textual features allows us to make initial observations about the aspects of text that drive decision making in our setup.(1)",2022,,JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH,73,,1025-1091,WOS:000782640800001,,,#4396,Apel 2022,"",""
Communication through popular culture: Analyzing a googi performance on early marriage among the Kusaas of Ghana,"Abubakari, H; Amankwah, AS; Mensah, AO","This work investigates the use of a popular cultural performance called googi, to advocate against early marriage and its associated cases of adolescent pregnancies in Kusaal speaking communities in Ghana. It highlights how a local cultural artist employs the power of an indigenous language to skillfully address a significant socio-cultural issue. This research analyses the literary techniques employed by the artist in her didactic performance which challenges cultural norms that endorse early marriage. The artist advocates for social transformation through education underscoring the causes of early marriage as including socio-economic and cultural factor. The findings demonstrate that the persuasive use of indigenous language in popular cultural performances serves as great instruments for communication, advocacy and entertainment in rural communities. (c) 2024 Elsevier Ltd. All rights are reserved, including those for text and data mining, AI training, and similar technologies.",2024,,LANGUAGE & COMMUNICATION,99,,90-106,WOS:001331051500001,10.1016/j.langcom.2024.09.001,,#4397,Abubakari 2024,"",""
"Nontransitive temporal multiagent logic, information and knowledge, deciding algorithms","Rybakov, VV","Multiagent and temporal logics are active domains in Information Sciences, CS, and AI. Attention has predominantly focused on the logics based on transitive relational models, with particular emphasis on transitive time. But this does not seem rather reliable assumption. Nontransitivity of passing information may be demonstrated with relative ease through persuasive examples. Therefore, we introduce and study multiagent temporal logics that are based on nontransitive linear time. Another innovative step is consideration of incomplete information: the information/knowledge with lacunas,-the linear time with forgettable intervals of time in the past. Technically, the most important problems are problems of satisfiability and decidability of suggested logics. The main results are the algorithms that compute satisfiability and solve decidability (and so provide solutions to these problems). The paper concludes by posing a series of open problems.",2017,,SIBERIAN MATHEMATICAL JOURNAL,58,5,875-886,WOS:000413438200014,10.1134/S0037446617050147,,#4398,Rybakov 2017,"",""
The End of Sophocles' Philoctetes and the Significance of TNI/MH,"Xian, RB","In this article, I argue for Sophocles' dramatic use of & gamma;v & omega;& mu;& eta;-language at the end of his Philoctetes. Through a thorough analysis of the phrase & gamma;v & omega;& mu;& eta; ... & phi;i & lambda;wv at L 1467, I demonstrate how Sophocles drew on the contemporary resonances of & gamma;v & omega;& mu;& eta; in Athenian legal contexts to make the play's final scene rich and complex. In addition, the tension between the mortal and divine worlds, which is a recurrent theme in the play, is mirrored in the expression & gamma;v & omega;& mu;& eta; ... & phi;i & lambda;wv, which is sandwiched between Moipa and aav & delta;a & mu;& alpha;mp & delta;ai & mu;wv at ll. 1466-1468. Both points add to our understanding of how the sense of closure is achieved at the end of the play.",2023,,HERMES-ZEITSCHRIFT FUR KLASSISCHE PHILOLOGIE,151,1,23-39,WOS:001043370400002,10.25162/HERMES-2023-0002,,#4399,Xian 2023,"",""
Drivers and Persuasive Strategies to Influence User Intention to Learn About Manipulative Design,"Assoc Computing Machinery; Babaei, P; Vassileva, J","The proliferation of e-commerce, game, and social networking sites, has brought to light the use of ""dark patterns"" or, more generally, manipulative designs (MDs), which exploit psychological effects and cognitive biases of users to channel their behavior toward outcomes that benefit the company or owner of the site, against the users' best interests. Previous research has categorized MDs, assessed their impact on users, gauged their prevalence, and attempted automated detection using computer vision and natural language processing techniques. However, limited attention has been given to understanding how to warn and educate users about MDs, guiding them to recognize and resist such manipulative tactics. To address this gap, we carried out a controlled study with n=134 participants, using a survey based on the Protection Motivation Theory (PMT) to better understand the motivations of people to learn about MDs. We also explored the effectiveness of two persuasive strategies, based on Cialdini's principles of influence (social influence and authority), to trigger attention towards MDs and intention to learn more about MDs and to avoid them. For this, we created a simulated application in a mobile app distribution platform modeled like Google Play Store containing a visual signal, a warning based on one of the two strategies, and simulated reviews from other users. The results indicate that two of the five PMT constructs - a higher Perceived Severity of MDs and a lower Perceived Response Cost of learning about MDs - have the most significant influence on the Intention to learn more about MDs. The participants in the experimental group, exposed to the two persuasive strategies exhibited a larger increase in their intention to seek information about MDs than the participants in the control group. Our study showcases the potential of a persuasive intervention, illustrating how mobile app distribution platforms can enhance user protection against MD exploitation. By implementing such interventions, these platforms can boost accountability and transparency of applications existing on their platform, and MD awareness among their users.",2024,,"PROCEEDINGS OF THE 2024 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, ACM FACCT 2024",,,2421-2431,WOS:001253359300160,10.1145/3630106.3659046,,#4400,AssocComputingMachinery 2024,"",""
The impact of graphic design on attention capture and behavior among outdoor recreationists: Results from an exploratory persuasive signage experiment,"Rice, WL; Shellhorn, J; Bloomgren, V; Booth, L; Duncan, S; Elias, J; Flowers, K; Gambini, I; Gans, A; Medina, A; Obadare, D; O'Neill, C; Rooney, Q; Scherck, G; Schmidt, K; Thomas, C; Thomas, E; Walhus, G; Whitney, P; Winckler, C","A considerable amount of research has been conducted on the efficacy of social and psychological theory-driven persuasive messaging in effecting visitor behavior in park and protected area settings. However, few studies have investigated the influence of other signage design elements, including graphic character, on the persuasiveness of park messaging. This exploratory research sought to answer the following research questions: 1) Does graphic design influence visitor attention capture in park and protected area signage? 2) Does graphic design influence visitor behavior through park and protected area signage? This study employed an experimental design of 6 signage-treatments incorporating diverse graphic design elements to address two separate management issues-dogs-off-leash and the spread of invasive plant species-at a popular trailhead in Missoula, MT. Results show that both administrative and graphic design signage treatments promoting shoe-cleaning to stop the spread of invasive species proved effective in capturing attention of visitors, suggesting that managers should incor-porate both attractive and authoritative elements in park messaging. In regards to influencing visitor behavior, two design treatments incorporating high color-contrast, large ""scale"" shift and ""typography as image"" elements proved the most effective for both management issues. These findings indicate that graphic design encapsulating persuasive language is very important to capture visitor attention and influence behavior, and design elements should be considered seriously by park managers when employing various communication strategies. Management implications:center dot The mixed results of treatment performance (between administrative and graphic design treat-ments) in regards to visitor attention capture indicate that signage designers should seek to balance attractive and eye-catching graphic qualities with graphic qualities that communicate authority.center dot Results suggest that if managers are able to minimally capture visitors' attention, they will dramatically increase their odds of influencing visitors' behavior. If visitors take the time to read and elaborate upon the messaging on the signs, the odds of influencing behavior are even more dramatic.center dot Managers should incorporate graphic design elements such as a ""typography as image.""",2023,,JOURNAL OF OUTDOOR RECREATION AND TOURISM-RESEARCH PLANNING AND MANAGEMENT,42,,,WOS:000992330000001,10.1016/j.jort.2023.100606,,#4401,Rice 2023,"",""
Leveraging human-centered design and causal pathway diagramming toward enhanced specification and development of innovative implementation strategies: a case example of an outreach tool to address racial inequities in breast cancer screening,"Marcotte, LM; Langevin, R; Hempstead, BH; Ganguly, A; Lyon, AR; Weiner, BJ; Akinsoto, N; Houston, PL; Fang, V; Hsieh, G","Background Implementation strategies are strategies to improve uptake of evidence-based practices or interventions and are essential to implementation science. Developing or tailoring implementation strategies may benefit from integrating approaches from other disciplines; yet current guidance on how to effectively incorporate methods from other disciplines to develop and refine innovative implementation strategies is limited. We describe an approach that combines community-engaged methods, human-centered design (HCD) methods, and causal pathway diagramming (CPD)-an implementation science tool to map an implementation strategy as it is intended to work-to develop innovative implementation strategies.Methods We use a case example of developing a conversational agent or chatbot to address racial inequities in breast cancer screening via mammography. With an interdisciplinary team including community members and operational leaders, we conducted a rapid evidence review and elicited qualitative data through interviews and focus groups using HCD methods to identify and prioritize key determinants (facilitators and barriers) of the evidence-based intervention (breast cancer screening) and the implementation strategy (chatbot). We developed a CPD using key determinants and proposed strategy mechanisms and proximal outcomes based in conceptual frameworks.Results We identified key determinants for breast cancer screening and for the chatbot implementation strategy. Mistrust was a key barrier to both completing breast cancer screening and using the chatbot. We focused design for the initial chatbot interaction to engender trust and developed a CPD to guide chatbot development. We used the persuasive health message framework and conceptual frameworks about trust from marketing and artificial intelligence disciplines. We developed a CPD for the initial interaction with the chatbot with engagement as a mechanism to use and trust as a proximal outcome leading to further engagement with the chatbot.Conclusions The use of interdisciplinary methods is core to implementation science. HCD is a particularly synergistic discipline with multiple existing applications of HCD to implementation research. We present an extension of this work and an example of the potential value in an integrated community-engaged approach of HCD and implementation science researchers and methods to combine strengths of both disciplines and develop human-centered implementation strategies rooted in causal perspective and healthcare equity.",2024,,IMPLEMENTATION SCIENCE COMMUNICATIONS,5,1,,WOS:001457565900027,10.1186/s43058-024-00569-w,,#4402,Marcotte 2024,"",""
The persuasive effects of warning messages,"Lai, FF; Xie, CW; Zhang, JC; Huang, R","Empirical investigations regarding tourists' safety-related responses to warning messages in natural recreational leisure settings are scarce. Through three online experiments with recreational scenarios, several findings emerged. First, strong (vs. weak) warning messages led to greater safety behavior (compliance and participation). Second, warning messages sequentially mediated safety behavior (compliance and participation) through threat appraisal and problem-focused coping. Warning messages also affected safety compliance, but not safety participation, via the sequential mediation of threat appraisal and emotion-focused coping. Third, other tourists' safety (vs. risky) behavior positively reinforced warning messages' roles in problem-focused coping and safety behavior; no significant moderating effect manifested between warning messages and emotion-focused coping. Understanding safety messages' persuasive effects can help destination management organizations control tourists' behavior. (c) 2024 Elsevier Ltd. All rights are reserved, including those for text and data mining, AI training, and similar technologies.",2024,,ANNALS OF TOURISM RESEARCH,109,,,WOS:001318028400001,10.1016/j.annals.2024.103829,,#4403,Lai 2024,"",""
Designing an Automatic Agent for Repeated Language-based Persuasion Games,"Raifer, M; Rotman, G; Apel, R; Tennenholtz, M; Reichart, R","Persuasion games are fundamental in economics and AI research and serve as the basis for important applications. However, work on this setup assumes communication with stylized messages that do not consist of rich human language. In this paper we consider a repeated sender (expert) - receiver (decision maker) game, where the sender is fully informed about the state of the world and aims to persuade the receiver to accept a deal by sending one of several possible natural language reviews. We design an automatic expert that plays this repeated game, aiming to achieve the maximal payoff. Our expert is implemented within the Monte Carlo Tree Search (MCTS) algorithm, with deep learning models that exploit behavioral and linguistic signals in order to predict the next action of the decision maker, and the future payoff of the expert given the state of the game and a candidate review. We demonstrate the superiority of our expert over strong baselines and its adaptability to different decision makers and potential proposed deals.(1)",2022,,TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,10,,307-324,WOS:000923421100003,10.1162/tacl_a_00462,,#4404,Raifer 2022,"",""
CaSiNo: A Corpus of Campsite Negotiation Dialogues for Automatic Negotiation Systems,"Assoc Computat Linguist; Chawla, K; Ramirez, J; Clever, R; Lucas, G; May, J; Gratch, J","Automated systems that negotiate with humans have broad applications in pedagogy and conversational AI. To advance the development of practical negotiation systems, we present CaSiNo: a novel corpus of over a thousand negotiation dialogues in English. Participants take the role of campsite neighbors and negotiate for food, water, and firewood packages for their upcoming trip. Our design results in diverse and linguistically rich negotiations while maintaining a tractable, closed domain environment. Inspired by the literature in human-human negotiations, we annotate persuasion strategies and perform correlation analysis to understand how the dialogue behaviors are associated with the negotiation performance. We further propose and evaluate a multi-task framework to recognize these strategies in a given utterance.We find that multi-task learning substantially improves the performance for all strategy labels,especially for the ones that are the most skewed. We release the dataset, annotations,and the code to propel future work in human-machine negotiations: https://github.com/kushalchawla/CaSiNo.",2021,,2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021),,,3167-3185,WOS:000895685603026,,,#4405,AssocComputatLinguist 2021,"",""
Mitigating Issues With/of/for True Personalization,"Oinas-Kukkonen, H; Pohjolainen, S; Agyei, E","A common but false perception persists about the level and type of personalization in the offerings of contemporary software, information systems, and services, known as Personalization Myopia: this involves a tendency for researchers to think that there are many more personalized services than there genuinely are, for the general audience to think that they are offered personalized services when they really are not, and for practitioners to have a mistaken idea of what makes a service personalized. And yet in an era, which mashes up large amounts of data, business analytics, deep learning, and persuasive systems, true personalization is a most promising approach for innovating and developing new types of systems and services-including support for behavior change. The potential of true personalization is elaborated in this article, especially with regards to persuasive software features and the oft-neglected fact that users change over time.",2022,,FRONTIERS IN ARTIFICIAL INTELLIGENCE,5,,,WOS:000915549400001,10.3389/frai.2022.844817,,#4406,Oinas-Kukkonen 2022,"",""
POLITENESS AND CERTAINTY - THE LANGUAGE OF COLLABORATION IN AN AI PROJECT,"MYERS, G","Collaboration in scientific groups can be investigated through analysis of linguistic features associated with politeness strategies.  Disagreements, especially, can carry possible threats to colleagues' face.  The strategies for redressing these threats can be seen in choices of pronouns or impersonal constructions, and uses of 'hedges' - modifications of the force of an assertion.  These features indicating politeness overlap with the features used to indicate degrees of doubt or certainty.  Thus neither the participants in the collaboration, nor the science studies analyst, can disentangle participants' personal interactions from reasoning, persuasion and decision-making.  For instance, the hedging of a criticism out of politeness will be hard to tell from the expression of uncertainty about the evidence or reasoning supporting a suggestion.  An exchange of memos in one natural language processing group, concerning a decision over the inclusion of one factor in an algorithm, shows the possible functions of politeness strategies in the course of the group's decision-making.",1991,,SOCIAL STUDIES OF SCIENCE,21,1,37-73,WOS:A1991FU72400003,10.1177/030631291021001004,,#4407,MYERS 1991,"",""
Trust in maps: what we know and what we need to know,"Prestby, TJ","Maps have served as authoritative and trustworthy sources of geospatial information for years. However, maps are increasingly being wielded to spread misinformation due to the democratization of mapmaking, advances in AI, and the emergence of post-truth politics. Trust plays a fundamental role in the spread of misinformation, but our understanding of trust in the context of maps is limited. In this paper, I examine the methodologies employed by empirical studies on trust in maps and synthesize the major findings of said studies. Most of the reviewed studies were experiments that utilized single-item self-reporting Likert-type measures to capture trust. I organized the findings of the studies into six major themes including source, metadata, transparency, uncertainty, design, and information modality. Additionally, I present a research agenda based on the findings and limitations of existing works. This agenda highlights methodological challenges to studying trust in maps and proposes opportunities in the form of research questions.",2025,,CARTOGRAPHY AND GEOGRAPHIC INFORMATION SCIENCE,52,1,1-18,WOS:001111602700001,10.1080/15230406.2023.2281306,,#4408,Prestby 2025,"",""
"Do Tourists Prefer Dialectal Service? The Role of Processing Fluency, Distinctiveness, and Cultural Learning Cues","Xiong, XL; Sun, DN; Wong, IA; Lian, QL","Serving tourists in dialect can be a double-edged sword, as the literature acknowledges it may hamper language processing fluency while offering a sense of distinctiveness for tourists. Building on Two-Factor Theory of Emotion, this research contributes to the literature by articulating a paradoxical process in which dialectal service can be internalized as both an enabling and an inhibiting factor in understanding a local culture. It further proposes a facilitating mechanism through cultural learning cues. We conducted three empirical experiments (Studies 1-3), followed by an external validation process through generative AI (Study 4), and finally employed methodological triangulation through semistructured interviews (Study 5). Through the explanatory lens of sequential mixed methods, the current inquiry further illuminates why and how dialects can add flavor to one's travel by spicing up the cultural appeals of a place in such a way that can replace a bitter pill with an enjoyable reminiscence.",2025,,JOURNAL OF TRAVEL RESEARCH,,,,WOS:001475255000001,10.1177/00472875251332953,,#4409,Xiong 2025,"",""
Understanding the Digital Epistemologies of Chat GPT: Towards a Decolonial Language Pedagogy,"ASSOC COMPUTING MACHINERY; Asmawi, A; Alam, MS","Since its emergence, research around Chat GPT and language teaching has trended into an asymmetry of opportunities and challenges from both utopian and dystopian perspectives. Chat GPT has Western data-based inherent coloniality and thus carries invisible colonial perpetuation when used in language education. However, Chat GPT has context-awareness and personalization capacity and is open to user control. Therefore, rather than decolonizing Chat GPT itself, decolonizing by Chat GPT can be a flipped approach to materialize decolonial persuasion in language pedagogy. Grounded in Santos's epistemology of the south, this paper attempts to conceptualize Chat GPT-assisted decolonial pedagogy. Using the authors' constructivist ideation, the study employed simulated text data generated through a series of Chat GPT-author conversations. The collected data were analyzed by applying the educational data mining (EDM) method to support the primary conceptualization of the proposed decolonial pedagogy. The findings serve as a breakthrough with a novelty discovered in Chat GPT-facilitated decolonization of language pedagogy empowering decolonially charged educators working in the global south.",2024,,"8TH INTERNATIONAL CONFERENCE ON DIGITAL TECHNOLOGY IN EDUCATION, ICDTE 2024",,,277-283,WOS:001435609900036,10.1145/3696230.3696248,,#4410,ASSOCCOMPUTINGMACHINERY 2024,"",""
Watch Those Words: Video Falsification Detection Using Word-Conditioned Facial Motion,"IEEE; Agarwal, S; Hu, LW; Ng, E; Darrell, T; Li, H; Rohrbach, A","In today's era of digital misinformation, we are increasingly faced with new threats posed by video falsification techniques. Such falsifications range from cheapfakes (e.g., lookalikes or audio dubbing) to deepfakes (e.g., sophisticated AI media synthesis methods), which are becoming perceptually indistinguishable from real videos. To tackle this challenge, we propose a multi-modal semantic forensic approach to discover clues that go beyond detecting discrepancies in visual quality, thereby handling both simpler cheapfakes and visually persuasive deepfakes. In this work, our goal is to verify that the purported person seen in the video is indeed themselves by detecting anomalous facial movements corresponding to the spoken words. We leverage the idea of attribution to learn person-specific biometric patterns that distinguish a given speaker from others. We use interpretable Action Units (AUs) to capture a person's face and head movement as opposed to deep CNN features, and we are the first to use word-conditioned facial motion analysis. We further demonstrate our method's effectiveness on a range of fakes not seen in training including those without video manipulation, that were not addressed in prior work.",2023,,2023 IEEE/CVF WINTER CONFERENCE ON APPLICATIONS OF COMPUTER VISION (WACV),,,4699-4708,WOS:000971500204080,10.1109/WACV56688.2023.00469,,#4411,IEEE 2023,"",""
Machine Learning Methods to Personalize Persuasive Strategiesin mHealth Interventions That Promote Physical Activity:ScopingReview and Categorization Overview,"Brons, A; Wang, SH; Visser, B; Kröse, B; Bakkes, S; Veltkamp, R","Background: Although physical activity (PA) has positive effects on health and well-being, physical inactivity is a worldwideproblem. Mobile health interventions have been shown to be effective in promoting PA. Personalizing persuasive strategiesimproves intervention success and can be conducted using machine learning (ML). For PA, several studies have addressedpersonalized persuasive strategies without ML, whereas others have included personalization using ML without focusing onpersuasive strategies. An overview of studies discussing ML to personalize persuasive strategies in PA-promoting interventionsand corresponding categorizations could be helpful for such interventions to be designed in the future but is still missing. Objective: First, we aimed to provide an overview of implemented ML techniques to personalize persuasive strategies in mobilehealth interventions promoting PA. Moreover, we aimed to present a categorization overview as a starting point for applying MLtechniques in this field. Methods: A scoping review was conducted based on the framework by Arksey and O'Malley and the PRISMA-ScR (PreferredReporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) criteria. Scopus, Web of Science,and PubMed were searched for studies that included ML to personalize persuasive strategies in interventions promoting PA.Papers were screened using the ASReview software. From the included papers, categorized by the research project they belongedto, we extracted data regarding general study information, target group, PA intervention, implemented technology, and studydetails. On the basis of the analysis of these data, a categorization overview was given.Results: In total, 40 papers belonging to 27 different projects were included. These papers could be categorized in 4 groupsbased on their dimension of personalization. Then, for each dimension, 1 or 2 persuasive strategy categories were found togetherwith a type of ML. The overview resulted in a categorization consisting of 3 levels: dimension of personalization, persuasivestrategy, and type of ML. When personalizing the timing of the messages, most projects implemented reinforcement learning topersonalize the timing of reminders and supervised learning (SL) to personalize the timing of feedback, monitoring, and goal-settingmessages. Regarding the content of the messages, most projects implemented SL to personalize PA suggestions and feedback oreducational messages. For personalizing PA suggestions, SL can be implemented either alone or combined with a recommendersystem. Finally, reinforcement learning was mostly used to personalize the type of feedback messages. Conclusions: The overview of all implemented persuasive strategies and their corresponding ML methods is insightful for thisinterdisciplinary field. Moreover, it led to a categorization overview that provides insights into the design and development of personalized persuasive strategies to promote PA. In future papers, the categorization overview might be expanded with additionallayers to specify ML methods or additional dimensions of personalization and persuasive strategies.",2024,,JOURNAL OF MEDICAL INTERNET RESEARCH,26,,,WOS:001368144300003,10.2196/47774,,#4412,Brons 2024,"",""
"The Complex Interaction Between Sleep-Related Information, Misinformation, and Sleep Health: Call for Comprehensive Research on Sleep Infodemiology and Infoveillance","Bragazzi, NL; Garbarino, S","The complex interplay between sleep-related information-both accurate and misleading-and its impact on clinical public health is an emerging area of concern. Lack of awareness of the importance of sleep, and inadequate information related to sleep, combined with misinformation about sleep, disseminated through social media, nonexpert advice, commercial interests, and other sources, can distort individuals' understanding of healthy sleep practices. Such misinformation can lead to the adoption of unhealthy sleep behaviors, reducing sleep quality and exacerbating sleep disorders. Simultaneously, poor sleep itself impairs critical cognitive functions, such as memory consolidation, emotional regulation, and decision-making. These impairments can heighten individuals' vulnerability to misinformation, creating a vicious cycle that further entrenches poor sleep habits and unhealthy behaviors. Sleep deprivation is known to reduce the ability to critically evaluate information, increase suggestibility, and enhance emotional reactivity, making individuals more prone to accepting persuasive but inaccurate information. This cycle of misinformation and poor sleep creates a clinical public health issue that goes beyond individual well-being, influencing occupational performance, societal productivity, and even broader clinical public health decision-making. The effects are felt across various sectors, from health care systems burdened by sleep-related issues to workplaces impacted by decreased productivity due to sleep deficiencies. The need for comprehensive clinical public health initiatives to combat this cycle is critical. These efforts must promote sleep literacy, increase awareness of sleep's role in cognitive resilience, and correct widespread sleep myths. Digital tools and technologies, such as sleep-tracking devices and artificial intelligence-powered apps, can play a role in educating the public and enhancing the accessibility of accurate, evidence-based sleep information. However, these tools must be carefully designed to avoid the spread of misinformation through algorithmic biases. Furthermore, research into the cognitive impacts of sleep deprivation should be leveraged to develop strategies that enhance societal resilience against misinformation. Sleep infodemiology and infoveillance, which involve tracking and analyzing the distribution of sleep-related information across digital platforms, offer valuable methodologies for identifying and addressing the spread of misinformation in real time. Addressing this issue requires a multidisciplinary approach, involving collaboration between sleep scientists, health care providers, educators, policy makers, and digital platform regulators. By promoting healthy sleep practices and debunking myths, it is possible to disrupt the feedback loop between poor sleep and misinformation, leading to improved individual health, better decision-making, and",2024,,JMIR INFODEMIOLOGY,4,,,WOS:001378874400001,10.2196/57748,,#4413,Bragazzi 2024,"",""
The dis-matching effect: How argumentation type and message design influence persuasion for emerging technology products,"Karpinska-Krakowiak, M; Trzebinski, W; Lim, H; Marciniak, B","Emerging technology products, like AI-driven goods or electric vehicles, have the potential to disrupt markets. However, little is still known about how to advance their adoption through advertising. Therefore, we conducted three experiments to explore the persuasive effects of argumentation used in an ad (argumentation type: abstract/concrete) and the design of an ad (message design: narrative/non-narrative) for emerging technology products. Previous studies have proposed a matching principle in advertising, suggesting that abstract argumentation is more persuasive when consumers feel psychologically distant from the message subject, while concrete argumentation is more persuasive when they feel psychologically close to it. However, our research reveals that the matching principle applies to established technology products (Study 1), while the dis-matching principle (aligning abstract argumentation with low psychological distance and concrete argumentation with high psychological distance) is more effective for emerging technology products, particularly when ads are designed in a narrative format (Studies 2-3).",2023,,JOURNAL OF BUSINESS RESEARCH,168,,,WOS:001058915300001,10.1016/j.jbusres.2023.114207,,#4414,Karpinska-Krakowiak 2023,"",""
Mobile Sensing and Engagement Features in Arabic Mental Well-Being Apps: Systematic Search and Analysis,"ACM; Aldaweesh, S; Van Kleek, M; Shadbolt, N","Various mobile apps have been released to track and promote mental health and well-being. Despite the high interest in developing these apps, they suffer from high attrition rates. These apps have limited utility if they are delivered in a manner that does not maintain individuals' engagement. Engagement features are therefore a critical factor to consider for fostering intended benefits. While there is considerable research on analysing the engagement features of these apps available in English, our understanding of engagement features in such Arabic apps is limited. Moreover, much less is known about mobile sensing in Arabic apps. To address this gap, we systematically searched app stores, identified 110 apps available in Arabic, and analyzed their features based on existing mHealth assessment frameworks. Our analysis found that available Arabic apps poorly implemented engagement features, apart from basic features such as sharing and reminders. Surprisingly, Arabic apps missed mobile sensing capabilities and AI applications. This paper highlights the importance of employing mobile sensing and persuasive design principles in the future design of Arabic apps.",2023,,"ADJUNCT PROCEEDINGS OF THE 2023 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING & THE 2023 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTING, UBICOMP/ISWC 2023 ADJUNCT",,,626-631,WOS:001197004600130,10.1145/3594739.3612875,,#4415,ACM 2023,"",""
"Can ChatGPT be a debate partner? Developing ChatGPT-based application ""DEBO"" for debate education, findings and limitations","Lee, U; Jeong, Y; Koh, J; Byun, G; Lee, Y; Hwang, Y; Kim, H; Lim, C","Debate is a universally acknowledged competency for its vital role in fostering essential skills such as analytical reasoning, eloquent communication, and persuasive argument construction. This is relevant in both formal educational settings like classrooms and informal venues such as after-school clubs. Traditional debate training methods often face challenges in facilitating personalized learning, primarily due to the difficulty of securing a debate partner. However, the emerging field of generative AI offers a promising alternative. This study evaluates the effectiveness of DEBO, a debate education application that utilizes ChatGPT, an advanced language model by OpenAI. Focusing on university students actively involved in a debate club, six volunteers tested DEBO and participated in interviews to provide insights. The findings reveal that DEBO notably enhances divergent thinking and features a comprehensive analytics dashboard for in-depth performance analysis. However, there are few limitations including occasional shortcomings in debate quality, minor inaccuracies, and the need for faster response times. The study underscores the transformative potential of advanced language models like ChatGPT in reshaping debate education, while also identifying areas for further improvement.",2024,,EDUCATIONAL TECHNOLOGY & SOCIETY,27,2,321-346,WOS:001497043900003,10.30191/ETS.202404_27(2).TP03,,#4416,Lee 2024,"",""
Rethinking Virtual Link Mapping in Network Virtualization,"IEEE; Nguyen, KTD; Lu, Q; Huang, CC","Virtual Network Embedding (VNE) that addresses the embedding problems of heterogeneous virtual networks onto a physical limited-capacity infrastructure efficiently is a major challenge in network virtualization (NV). VNE is computationally intractable when considering various constraints on nodes and links, and is also known as NP-hard even in offline embedding. Although the VNE problems have received attentions over recent decades with a vast number of VNE solutions, the majority of them only focus on VNE node mapping, whilst leaving the link mapping stage for the shortest path method or multicommodity flow (MCF) algorithm. We persuasively argue that node and link mappings equally play pivotal roles to approach an efficient VNE solution. In this paper, we reassess the role of link mapping stage in VNE problem, and then propose a novel intelligent VNE orchestration which effectively implements a distributed parallel model to reduce the operation time remarkably. Extensive evaluation results show that our proposed algorithm is not only faster than state-of-the-art VNE algorithms in speed, but also better in all performance metrics.",2020,,2020 IEEE 92ND VEHICULAR TECHNOLOGY CONFERENCE (VTC2020-FALL),,,,WOS:000662218600340,10.1109/VTC2020-Fall49728.2020.9348799,,#4417,IEEE 2020,"",""
An Adaptive Learning with Gamification & Conversational UIs: The Rise of CiboPoliBot,"ACM; Fadhil, A; Villafiorita, A","Gamification in the era of chatbots is a novel way to engage users with the chatbot application. When developing a gamified chatbot system, there are factors related to user types (ages, gender and others) that we should consider to effectively integrate the game elements into the chatbot while targeting the right audience. In this study, we discuss the development of an educational chatbot game 'CiboPoli', that's specialised in teaching children about healthy lifestyle through an interactive social game environment. The presented game is based on a paper prototype that we developed to teach primary school students about healthy diet and food waste management. The current approach will be more engaging and pose AI capabilities. This is still a work in progress and we plan to improve its design by incorporating additional components, such as dialog management module, user-specific knowledge module or machine learning module. Future work will be devoted to integrating machine learning to automatically identify learners emotions and provide personalised suggestions. Moreover, we tested the initial prototype with school students and found that it outperforms the paper version. Future work will focus on applying it to other domains and demographics.",2017,,"ADJUNCT PUBLICATION OF THE 25TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'17)",,,408-412,WOS:000850443800077,10.1145/3099023.3099112,,#4418,ACM 2017,"",""
"What Gets Echoed? Understanding the ""Pointers"" in Explanations of Persuasive Arguments","Assoc Computat Linguist; Atkinson, D; Srinivasan, KB; Tan, CH","Explanations are central to everyday life, and are a topic of growing interest in the AI community. To investigate the process of providing natural language explanations, we leverage the dynamics of the /r/ChangeMyView subreddit to build a dataset with 36K naturally occurring explanations of why an argument is persuasive. We propose a novel word-level prediction task to investigate how explanations selectively reuse, or echo, information from what is being explained (henceforth, explanandum). We develop features to capture the properties of a word in the explanandum, and show that our proposed features not only have relatively strong predictive power on the echoing of a word in an explanation, but also enhance neural methods of generating explanations. In particular, while the non-contextual properties of a word itself are more valuable for stopwords, the interaction between the constituent parts of an explanandum is crucial in predicting the echoing of content words. We also find intriguing patterns of a word being echoed. For example, although nouns are generally less likely to be echoed, subjects and objects can, depending on their source, be more likely to be echoed in the explanations.",2019,,2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019): PROCEEDINGS OF THE CONFERENCE,,,2911-2921,WOS:000854193303007,,,#4419,AssocComputatLinguist 2019,"",""
Does ChatGPT Argue Like Students? Bundles in Argumentative Essays,"Jiang, F; Hyland, K","The advent of ChatGPT, a novel AI-powered language model able to create grammatically accurate and coherent texts, has generated considerable concern among educationalists anxious about its potential to enable cheating among students and to undermine the development of critical thinking, problem-solving, and literacy skills. The similarities and differences between ChatGPT texts and human writing, however, remain underexplored. This study aims to bridge this gap by comparing the use of 3-word bundles in A-level argumentative essays written by British students with those generated by ChatGPT. Our findings show that ChatGPT essays contain a lower frequency of bundles but these have a higher type/token ratio, suggesting that its bundles are more rigid and formulaic. We also found noun and preposition-based bundles are more prevalent in ChatGPT texts, employed for abstract descriptions and to provide transitional and structuring cues. Student essays are characterized by more epistemic stances and authorial presence, crucial in persuasive argumentation. We attribute these distinct patterns in ChatGPT's output to its processing of vast training data and underlying statistical algorithms. The study points to pedagogical implications for incorporating ChatGPT in writing instruction.",2024,,APPLIED LINGUISTICS,,,,WOS:001293811500001,10.1093/applin/amae052,,#4420,Jiang 2024,"",""
"Subjective variability of the ""just-right feeling"": Effectiveness of social media advertising design","Wang, Y; Wu, SL; Zhao, JJ; Yuan, YN","With the rapid advancement of AI and algorithmic technologies, social media platforms have gained the ability to identify consumer personality traits. However, developing compelling advertising strategies for individuals with different self-construals remains challenging. Based on construal level theory, this research investigates the interactions between shot scale, advertising appeals, and self-construal on social media. The results of the four empirical studies indicated that independent individuals prefer advertisements with long-shot images and desirability appeals. In contrast, interdependent individuals favor advertisements with close-up images and feasibility appeals. Furthermore, the findings reveal that long-shot images match with desirability appeals or close-up images paired with feasibility appeals significantly increase the click-through rate and foster more positive advertising attitudes. The above findings are central to the feeling right during information processing, which plays a crucial role in advertising acceptance. Therefore, this research constructs a new framework for personalized advertisement design in social media and offers a practical guide for businesses seeking to optimize their advertising strategies.",2024,,ELECTRONIC COMMERCE RESEARCH AND APPLICATIONS,68,,,WOS:001358521500001,10.1016/j.elerap.2024.101466,,#4421,Wang 2024,"",""
Oceanopolítica: Therezinha de Castro and the use of maps in the geopolitics of the sea,"Novaes, AR; Lamego, M","This paper explores the use of cartography in circulating geopolitical ideas about the seas. It focuses on the texts and maps produced by Therezinha de Castro (1930-200 0), a Brazilian geopolitical thinker who influenced practical and popular geopolitical reasoning about Antarctica and the South Atlantic from the 1950s until her death in 2000. Through her papers, books, atlas and lectures, Castro addressed the oceans not as restrictive boundaries delimiting spaces of sovereignty but as a borderland, a transition zone and a territory of expansion. The paper first explores Castro's academic trajectory and collaborations, supported by historical-geographical perspectives that emphasise the role of contingencies, positionalities, and biographies in knowledge production. Then, it analyses the persuasive visuality of Castro's arguments on seas, drawing on methodological perspectives that articulate maps, meanings and geopolitics. Finally, the paper discusses how Castro's claims on ocean geopolitics could contribute to contemporary human geography debates about land/sea assemblages. (c) 2024 Elsevier Ltd. All rights are reserved, including those for text and data mining, AI training, and similar technologies.",2025,,JOURNAL OF HISTORICAL GEOGRAPHY,87,,22-34,WOS:001426416100001,10.1016/j.jhg.2024.12.002,,#4422,Novaes 2025,"",""
Problems that Can Occur when Assaying Extracts to Pure Compounds in Biological Systems,"Newman, DJ","A B S T R A C T For a significant number of years, scientists of many persuasions have assayed natural product materials ranging from crude extracts to pure compounds, in a multitude of assays causally related to some biological processes. However, in a very significant number of submitted papers and published articles, what may be considered as canned biological assays were used, and if a positive effect was observed, then the authors would claim that the material assayed was a potential drug lead. This also occurred with pure synthetic compounds and compounds derived from natural products by simple chemical modifications. However, what has now become quite obvious-with all such classes of materials-is that there are many promiscuous players with multiple bioactivities. These can range from relatively crude extracts, pure compounds from natural products, synthetic processes that produce natural product derivatives, and even compounds that are truly synthetic in origin. There is also a potential problem with the data from crude to purified extracts being used to claim some form of beneficial activities for such materials, to sell that particular mixture to the lay public, by very careful descriptions of its possible uses due to legal hurdles. With the advent of artificial intelligence and very large compound databases, some of which may well contain impure materials, scientists from a variety of backgrounds have begun to utilize such listings to obtain compounds for their low to high throughput biological screens, without realizing that there are very significant numbers of active compounds (eg, pan assay interference compounds and invalid metabolic panaceas), that will hit in many different screens for a variety of reasons, thus leading to significant wasted effort s and published scientific articles that have incorrect results. This commentary gives some of the history of such materials but is designed to be used as a warning to both researchers and in particular, journal editors, and reviewers, that reports of biological results that are claimed to be the result of the compounds used, need to be very carefully screened for results due to such promiscuous compounds, irrespective of their nominal source(s). All literature searches were made by the author and the background knowledge has come from more than 55 years of research in industry and governmental laboratories in both the United Kingdom and the United States, for enzyme inhibitors/activators as well as antimicrobial and antitumor lead compounds mainly from natural product sources. The conclusion that I came up with as a result is this: Caveat emptor. (Curr Ther Res Clin Exp. 2021; 82:XXX-XXX) 0 2021 Elsevier HS Journals, Inc. 0 2021 The Author(s). Published by Elsevier Inc. This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ )",2021,,CURRENT THERAPEUTIC RESEARCH-CLINICAL AND EXPERIMENTAL,95,,,WOS:000707936500001,10.1016/j.curtheres.2021.100645,,#4423,Newman 2021,"",""
Witnessing: iteration and social change,"McPherson, E","At first thought, iteration seems banal. It is about repeating the existing; nothing is changing. But this special issue shows that, in an era obsessed with the new, it is often the repetition of the old that creates social change. Iteration fosters persuasion. It affords opportunities for critical and creative engagement with meaning, values and knowledge. It invites collaboration, though its apparent simplicity often belies a tremendous amount of individual and collective labour involved in the practices of iteration. Through its repetition of the existing, however, iteration also can be a mechanism for reproducing the status quo. Its pervasiveness and banality naturalises power, and its mimetic qualities shrink spaces for critical distance and care. The editors of this special issue have brought together a delightful and fascinating diversity of articles focussed on iteration in cultural production in the digital age. We hop across geographies to examine lockdown diaries, artists' books, socialist memes, fake news, the design of social media platforms and artificial intelligence, activism, film, social media forum moderation, news website reader comments and more. Iterating through the collection as a whole, across its many disciplines, is a commitment to theorising through empirical evidence, to explaining with critique, and to providing pathways to praxis. These characteristics of this special issue, and the many concepts and arguments it puts forward, make this collection of work exceptionally rich material for seeing iteration and how it shapes the world we live in today, as well as the world we want it to be. In this preface, I take a media sociology approach to show how iteration can be usefully understood as collaborative communication for change. I see this understanding of iteration, whose ascendancy is related to the ascendancy of computer science, as baked into the form of communication technologies-and thus as shaping the kinds of iteration that are possible when we use these technologies. This understanding also prompts us to focus on the connection between iteration and social change. To explore how this works, I analytically slow down the practice of iteration to show that it is a communication practice of transmission. That transmission practice is itself constituted of cognate communication practices-the reception, evaluation and production of knowledge-in which visibility and persuasion are key. In the latter parts of the preface, I illustrate this through the example of witnessing as iteration, as the high-stakes nature of witnessing make it a canary in the coalmine, more generally, for mediated communication in the digital age. I show how breaking the witnessing practice down into its various parts allows us to see how power enters and inflects who and what are iterated, when-and who and what are not. Thinking critically with iteration and against unequal power relations, the praxis this preface suggests is one-much in line with the rest of this special issue-of explaining how iteration might move the grassroots towards their goals.",2023,,AI & SOCIETY,38,5,1987-1995,WOS:000850417800001,10.1007/s00146-022-01508-w,,#4424,McPherson 2023,"",""
Can we serve both God and Money? The role of indirect appeal and its limitation,"Park, S; Kang, JS; Markman, GD","PurposeHarmonizing religion and economic pursuits is treacherous because mixing the two rarely resonate with consumers, often resulting consumers' greed perceptions. This paper aims to explore the antecedents and consequence of consumers' greed perceptions in the context of for-profit religious-affiliated companies (FPRCs) and how they can harmonize religious and commercial missions by using different ad types (direct vs indirect appeal). Design/methodology/approachThe authors conducted two experiments: Study 1 was an online experiment with participants from the USA collected through Amazon's Mechanical Turk (n = 410) to reveal the overall mechanism. Study 2 was a field experiment (n = 292) to corroborate Study 1's findings. The authors analyzed the data using a multigroup structural equation model. FindingsFirst, consumers perceive greed against FPRCs' dual identities incurred by their commercial activities. Second, when FPRCs obscure their religious identities by using third-party organizations (TPOs) as its promoter (i.e. indirect appeal), consumers' greed perceptions decline, but this does not increase consumers' future patronage intentions. Finally, in online and field experiments, consumers enhance their purchase intentions and behavior, respectively, under indirect appeal. Research limitations/implicationsFirst, further investigation of the cognitive dissonance mechanism when consumers face seemingly contradictory identities of organizations is crucial to identify bottlenecks in promoting FPRCs' commercial offerings. Second, examining boundary conditions of indirect appeal is important to enhance our understanding of FPRCs' advertising, such as consumers' awareness of TPOs' intentionality. Lastly, not every type of indirect appeal brings the same effects. Future studies may explore diverse forms of indirect appeal, such as using artificial intelligence-based algorithms without TPOs. Practical implicationsDespite heightened interest in supporting dual missions (i.e. purpose and profit), this study shows why doing well while doing good is inherently challenging in practice creating marketing liability. To deal with this, the present findings suggest that, first, rather than exposing an FPRC's religious (or communal) identity upfront, providing subtle cues through a TPO of its religious affiliation can be persuasive to win the hearts of target customers. Second, given the short-term effectiveness of indirect appeal, FPRCs need to use both direct and indirect appeal flexibly, as each type of ad delivers a distinctive advantage. Lastly, indirect appeal is particularly effective in offline promotional activities in the context of FPRCs. Originality/valueFirst, by meshing paradox theory, the authors show that dual identities of FPRCs expose them to a marketing liability that single-mission enterprises rarely face. Second, when FPRCs use indirect appeal, they face a tradeoff between mitigating greed perception and securing future patronage. Third, results from the online experiment and field experiment show when consumers' intention and actual behavior align.",2023,,EUROPEAN JOURNAL OF MARKETING,57,7,1912-1938,WOS:000939478000001,10.1108/EJM-03-2022-0234,,#4425,Park 2023,"",""
Model-Agnostic Knowledge Graph Embedding Explanations for Recommender Systems,"Zanon, AL; da Rocha, LCD; Manzato, MG","Explanations in recommender systems play an essential role in enhancing transparency, trust, and persuasiveness. In that regard, Knowledge Graphs (KGs) model-agnostic explanations do not rely on user-inputted data such as reviews or require any changes in a recommendation algorithm to provide explanations. The state-of-the-art of modelagnostic KG explainable algorithms are based on syntactic approaches that consider the trade-off of attributes among the user-interacted items and the catalog to explain recommendations. In this study, we propose a novel model-agnostic KG algorithm for explanations. Our approach utilizes KG embeddings to rank explanations based on the path's similarity to the user. Specifically, we train an embedding algorithm on a KG and compare path embeddings, composed of node and edge embeddings, to the user embedding derived from previously interacted item embeddings. Our proposed method is evaluated by comparing it against three baselines representing the state-of-the-art of KG explanation algorithms. We assess explanation quality using three metrics: diversity and popularity of attributes displayed in explanations and recency of interacted items. Results indicate that the embedding approach achieves a superior balance between attribute popularity and explanation diversity. Furthermore, our analysis emphasizes the importance of tailored metrics for evaluating explanations in recommender systems.",2024,,"EXPLAINABLE ARTIFICIAL INTELLIGENCE, PT II, XAI 2024",2154,,3-27,WOS:001282234900001,10.1007/978-3-031-63797-1_1,,#4426,Zanon 2024,"",""
The persuasive effects of voice characteristics embedded in paid tour guide audio on tourist purchase decisions based on deep learning,"Zhou, C; Huang, MJ","Different voices may have persuasive effects on individuals' decision-making processes; however, in the tourism context, little attention has been paid to online paid tour guide audio. This study investigates how the voice characteristics of tour guide audio play a persuasive role in tourist purchase decisions. Drawing on the stereotype content model, we identify two voice characteristics: perceived warmth and competence. We then extract them from tour guide audio using speech processing and deep learning techniques. Our results show that perceived warmth and competence are positively related to tourist purchase decisions. The contingency effects further indicate greater warmth perception for female tour guides and greater competence perception for male tour guides. In addition, drawing on the value co-creation paradigm, we imply that perceived warmth is more salient for nonprofessionals, such as scholars, cultural celebrities, and even tourists themselves, whereas perceived competence is more salient for professionals, such as tour guides. This study represents pioneering work in AI- based sonic analysis in the tourism context and offers practical implications for tour guides on how to design their online tour guide audio and enhance tourist purchase decisions.",2024,,JOURNAL OF HOSPITALITY AND TOURISM MANAGEMENT,60,,313-321,WOS:001301128700001,10.1016/j.jhtm.2024.08.007,,#4427,Zhou 2024,"",""
The media literacy dilemma: can ChatGPT facilitate the discernment of online health misinformation?,"Peng, W; Meng, JB; Ling, TW","Online health misinformation carries serious social and public health implications. A growing prevalence of sophisticated online health misinformation employs advanced persuasive tactics, making misinformation discernment progressively more challenging. Enhancing media literacy is a key approach to improving the ability to discern misinformation. The objective of the current study was to examine the feasibility of using generative AI to dissect persuasive tactics as a media literacy scaffolding tool to facilitate online health misinformation discernment. In a mixed 3 (media literacy tool: control vs. National Library of Medicine [NLM] checklist vs. ChatGPT tool) x 2 (information type: true information vs. misinformation) x 2 (information evaluation difficulty: hard vs. easy) online experiment, we found that using dissecting persuasive strategies of ChatGPT can be equally effective when compared with the NLM checklist, and that information type was a significant moderator such that the ChatGPT tool was more effective in helping people identify true information than misinformation. However, the ChatGPT tool performed worse than control in terms of helping people discern misinformation. No difference was found in terms of perceived usefulness and future use intention of the ChatGPT tool and the NLM checklist. The results suggest that more interactive or conversational features might enhance usefulness of ChatGPT as a media literacy tool.",2024,,FRONTIERS IN COMMUNICATION,9,,,WOS:001375917900001,10.3389/fcomm.2024.1487213,,#4428,Peng 2024,"",""
"""This is perplexing because."": Examining the impact of gender and geo-academic location on expressions of confusion in research articles","Wang, Q; Hu, GW","Linguistic expressions of confusion (e.g., perplexing, puzzling, confusing) are important lexico-grammatical resources for academic authors to construct knowledge, enhance persuasion, and promote their research. Drawing on a frame-semantic approach, this paper examined whether the deployment of such expressions differed between male and female academics and between authors based in the Core countries (i.e., Anglophone countries, Western and North European countries), which represent the locus of dominance, power and resource in scholarly publishing, and their counterparts affiliated with the Periphery ones (i.e., the remaining countries). The analyses of 640 research articles sampled from 4 disciplines and semi-structured interviews with 16 disciplinary experts revealed multiple gender- and location-based differences in authors' use of linguistic expressions of confusion for scientific communication. These observed differences can be attributed to the female and Periphery-based academics' underrepresentation in the disciplinary community as well as the epistemological positioning and academic literacies that they developed in their particular contexts. (c) 2024 Elsevier Ltd. All rights are reserved, including those for text and data mining, AI training, and similar technologies.",2024,,LANGUAGE SCIENCES,105,,,WOS:001347785200001,10.1016/j.langsci.2024.101647,,#4429,Wang 2024,"",""
Digital Health Education for the Future: The SaNuRN (Santé Numérique Rouen-Nice) Consortium's Journey,"Grosjean, J; Dufour, F; Benis, A; Januel, JM; Staccini, P; Darmoni, SJ","Sant & eacute; Num & eacute;rique Rouen -Nice (SaNuRN; ""Digital Health Rouen -Nice"" in English) is a 5 -year project by the University of Rouen Normandy (URN) and C & ocirc;te d'Azur University (CAU) consortium to optimize digital health education for medical and paramedical students, professionals, and administrators. The project includes a skills framework, training modules, and teaching resources. In 2027, SaNuRN is expected to train a significant portion of the 400,000 health and paramedical students at the French national level. Our purpose is to give a synopsis of the SaNuRN initiative, emphasizing its novel educational methods and how they will enhance the delivery of digital health education. Our goals include showcasing SaNuRN as a comprehensive program consisting of a proficiency framework, instructional modules, and educational materials and explaining how SaNuRN is implemented in the participating academic institutions. SaNuRN is aimed at educating and training health and paramedical students in digital health. The project is a cooperative effort between URN and CAU, covering 4 French departments. It is based on the French National Referential on Digital Health ( FNRDH ), which defines the skills and competencies to be acquired and validated by every student in the health, paramedical, and social professions curricula. The SaNuRN team is currently adapting the existing URN and CAU syllabi to FNRDH and developing short -duration video capsules of 20-30 minutes to teach all the relevant material. The project aims to ensure that the largest student population earns the necessary skills, and it has developed a 2 -tier system involving facilitators who will enable the efficient expansion of the project's educational outreach and support the students in learning the needed material efficiently. With a focus on real -world scenarios and innovative teaching activities integrating telemedicine devices and virtual professionals, SaNuRN is committed to enabling continuous learning for health care professionals in clinical practice. The SaNuRN team introduced new ways of evaluating health care professionals by shifting from a knowledge -based to a competencies -based evaluation, aligning with the Miller teaching pyramid and using the Objective Structured Clinical Examination and Script Concordance Test in digital health education. Drawing on the expertise of URN, CAU, and their public health and digital research laboratories and partners, SaNuRN represents a platform for continuous innovation, including telemedicine training and living labs with virtual and interactive professional activities. SaNuRN provides a comprehensive, personalized, 30 -hour training package for health and paramedical students, addressing all 70 FNRDH competencies. The project is enhanced using artificial intelligence and natural language processing to create virtual patients and professionals for digital health care simulation. SaNuRN teaching materials are open access. It collaborates with academic institutions worldwide to develop educational material on digital health in English and multilingual formats. SaNuRN offers a practical and persuasive training approach to meet the current digital health education requirements.",2024,,JMIR MEDICAL EDUCATION,10,,,WOS:001240906000001,10.2196/53997,,#4430,Grosjean 2024,"",""
Renewable energy role in low-carbon economy and net-zero goal: Perspectives and prospects,"Nguyen, VG; Sirohi, R; Tran, MH; Truong, TH; Duong, MT; Pham, MT; Cao, DN","Several issues such as sustainability, CO2 footprint, and energy supply security which primarily resulted from fossil fuel emissions have become the main concerns for analysts and policymakers worldwide. Therefore, to meet the goals of sustainable energy as well as the switch to a net-zero and low-carbon economy, energy systems must be diversified by increasing the implementation of renewable and clean sources of energy. This paper focused on the deep analysis of the key role of bioenergy, geothermal, solar, hydropower or hydrogen, ocean, and wind (BIGSHOW) renewable energy in producing clean energy aiming to attain the sustainable net-zero norms and climate change mitigation. Furthermore, AI technology and its applicability were also introduced to enhance the management efficiency of BIGSHOW in energy-use strategies. More importantly, barriers and bottlenecks of deploying BIGSHOW projects and applications were comprehensively analyzed. Finally, policy implications and vital solutions were thoroughly presented aiming to increase the penetration of BIGSHOW to the energy system. In short, this work could be strong and persuasive evidence for speeding up the shifting progress of a precarious fossil fuel-based economy to a sustainable low-carbon one, in which BIGSHOW has been known as the core role.",2024,,ENERGY & ENVIRONMENT,,,,WOS:001228846500001,10.1177/0958305X241253772,,#4431,Nguyen 2024,"",""
Global Catastrophic Risk and the Drivers of Scientist Attitudes Towards Policy,"Nathan, C; Hyams, K","An anthropogenic global catastrophic risk is a human-induced risk that threatens sustained and wide-scale loss of life and damage to civilisation across the globe. In order to understand how new research on governance mechanisms for emerging technologies might assuage such risks, it is important to ask how perceptions, beliefs, and attitudes towards the governance of global catastrophic risk within the research community shape the conduct of potentially risky research. The aim of this study is to deepen our understanding of emerging technology research culture as it relates to global catastrophic risks, and to shed new light on how new research governance mechanisms might be developed. We analyse in-depth interviews with leading AI and biotech researchers both from universities and the private sector. We develop new insights in terms of four salient themes. First, 'engineering mindset', which highlights the premium placed by many interviewees on pursuing interesting research about the physical world for its own sake. Second, 'self-government', which looks at how self-regulation of technological development currently occurs. Third, 'pure incentives', focussing on how career and other incentives shapes research. Fourth, 'norms and persuasion', which examines the role of moral considerations in guiding the research choices of scientists. We end by considering the implications of these findings for future research on governance of anthropogenic global catastrophic risk.",2022,,SCIENCE AND ENGINEERING ETHICS,28,6,,WOS:000876261100002,10.1007/s11948-022-00411-3,,#4432,Nathan 2022,"",""
"The mass, fake news, and cognition security","Guo, B; Ding, YS; Sun, YH; Ma, S; Li, K; Yu, ZW","The widespread fake news in social networks is posing threats to social stability, economic development, and political democracy, etc. Numerous studies have explored the effective detection approaches of online fake news, while few works study the intrinsic propagation and cognition mechanisms of fake news. Since the development of cognitive science paves a promising way for the prevention of fake news, we present a new research area called Cognition Security (CogSec), which studies the potential impacts of fake news on human cognition, ranging from misperception, untrusted knowledge acquisition, targeted opinion/attitude formation, to biased decision making, and investigates the effective ways for fake news debunking. CogSec is a multidisciplinary research field that leverages the knowledge from social science, psychology, cognition science, neuroscience, AI and computer science. We first propose related definitions to characterize CogSec and review the literature history. We further investigate the key research challenges and techniques of CogSec, including humancontent cognition mechanism, social influence and opinion diffusion, fake news detection, and malicious bot detection. Finally, we summarize the open issues and future research directions, such as the cognition mechanism of fake news, influence maximization of fact-checking information, early detection of fake news, fast refutation of fake news, and so on.",2021,,FRONTIERS OF COMPUTER SCIENCE,15,3,,WOS:000588691500001,10.1007/s11704-020-9256-0,,#4433,Guo 2021,"",""
Towards interactive explanation-based nutrition virtual coaching systems,"Buzcu, B; Tessa, M; Tchappi, I; Najjar, A; Hulstijn, J; Calvaresi, D; Aydogan, R","The awareness about healthy lifestyles is increasing, opening to personalized intelligent health coaching applications. A demand for more than mere suggestions and mechanistic interactions has driven attention to nutrition virtual coaching systems (NVC) as a bridge between human-machine interaction and recommender, informative, persuasive, and argumentation systems. NVC can rely on data-driven opaque mechanisms. Therefore, it is crucial to enable NVC to explain their doing (i.e., engaging the user in discussions (via arguments) about dietary solutions/alternatives). By doing so, transparency, user acceptance, and engagement are expected to be boosted. This study focuses on NVC agents generating personalized food recommendations based on user-specific factors such as allergies, eating habits, lifestyles, and ingredient preferences. In particular, we propose a user-agent negotiation process entailing run-time feedback mechanisms to react to both recommendations and related explanations. Lastly, the study presents the findings obtained by the experiments conducted with multi-background participants to evaluate the acceptability and effectiveness of the proposed system. The results indicate that most participants value the opportunity to provide feedback and receive explanations for recommendations. Additionally, the users are fond of receiving information tailored to their needs. Furthermore, our interactive recommendation system performed better than the corresponding traditional recommendation system in terms of effectiveness regarding the number of agreements and rounds.",2024,,AUTONOMOUS AGENTS AND MULTI-AGENT SYSTEMS,38,1,,WOS:001145051900001,10.1007/s10458-023-09634-5,,#4434,Buzcu 2024,"",""
"Kuaering queer theory:: My autocritography and a race-conscious, womanist, transnational turn","Lee, W","Critiquing queer theory's omissions in race and class, E. Patrick Johnson (2001) suggests ""quare"" studies, a turn similar to that being made from feminism to womanism. I fully embrace Johnson's theorizing. But to make relevant the worlds lying beyond the pale of North America, Europe, and the English language to the study of sexualities and other dimensions of systematic discrimination, I use kuaer theory to make another turn. One that is at once race-conscious, womanist and transnational. I travel through three awakenings, and look into nu nu (female-female) words in Taiwanese and Chinese lesbian existence in different historical periods. I also offer a rhetorical analysis of the title of Ai Bao, the first officially registered Taiwanese lesbian magazine, exploring its persuasiveness via wordplay and multiple entendre. In addition, from jin lan hui to nu tongzhi, from T/puo and lazi to kuer, I provide sketches of heterogeneous and complex Taiwanese and Chinese nu nu worlds. As I get deeper into my autocritography, these women become my women and I learn to utter my own words in a language that is little pre-packaged. My crossing marks a daring but humble beginning. If nothing else, there is at least more space for bringing up race and transnational complicity queerly. (C) 2003 by The Haworth Press, Inc. All rights reserved.",2003,,JOURNAL OF HOMOSEXUALITY,45,2-4,147-170,WOS:000186710200008,10.1300/J082v45n02_07,,#4435,Lee 2003,"",""
Analysis of Federated Learning Paradigm in Medical Domain: Taking COVID-19 as an Application Use Case,"Hwang, SO; Majeed, A","Federated learning (FL) has emerged as one of the de-facto privacy-preserving paradigms that can effectively work with decentralized data sources (e.g., hospitals) without acquiring any private data. Recently, applications of FL have vastly expanded into multiple domains, particularly the medical domain, and FL is becoming one of the mainstream technologies of the near future. In this study, we provide insights into FL fundamental concepts (e.g., the difference from centralized learning, functions of clients and servers, workflows, and nature of data), architecture and applications in the general medical domain, synergies with emerging technologies, key challenges (medical domain), and potential research prospects. We discuss major taxonomies of the FL systems and enlist technical factors in the FL ecosystem that are the foundation of many adversarial attacks on these systems. We also highlight the promising applications of FL in the medical domain by taking the recent COVID-19 pandemic as an application use case. We highlight potential research and development trajectories to further enhance the persuasiveness of this emerging paradigm from the technical point of view. We aim to concisely present the progress of FL up to the present in the medical domain including COVID-19 and to suggest future research trajectories in this area.",2024,,APPLIED SCIENCES-BASEL,14,10,,WOS:001232748700001,10.3390/app14104100,,#4436,Hwang 2024,"",""
BrainHood: Designing a cognitive training system that supports self-regulated learning skills in children,"Tsiakas, K; Barakova, E; Khan, JV; Markopoulos, P","BACKGROUND: There is strong evidence that cognitive skills and executive functions are skills that children need in order to successfully learn in school. Although executive function disorders are not considered a learning disability, weaknesses in executive functioning are often observed in students with learning disabilities or ADHD. Cognitive games are a type of educational games which focus on enhancing cognitive functioning in children with different profiles of cognitive development, including students with neurocognitive and/or learning disabilities. Self-regulation and metacognitive skills also play an important role in academic performance.OBJECTIVE: In this work, we highlight the need of monitoring and supporting metacognitive skills (self-regulation) in the context of a cognitive training game. We propose a system for self-regulated cognitive training for children which supports metacognitive strategies allowing the child to reflect on their own progress, weaknesses and strengths, self-arrange the training content, and thus to promote their self-regulated learning skills.METHODS: We provide a narrative review of research in cognitive training, self-regulated learning and explainable recommendation systems for children in educational settings.RESULTS AND CONCLUSIONS: Based on the review, an experimental testbed is proposed to explore how transparency, explainability and persuasive strategies can be used to promote self-regulated learning skills in children, considering individual differences on learning abilities, preferences, and needs.",2020,,TECHNOLOGY AND DISABILITY,32,4,219-228,WOS:000937927100001,10.3233/TAD-200294,,#4437,Tsiakas 2020,"",""
"Artificial Presence, Real-Life Influence? Effects of CGI Influencers on Young Adults' Health Behavior Intentions","Saumer, M; Neureiter, A; Varg, ÉM; Gataric, V; Liu, CY; Matthes, J","Computer Generated Imagery (CGI) influencers-also known as virtual influencers-are an increasingly influential phenomenon on social media. Some CGI influencers are presented as cartoon characters and are thus clearly recognizable as non-human. Other CGI influencers, however, are almost indistinguishable from real humans. Although CGIs can elicit parasocial interaction (PSI), we lack research distinguishing cartoon-look CGI influencers from human-look CGI influencers. Also, we do not know whether CGIs can lead to persuasive effects. This is particularly relevant regarding health topics because CGIs cannot have health issues. In an experimental study with a quota-based sample of N = 443 young adults (62.8% female) aged 16 to 26 from the United Kingdom, we compared the effects of a real human influencer, a human-look CGI influencer, and a cartoon-look CGI influencer advising about insomnia (i.e., sleeping problems) on young adults' PSI and health behavior intentions. We found that PSI was strongest for the real human and weakest for the cartoon-look CGI influencer and was significantly positively related to young adults' health behavior intentions. Personal affectedness by insomnia and gender did not moderate these relationships. Overall, findings suggest that the persuasive power of CGIs is limited, at least regarding topics such as health. Implications are discussed.",2025,,CYBERPSYCHOLOGY-JOURNAL OF PSYCHOSOCIAL RESEARCH ON CYBERSPACE,19,2,,WOS:001475282800001,10.5817/CP2025-2-3,,#4438,Saumer 2025,"",""
Deepfakes Unmasked: The Effects of Information Priming and Bullshit Receptivity on Deepfake Recognition and Sharing Intention,"Iacobucci, S; De Cicco, R; Michetti, F; Palumbo, R; Pagliaro, S","The study aims to test whether simple priming of deepfake (DF) information significantly increases users' ability to recognize DF media. Although undoubtedly fascinating from a technological point of view, these highly realistic artificial intelligent (AI)-generated fake videos hold high deceptive potential. Both practitioners and institutions are thus joining forces to develop debunking strategies to counter the spread of such difficult-to-recognize and potentially misleading video content. On this premise, this study addresses the following research questions: does simple priming with the definition of DFs and information about their potentially harmful applications increase users' ability to recognize DFs? Does bullshit receptivity, as an individual tendency to be overly accepting of epistemically suspect beliefs, moderate the relationship between such priming and DF recognition? Results indicate that the development of strategies to counter the deceitfulness of DFs from an educational and cultural perspective might work well, but only for people with a lower susceptibility to believe willfully misleading claims. Finally, through a serial mediation analysis, we show that DF recognition does, in turn, negatively impact users' sharing intention, thus limiting the potential harm of DFs at the very root of one of their strengths: virality. We discuss the implications of our finding that society's defense against DFs could benefit from a simple reasoned digital literacy intervention.",2021,,CYBERPSYCHOLOGY BEHAVIOR AND SOCIAL NETWORKING,24,3,194-202,WOS:000624611600001,10.1089/cyber.2020.0149,,#4439,Iacobucci 2021,"",""
Novel costimulators in the immune gene therapy of cancer,"GaleaLauri, J; Farzaneh, F; Gaken, J","One of the major goals of cancer immunotherapy is the induction of tumour-specific T-lymphocyte responses that will be effective in the rejection of established tumours. The prospects for such therapy rely on the identification of tumour antigens, and although there is persuasive evidence for the presence of such antigens,(1,2) the occurrence of the disease does illustrate that the immune system is at least, on some occasions, unable to recognise and destroy these targets. Tumour antigens may be novel proteins (from genetic lesions or viral infections), modified existing antigens (eg, abnormally glycosylated cell surface proteins), or inappropriately expressed normal gene products (eg, CA125, carcinoembryonic antigen, and alpha-fetoprotein).(1) Involvement of the immune system in the normal surveillance and suppression on cancer is further suggested by the increased incidence ai tumours in immunocompromised patients.(3) However, recent evidence has shown that, al least in model systems, cancer cells can be modulated in such a way that they stimulate cells on the immune system to recognise and destroy these malignant cells. This review summarizes the costimulatory molecules involved in the activation on such cells, the principles and mechanisms underlying their activation, and how such knowledge can be used to persuade the immune system to challenge cancer.",1996,,CANCER GENE THERAPY,3,3,202-214,WOS:A1996UN88900009,,,#4440,GaleaLauri 1996,"",""
"""I'm telling you"": The use of interactional metadiscourse in Chinese live streaming commerce","Liu, Q; Cheng, W","As an emerging form of mediated communication, live streaming commerce (LSC) has established itself as a distinctive business genre. This study examines the use of interactional metadiscourse by streamers in Chinese LSC. Using Hyland's interactional meta- discourse model, we analyzed a corpus of 60 LSC videos sourced from Alibaba's Taobao Live platform to identify patterns and functions of metadiscourse in fostering parasocial interaction. The findings reveal that streamers' promotional speech was rich in interactional metadiscourse. Among stance resources, self-mentions and boosters were used frequently, whereas hedges and attitude markers were less common. Engagement markers mainly included audience references, followed by questions and directives, with minimal use of personal asides and shared knowledge. These metadiscourse resources contribute to parasocial interaction. Stance resources enhance source credibility by presenting streamers as expert and trustworthy product endorsers. Engagement resources foster mutual awareness by cultivating a sense of co-presence between streamers and reviewers in personalized interactions, while also enhancing homophily by highlighting perceived similarities between the two. Collectively, these interactional metadiscourse strategies create an interactive online shopping discourse, fostering a heightened level of parasocial interaction, in which viewers are drawn into in an illusionary, reciprocal communication and form imagined friendships with streamers in the digital space. (c) 2025 Elsevier B.V. All rights are reserved, including those for text and data mining, AI training, and similar technologies.",2025,,JOURNAL OF PRAGMATICS,237,,14-29,WOS:001405526700001,10.1016/j.pragma.2025.01.001,,#4441,Liu 2025,"",""
Pioglitazone protects HDL2&3 against oxidation in overweight and obese men,"McEneny, J; McPherson, PA; McGinty, A; Hull, SS; McCance, DR; Young, IS","Background: The worldwide epidemic of obesity is a major public health concern and is persuasively linked to the rising prevalence of diabetes and cardiovascular disease. Obesity is often associated with an abnormal lipoprotein profile, which may be partly negated by pioglitazone intervention, as this can influence the composition and oxidation characteristics of low-density lipoprotein (LDL). However, as pioglitazone's impact on these parameters within high-density lipoprotein (HDL), specifically HDL2&3, is absent from the literature, this study was performed to address this shortcoming.Methods: Twenty men were randomized to placebo or pioglitazone (30 mg/day) for 12 weeks. HDL2&3 were isolated by rapid-ultracentrifugation. HDL2&3-cholesterol and phospholipid content were assessed by enzymatic assays and apolipoprotein AI (apoAI) content by single-radial immunodiffusion. HDL2&3 oxidation characteristics were assessed by monitoring conjugated diene production and paraoxonase-1 activity by spectrophotometric assays.Results: Compared with the placebo group, pioglitazone influenced the composition and oxidation potential of HDL2&3. Specifically, total cholesterol (P < 0.05), phospholipid (P < 0.001) and apoAI (P < 0.001) were enriched within HDL2. Furthermore, the resistance of HDL2&3 to oxidation (P < 0.05) and the activity of paroxonase-1 were also increased (P, 0.001).Conclusions: Overall, these findings indicate that pioglitazone treatment induced antiatherogenic changes within HDL2&3, which may help reduce the incidence of premature cardiovascular disease linked with obesity.",2013,,ANNALS OF CLINICAL BIOCHEMISTRY,50,1,20-24,WOS:000319395500005,10.1258/acb.2012.012019,,#4442,McEneny 2013,"",""
Is being human-like beneficial? The effect of anthropomorphism on chatbot persuasion in e-commerce,"Yang, MR; Peng, XX; Wang, QZ; Zhao, YXC; Wang, XW","Purpose Chatbots are vital for enhancing e-commerce sustainability by providing efficient customer support. Although previous studies have considered both linguistic and visual anthropomorphism as crucial factors in e-commerce chatbot design, their joint effects and their underlying mechanisms have not been thoroughly investigated. Drawing on insights from the literature on anthropomorphism and the elaboration likelihood model, this research attempts to examine the joint effects of the two types of anthropomorphism, the boundary condition, and the subsequent impact on purchase intention.Design/methodology/approach A research model was proposed and empirically tested using two laboratory-controlled experimental studies.Findings Linguistic anthropomorphism plays a dominant role over visual anthropomorphism in influencing social presence and communicative effectiveness. In addition, linguistic anthropomorphism harms persuasion through the mediating role of communicative effectiveness, and the fit between linguistic and visual anthropomorphism amplifies the negative effect on purchase intention. Moreover, shopping motivation serves as a boundary condition for the negative effect of anthropomorphism.Practical implications Chatbot designers should be cautious when using anthropomorphism in e-commerce chatbot design. The use of machine-like languages may be more persuasive than that of human-like languages, especially for utilitarian products. Notably, mismatched anthropomorphic elements may harm user experience.Originality/value This study enriches chatbot literature by examining the role of chatbot anthropomorphism in the e-commerce context. Moreover, this study provides a more comprehensive framework for understanding how chatbots' linguistic and visual anthropomorphism jointly influence consumer behavior.",2025,,INTERNET RESEARCH,,,,WOS:001445954100001,10.1108/INTR-10-2023-0866,,#4443,Yang 2025,"",""
"Computational persuasion technologies, explainability, and ethical-legal implications: A systematic literature review","Calvaresi, D; Carli, R; Tiribelli, S; Buzcu, B; Aydogan, R; Di Vincenzo, A; Mualla, Y; Schumacher, M; Calbimonte, JP","This paper conducts a systematic literature review (SLR) to evaluate the effectiveness of computational persuasion technology (CPT) in the eHealth domain. Over the past fifteen years, CPT has been used in various scenarios, from promoting healthy diets to supporting chronic disease management. Despite the proliferation of intelligent systems and Web-based applications, the ethical and legal nuances of these technologies have become increasingly significant. The review follows a structured methodology, assessing 92 primary studies through sixteen research questions covering demographics, application scenarios, user requirements, objectives, functionalities, technologies, advantages, limitations, proposed solutions, ethical and legal implications, and the role of explainable AI (XAI). The findings indicate that while CPT holds promise in inducing behavioral change, many prototypes remain untested on a large scale (60% of surveyed studies only developed at a conceptual level), and long-term effectiveness is still uncertain (36% report attaining their goals, but none focuses on long-term assessment). The study highlights the need for more comparative analyses of persuasion models and tailored approaches to meet diverse user needs. Ethical and legal concerns, such as patient consent, data privacy, and potential for users' manipulation, are under-explored and require deeper investigation. The paper recommends a bottom-up regulatory approach to create more effective and flexible ethical and legal guidelines for CPT applications. In conclusion, significant advancements have been made in CPT for eHealth, but ongoing research is essential to address current limitations, enhance user acceptability and adherence, and ensure ethical and legal soundness.",2025,,COMPUTERS IN HUMAN BEHAVIOR REPORTS,17,,,WOS:001421218200001,10.1016/j.chbr.2024.100577,,#4444,Calvaresi 2025,"",""
BGFL: a blockchain-enabled group federated learning at wireless industrial edges,"Peng, GZ; Shi, XY; Zhang, J; Gao, LS; Tan, YP; Xiang, N; Wang, WG","In the rapidly evolving landscape of Industry 4.0, the complex computational tasks and the associated massive data volumes present substantial opportunities for advancements in machine learning at industry edges. Federated learning (FL), which is a variant of distributed machine learning for edge-cloud computing, presents itself as a persuasive resolution for these industrial edges, with its main objectives being the mitigation of privacy breaches and the resolution of data privacy concerns. However, traditional FL methodologies encounter difficulties in effectively overseeing extensive undertakings in Industry 4.0 as a result of challenges including wireless communications with high latency, substantial heterogeneity, and insufficient security protocols. As a consequence of these obstacles, blockchain technology has garnered acclaim for its secure, decentralized, and transparent data storage functionalities. A novel blockchain-enabled group federated learning (BGFL) framework designed specifically for wireless industrial edges is presented in this paper. By strategically dividing industrial devices into multiple groups, the BGFL framework simultaneously reduces the wireless traffic loads required for convergence and improves the accuracy of collaborative learning. Moreover, to optimize aggregation procedures and reduce communication resource utilization, the BGFL employs a hierarchical aggregation strategy that consists of both local and global aggregation off-chain and on-chain, respectively. The integration of a smart contract mechanism serves to fortify the security framework. The results of comparative experimental analyses demonstrate that the BGFL framework enhances the resilience of the learning framework and effectively reduces wireless communication latency. Thus, it offers a scalable and efficient solution for offloading tasks in edge-cloud computing environments.",2024,,JOURNAL OF CLOUD COMPUTING-ADVANCES SYSTEMS AND APPLICATIONS,13,1,,WOS:001328489000001,10.1186/s13677-024-00700-1,,#4445,Peng 2024,"",""
"An artificially intelligent, natural language processing chatbot designed to promote COVID-19 vaccination: A proof-of-concept pilot study","Zhou, S; Silvasstar, J; Clark, C; Salyers, AJ; Chavez, C; Bull, SS","ObjectiveOur goal is to establish the feasibility of using an artificially intelligent chatbot in diverse healthcare settings to promote COVID-19 vaccination. MethodsWe designed an artificially intelligent chatbot deployed via short message services and web-based platforms. Guided by communication theories, we developed persuasive messages to respond to users' COVID-19-related questions and encourage vaccination. We implemented the system in healthcare settings in the U.S. between April 2021 and March 2022 and logged the number of users, topics discussed, and information on system accuracy in matching responses to user intents. We regularly reviewed queries and reclassified responses to better match responses to query intents as COVID-19 events evolved. ResultsA total of 2479 users engaged with the system, exchanging 3994 COVID-19 relevant messages. The most popular queries to the system were about boosters and where to get a vaccine. The system's accuracy rate in matching responses to user queries ranged from 54% to 91.1%. Accuracy lagged when new information related to COVID emerged, such as that related to the Delta variant. Accuracy increased when we added new content to the system. ConclusionsIt is feasible and potentially valuable to create chatbot systems using AI to facilitate access to current, accurate, complete, and persuasive information on infectious diseases. Such a system can be adapted to use with patients and populations needing detailed information and motivation to act in support of their health.",2023,,DIGITAL HEALTH,9,,,WOS:000943784600001,10.1177/20552076231155679,,#4446,Zhou 2023,"",""
Regulating Cross-Cultural Moral Sensitivity: An Image Ethic Analysis of Appearance Design of Intelligent Machine,"Zhane, ZQ; Wang, YY","Machine appearance is a crucial research topic in human-machine interaction, and different cultures hold different ethical attitudes toward different machine appearances. Cultural sensitivity research on appearance lacks in-depth ethical considerations, while value sensitivity research on appearance does not focus well on user-driven design concepts. Image ethics using the resources of phenomenological theory can circumvent the problems above, while a persuasive support of valid empirical research is in demand. This study's approach to image ethics discusses differences in the moral sensitivity of image viewers from different cultures. It is designed to compare the attitudes of two groups of people towards the appearance of a machine in a scenario where two machines are interacting, by textually analyzing the results of a classroom experiment and social media comments on viewing the same image. The study finds that different cultures have different moral sensitivities to the appearance of the same machine, as evidenced by the difference in the proportion of normative and descriptive content in the viewing representations. There are structural differences in the perceptions of machine appearance among viewers from different cultures, which can be observed in the distinctive themes in the texts of the two cultures. The findings can empirically support the role of moral energizers in moderating moral sensitivity in appearance, leading to a better use of phenomenological approaches to focus on the user's experience of using the machine, and providing cultural explanations for the affective characterization of users' ethical perceptions.",2024,,"CROSS-CULTURAL DESIGN, PT III, CCD 2024",14701,,334-358,WOS:001284756800024,10.1007/978-3-031-60904-6_24,,#4447,Zhane 2024,"",""
Leveraging Natural Language Processing in Persuasive Marketing,"Christodoulou, E; Gregoriades, A","The language used in marketing communication influences consumers' attitudes towards products or services and likelihood of purchasing or recommending these to others. Knowing the personality of the consumer is important in persuasion marketing and can be inferred from the abundance of consumer information available online. This paper utilizes text classification to extract consumers' personality from electronicword-of-mouth (e-WOM) and topic modelling to identify consumers' opinions. The aim is to optimizemarketing communication through personalized messages that abide to targeted consumers' personalities. The method is based on the theory of self-congruence, stipulating that consumers are inclined to purchase a brand that reflects their own personalities. Consumer reviews are obtained from TripAdvisor and their textual part is expressed as a proportion of different discussion themes identified through topic modelling. The personality of each reviewer is recognised using the textual part of their eWOM and a deep learning model trained on labelled text using the personality model of Myers-Briggs Type Indicator (MBTI). Four XGBoost (eXtreme Gradient Boosting) classifiers are trained, one for each of the four MBTI personality traits, using as predictors the topic embeddings and output the personality type of consumers. An explainable AI technique, namely, Shapley Additive Explanations (SHAP), is used to explain how the topics discussed by consumers in eWOM are related to their personality. Patterns from each XGBoost model are collated into a table showing how topics can be exploited by marketers during advertisement message design to appeal to specific consumer personalities. Preliminary results are compared against persuasion marketing and consumer behavior literature.",2023,,"INTELLIGENT INFORMATION AND DATABASE SYSTEMS, ACIIDS 2023, PT I",13995,,197-209,WOS:001155008700016,10.1007/978-981-99-5834-4_16,,#4448,Christodoulou 2023,"",""
Sketching the vision of the Web of Debates,"Bikakis, A; Flouris, G; Patkos, T; Plexousakis, D","The exchange of comments, opinions, and arguments in blogs, forums, social media, wikis, and review websites has transformed the Web into a modern agora, a virtual place where all types of debates take place. This wealth of information remains mostly unexploited: due to its textual form, such information is difficult to automatically process and analyse in order to validate, evaluate, compare, combine with other types of information and make it actionable. Recent research in Machine Learning, Natural Language Processing, and Computational Argumentation has provided some solutions, which still cannot fully capture important aspects of online debates, such as various forms of unsound reasoning, arguments that do not follow a standard structure, information that is not explicitly expressed, and non-logical argumentation methods. Tackling these challenges would give immense added-value, as it would allow searching for, navigating through and analyzing online opinions and arguments, obtaining a better picture of the various debates for a well-intentioned user. Ultimately, it may lead to increased participation of Web users in democratic, dialogical interchange of arguments, more informed decisions by professionals and decision-makers, as well as to an easier identification of biased, misleading, or deceptive arguments. This paper presents the vision of the Web of Debates, a more human-centered version of the Web, which aims to unlock the potential of the abundance of argumentative information that currently exists online, offering its users a new generation of argument-based web services and tools that are tailored to their real needs.",2023,,FRONTIERS IN ARTIFICIAL INTELLIGENCE,6,,,WOS:001016586000001,10.3389/frai.2023.1124045,,#4449,Bikakis 2023,"",""
The Effectiveness of Social Influence Tactics when Used by a Virtual Agent,"ACM; Lucas, GM; Lehr, J; Gratch, J; Kramer, N","Research in social science distinguishes between two types of social influence: informational and normative. Informational social influence is driven by the desire to evaluate ambiguous situations correctly, whereas normative social influence is driven by the desire to be liked and gain social acceptance from another person. Although we know from research that humans can effectively use either of these techniques to persuade other humans, scholars have yet to examine the relative effectiveness of informational versus normative social influence when used by virtual agents. We report a study in which users interact with a system that persuades them either using informational or normative social influence. Furthermore, to compare agents to human interlocutors, users are told that the system is either tele-operated by a human (avatar) or fully -automated (agent). Using this design, we are able to compare the effectiveness of virtual agents (vs humans) in employing informational versus normative social influence. Participants interacted with the system, which employed a Wizard-of-Oz operated virtual agent that tried to persuade the user to agree with its rankings on a ""survival task."" Controlling for initial divergence in rankings between user and the agent, there was a significant main effect such that informational social influence resulted in greater influence than normative influence. However, this was qualified by an interaction that approached significance; users were, if anything, more persuaded by informational influence when they believe the agent was AI (compared to a human), whereas there was no difference between the agent and avatar in the normative influence condition.",2019,,PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19),,,22-29,WOS:000556671900010,10.1145/3308332.3329464,,#4450,ACM 2019,"",""
How Do Consumers Interact with Digital Expert Advice? Experimental Evidence from Health Insurance,"Bundorf, MK; Polyakova, M; Tai-Seale, M","Consumers increasingly use digital advice when making purchasing decisions. How do such tools change consumer behavior and what types of consumers are likely to use them? We examine these questions with a randomized controlled trial of digital expert advice in the context of prescription drug insurance. The intervention we study was effective at changing consumer choices. We propose that, conceptually, expert advice can affect consumer choices through two distinct channels: by updating consumer beliefs about product features (learning) and by influencing how much consumers value product features (interpretation). Using our trial data to estimate a model of consumer demand, we find that both channels are quantitatively important. Digital expert advice tools not only provide consumers with information, but also alter how consumers value product features. For example, consumers are willing to pay 14% less for a plan with the most popular brand and 37% less for an extra star rating when they incorporate digital expert advice on plan choice relative to only having information about product features. Further, we document substantial selection into the use of digital advice on two margins. Consumers who are inherently less active shoppers and those who we predict would have responded to advice more were less likely to demand it. Our results raise concerns regarding the ability of digital advice to alter consumer preferences as well as the distributional implications of greater access to digital expert advice.",2024,,MANAGEMENT SCIENCE,70,11,,WOS:001146137300001,10.1287/mnsc.2020.02453,,#4451,Bundorf 2024,"",""
On the Future of Serious Games in Science and Industry,"Encarnaçao, LM","The availability of high-performance commodity graphics hardware at low cost allowed the convergence of two historically distinct application areas of Computer Graphics video games and interactive visual simulation. The result is the newly emerging R&D area of Serious Games at the nexus of videogame design, pedagogy, human-computer interaction, simulation, AI and digital storytelling. It is aimed at exploring the opportunities and challenges of using entertaining game play for real-world applications beyond mere entertainment towards for instance education, training, motivation, rehabilitation, persuasion and decision making.True success of Serious Games depends on consumers' realization of the inherent value of those products for various self-efficacy applications in life. Additionally, there exist numerous challenges for Serious Games developers including smaller consumer audiences, higher development cost, the need for embedded evaluation and assessment functionality, as well as insufficient business models and distribution channels. Those challenges make it traditionally hard to compete against popular entertainment titles in the consumer retail market. It might, however, well be this additional value that has the potential to give Serious Games if well designed and properly targeted a competitive edge over mere entertainment titles in the current recession-plagued industry.This paper is providing the rationale behind the corresponding keynote presentation and aims at giving an overview on the field of Serious Games from an application industry perspective. It further aims at discussing and identifying requirements for Serious Games R&D towards effectiveness as well as consumer acceptance and adoption.",2009,,"PROCEEDINGS OF CGAMES 2009 USA - 14TH INTERNATIONAL CONFERENCE ON COMPUTER GAMES: AI, ANIMATION, MOBILE, INTERACTIVE MULTIMEDIA, EDUCATIONAL AND SERIOUS GAMES",,,9-16,WOS:000276131400001,,,#4452,Encarnaçao 2009,"",""
Assessing the Validity of Standard-Setting for an English Language Assessment With a Hybrid Expert and Empirical Performance Model,"Hsieh, JC","Background and PurposeThe Taiwan Assessment of Student Achievement: Longitudinal Study (TASAL) was implemented to evaluate the effect of the new 12-year basic education curriculum on student performance in Taiwan. TASAL is a standards-based, large-scale assessment that aims to track the literacy growth of Taiwanese students, explore relevant factors, and collect empirical evidence to assist in the development of future curriculum guidelines. This study assessed the validity of standard-setting with a hybrid model combining expert and student empirical performance.The hybrid model exhibits multidimensional, multisource, and long-term cumulative features. The multidimensional feature provides evidence for procedural, internal, and external validity and for setting appropriate standards (Kane, 1994, 2001; Pant et al., 2009). The multisource feature indicates that the evidence of validity is derived from various sources, such as expert opinions and students' empirical performance. Finally, the long-term cumulative feature represents the process of accumulating evidence over a long period. Presenting every type of evidence in a study is challenging due to time and resource constraints. The burden placed on researchers and students should be considered.Method1. SamplingIn 2019, the evaluation of seventh-grade students was initiated formally in TASAL. In 2020, the same group of students, now in the eighth grade, was evaluated in TASAL. The sampling method was stratified two-stage cluster sampling. Initially, 256 junior high schools were selected to take part in the evaluation. Finally, 246 schools with a total of 2,793 students were enrolled for this project. Regarding the English test of TASAL, in 2019, 2,793 seventh-grade students took the TASAL English test. In 2020, 2,893 eighth-grade students took the test. Among the eighth-grade students, 2,554 took the English test in both years.2. MaterialsThe TASAL English core competence assessment was developed through a standardized procedure, including purpose clarification, theory construction, assessment guidelines, performance level descriptor development, test item designation, test assembly, and data analysis. The TASAL English core competence assessment examines English reading comprehension according to the corresponding content in the 12-year basic education curriculum. Based on the concept of transforming verb-noun usage into cognitive processes and content knowledge, as proposed by Anderson et al. (2001), a separate set of assessment criteria and test items has been developed for the TASAL English core competence assessment to evaluate reading comprehension.In the TASAL English core competence assessment, six levels of performance descriptors was initially proposed (Hsieh, 2023). However, no corresponding test items were available for the sixth (highest) level of the assessment, because the standard-setting process still focused on the seventh-grade test items. Therefore, this study focused on the first five levels, which included acquiring linguistic fluency, locating explicitly stated information, literal comprehension, implicit comprehension, and evaluation and reflection beyond text comprehension. According to a review of the literature, various text types based on the OECD text types (2019) are used in the TASAL English core competence assessment, and these types are modified to include descriptive, introductive, transactional, expository, commentary, persuasive, narrative, and literary texts.The assessment for seventh-grade students contained 182 test items, and the assessment for eighth-grade students contained 196 test items; 84 common items were included in both assessments. The response consistency was good. The Expected A Posteriori (EAP) estimate of the items were 0.85 and 0.91 in the assessments for seventh-grade and eighth-grade students, respectively.3. Standard-settingThis study employed the extended Angoff method (Hambleton & Plake, 1995) to establish assessment standards. A total of 15 experts from various regions in Taiwan were trained and participated in the standard-setting meeting. Among these experts, 10 were women and 5 were men, with an average teaching experience of 18.25 years.The standard-setting meeting was implemented in three rounds, and student ability and cutoff scores were estimated by weighted likelihood estimation (Warm, 1989). Statistical analyses were performed in R (R Core Team, 2022) and TAM software packages (Robitzsch et al., 2020).Result and ConclusionFeedback was collected using a questionnaire on standard-setting. Most of the experts rated the process and outcome of the standard-setting meeting as being well above or above average. The experts agreed or strongly agreed that providing feedback and PLD procedures were helpful in establishing standards. In summary, this study provides satisfactory evidence for the procedural validity of standard-setting.This study also provides evidence for the internal validity of standard-setting. During the initial round, the standard error of cutoff scores was between 2.03 and 11.58, as reported by all experts across all levels. However, during subsequent rounds, the margin of error decreased. In general, most standard errors (relative to the measurement error of 34.64) were within an acceptable level of 0.33, which is consistent with the results of Kaftandjieva (2010, p. 104).Using the English comprehension performance of eighth-grade students as the external criteria, the use of the scores obtained from the seventh-grade assessment to set cutoff scores was effective for significantly distinguishing between different levels of achievement. A partial eta 2 of .506 was obtained, indicating a large effect size, as suggested by Cohen (1988). In conclusion, this study provides evidence for the external validity of standard-setting.In summary, some valuable suggestions are provided based on the study results. For example, when evaluating changes in student performance, the regression toward the mean may be a crucial factor affecting the result of standard-setting during the implementation of vertical articulation of cutoff scores across grades. Additionally, continuously collecting evidence to support the validity of standard-setting is crucial in responding to educational policies and curriculum guidelines. Therefore, the study results indicate the importance of building ongoing proof of validity in future research.",2023,,JOURNAL OF RESEARCH IN EDUCATION SCIENCES,68,2,1-35,WOS:001097122700001,10.6209/JORIES.202306_68(2).0001,,#4453,Hsieh 2023,"",""
ProtoTree-MIL: Interpretable Multiple Instance Learning for Whole Slide Image Classification,"IEEE; Wu, ZF; Li, XH; Wang, LN; Wang, SD; Cui, YF; Wang, JH","Whole slide image (WSI) classification is one of the important fields of digital pathology, and is generally solved as a weakly supervised learning problem by adopting multiple instance learning (MIL). However, a common but crucial challenge faced by existing MIL models is their inability to provide convincing explanations that can win the trust of pathologists and be applied to clinical diagnosis. In addition, most attention-based MIL models use attention scores to represent the importance of each patch in the WSI rather than inferring patch probabilities directly, which does not accurately detect the critical patches. To address these two challenges, we propose a ProtoTree based MIL model for WSI classification, called ProtoTree-MIL, where ProtoTree is an interpretable model that combines the advantages of prototype-learning and decision tree. ProtoTree-MIL not only explains why some patches are important for the final prediction through prototype-learning, but also provides global and local explanation through decision tree. We also propose a method to infer patch probabilities and measure their importance under the framework of ProtoTree-MIL. By conducting various experiments on three public WSI datasets, Camelyon16, TCGA-NSCLC, and TCGA-RCC, we demonstrate that our proposed ProtoTree-MIL can achieve a competitive performance to the state-of-the-art MIL models but provide more persuasive explanations than them. Explicitly generating patch probabilities also makes ProtoTree-MIL more accurate to detect the key patches than other attention-based MIL models. Specially, by evaluating our model on a real clinical gastritis and gastric cancer dataset, we show the explanations provided by ProtoTree-MIL are significant and faithful.",2024,,"2024 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, IJCNN 2024",,,,WOS:001315691501015,10.1109/IJCNN60899.2024.10650015,,#4454,IEEE 2024,"",""
Sodium and Health Outcomes: Ascertaining Valid Estimates in Research Studies,"Anderson, CAM; Delker, E; Ix, JH","Purpose of Review The dietary reference intake (DRI) for sodium has been highly debated with persuasive and elegant arguments made for both population sodium reduction and for maintenance of the status quo. After the 2015 Dietary Guidelines Advisory Committee (DGAC) report was published, controversy ensued, and by Congressional mandate, the sodium DRIs were updated in 2019. The 2019 DRIs defined adequate intake (AI) levels by age-sex groups that are largely consistent with the DRIs for sodium that were published in 2005. Given the overall similarities between the 2005 and 2019 DRIs, one may wonder how the recently published research on sodium and health outcomes was considered in determining the DRIs, particularly, the recent studies from very large observational cohort studies. We aim to address this concern and outline the major threats to ascertaining valid estimates of the relationship between dietary sodium and health outcomes in observational cohort studies. We use tools from modern epidemiology to demonstrate how unexpected and inconsistent findings in these relationships may emerge. We use directed acyclic graphs to illustrate specific examples in which biases may occur. Recent Findings We identified the following key threats to internal validity: poorly defined target intervention, poorly measured sodium exposure, unmeasured or residual confounding, reverse causality, and selection bias. Researchers should consider these threats to internal validity while developing research questions and throughout the research process. For the DRIs to inform real-world interventions relating to sodium reduction, it is recommended that more specific research questions be asked that can clearly define potential interventions of interest.",2021,,CURRENT ATHEROSCLEROSIS REPORTS,23,7,,WOS:000649369400001,10.1007/s11883-021-00909-4,,#4455,Anderson 2021,"",""
"Hi Model, generating ""nice"" instead of ""good"" is not as bad as generating ""rice""! Towards Context and Semantic Infused Dialogue Generation Loss Function","Tiwari, A; Sinan, M; Roy, K; Sheth, A; Saha, S; Bhattacharyya, P","Over the past two decades, dialogue modeling has made significant strides, moving from simple rule-based responses to personalized and persuasive response generation. However, despite these advancements, the objective functions and evaluation metrics for dialogue generation have remained stagnant. These lexical-based metrics, e.g., cross-entropy and BLEU, have two key limitations: (a) word-to-word matching without semantic consideration: It assigns the same credit for failure to generate ""nice"" and ""rice"" for ""good"", (b) missing context attribute for evaluating the generated response: Even if a generated response is relevant to the ongoing dialogue context, it may still be penalized for not matching the gold utterance provided in the corpus. In this paper, we first investigate these limitations comprehensively and propose a new loss function called Semantic Infused Contextualized diaLogue (SemTextual-Logue) loss function. We also formulate an evaluation metric called Dialuation, incorporating both context and semantic relevance. We experimented with both non-pretrained and pre-trained models on two dialogue corpora, encompassing task-oriented and open-domain scenarios. We found that the dialogue generation models trained with SemTextual-Logue loss attained superior performance compared to the traditional cross-entropy loss function. Tshe findings establish that the effective training of a dialogue generation model hinges significantly on incorporating semantics and context. This pattern is also mirrored in the introduced Dialuation metric, where the consideration of both context and semantics correlates more strongly with human evaluation compared to traditional metrics (The code and dataset are available at https://github.com/NLP-RL/SemTextualLogue-Loss).",2024,,"MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES-RESEARCH TRACK AND DEMO TRACK, PT VIII, ECML PKDD 2024",14948,,342-360,WOS:001330398000020,10.1007/978-3-031-70371-3_20,,#4456,Tiwari 2024,"",""
Beyond Logic: Developing Pathos and Ethos in STEM Undergraduate Communication Using the Rhetorical Triangle,"Rakedzon, T; Hazzan, O","About the case: We suggest using Aristotle's rhetorical triangle, a tool for analyzing communication in terms of logos (logic), pathos (values), and ethos (identity), in science, technology, engineering, and mathematics (STEM) undergraduate classes. We investigate how the triangle can enhance students' communication skills by developing awareness of pathos and ethos, and shed light on values, considerations, and professional identity at different stages of their studies. Situating the case: Developing communication skills among STEM students is imperative even in the age of AI-based tools. Although many books and platforms exist to help facilitate communication in general, STEM students require practical tools to foster the rhetorical skills needed for effective and persuasive communication. Methods: The rhetorical triangle intervention was implemented in two undergraduate courses to help students develop the other necessary elements of effective communication beyond logos: i.e., pathos and ethos. Results: Our results show that the intervention enhanced students' ability to express shared values (pathos) with their audience and fostered the development of professional identity (ethos). Our findings also revealed notable differences in professional identity expression when comparing two different samples of future scientists and engineers in their freshmen and senior years. Conclusion: We suggest that incorporating the elements of the rhetorical triangle into STEM education can enhance students' communication skills, particularly in expressing the value of their work and developing a strong professional identity. We recommend integrating these elements throughout various stages of the curriculum to deepen students' understanding of effective communication and persuasion.",2025,,IEEE TRANSACTIONS ON PROFESSIONAL COMMUNICATION,,,,WOS:001494178200001,10.1109/TPC.2025.3562716,,#4457,Rakedzon 2025,"",""
Explainable Recommendation: A Survey and New Perspectives,"Zhang, YF; Chen, X","Explainable recommendation attempts to develop models that generate not only high-quality recommendations but also intuitive explanations. The explanations may either be post-hoc or directly come from an explainable model (also called interpretable or transparent model in some contexts). Explainable recommendation tries to address the problem of why: by providing explanations to users or system designers, it helps humans to understand why certain items are recommended by the algorithm, where the human can either be users or system designers. Explainable recommendation helps to improve the transparency, persuasiveness, effectiveness, trustworthiness, and satisfaction of recommendation systems. It also facilitates system designers for better system debugging. In recent years, a large number of explainable recommendation approaches - especially model-based methods - have been proposed and applied in real-world systems.In this survey, we provide a comprehensive review for the explainable recommendation research. We first highlight the position of explainable recommendation in recommender system research by categorizing recommendation problems into the 5W, i.e., what, when, who, where, and why. We then conduct a comprehensive survey of explainable recommendation on three perspectives: 1) We provide a chronological research timeline of explainable recommendation, including user study approaches in the early years and more recent model-based approaches. 2) We provide a two-dimensional taxonomy to classify existing explainable recommendation research: one dimension is the information source (or display style) of the explanations, and the other dimension is the algorithmic mechanism to generate explainable recommendations. 3) We summarize how explainable recommendation applies to different recommendation tasks, such as product recommendation, social recommendation, and POI recommendation.We also devote a section to discuss the explanation perspectives in broader IR and AI/ML research. We end the survey by discussing potential future directions to promote the explainable recommendation research area and beyond.",2020,,FOUNDATIONS AND TRENDS IN INFORMATION RETRIEVAL,14,1,1-101,WOS:000519758400001,10.1561/1500000066,,#4458,Zhang 2020,"",""
"""See the Image in Different Contexts"": Using Reverse Image Search to Support the Identification of Fake News in Instagram-Like Social Media","Aprin, F; Chounta, IA; Hoppe, HU","Social media are an integral part of the daily lives of today's young generation. In addition to the positive impact on learning through these channels, there are also risks related to toxic content like ""fake news"" on various social media. Fake news aims to change opinions based on disinformation or misinformation supporting conspiracy theories, e.g., related to the pandemic. Fake news creators use various multimedia artifacts, including images taken from serious and valid news sources, to attract the audience's attention. Tracking images in different contexts can give social media users important clues to distinguish fake news from credible information. We report on the development of a web-based learning environment that includes a ""virtual learning companion"" to help learners improve their understanding, awareness, and critical thinking concerning such social media threats. The learning environment mimics Instagram and includes toxic and nontoxic content in a controlled way. The companion is implemented as a browser plugin that communicates with students via chat. The companion poses knowledge activation questions and answers according to an underlying script. The companion offers other sources with the same image identified through Reverse Image Search (RIS). The goal is to help learners find the same image in different contexts with different textual descriptions and keywords. For this purpose, we added basic NLP mechanisms to extract keywords from these contexts, including keywords that signal persuasiveness. Currently, we evaluate the impact of this tool and the provided support in distinguishing fake or credible news.",2022,,"INTELLIGENT TUTORING SYSTEMS, ITS 2022",13284,,264-275,WOS:000874464200025,10.1007/978-3-031-09680-8_25,,#4459,Aprin 2022,"",""
EREBOTS: Privacy-Compliant Agent-Based Platform for Multi-Scenario Personalized Health-Assistant Chatbots,"Calvaresi, D; Calbimonte, JP; Siboni, E; Eggenschwiler, S; Manzo, G; Hilfiker, R; Schumacher, M","Context. Asynchronous messaging is increasingly used to support human-machine interactions, generally implemented through chatbots. Such virtual entities assist the users in activities of different kinds (e.g., work, leisure, and health-related) and are becoming ingrained into humans' habits due to factors including (i) the availability of mobile devices such as smartphones and tablets, (ii) the increasingly engaging nature of chatbot interactions, (iii) the release of dedicated APIs from messaging platforms, and (iv) increasingly complex AI-based mechanisms to power the bots' behaviors. Nevertheless, most of the modern chatbots rely on state machines (implementing conversational rules) and one-fits-all approaches, neglecting personalization, data-stream privacy management, multi-topic management/interconnection, and multimodal interactions. Objective. This work addresses the challenges above through an agent-based framework for chatbot development named EREBOTS. Methods. The foundations of the framework are based on the implementation of (i) multi-front-end connectors and interfaces (i.e., Telegram, dedicated App, and web interface), (ii) enabling the configuration of multi-scenario behaviors (i.e., preventive physical conditioning, smoking cessation, and support for breast-cancer survivors), (iii) online learning, (iv) personalized conversations and recommendations (i.e., mood boost, anti-craving persuasion, and balance-preserving physical exercises), and (v) responsive multi-device monitoring interface (i.e., doctor and admin). Results. EREBOTS has been tested in the context of physical balance preservation in social confinement times (due to the ongoing pandemic). Thirteen individuals characterized by diverse age, gender, and country distribution have actively participated in the experimentation, reporting advancements in the physical balance and overall satisfaction of the interaction and exercises' variety they have been proposed.",2021,,ELECTRONICS,10,6,,WOS:000634342000001,10.3390/electronics10060666,,#4460,Calvaresi 2021,"",""
Strategies for Combating Adversarial Information Operations: Theory and Practical Applications,"Olivieri, AF; Guadagno, RE","In the contemporary information landscape, the proliferation of disinformation and propaganda poses a significant challenge to societal discourse and democratic processes. This paper proposes a multi-disciplinary approach to combatting adversarial information operations, drawing upon theoretical frameworks and practical applications. Theoretical foundations are established through an examination of the Persuasive System Design (PSD) model (Oinas-Kukkonen, 2013) and its parallels with propaganda tactics. By analyzing the shared flaws and vulnerabilities, insights emerge into the manipulation techniques employed by threat actors in online information spaces. Building upon this theoretical framework, the paper presents a proactive strategy for countering disinformation: the development of Early Warning and Control Systems (EWACS). These systems leverage AI-assisted narrative discovery to monitor the digital information landscape continuously. By identifying emerging threats and inauthentic activity, strategic communicators gain valuable insights for crafting counter-narratives and pre-emptive communication strategies. Key components of the proposed approach include deterrence by denial and resilience-building measures. By shifting the cost-gain calculation of adversaries and enhancing societal resilience, the aim is to create an environment where propagandists face increased challenges in achieving their objectives. This paper emphasizes the importance of collaboration between diverse stakeholders, including governmental organizations, academia, NGOs, and journalists. By harnessing the collective expertise from multiple fields, more effective strategies can be developed to safeguard information integrity and restore public trust. In conclusion, this paper advocates for a convergence of theory and practice in addressing the complex challenges posed by adversarial information operations. By integrating theoretical insights with practical applications, the proposed approach offers a holistic framework for countering disinformation and propaganda in contemporary information environments.",2024,,"PROCEEDINGS OF THE 23RD EUROPEAN CONFERENCE ON CYBER WARFARE AND SECURITY, ECCWS 2024",23,,341-347,WOS:001419654100100,,,#4461,Olivieri 2024,"",""
DIRECT: Dual Interpretable Recommendation with Multi-aspect Word Attribution,"Wu, XS; Wan, HQ; Tan, QY; Yao, WL; Li, NH","Recommending products to users with intuitive explanations helps improve the system in transparency, persuasiveness, and satisfaction. Existing interpretation techniques include post hoc methods and interpretable modeling. The former category could quantitatively analyze input contribution to model prediction but has limited interpretation faithfulness, while the latter could explain model internal mechanisms but may not directly attribute model predictions to input features. In this study, we propose a novel Dual Interpretable Recommendation model called DIRECT, which integrates ideas of the two interpretation categories to inherit their advantages and avoid limitations. Specifically, DIRECT makes use of item descriptions as explainable evidence for recommendation. First, similar to the post hoc interpretation, DIRECT could attribute the prediction of a user preference score to textual words of the item descriptions. The attribution of each word is related to its sentiment polarity and word importance, where a word is important if it corresponds to an item aspect that the user is interested in. Second, to improve the interpretability of embedding space, we propose to extract high-level concepts from embeddings, where each concept corresponds to an item aspect. To learn discriminative concepts, we employ a concept bottleneck layer and maximize the coding rate reduction on word-aspect embeddings by leveraging a word-word affinity graph extracted from a pre-trained language model. In this way, DIRECT simultaneously achieves faithful attribution and usable interpretation of embedding space. We also show that DIRECT achieves linear inference time complexity regarding the length of item reviews. We conduct experiments including ablation studies on five real-world datasets. Quantitative analysis, visualizations, and case studies verify the interpretability of DIRECT. Our code is available at: https://github. com/JacksonWuxs/DIRECT.",2024,,ACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY,15,5,,WOS:001362551500003,10.1145/3663483,,#4462,Wu 2024,"",""
An explainable multi-agent recommendation system for energy-efficient decision support in smart homes,"Zharova, A; Boer, A; Knoblauch, J; Schewina, KI; Vihs, J","Transparent, understandable, and persuasive recommendations support the electricity consumers' behavioral change to tackle the energy efficiency problem. This paper proposes an explainable multi-agent recommendation system for load shifting for household appliances. First, we extend a novel multi-agent approach by designing and implementing an Explainability Agent that provides explainable recommendations for optimal appliance scheduling in a textual and visual manner. Second, we enhance the predictive capacity of other agents by including weather data and applying state-of-the-art models (i.e., k-nearest-neighbors, extreme gradient boosting, adaptive boosting, Random Forest, logistic regression, and explainable boosting machines). Since we want to help the user understand a single recommendation, we focus on local explainability approaches. In particular, we apply post-model approaches local, interpretable, model-agnostic explanation and SHapley Additive exPlanations as model-agnostic tools that can explain the predictions of the chosen classifiers. We further provide an overview of the predictive and explainability performance. Our results show a substantial improvement in the performance of the multi-agent system while at the same time opening up the ""black box"" of recommendations.Impact StatementThis application paper addresses the explainability side of the load-shifting recommendations aiming at energy efficiency in residential households. Seeing the transparent and understandable recommendations daily will increase the awareness of residents of their energy consumption and will encourage more climate-related actions (supporting SDG 13). The shifted load will facilitate energy efficiency in the grid (SDG 7), foster energy innovation toward sustainable development (SDG 9), reduce the environmental impact, and stronger the households' sustainability, making them inclusive, safe, and resilient (SDG 11).",2024,,ENVIRONMENTAL DATA SCIENCE,3,,,WOS:001223647600007,10.1017/eds.2024.8,,#4463,Zharova 2024,"",""
Dual Cognitive UXD and Explainable AI,"Cham, K; Shakiry, R; Yates, C","We are in an age where route to market for technological innovation is unimpeded by even the simplest of safety checks. Computer vision, for example, cannot differentiate the side of a lorry from an open patch of sky when ""driving"" an autonomous vehicle, whilst iris and facial recognition technologies are rolled out as infallible ID systems with huge error rates on black skin and eyes. Meanwhile, whistleblower testimony about how social media inadvertently engineers self-harm in young people and how there is more than a suggestion that our collective big data is being used in social engineering experiments at scale reinforces a growing vocal concern with ethics in professional UX circles.The chasm into which all of this simultaneously falls into and erupts from is human factors-that traditional ""add on"" to technology development that is firmly in the gap between analog and automation; between people and machine; between user and design, affordance, and agency. All of these issues are thus digital transformation issues. The steady migration of personal, social, and cultural values; policy; practice; law; and ideology into computer code with greater and lesser degrees of success.The goal of this essay is to share seminal research findings in eCommerce and games UX as a foundation for a dual cognitive or ""deep user experience design"" (Deep UXD) that integrates biometric insights. I suggest this can provide a fundamental basis from which to address persuasion, emotion, and trust (PET; Schaffer, 2009) in the development cycle of all human-computer interaction (HCI) applications. I conclude on the future field of application in terms of UX informed human-centered Al (HCAI) and human-in- the-loop (HITL) service design for Industry 4.0.",2021,,JOURNAL OF USABILITY STUDIES,17,1,1-11,WOS:000755073200001,,,#4464,Cham 2021,"",""
Vishing: Detecting social engineering in spoken communication - A first survey & urgent roadmap to address an emerging societal challenge,"Triantafyllopoulos, A; Spiesberger, AA; Tsangko, I; Jing, X; Distler, V; Dietz, F; Alt, F; Schuller, BW","Vishing - the use of voice calls for phishing - is a form of Social Engineering (SE) attacks. The latter have become a pervasive challenge in modern societies, with over 300,000 yearly victims in the US alone. An increasing number of those attacks is conducted via voice communication, be it through machine-generated 'robocalls' or human actors. The goals of 'social engineers' can be manifold, from outright fraud to more subtle forms of persuasion. Accordingly, social engineers adopt multi-faceted strategies for voice-based attacks, utilising a variety of 'tricks' to exert influence and achieve their goals. Importantly, while organisations have set in place a series of guardrails against other types of SE attacks, voice calls still remain 'open ground' for potential bad actors. In the present contribution, we provide an overview of the existing speech technology subfields that need to coalesce into a protective net against one of the major challenges to societies worldwide. Given the dearth of speech science and technology works targeting this issue, we have opted for a narrative review that bridges the gap between the existing psychological literature on the topic and research that has been pursued in parallel by the speech community on some of the constituent constructs. Our review reveals that very little literature exists on addressing this very important topic from a speech technology perspective, an omission further exacerbated by the lack of available data. Thus, our main goal is to highlight this gap and sketch out a roadmap to mitigate it, beginning with the psychological underpinnings of vishing, which primarily include deception and persuasion strategies, continuing with the speech-based approaches that can be used to detect those, as well as the generation and detection of AI-based vishing attempts, and close with a discussion of ethical and legal considerations.",2025,,COMPUTER SPEECH AND LANGUAGE,94,,,WOS:001473993200001,10.1016/j.csl.2025.101802,,#4465,Triantafyllopoulos 2025,"",""
"Challenges in Serious Gaming as Emerging Multimedia Technology for Education, Training, Sports and Health","Steinmetz, R; Göbel, S","Digital computer games are very popular and successful, both as leisure activity and contemporary information and communication medium in the digital age, and as relevant economic factor and prospering market, not only in the creative industries. Games tackle a diversity of research aspects, e.g. Computer Graphics, AI, Storytelling, interfaces and sensors, authoring and production, usability and user experience or other ICT and multimedia technologies. Game technology and game techniques are broadly used by other application domains apart from pure entertainment as well. The rather new field of Serious Games, games with an additional purpose other than mere entertainment, offers a variety of new challenges and new fields of research. In our opinion, the term Serious Games comprises games for education (in terms of learning and practice), training, sports, and health. The core idea of Serious Games is to use the motivation inherited in games for other purposes like learning, sports, rehabilitation exercises, or even advertisement or opinion forming. Prominent examples in the field of Serious Games (games 'more than fun') are games for health, persuasive games, advergames or games for education and training, for instance in the form of multiplayer online games as tools to support collaborative learning settings. The combination of gaming technologies and gaming concepts with other research disciplines, technologies, methods and concepts results in a broad range of application do-mains. The resulting research areas are Authoring of Serious Games, Collaborative Learning using multiplayer Serious Games, Serious Games in Social Networks, and sensor technology for Serious Games for Sports Sz Health. In this talk, we will review the various aspects and application areas of Serious Games and point out some of the grand challenges in the field of Serious Gaming. Some of the core research topics of the Serious Games at the Techn""sche Universitt Darmstadt and the httc will be reviewed. Story'rec, an authoring environment for the creation of Serious Games for non-programmers, will be illustrated, as well as 3D multiplayer Serious Games for collaborative learning and team (leader) training. Furthermore, Serious Games for sports 86 health, especially for fall prevention, rehabilitation, and management of obesity will be outlined.",2012,,ADVANCES IN MULTIMEDIA MODELING,7131,,3-3,WOS:000306579900003,,,#4466,Steinmetz 2012,"",""
Citizens Versus the Internet: Confronting Digital Challenges With Cognitive Tools,"Kozyreva, A; Lewandowsky, S; Hertwig, R","The Internet has evolved into a ubiquitous and indispensable digital environment in which people communicate, seek information, and make decisions. Despite offering various benefits, online environments are also replete with smart, highly adaptive choice architectures designed primarily to maximize commercial interests, capture and sustain users' attention, monetize user data, and predict and influence future behavior. This online landscape holds multiple negative consequences for society, such as a decline in human autonomy, rising incivility in online conversation, the facilitation of political extremism, and the spread of disinformation. Benevolent choice architects working with regulators may curb the worst excesses of manipulative choice architectures, yet the strategic advantages, resources, and data remain with commercial players. One way to address some of this imbalance is with interventions that empower Internet users to gain some control over their digital environments, in part by boosting their information literacy and their cognitive resistance to manipulation. Our goal is to present a conceptual map of interventions that are based on insights from psychological science. We begin by systematically outlining how online and offline environments differ despite being increasingly inextricable. We then identify four major types of challenges that users encounter in online environments: persuasive and manipulative choice architectures, AI-assisted information architectures, false and misleading information, and distracting environments. Next, we turn to how psychological science can inform interventions to counteract these challenges of the digital world. After distinguishing among three types of behavioral and cognitive interventions-nudges, technocognition, and boosts-we focus on boosts, of which we identify two main groups: (a) those aimed at enhancing people's agency in their digital environments (e.g., self-nudging, deliberate ignorance) and (b) those aimed at boosting competencies of reasoning and resilience to manipulation (e.g., simple decision aids, inoculation). These cognitive tools are designed to foster the civility of online discourse and protect reason and human autonomy against manipulative choice architectures, attention-grabbing techniques, and the spread of false information.",2020,,PSYCHOLOGICAL SCIENCE IN THE PUBLIC INTEREST,21,3,103-156,WOS:000599541800002,10.1177/1529100620946707,,#4467,Kozyreva 2020,"",""
Decoding persuasion: a survey on ML and NLP methods for the study of online persuasion,"Bassi, D; Fomsgaard, S; Pereira-Farina, M","The proliferation of digital communication has profoundly transformed the landscape of persuasive discourse. Online platforms have amplified the reach and impact of persuasive techniques. However, they have also enabled the rapid spread of manipulative content, targeted propaganda, and divisive rhetoric. Consequently, a wide range of computational approaches has emerged to address the multifaceted nature of digital persuasion, to detect and mitigate its harmful practices. In light of this, the paper surveys computational methods for detecting persuasive means in digital communication, focusing on how they integrate humanistic knowledge to operationalize this construct. Additionally, special emphasis is placed on models' explainability, a pivotal aspect considering these models are used by institutions to influence societal interactions. For the analysis, two primary perspectives in persuasion are defined: linguistic and argumentative. The linguistic approach analyzes specific textual features, allowing for highly accountable algorithms based on explicit rules. The argumentative approach focuses on broader persuasive mechanisms, offering greater scalability but often resulting in less explainable models due to their complexity. This tension between model sophistication and explainability presents a key challenge in developing effective and transparent persuasion detection systems. The results highlight the spectrum of methodologies for studying persuasion, ranging from analyzing stylistic elements to detecting explicitly propagandist messages. Our findings highlight two key challenges in using these algorithms to tackle societal issues of persuasion misuse: the opacity of deep learning models and the absence of a theoretically grounded distinction between vicious and virtuous persuasion. To address these challenges, we propose integrating social sciences and humanities theories to enhance the effectiveness and ethical robustness of persuasion detection systems. This interdisciplinary approach enables a more nuanced characterization of text, facilitating the differentiation between vicious and virtuous persuasion through analysis of rhetorical, argumentative, and emotional aspects. We emphasize the potential of hybrid approaches that combine rule-based methods with deep learning techniques, as these offer a promising avenue for implementing this interdisciplinary framework. The paper concludes by outlining future challenges, including the importance of multimodal and multilingual analysis, ethical considerations in handling user-generated data and the growing challenge of distinguishing between human and AI-generated persuasive content.",2024,,FRONTIERS IN COMMUNICATION,9,,,WOS:001331914600001,10.3389/fcomm.2024.1457433,,#4468,Bassi 2024,"",""
Exploring gender dynamics: multigroup analysis of workplace persuasion and intimate co-creation using structural equation modeling,"Shahzad, MU","PurposeOne of the novel concepts in the management literature is intimate co-creation. Considering it as the outcome of workplace persuasion, this study examines its effect via team-member exchange and ethical climate for the assessment of multigroup analysis. Finding a relationship among variables is not the core objective of the study. The core objective was to assess multigroup analysis for examining measurement scales' uniformity or perceptual differences across the male and female groups using measurement invariance.Design/methodology/approachThis was a quantitative study for a survey of faculty members from the top 10 Pakistani universities. It employed state-of-the-art statistical techniques, including the application of the foundational social exchange theory and the utilization of multigroup analysis in structural equation modeling (SEM) with the Analysis of Moment Structure (AMOS). The research methodology was designed to investigate the relationships between workplace persuasion, ethical climate, team member exchange and intimate co-creation. A specific emphasis was placed on assessing whether gender influences these relationships consistently across male and female groups, as determined by measurement invariance tests.FindingsThis study underscores the significant impact of ethical persuasion in the workplace on enhancing intimate co-creation among individuals, offering invaluable insights for organizational leaders. Importantly, it emphasizes that gender dynamics do not influence this relationship, underscoring the imperative of addressing gender-related workplace issues to optimize intimate co-creation. This holds particular relevance for service-based organizations, such as universities in this case.Originality/valueThis study makes a significant contribution by exploring the concept of intimate co-creation within the realm of organizational science, while also highlighting the crucial importance of considering workplace gender dynamics. It offers fresh insights into how these dynamics influence group creativity, guiding human resource practices toward fostering innovation within gender-inclusive workplaces. These insights gain added relevance in the evolving post-COVID-19 era and in the context of AI integration. Notably, a distinctive contribution of this study to social exchange theory lies in its innovative application of multigroup analysis to variables related to gender.",2024,,JOURNAL OF MANAGEMENT DEVELOPMENT,43,3,374-393,WOS:001193307600001,10.1108/JMD-10-2023-0304,,#4469,Shahzad 2024,"",""
Digital nudge persuasiveness of avatars in restaurants toward healthy choices and happy diners,"Aman, AM; Ng, W; Hao, F; Zhang, C; Chon, KKS","PurposeAmid rising concerns over unhealthy dietary habits and their impact on public health, this study aims to explore the role of avatars in promoting healthier eating and enhancing customer satisfaction in restaurants. By leveraging the theory of planned behavior (TPB) and nudge theory, this research sought to gain insights into consumer behavior and assess how digital innovations can encourage healthier food choices.Design/methodology/approachThis study recruited 672 participants in the USA. Participants viewed a video featuring an avatar that informed them about available healthy food options, simulating a restaurant ordering scenario. Following the video, participants completed comprehensive online surveys. The collected data was analyzed using partial least squares structural equation modeling to assess the effectiveness and implications of the intervention.FindingsThe findings revealed that health consciousness, environmental awareness, social norms and perceived behavioral control significantly influence dietary habits. Restaurant health initiatives and avatar persuasiveness were found to encourage healthier food choices, improve customer satisfaction and loyalty and enhance electronic word-of-mouth. The study confirmed that avatars equipped with attributes such as competence, warmth, trustworthiness and credibility can be an effective digital nudge for consumers toward healthier dietary decisions.Originality/valueThis study's originality lies in its integration of TPB and nudge theory, bridging the gap between individual psychological factors and external cues. This comprehensive framework provides valuable insights for restaurant managers, artificial intelligence developers and policymakers, offering practical strategies to promote healthier eating and enhance customer experiences through digital innovation.(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(TPB)(sic)(sic)(sic)(sic)(sic)(Nudge Theory), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).(sic)(sic)/(sic)(sic)/(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)672(sic)(sic)(sic)(sic).(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(PLS-SEM)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic),(sic)(sic)(sic)(sic),(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic).(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic),(sic)(sic),(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).(sic)(sic)(sic)/(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic),(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).ObjetivoEn medio de la creciente preocupaci & oacute;n por los h & aacute;bitos alimentarios poco saludables y su impacto en la salud p & uacute;blica, este estudio pretende explorar el papel de los avatares en la promoci & oacute;n de una alimentaci & oacute;n m & aacute;s saludable y la mejora de la satisfacci & oacute;n del cliente en los restaurantes. Aprovechando la Teor & iacute;a del Comportamiento Planificado (TPB) y la Teor & iacute;a del Impulso, esta investigaci & oacute;n trata de profundizar en el comportamiento del consumidor y eval & uacute;a c & oacute;mo las innovaciones digitales pueden fomentar la elecci & oacute;n de alimentos m & aacute;s saludables.Dise & ntilde;o/metodolog & iacute;a/enfoqueEl estudio reclut & oacute; a 672 participantes en Estados Unidos. Los participantes visionaron un v & iacute;deo en el que un avatar les informaba sobre las opciones de comida saludable disponible, simulando una situaci & oacute;n en la que solicitaban comida en un restaurante. Despu & eacute;s del v & iacute;deo, los participantes rellenaron unas exhaustivas encuestas en l & iacute;nea. Los datos recogidos se analizaron mediante un modelo de ecuaciones estructurales por m & iacute;nimos cuadrados parciales para evaluar la eficacia y las implicaciones de la intervenci & oacute;n.ResultadosLos resultados revelaron que la conciencia saludable, la conciencia medioambiental, las normas sociales y el control conductual percibido influyen significativamente en los h & aacute;bitos alimentarios. Se comprob & oacute; que las iniciativas relacionadas con la salud en los restaurantes y la capacidad de persuasi & oacute;n de los avatares fomentan la elecci & oacute;n de alimentos m & aacute;s sanos, mejoran la satisfacci & oacute;n y la fidelidad de los clientes y potencian el boca a boca electr & oacute;nico. El estudio confirm & oacute; que los avatares dotados de atributos como competencia, calidez, fiabilidad y credibilidad pueden ser un est & iacute;mulo digital eficaz para que los consumidores tomen decisiones diet & eacute;ticas m & aacute;s saludables.Originalidad/valorLa originalidad de este estudio radica en la integraci & oacute;n de la TPB y la Teor & iacute;a de los Est & iacute;mulos, que tiende un puente entre los factores psicol & oacute;gicos individuales y las se & ntilde;ales externas. Este marco integral aporta valiosas ideas a los gestores de restaurantes, desarrolladores de IA y responsables pol & iacute;ticos, ofreciendo estrategias pr & aacute;cticas para promover una alimentaci & oacute;n m & aacute;s sana y mejorar las experiencias de los clientes a trav & eacute;s de la innovaci & oacute;n digital.",2025,,TOURISM REVIEW,,,,WOS:001406722200001,10.1108/TR-07-2024-0567,,#4470,Aman 2025,"",""
